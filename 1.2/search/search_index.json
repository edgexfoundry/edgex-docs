{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction EdgeX Foundry is an open source, vendor neutral, flexible, interoperable, software platform at the edge of the network, that interacts with the physical world of devices , sensors, actuators, and other IoT objects. In simple terms, EdgeX is edge middleware - serving between physical sensing and actuating \"things\" and our information technology (IT) systems. The EdgeX platform enables and encourages the rapidly growing community of IoT solution providers to work together in an ecosystem of interoperable components to reduce uncertainty, accelerate time to market, and facilitate scale. By bringing this much-needed interoperability, EdgeX makes it easier to monitor physical world items, send instructions to them, collect data from them, move the data across the fog up to the cloud where it may be stored, aggregated, analyzed, and turned into information, actuated, and acted upon. So EdgeX enables data to travel northwards towards the cloud or enterprise and back to devices, sensors, and actuators. The initiative is aligned around a common goal: the simplification and standardization of the foundation for tiered edge computing architectures in the IoT market while still enabling the ecosystem to provide significant value-added differentiation. If you don't need further description and want to immediately use EdgeX Foundry use this link: Getting Started Guide EdgeX Foundry Use Cases Originally built to support industrial IoT needs, EdgeX today is used in a variety of use cases to include: Building automation \u2013 helping to manage shared workspace facilities Oil/gas \u2013 closed loop control of a gas supply valve Retail \u2013 multi-sensor reconciliation for loss prevention at the point of sale Water treatment \u2013 monitor and control chemical dosing Consumer IoT \u2013 the open source HomeEdge project is using elements of EdgeX as part of its smart home platform EdgeX Foundry Architectural Tenets EdgeX Foundry was conceived with the following tenets guiding the overall architecture: EdgeX Foundry must be platform agnostic with regard to Hardware (x86, ARM) Operating system (Linux, Windows, MacOS, ...) Distribution (allowing for the distribution of functionality through microservices at the edge, on a gateway, in the fog, on cloud, etc.) Deployment/orchestration (Docker, Snaps, K8s, roll-your-own, ... ) Protocols ( north or south side protocols) EdgeX Foundry must be extremely flexible Any part of the platform may be upgraded, replaced or augmented by other micro services or software components Allow services to scale up and down based on device capability and use case EdgeX Foundry should provide \" reference implementation \" services but encourages best of breed solutions EdgeX Foundry must provide for store and forward capability To support disconnected/remote edge systems To deal with intermittent connectivity EdgeX Foundry must support and facilitate \"intelligence\" moving closer to the edge in order to address Actuation latency concerns Bandwidth and storage concerns Operating remotely concerns EdgeX Foundry must support brown and green device/sensor field deployments EdgeX Foundry must be secure and easily managed Deployments EdgeX was originally built by Dell to run on its IoT gateways . While EdgeX can and does run on gateways, its platform agnostic nature and micro service architecture enables tiered distributed deployments. In other words, a single instance of EdgeX\u2019s micro services can be distributed across several host platforms. The host platform for one or many EdgeX micro services is called a node. This allows EdgeX to leverage compute, storage, and network resources wherever they live on the edge. Its loosely-coupled architecture enables distribution across nodes to enable tiered edge computing. For example, thing communicating services could run on a programmable logic controller (PLC), a gateway, or be embedded in smarter sensors while other EdgeX services are deployed on networked servers or even in the cloud. The scope of a deployment could therefore include embedded sensors, controllers, edge gateways, servers and cloud systems. EdgeX micro services can be deployed across an array of compute nodes to maximize resources while at the same time position more processing intelligence closer to the physical edge. The number and the function of particular micro services deployed on a given node depends on the use case and capability of the hardware and infrastructure. Apache 2 License EdgeX is distributed under Apache 2 License backed by the Apache Foundation. Apache 2 licensing is very friendly (\u201cpermissive\u201d) to open and commercial interests. It allows users to use the software for any purpose. It allows users to distribute, modify or even fork the code base without seeking permission from the founding project. It allows users to change or extend the code base without having to contribute back to the founding project. It even allows users to build commercial products without concerns for profit sharing or royalties to go back to the Linux Foundation or open source project organization. EdgeX Foundry Service Layers EdgeX Foundry is a collection of open source micro services. These micro services are organized into 4 service layers, and 2 underlying augmenting system services. The Service Layers traverse from the edge of the physical realm (from the Device Services Layer), to the edge of the information realm (that of the Application Services Layer), with the Core and Supporting Services Layers at the center. The 4 Service Layers of EdgeX Foundry are as follows: Core Services Layer Supporting Services Layer Application Services Layer Device Services Layer The 2 underlying System Services of EdgeX Foundry are as follows: Security System Management Core Services Layer Core services provide the intermediary between the north and south sides of EdgeX. As the name of these services implies, they are \u201ccore\u201d to EdgeX functionality. Core services is where most of the innate knowledge of what \u201cthings\u201d are connected, what data is flowing through, and how EdgeX is configured resides in an EdgeX instance. Core consists of the following micro services: Core data: a persistence repository and associated management service for data collected from south side objects. Command: a service that facilitates and controls actuation requests from the north side to the south side. Metadata: a repository and associated management service of metadata about the objects that are connected to EdgeX Foundry. Metadata provides the capability to provision new devices and pair them with their owning device services. Registry and Configuration: provides other EdgeX Foundry micro services with information about associated services within EdgeX Foundry and micro services configuration properties (i.e. - a repository of initialization values). Core services provide intermediary communications between the things and the IT systems. Supporting Services Layer The supporting services encompass a wide range of micro services to include edge analytics (also known as local analytics). Normal software application duties such as logging, scheduling, and data clean up (also known as scrubbing in EdgeX) are performed by micro services in the supporting services layer. These services often require some amount of core services in order to function. In all cases, supporting service can be considered optional \u2013 that is they can be left out of an EdgeX deployment depending on use case needs and system resources. Supporting services include: Rules Engine: the reference implementation edge analytics service that performs if-then conditional actuation at the edge based on sensor data collected by the EdgeX instance. This service will likely be replaced or augmented by use case specific analytics capability. Scheduling: an internal EdgeX \u201cclock\u201d that can kick off operations in any EdgeX service. At a configuration specified time, the service will call on any EdgeX service API URL via REST to trigger an operation. For example, the scheduling service periodically calls on core data APIs to clean up old sensed events that have been successfully exported out of EdgeX. Logging: provides a central logging facility for all of EdgeX services. Services send log entries into the logging facility via a REST API where log entries can be persisted in a database or log file. Note : this service is being deprecated and will be removed after the Geneva release. Services will still be able to log using standard output or log to a file. Most operating systems and logging facilities provide better logging aggregation then what EdgeX was providing through the logging service. Alerts and Notifications: provides EdgeX services with a central facility to send out an alert or notification. These are notices sent to another system or to a person monitoring the EdgeX instance (internal service communications are often handled more directly). Application Services Layer Application services are the means to extract, process/transform and send sensed data from EdgeX to an endpoint or process of your choice. EdgeX today offers application service examples to send data to many of the major cloud providers (Amazon IoT Hub, Google IoT Core, Azure IoT Hub, IBM Watson IoT\u2026), to MQTT(s) topics, and HTTP(s) REST endpoints. Application services are based on the idea of a \"functions pipeline\". A functions pipeline is a collection of functions that process messages (in this case EdgeX event messages) in the order specified. The first function in a pipeline is a trigger. A trigger begins the functions pipeline execution. A trigger, for example, is something like a message landing in a message queue. Each function then acts on the message. Common functions include filtering, transformation (i.e. to XML or JSON), compression, and encryption functions. The function pipeline ends when the message has gone through all the functions and is set to a sink. Putting the resulting message into an MQTT topic to be sent to Azure or AWS is an example of a sink completing an application service. Device Services Layer Device services connect \u201cthings\u201d \u2013 that is sensors and devices \u2013 into the rest of EdgeX. Device services are the edge connectors interacting with the \"things\" that include, but are not limited to: alarm systems, heating and air conditioning systems in homes and office buildings, lights, machines in any industry, irrigation systems, drones, currently automated transit such as some rail systems, currently automated factories, and appliances in your home. In the future, this may include driverless cars and trucks, traffic signals, fully automated fast food facilities, fully automated self-serve grocery stores, devices taking medical readings from patients, etc. Device services may service one or a number of things or devices (sensor, actuator, etc.) at one time. A device that a device service manages, could be something other than a simple, single, physical device. The device could be another gateway (and all of that gateway's devices), a device manager, a device aggregator that acts as a device, or collection of devices, to EdgeX Foundry. The device service communicates with the devices, sensors, actuators, and other IoT objects through protocols native to each device object. The device service converts the data produced and communicated by the IoT object into a common EdgeX Foundry data structure, and sends that converted data into the core services layer, and to other micro services in other layers of EdgeX Foundry. EdgeX comes with a number of device services speaking many common IoT protocols such as Modbus, BACnet, BLE, etc. System Services Layer Security Infrastructure Security elements of EdgeX Foundry protect the data and control of devices, sensors, and other IoT objects managed by EdgeX Foundry. Based on the fact that EdgeX is a \"vendor-neutral open source software platform at the edge of the network\", the EdgeX security features are also built on a foundation of open interfaces and pluggable, replaceable modules. There are two major EdgeX security components. A security store, which is used to provide a safe place to keep the EdgeX secrets. Examples of EdgeX secrets are the database access passwords used by the other services and tokens to connect to cloud systems. An API gateway serves as the reverse proxy to restrict access to EdgeX REST resources and perform access control related works. System Management System Management facilities provide the central point of contact for external management systems to start/stop/restart EdgeX services, get the status/health of a service, or get metrics on the EdgeX services (such as memory usage) so that the EdgeX services can be monitored. Software Development Kits (SDKs) Two types of SDKs are provided by EdgeX to assist in creating north and south side services \u2013 specifically to create application services and device services. SDKs for both the north and south side services make connecting new things or new cloud/enterprise systems easier by providing developers all the scaffolding code that takes care of the basic operations of the service. Thereby allowing developers to focus on specifics of their connectivity to the south or north side object without worrying about all the raw plumbing of a micro service. SDKs are language specific; meaning an SDK is written to create services in a particular programming language. Today, EdgeX offers the following SDKs: Golang Device Service SDK C Device Service SDK Golang Device Service SDK How EdgeX Works Sensor Data Collection EdgeX\u2019s primary job is to collect data from sensors and devices and make that data available to north side applications and systems. Data is collected from a sensor by a device service that speaks the protocol of that device. Example: a Modbus device service would communicate in Modbus to get a pressure reading from a Modbus pump. The device service translates the sensor data into an EdgeX event object and sends the event object to the core data service via REST communications (step 1). Core data persists the sensor data in the local edge database. Redis is used as the database by default (other databases can be used alternatively). In fact, persistence is not required and can be turned off. Data is persisted in EdgeX at the edge for two basics reasons: Edge nodes are not always connected. During periods of disconnected operations, the sensor data must be saved so that it can be transmitted northbound when connectivity is restored. This is referred to as store and forward capability. In some cases, analytics of sensor data needs to look back in history in order to understand the trend and to make the right decision based on that history. If a sensor reports that it is 72\u00b0 F right now, you might want to know what the temperature was ten minutes ago before you make a decision to adjust a heating or cooling system. If the temperature was 85\u00b0 F, you may decide that adjustments to lower the room temperature you made ten minutes ago were sufficient to cool the room. It is the context of historical data that are important to local analytic decisions. Core data puts sensor data events on a message topic destined for application services. Zero MQ is used as the messaging infrastructure by default (step 2). The application service transforms the data as needed and pushes the data to an endpoint. It can also filter, enrich, compress, encrypt or perform other functions on the event before sending it to the endpoint (step 3). The endpoint could be an HTTP/S endpoint, an MQTT topic, a cloud system (cloud topic), etc. Edge Analytics and Actuation In edge computing, simply collecting sensor data is only part of the job of an edge platform like EdgeX. Another important job of an edge platform is to be able to: Analyze the incoming sensor data locally Act quickly on that analysis Edge or local analytics is the processing that performs an assessment of the sensor data collected at the edge (\u201clocally\u201d) and triggers actuations or actions based on what it sees. Why edge analytics ? Local analytics are important for two reasons: Some decisions cannot afford to wait for sensor collected data to be fed back to an enterprise or cloud system and have a response returned. Additionally, some edge systems are not always connected to the enterprise or cloud \u2013 they have intermittent periods of connectivity. Local analytics allows systems to operate independently, at least for some stretches of time. For example: a shipping container\u2019s cooling system must be able to make decisions locally without the benefit of Internet connectivity for long periods of time when the ship is at sea. Local analytics also allow a system to act quickly in a low latent fashion when critical to system operations. As an extreme case, imagine that your car\u2019s airbag fired on the basis of data being sent to the cloud and analyzed for collisions. Your car has local analytics to prevent such a potentially slow and error prone delivery of the safety actuation in your automobile. EdgeX is built to act locally on data it collects from the edge. In other words, events are processed by local analytics and can be used to trigger action back down on a sensor/device. Just as application services prepare data for consumption by north side cloud systems or applications, application services can process and get EdgeX events (and the sensor data they contain) to any analytics package (see step 4). By default, EdgeX ships with a simple rules engine (the default EdgeX rules engine is Kuiper \u2013 an open source rules engine by EMQ X). Your own analytics package (or ML agent) could replace or augment the local rules engine. The analytic package can explore the sensor event data and make a decision to trigger actuation of a device. For example, it could check that the pressure reading of an engine is greater than 60 PSI. When such a rule is determined to be true, the analytic package calls on the core command service to trigger some action, like \u201copen a valve\u201d on some controllable device (see step 5). The core command service gets the actuation request and determines which device it needs to act on with the request; then calling on the owning device service to do the actuation (see step 6). Core command allows developers to put additional security measures or checks in place before actuating. The device service receives the request for actuation, translates that into a protocol specific request and forwards the request to the desired device (see step 7). Project Release Cadence Typically, EdgeX releases twice a year; once in the spring and once in the fall. Bug fix releases may occur more often. Each EdgeX release has a code name. The code name follows an alphabetic pattern similar to Android (code names sequentially follow the alphabet). The code name of each release is named after some geographical location in the world. The honor of naming an EdgeX release is given to a developer deemed to have contributed significantly to the project in the past six months. A release also has a version number. The release version follows sematic versioning to indicate the release is major or minor in scope. Major releases typically contain significant new features and functionality and are not always backward compatible with prior releases. Minor releases are backward compatible and usually contain bug fixes and fewer new features. See the project Wiki for more information on releases, versions and patches . Release Schedule Version Barcelona Oct 2017 0.5.0 California Jun 2017 0.6.0 Delhi Oct 2018 0.7.0 Edinburgh Jul 2019 1.0.0 Fuji Nov 2019 1.1.0 Geneva May 2020 1.2.0 Hanoi Fall 2020 TBD Ireland Spring 2021 TBD Jakarta Fall 2021 TBD Note : minor releases of the Device Services and Application Services (along with their associated SDKs) can be release independently. EdgeX community members convene in a face-to-face meeting right at the time of a release to plan the next release and roadmap future releases. See the Project Wiki for more detailed information on releases and roadmap . EdgeX History and Naming EdgeX Foundry began as a project chartered by Dell IoT Marketing and developed by the Dell Client Office of the CTO as an incubation project called Project Fuse in July 2015. It was initially created to run as the IoT software application on Dell\u2019s introductory line of IoT gateways. Dell entered the project into open source through the Linux Foundation on April 24, 2017. EdgeX was formally announced and demonstrated at Hanover Messe 2017. Hanover Messe is one of the world's largest industrial trade fairs. At the fair, the Linux Foundation also announced the association of 50 founding member organizations \u2013 the EdgeX ecosystem \u2013 to help further the project and the goals of creating a universal edge platform. The name \u2018foundry\u2019 was used to draw parallels to Cloud Foundry . EdgeX Foundry is meant to be a foundry for solutions at the edge just like Cloud Foundry is a foundry for solutions in the cloud. Cloud Foundry was originated by VMWare (Dell Technologies is a major shareholder of VMWare - recall that Dell Technologies was the original creator of EdgeX). The \u2018X\u2019 in EdgeX represents the transformational aspects of the platform and allows the project name to be trademarked and to be used in efforts such as certification and certification marks. The EdgeX Foundry Logo represents the nature of its role as transformation engine between the physical OT world and the digital IT world. The EdgeX community selected the octopus as the mascot or \u201cspirit animal\u201d of the project at its inception. Its eight arms and the suckers on the arms represent the sensors. The sensors bring the data into the octopus. Actually, the octopus has nine brains in a way. It has millions of neurons running down each arm; functioning as mini-brains in each of those arms. The arms of the octopus serve as \u201clocal analytics\u201d like that offered by EdgeX. The mascot is affectionately called \u201cEdgey\u201d by the community.","title":"Introduction"},{"location":"#introduction","text":"EdgeX Foundry is an open source, vendor neutral, flexible, interoperable, software platform at the edge of the network, that interacts with the physical world of devices , sensors, actuators, and other IoT objects. In simple terms, EdgeX is edge middleware - serving between physical sensing and actuating \"things\" and our information technology (IT) systems. The EdgeX platform enables and encourages the rapidly growing community of IoT solution providers to work together in an ecosystem of interoperable components to reduce uncertainty, accelerate time to market, and facilitate scale. By bringing this much-needed interoperability, EdgeX makes it easier to monitor physical world items, send instructions to them, collect data from them, move the data across the fog up to the cloud where it may be stored, aggregated, analyzed, and turned into information, actuated, and acted upon. So EdgeX enables data to travel northwards towards the cloud or enterprise and back to devices, sensors, and actuators. The initiative is aligned around a common goal: the simplification and standardization of the foundation for tiered edge computing architectures in the IoT market while still enabling the ecosystem to provide significant value-added differentiation. If you don't need further description and want to immediately use EdgeX Foundry use this link: Getting Started Guide","title":"Introduction"},{"location":"#edgex-foundry-use-cases","text":"Originally built to support industrial IoT needs, EdgeX today is used in a variety of use cases to include: Building automation \u2013 helping to manage shared workspace facilities Oil/gas \u2013 closed loop control of a gas supply valve Retail \u2013 multi-sensor reconciliation for loss prevention at the point of sale Water treatment \u2013 monitor and control chemical dosing Consumer IoT \u2013 the open source HomeEdge project is using elements of EdgeX as part of its smart home platform","title":"EdgeX Foundry Use Cases"},{"location":"#edgex-foundry-architectural-tenets","text":"EdgeX Foundry was conceived with the following tenets guiding the overall architecture: EdgeX Foundry must be platform agnostic with regard to Hardware (x86, ARM) Operating system (Linux, Windows, MacOS, ...) Distribution (allowing for the distribution of functionality through microservices at the edge, on a gateway, in the fog, on cloud, etc.) Deployment/orchestration (Docker, Snaps, K8s, roll-your-own, ... ) Protocols ( north or south side protocols) EdgeX Foundry must be extremely flexible Any part of the platform may be upgraded, replaced or augmented by other micro services or software components Allow services to scale up and down based on device capability and use case EdgeX Foundry should provide \" reference implementation \" services but encourages best of breed solutions EdgeX Foundry must provide for store and forward capability To support disconnected/remote edge systems To deal with intermittent connectivity EdgeX Foundry must support and facilitate \"intelligence\" moving closer to the edge in order to address Actuation latency concerns Bandwidth and storage concerns Operating remotely concerns EdgeX Foundry must support brown and green device/sensor field deployments EdgeX Foundry must be secure and easily managed","title":"EdgeX Foundry Architectural Tenets"},{"location":"#deployments","text":"EdgeX was originally built by Dell to run on its IoT gateways . While EdgeX can and does run on gateways, its platform agnostic nature and micro service architecture enables tiered distributed deployments. In other words, a single instance of EdgeX\u2019s micro services can be distributed across several host platforms. The host platform for one or many EdgeX micro services is called a node. This allows EdgeX to leverage compute, storage, and network resources wherever they live on the edge. Its loosely-coupled architecture enables distribution across nodes to enable tiered edge computing. For example, thing communicating services could run on a programmable logic controller (PLC), a gateway, or be embedded in smarter sensors while other EdgeX services are deployed on networked servers or even in the cloud. The scope of a deployment could therefore include embedded sensors, controllers, edge gateways, servers and cloud systems. EdgeX micro services can be deployed across an array of compute nodes to maximize resources while at the same time position more processing intelligence closer to the physical edge. The number and the function of particular micro services deployed on a given node depends on the use case and capability of the hardware and infrastructure.","title":"Deployments"},{"location":"#apache-2-license","text":"EdgeX is distributed under Apache 2 License backed by the Apache Foundation. Apache 2 licensing is very friendly (\u201cpermissive\u201d) to open and commercial interests. It allows users to use the software for any purpose. It allows users to distribute, modify or even fork the code base without seeking permission from the founding project. It allows users to change or extend the code base without having to contribute back to the founding project. It even allows users to build commercial products without concerns for profit sharing or royalties to go back to the Linux Foundation or open source project organization.","title":"Apache 2 License"},{"location":"#edgex-foundry-service-layers","text":"EdgeX Foundry is a collection of open source micro services. These micro services are organized into 4 service layers, and 2 underlying augmenting system services. The Service Layers traverse from the edge of the physical realm (from the Device Services Layer), to the edge of the information realm (that of the Application Services Layer), with the Core and Supporting Services Layers at the center. The 4 Service Layers of EdgeX Foundry are as follows: Core Services Layer Supporting Services Layer Application Services Layer Device Services Layer The 2 underlying System Services of EdgeX Foundry are as follows: Security System Management","title":"EdgeX Foundry Service Layers"},{"location":"#core-services-layer","text":"Core services provide the intermediary between the north and south sides of EdgeX. As the name of these services implies, they are \u201ccore\u201d to EdgeX functionality. Core services is where most of the innate knowledge of what \u201cthings\u201d are connected, what data is flowing through, and how EdgeX is configured resides in an EdgeX instance. Core consists of the following micro services: Core data: a persistence repository and associated management service for data collected from south side objects. Command: a service that facilitates and controls actuation requests from the north side to the south side. Metadata: a repository and associated management service of metadata about the objects that are connected to EdgeX Foundry. Metadata provides the capability to provision new devices and pair them with their owning device services. Registry and Configuration: provides other EdgeX Foundry micro services with information about associated services within EdgeX Foundry and micro services configuration properties (i.e. - a repository of initialization values). Core services provide intermediary communications between the things and the IT systems.","title":"Core Services Layer"},{"location":"#supporting-services-layer","text":"The supporting services encompass a wide range of micro services to include edge analytics (also known as local analytics). Normal software application duties such as logging, scheduling, and data clean up (also known as scrubbing in EdgeX) are performed by micro services in the supporting services layer. These services often require some amount of core services in order to function. In all cases, supporting service can be considered optional \u2013 that is they can be left out of an EdgeX deployment depending on use case needs and system resources. Supporting services include: Rules Engine: the reference implementation edge analytics service that performs if-then conditional actuation at the edge based on sensor data collected by the EdgeX instance. This service will likely be replaced or augmented by use case specific analytics capability. Scheduling: an internal EdgeX \u201cclock\u201d that can kick off operations in any EdgeX service. At a configuration specified time, the service will call on any EdgeX service API URL via REST to trigger an operation. For example, the scheduling service periodically calls on core data APIs to clean up old sensed events that have been successfully exported out of EdgeX. Logging: provides a central logging facility for all of EdgeX services. Services send log entries into the logging facility via a REST API where log entries can be persisted in a database or log file. Note : this service is being deprecated and will be removed after the Geneva release. Services will still be able to log using standard output or log to a file. Most operating systems and logging facilities provide better logging aggregation then what EdgeX was providing through the logging service. Alerts and Notifications: provides EdgeX services with a central facility to send out an alert or notification. These are notices sent to another system or to a person monitoring the EdgeX instance (internal service communications are often handled more directly).","title":"Supporting Services Layer"},{"location":"#application-services-layer","text":"Application services are the means to extract, process/transform and send sensed data from EdgeX to an endpoint or process of your choice. EdgeX today offers application service examples to send data to many of the major cloud providers (Amazon IoT Hub, Google IoT Core, Azure IoT Hub, IBM Watson IoT\u2026), to MQTT(s) topics, and HTTP(s) REST endpoints. Application services are based on the idea of a \"functions pipeline\". A functions pipeline is a collection of functions that process messages (in this case EdgeX event messages) in the order specified. The first function in a pipeline is a trigger. A trigger begins the functions pipeline execution. A trigger, for example, is something like a message landing in a message queue. Each function then acts on the message. Common functions include filtering, transformation (i.e. to XML or JSON), compression, and encryption functions. The function pipeline ends when the message has gone through all the functions and is set to a sink. Putting the resulting message into an MQTT topic to be sent to Azure or AWS is an example of a sink completing an application service.","title":"Application Services Layer"},{"location":"#device-services-layer","text":"Device services connect \u201cthings\u201d \u2013 that is sensors and devices \u2013 into the rest of EdgeX. Device services are the edge connectors interacting with the \"things\" that include, but are not limited to: alarm systems, heating and air conditioning systems in homes and office buildings, lights, machines in any industry, irrigation systems, drones, currently automated transit such as some rail systems, currently automated factories, and appliances in your home. In the future, this may include driverless cars and trucks, traffic signals, fully automated fast food facilities, fully automated self-serve grocery stores, devices taking medical readings from patients, etc. Device services may service one or a number of things or devices (sensor, actuator, etc.) at one time. A device that a device service manages, could be something other than a simple, single, physical device. The device could be another gateway (and all of that gateway's devices), a device manager, a device aggregator that acts as a device, or collection of devices, to EdgeX Foundry. The device service communicates with the devices, sensors, actuators, and other IoT objects through protocols native to each device object. The device service converts the data produced and communicated by the IoT object into a common EdgeX Foundry data structure, and sends that converted data into the core services layer, and to other micro services in other layers of EdgeX Foundry. EdgeX comes with a number of device services speaking many common IoT protocols such as Modbus, BACnet, BLE, etc.","title":"Device Services Layer"},{"location":"#system-services-layer","text":"Security Infrastructure Security elements of EdgeX Foundry protect the data and control of devices, sensors, and other IoT objects managed by EdgeX Foundry. Based on the fact that EdgeX is a \"vendor-neutral open source software platform at the edge of the network\", the EdgeX security features are also built on a foundation of open interfaces and pluggable, replaceable modules. There are two major EdgeX security components. A security store, which is used to provide a safe place to keep the EdgeX secrets. Examples of EdgeX secrets are the database access passwords used by the other services and tokens to connect to cloud systems. An API gateway serves as the reverse proxy to restrict access to EdgeX REST resources and perform access control related works. System Management System Management facilities provide the central point of contact for external management systems to start/stop/restart EdgeX services, get the status/health of a service, or get metrics on the EdgeX services (such as memory usage) so that the EdgeX services can be monitored.","title":"System Services Layer"},{"location":"#software-development-kits-sdks","text":"Two types of SDKs are provided by EdgeX to assist in creating north and south side services \u2013 specifically to create application services and device services. SDKs for both the north and south side services make connecting new things or new cloud/enterprise systems easier by providing developers all the scaffolding code that takes care of the basic operations of the service. Thereby allowing developers to focus on specifics of their connectivity to the south or north side object without worrying about all the raw plumbing of a micro service. SDKs are language specific; meaning an SDK is written to create services in a particular programming language. Today, EdgeX offers the following SDKs: Golang Device Service SDK C Device Service SDK Golang Device Service SDK","title":"Software Development Kits (SDKs)"},{"location":"#how-edgex-works","text":"","title":"How EdgeX Works"},{"location":"#sensor-data-collection","text":"EdgeX\u2019s primary job is to collect data from sensors and devices and make that data available to north side applications and systems. Data is collected from a sensor by a device service that speaks the protocol of that device. Example: a Modbus device service would communicate in Modbus to get a pressure reading from a Modbus pump. The device service translates the sensor data into an EdgeX event object and sends the event object to the core data service via REST communications (step 1). Core data persists the sensor data in the local edge database. Redis is used as the database by default (other databases can be used alternatively). In fact, persistence is not required and can be turned off. Data is persisted in EdgeX at the edge for two basics reasons: Edge nodes are not always connected. During periods of disconnected operations, the sensor data must be saved so that it can be transmitted northbound when connectivity is restored. This is referred to as store and forward capability. In some cases, analytics of sensor data needs to look back in history in order to understand the trend and to make the right decision based on that history. If a sensor reports that it is 72\u00b0 F right now, you might want to know what the temperature was ten minutes ago before you make a decision to adjust a heating or cooling system. If the temperature was 85\u00b0 F, you may decide that adjustments to lower the room temperature you made ten minutes ago were sufficient to cool the room. It is the context of historical data that are important to local analytic decisions. Core data puts sensor data events on a message topic destined for application services. Zero MQ is used as the messaging infrastructure by default (step 2). The application service transforms the data as needed and pushes the data to an endpoint. It can also filter, enrich, compress, encrypt or perform other functions on the event before sending it to the endpoint (step 3). The endpoint could be an HTTP/S endpoint, an MQTT topic, a cloud system (cloud topic), etc.","title":"Sensor Data Collection"},{"location":"#edge-analytics-and-actuation","text":"In edge computing, simply collecting sensor data is only part of the job of an edge platform like EdgeX. Another important job of an edge platform is to be able to: Analyze the incoming sensor data locally Act quickly on that analysis Edge or local analytics is the processing that performs an assessment of the sensor data collected at the edge (\u201clocally\u201d) and triggers actuations or actions based on what it sees. Why edge analytics ? Local analytics are important for two reasons: Some decisions cannot afford to wait for sensor collected data to be fed back to an enterprise or cloud system and have a response returned. Additionally, some edge systems are not always connected to the enterprise or cloud \u2013 they have intermittent periods of connectivity. Local analytics allows systems to operate independently, at least for some stretches of time. For example: a shipping container\u2019s cooling system must be able to make decisions locally without the benefit of Internet connectivity for long periods of time when the ship is at sea. Local analytics also allow a system to act quickly in a low latent fashion when critical to system operations. As an extreme case, imagine that your car\u2019s airbag fired on the basis of data being sent to the cloud and analyzed for collisions. Your car has local analytics to prevent such a potentially slow and error prone delivery of the safety actuation in your automobile. EdgeX is built to act locally on data it collects from the edge. In other words, events are processed by local analytics and can be used to trigger action back down on a sensor/device. Just as application services prepare data for consumption by north side cloud systems or applications, application services can process and get EdgeX events (and the sensor data they contain) to any analytics package (see step 4). By default, EdgeX ships with a simple rules engine (the default EdgeX rules engine is Kuiper \u2013 an open source rules engine by EMQ X). Your own analytics package (or ML agent) could replace or augment the local rules engine. The analytic package can explore the sensor event data and make a decision to trigger actuation of a device. For example, it could check that the pressure reading of an engine is greater than 60 PSI. When such a rule is determined to be true, the analytic package calls on the core command service to trigger some action, like \u201copen a valve\u201d on some controllable device (see step 5). The core command service gets the actuation request and determines which device it needs to act on with the request; then calling on the owning device service to do the actuation (see step 6). Core command allows developers to put additional security measures or checks in place before actuating. The device service receives the request for actuation, translates that into a protocol specific request and forwards the request to the desired device (see step 7).","title":"Edge Analytics and Actuation"},{"location":"#project-release-cadence","text":"Typically, EdgeX releases twice a year; once in the spring and once in the fall. Bug fix releases may occur more often. Each EdgeX release has a code name. The code name follows an alphabetic pattern similar to Android (code names sequentially follow the alphabet). The code name of each release is named after some geographical location in the world. The honor of naming an EdgeX release is given to a developer deemed to have contributed significantly to the project in the past six months. A release also has a version number. The release version follows sematic versioning to indicate the release is major or minor in scope. Major releases typically contain significant new features and functionality and are not always backward compatible with prior releases. Minor releases are backward compatible and usually contain bug fixes and fewer new features. See the project Wiki for more information on releases, versions and patches . Release Schedule Version Barcelona Oct 2017 0.5.0 California Jun 2017 0.6.0 Delhi Oct 2018 0.7.0 Edinburgh Jul 2019 1.0.0 Fuji Nov 2019 1.1.0 Geneva May 2020 1.2.0 Hanoi Fall 2020 TBD Ireland Spring 2021 TBD Jakarta Fall 2021 TBD Note : minor releases of the Device Services and Application Services (along with their associated SDKs) can be release independently. EdgeX community members convene in a face-to-face meeting right at the time of a release to plan the next release and roadmap future releases. See the Project Wiki for more detailed information on releases and roadmap .","title":"Project Release Cadence"},{"location":"#edgex-history-and-naming","text":"EdgeX Foundry began as a project chartered by Dell IoT Marketing and developed by the Dell Client Office of the CTO as an incubation project called Project Fuse in July 2015. It was initially created to run as the IoT software application on Dell\u2019s introductory line of IoT gateways. Dell entered the project into open source through the Linux Foundation on April 24, 2017. EdgeX was formally announced and demonstrated at Hanover Messe 2017. Hanover Messe is one of the world's largest industrial trade fairs. At the fair, the Linux Foundation also announced the association of 50 founding member organizations \u2013 the EdgeX ecosystem \u2013 to help further the project and the goals of creating a universal edge platform. The name \u2018foundry\u2019 was used to draw parallels to Cloud Foundry . EdgeX Foundry is meant to be a foundry for solutions at the edge just like Cloud Foundry is a foundry for solutions in the cloud. Cloud Foundry was originated by VMWare (Dell Technologies is a major shareholder of VMWare - recall that Dell Technologies was the original creator of EdgeX). The \u2018X\u2019 in EdgeX represents the transformational aspects of the platform and allows the project name to be trademarked and to be used in efforts such as certification and certification marks. The EdgeX Foundry Logo represents the nature of its role as transformation engine between the physical OT world and the digital IT world. The EdgeX community selected the octopus as the mascot or \u201cspirit animal\u201d of the project at its inception. Its eight arms and the suckers on the arms represent the sensors. The sensors bring the data into the octopus. Actually, the octopus has nine brains in a way. It has millions of neurons running down each arm; functioning as mini-brains in each of those arms. The arms of the octopus serve as \u201clocal analytics\u201d like that offered by EdgeX. The mascot is affectionately called \u201cEdgey\u201d by the community.","title":"EdgeX History and Naming"},{"location":"api/Ch-APIAppFunctionsSDK/","text":"Application Service - Application Service SDK Architecture Reference For a description of the architecture, see Application Functions SDK Introduction The SDK is provided to help build Application Services by assembling triggers, pre-existing functions and custom functions of your making into a pipeline. Application Service SDK V1 API Swagger Documentation","title":"Application Service - Application Service SDK"},{"location":"api/Ch-APIAppFunctionsSDK/#application-service-application-service-sdk","text":"","title":"Application Service - Application Service SDK"},{"location":"api/Ch-APIAppFunctionsSDK/#architecture-reference","text":"For a description of the architecture, see Application Functions SDK","title":"Architecture Reference"},{"location":"api/Ch-APIAppFunctionsSDK/#introduction","text":"The SDK is provided to help build Application Services by assembling triggers, pre-existing functions and custom functions of your making into a pipeline. Application Service SDK V1 API Swagger Documentation","title":"Introduction"},{"location":"api/Ch-APIDeviceSDK/","text":"Device Service - Device SDK Architecture Reference For a description of the architecture, see Device Services Introduction The EdgeX Foundry Device Service Software Development Kit (SDK) takes the Developer through the step-by-step process to create an EdgeX Foundry Device Service microservice. Then setup the SDK and execute the code to generate the Device Service scaffolding to get you started using EdgeX. The Device Service SDK supports: Synchronous read and write operations Asynchronous Device data Initialization and deconstruction of Driver Interface Initialization and destruction of Device Connection Framework for automated Provisioning Mechanism Support for multiple classes of Devices with Profiles Support for sets of actions triggered by a command Cached responses to queries Device SDK V1 API Swagger Documentation","title":"Device Service - Device SDK"},{"location":"api/Ch-APIDeviceSDK/#device-service-device-sdk","text":"","title":"Device Service - Device SDK"},{"location":"api/Ch-APIDeviceSDK/#architecture-reference","text":"For a description of the architecture, see Device Services","title":"Architecture Reference"},{"location":"api/Ch-APIDeviceSDK/#introduction","text":"The EdgeX Foundry Device Service Software Development Kit (SDK) takes the Developer through the step-by-step process to create an EdgeX Foundry Device Service microservice. Then setup the SDK and execute the code to generate the Device Service scaffolding to get you started using EdgeX. The Device Service SDK supports: Synchronous read and write operations Asynchronous Device data Initialization and deconstruction of Driver Interface Initialization and destruction of Device Connection Framework for automated Provisioning Mechanism Support for multiple classes of Devices with Profiles Support for sets of actions triggered by a command Cached responses to queries Device SDK V1 API Swagger Documentation","title":"Introduction"},{"location":"api/Ch-APISystemManagement/","text":"APIs - System Management - Agent Architecture Reference Coming Soon Introduction The EdgeX System Management Agent (SMA) exposes the EdgeX management service API to 3rd party systems. In other words, the Agent serves as a proxy for system management service API calls into each micro service. In the future, the SMA may also offer the management API in other remote management/control system protocols like LWM2M, OMA DM, etc. https://github.com/edgexfoundry/edgex-go/blob/master/api/raml/system-agent.raml System Management V1 API Swagger Documentation","title":"APIs - System Management - Agent"},{"location":"api/Ch-APISystemManagement/#apis-system-management-agent","text":"","title":"APIs - System Management - Agent"},{"location":"api/Ch-APISystemManagement/#architecture-reference","text":"Coming Soon","title":"Architecture Reference"},{"location":"api/Ch-APISystemManagement/#introduction","text":"The EdgeX System Management Agent (SMA) exposes the EdgeX management service API to 3rd party systems. In other words, the Agent serves as a proxy for system management service API calls into each micro service. In the future, the SMA may also offer the management API in other remote management/control system protocols like LWM2M, OMA DM, etc. https://github.com/edgexfoundry/edgex-go/blob/master/api/raml/system-agent.raml System Management V1 API Swagger Documentation","title":"Introduction"},{"location":"api/core/Ch-APICoreCommand/","text":"Core Command Architecture Reference For a description of the architecture, see Core-Command Introduction EdgeX Foundry's Command microservice is a conduit for other services to trigger action on devices and sensors through their managing Device Services. The service provides an API to get the list of commands that can be issued for all devices or a single device. Commands are divided into two groups for each device: GET commands are issued to a device or sensor to get a current value for a particular attribute on the device, such as the current temperature provided by a thermostat sensor, or the on/off status of a light. PUT commands are issued to a device or sensor to change the current state or status of a device or one of its attributes, such as setting the speed in RPMs of a motor, or setting the brightness of a dimmer light. https://github.com/edgexfoundry/edgex-go/blob/master/api/raml/core-command.raml Core Command V1 API Swagger Documentation","title":"Core Command"},{"location":"api/core/Ch-APICoreCommand/#core-command","text":"","title":"Core Command"},{"location":"api/core/Ch-APICoreCommand/#architecture-reference","text":"For a description of the architecture, see Core-Command","title":"Architecture Reference"},{"location":"api/core/Ch-APICoreCommand/#introduction","text":"EdgeX Foundry's Command microservice is a conduit for other services to trigger action on devices and sensors through their managing Device Services. The service provides an API to get the list of commands that can be issued for all devices or a single device. Commands are divided into two groups for each device: GET commands are issued to a device or sensor to get a current value for a particular attribute on the device, such as the current temperature provided by a thermostat sensor, or the on/off status of a light. PUT commands are issued to a device or sensor to change the current state or status of a device or one of its attributes, such as setting the speed in RPMs of a motor, or setting the brightness of a dimmer light. https://github.com/edgexfoundry/edgex-go/blob/master/api/raml/core-command.raml Core Command V1 API Swagger Documentation","title":"Introduction"},{"location":"api/core/Ch-APICoreData/","text":"Core Data Architecture Reference For a description of the architecture, see Core-Data Introduction EdgeX Foundry Core Data Service includes the device and sensor collected data database and APIs to expose the database to other services as well as north-bound integration. The database is secure. Direct access to the database is restricted to the Core Data service APIs. Core Data also provides the REST API to create and register a new device. https://github.com/edgexfoundry/edgex-go/blob/master/api/raml/core-data.raml Core Data V1 API Swagger Documentation","title":"Core Data"},{"location":"api/core/Ch-APICoreData/#core-data","text":"","title":"Core Data"},{"location":"api/core/Ch-APICoreData/#architecture-reference","text":"For a description of the architecture, see Core-Data","title":"Architecture Reference"},{"location":"api/core/Ch-APICoreData/#introduction","text":"EdgeX Foundry Core Data Service includes the device and sensor collected data database and APIs to expose the database to other services as well as north-bound integration. The database is secure. Direct access to the database is restricted to the Core Data service APIs. Core Data also provides the REST API to create and register a new device. https://github.com/edgexfoundry/edgex-go/blob/master/api/raml/core-data.raml Core Data V1 API Swagger Documentation","title":"Introduction"},{"location":"api/core/Ch-APICoreMetadata/","text":"Core Metadata Architecture Reference For a description of the architecture, see Core-Metadata Introduction The Metadata microservice includes the device/sensor metadata database and APIs to expose the database to other services. In particular, the device provisioning service deposits and manages device metadata through this service. This service may also hold and manage other configuration metadata used by other services on the gateway such as clean up schedules, hardware configuration (Wi-Fi connection info, MQTT queues, and so forth). Non-device metadata may need to be held in a different database and/or managed by another service--depending upon implementation. https://github.com/edgexfoundry/edgex-go/blob/master/api/raml/core-metadata.raml Core Metadata V1 API Swagger Documentation","title":"Core Metadata"},{"location":"api/core/Ch-APICoreMetadata/#core-metadata","text":"","title":"Core Metadata"},{"location":"api/core/Ch-APICoreMetadata/#architecture-reference","text":"For a description of the architecture, see Core-Metadata","title":"Architecture Reference"},{"location":"api/core/Ch-APICoreMetadata/#introduction","text":"The Metadata microservice includes the device/sensor metadata database and APIs to expose the database to other services. In particular, the device provisioning service deposits and manages device metadata through this service. This service may also hold and manage other configuration metadata used by other services on the gateway such as clean up schedules, hardware configuration (Wi-Fi connection info, MQTT queues, and so forth). Non-device metadata may need to be held in a different database and/or managed by another service--depending upon implementation. https://github.com/edgexfoundry/edgex-go/blob/master/api/raml/core-metadata.raml Core Metadata V1 API Swagger Documentation","title":"Introduction"},{"location":"api/core/Ch-APICoreServiceConfiguration/","text":"Configuration and Registry Architecture Reference For a description of the architecture, see Configuration Introduction The RESTful APIs are provided by Consul directly, and several communities supply Consul client libraries for different programming languages, including Go (official), Python, Java, PHP, Scala, Erlang/OTP, Ruby, Node.js, and C#. For the client libraries of different languages, please refer to the list of this page: https://www.consul.io/downloads_tools.html Configuration Management For the current API documentation, please refer to the official Consul web site: https://www.consul.io/intro/getting-started/kv.html https://www.consul.io/docs/agent/http/kv.html Service Registry For the current API documentation, please refer to the official Consul web site: https://www.consul.io/intro/getting-started/services.html https://www.consul.io/docs/agent/http/catalog.html https://www.consul.io/docs/agent/http/agent.html https://www.consul.io/docs/agent/checks.html https://www.consul.io/docs/agent/http/health.html Service Registration While each microservice is starting up, it should connect to Consul to register its endpoint information, including microservice ID, address, port number, and health checking method. After that, other microservices can locate its URL from Consul, and Consul has the ability to monitor its health status. The RESTful API of registration is described on the following Consul page: https://www.consul.io/docs/agent/http/agent.html#agent_service_register Service Deregistration Before microservices shut down, they have to deregister themselves from Consul. The RESTful API of deregistration is described on the following Consul page: https://www.consul.io/docs/agent/http/agent.html#agent_service_deregister Service Discovery Service Discovery feature allows client micro services to query the endpoint information of a particular microservice by its microservice IDor list all available services registered in Consul. The RESTful API of querying service by microservice IDis described on the following Consul page: https://www.consul.io/docs/agent/http/catalog.html#catalog_service The RESTful API of listing all available services is described on the following Consul page: https://www.consul.io/docs/agent/http/agent.html#agent_services Health Checking Health checking is a critical feature that prevents using services that are unhealthy. Consul provides a variety of methods to check the health of services, including Script + Interval, HTTP + Interval, TCP + Interval, Time to Live (TTL), and Docker + Interval. The detailed introduction and examples of each checking methods are described on the following Consul page: https://www.consul.io/docs/agent/checks.html The health checks should be established during service registration. Please see the paragraph on this page of Service Registration section.","title":"Configuration and Registry"},{"location":"api/core/Ch-APICoreServiceConfiguration/#configuration-and-registry","text":"","title":"Configuration and Registry"},{"location":"api/core/Ch-APICoreServiceConfiguration/#architecture-reference","text":"For a description of the architecture, see Configuration","title":"Architecture Reference"},{"location":"api/core/Ch-APICoreServiceConfiguration/#introduction","text":"The RESTful APIs are provided by Consul directly, and several communities supply Consul client libraries for different programming languages, including Go (official), Python, Java, PHP, Scala, Erlang/OTP, Ruby, Node.js, and C#. For the client libraries of different languages, please refer to the list of this page: https://www.consul.io/downloads_tools.html","title":"Introduction"},{"location":"api/core/Ch-APICoreServiceConfiguration/#configuration-management","text":"For the current API documentation, please refer to the official Consul web site: https://www.consul.io/intro/getting-started/kv.html https://www.consul.io/docs/agent/http/kv.html","title":"Configuration Management"},{"location":"api/core/Ch-APICoreServiceConfiguration/#service-registry","text":"For the current API documentation, please refer to the official Consul web site: https://www.consul.io/intro/getting-started/services.html https://www.consul.io/docs/agent/http/catalog.html https://www.consul.io/docs/agent/http/agent.html https://www.consul.io/docs/agent/checks.html https://www.consul.io/docs/agent/http/health.html Service Registration While each microservice is starting up, it should connect to Consul to register its endpoint information, including microservice ID, address, port number, and health checking method. After that, other microservices can locate its URL from Consul, and Consul has the ability to monitor its health status. The RESTful API of registration is described on the following Consul page: https://www.consul.io/docs/agent/http/agent.html#agent_service_register Service Deregistration Before microservices shut down, they have to deregister themselves from Consul. The RESTful API of deregistration is described on the following Consul page: https://www.consul.io/docs/agent/http/agent.html#agent_service_deregister Service Discovery Service Discovery feature allows client micro services to query the endpoint information of a particular microservice by its microservice IDor list all available services registered in Consul. The RESTful API of querying service by microservice IDis described on the following Consul page: https://www.consul.io/docs/agent/http/catalog.html#catalog_service The RESTful API of listing all available services is described on the following Consul page: https://www.consul.io/docs/agent/http/agent.html#agent_services Health Checking Health checking is a critical feature that prevents using services that are unhealthy. Consul provides a variety of methods to check the health of services, including Script + Interval, HTTP + Interval, TCP + Interval, Time to Live (TTL), and Docker + Interval. The detailed introduction and examples of each checking methods are described on the following Consul page: https://www.consul.io/docs/agent/checks.html The health checks should be established during service registration. Please see the paragraph on this page of Service Registration section.","title":"Service Registry"},{"location":"api/supporting/Ch-APISupportingServicesAlerts/","text":"Alerts & Notifications Architecture Reference For a description of the architecture, see Alerts and Notifications Introduction When a person or a system needs to be informed of something discovered on the node by another microservice on the node, EdgeX Foundry's Alerts and Notifications microservice delivers that information. Examples of Alerts and Notifications that other services might need to broadcast include sensor data detected outside of certain parameters, usually detected by a Rules Engine service, or a system or service malfunction, usually detected by system management services. https://github.com/edgexfoundry/support-notifications/blob/master/raml/support-notifications.raml Alerts and Notifications V1 API Swagger Documentation","title":"Alerts & Notifications"},{"location":"api/supporting/Ch-APISupportingServicesAlerts/#alerts-notifications","text":"","title":"Alerts &amp; Notifications"},{"location":"api/supporting/Ch-APISupportingServicesAlerts/#architecture-reference","text":"For a description of the architecture, see Alerts and Notifications","title":"Architecture Reference"},{"location":"api/supporting/Ch-APISupportingServicesAlerts/#introduction","text":"When a person or a system needs to be informed of something discovered on the node by another microservice on the node, EdgeX Foundry's Alerts and Notifications microservice delivers that information. Examples of Alerts and Notifications that other services might need to broadcast include sensor data detected outside of certain parameters, usually detected by a Rules Engine service, or a system or service malfunction, usually detected by system management services. https://github.com/edgexfoundry/support-notifications/blob/master/raml/support-notifications.raml Alerts and Notifications V1 API Swagger Documentation","title":"Introduction"},{"location":"api/supporting/Ch-APISupportingServicesLogging/","text":"Logging Architecture Reference For a description of the architecture, see Logging Introduction Logging Service is a microservice featuring REST API for other microservices to add, query, and delete logging requests. Two options of persistence--file or mongodb--are supported and configurable through the property file or remote consul configuration service. https://github.com/edgexfoundry/edgex-go/blob/master/api/raml/support-logging.raml Logging V1 API Swagger Documentation","title":"Logging"},{"location":"api/supporting/Ch-APISupportingServicesLogging/#logging","text":"","title":"Logging"},{"location":"api/supporting/Ch-APISupportingServicesLogging/#architecture-reference","text":"For a description of the architecture, see Logging","title":"Architecture Reference"},{"location":"api/supporting/Ch-APISupportingServicesLogging/#introduction","text":"Logging Service is a microservice featuring REST API for other microservices to add, query, and delete logging requests. Two options of persistence--file or mongodb--are supported and configurable through the property file or remote consul configuration service. https://github.com/edgexfoundry/edgex-go/blob/master/api/raml/support-logging.raml Logging V1 API Swagger Documentation","title":"Introduction"},{"location":"api/supporting/Ch-APISupportingServicesRulesEngine/","text":"Rules Engine Architecture Reference For a description of the architecture, see Rules Engine Introduction EdgeX Foundry Rules Engine Microservice receives data from the Export Service through 0MQ, and then triggers actuation based on event data it receives and analyzes. Built on Drools technology. https://github.com/edgexfoundry/support-rulesengine/blob/master/raml/support-rulesengine.raml","title":"Rules Engine"},{"location":"api/supporting/Ch-APISupportingServicesRulesEngine/#rules-engine","text":"","title":"Rules Engine"},{"location":"api/supporting/Ch-APISupportingServicesRulesEngine/#architecture-reference","text":"For a description of the architecture, see Rules Engine","title":"Architecture Reference"},{"location":"api/supporting/Ch-APISupportingServicesRulesEngine/#introduction","text":"EdgeX Foundry Rules Engine Microservice receives data from the Export Service through 0MQ, and then triggers actuation based on event data it receives and analyzes. Built on Drools technology. https://github.com/edgexfoundry/support-rulesengine/blob/master/raml/support-rulesengine.raml","title":"Introduction"},{"location":"api/supporting/Ch-APISupportingServicesScheduling/","text":"Scheduling Architecture Reference For a description of the architecture, see Scheduling Introduction The following API RESTful Web Service(s) for EdgeX Foundry. https://github.com/edgexfoundry/edgex-go/blob/master/api/raml/support-scheduling.raml Scheduling V1 API Swagger Documentation Description Scheduler Service - a service that can be used to schedule invocation of a URL. Requires the use of interval(s), and interval action(s). Interval(s) : - name - unique name of the service. - start - identifies when the operation starts. Expressed in ISO 8601 YYYYMMDD't'HHmmss format. Empty means now. - end - identifies when the operation ends. Expressed in ISO 8601 YYYYMMDD't'HHmmss format. Empty means never - frequency - identifies the interval between invocations. Expressed in ISO 8601 PxYxMxDTxHxMxS format. Empty means no frequency. Interval Action(s) : - name - unique name of the interval action. - interval - unique name of an existing interval. - target - the recipient of the interval action (ergo service or name). - protocol - the protocol type to be used to contact the target. (example HTTP). - httpMethod - HTTP protocol verb. - address - the endpoint server host. - port - the desired port. - path - the api path which will be acted on. - parameters - (optional) parameters which will be included in the BODY tag for HttpMethods. Any parameters that should be provided to the call, e.g. {\"milliseconds\":86400000} Examples Create an interval upon which the scheduler will operate : curl -X POST -H \"Content-Type: application/json\" -H \"Cache-Control: no-cache\" -d '{ : \"name\": \"midnight\", \"start\": \"20180101T000000\", \"frequency\": \"P1D\"}' \" http://localhost:48081/api/v1/interval \" Example of a second interval which will run every 20 seconds : curl -X POST -H \"Content-Type: application/json\" -H \"Cache-Control: no-cache\" -d '{ : \"name\": \"every20s\", \"start\":\"20000101T000000\", \"end\":\"\", \"frequency\":\"PT20S\"}' \" http://localhost:48081/api/v1/interval \" Create an interval action that will invoke the interval action (drive the scrubber) in core-data : curl -X POST -H \"Content-Type: application/json\" -H \"Cache-Control: no-cache\" -d '{ : \"name\": \"scrub-pushed-events\", \"interval\": \"midnight\", \"target\": \"core-data\", \"protocol\": \"http\", \"httpMethod\": \"DELETE\", \"address\": \"localhost\", \"port\": 48080, \"path\": \"/api/v1/event/scrub\"}' \" http://localhost:48085/api/v1/intervalaction \" This is a Random-Boolean-Device which created by edgex-device-virtual that connects every 20 seconds. : curl -X POST -H \"Content-Type: application/json\" -d '{ : \"name\": \"put-action\", \"interval\": \"every20s\", \"target\": \"edgex-device-modbus\", \"protocol\": \"http\", \"httpMethod\": \"PUT\", \"address\": \"localhost\", \"port\": 49990, \"path\":\"/api/v1/device/name/Random-Boolean-Device/RandomValue_Bool\", \"parameters\": \"{\"RandomValue_Bool\": \"true\",\"EnableRandomization_Bool\": \"true\"}\" }' \" http://localhost:48085/api/v1/intervalaction \"","title":"Scheduling"},{"location":"api/supporting/Ch-APISupportingServicesScheduling/#scheduling","text":"","title":"Scheduling"},{"location":"api/supporting/Ch-APISupportingServicesScheduling/#architecture-reference","text":"For a description of the architecture, see Scheduling","title":"Architecture Reference"},{"location":"api/supporting/Ch-APISupportingServicesScheduling/#introduction","text":"The following API RESTful Web Service(s) for EdgeX Foundry. https://github.com/edgexfoundry/edgex-go/blob/master/api/raml/support-scheduling.raml Scheduling V1 API Swagger Documentation","title":"Introduction"},{"location":"api/supporting/Ch-APISupportingServicesScheduling/#description","text":"Scheduler Service - a service that can be used to schedule invocation of a URL. Requires the use of interval(s), and interval action(s). Interval(s) : - name - unique name of the service. - start - identifies when the operation starts. Expressed in ISO 8601 YYYYMMDD't'HHmmss format. Empty means now. - end - identifies when the operation ends. Expressed in ISO 8601 YYYYMMDD't'HHmmss format. Empty means never - frequency - identifies the interval between invocations. Expressed in ISO 8601 PxYxMxDTxHxMxS format. Empty means no frequency. Interval Action(s) : - name - unique name of the interval action. - interval - unique name of an existing interval. - target - the recipient of the interval action (ergo service or name). - protocol - the protocol type to be used to contact the target. (example HTTP). - httpMethod - HTTP protocol verb. - address - the endpoint server host. - port - the desired port. - path - the api path which will be acted on. - parameters - (optional) parameters which will be included in the BODY tag for HttpMethods. Any parameters that should be provided to the call, e.g. {\"milliseconds\":86400000}","title":"Description"},{"location":"api/supporting/Ch-APISupportingServicesScheduling/#examples","text":"Create an interval upon which the scheduler will operate : curl -X POST -H \"Content-Type: application/json\" -H \"Cache-Control: no-cache\" -d '{ : \"name\": \"midnight\", \"start\": \"20180101T000000\", \"frequency\": \"P1D\"}' \" http://localhost:48081/api/v1/interval \" Example of a second interval which will run every 20 seconds : curl -X POST -H \"Content-Type: application/json\" -H \"Cache-Control: no-cache\" -d '{ : \"name\": \"every20s\", \"start\":\"20000101T000000\", \"end\":\"\", \"frequency\":\"PT20S\"}' \" http://localhost:48081/api/v1/interval \" Create an interval action that will invoke the interval action (drive the scrubber) in core-data : curl -X POST -H \"Content-Type: application/json\" -H \"Cache-Control: no-cache\" -d '{ : \"name\": \"scrub-pushed-events\", \"interval\": \"midnight\", \"target\": \"core-data\", \"protocol\": \"http\", \"httpMethod\": \"DELETE\", \"address\": \"localhost\", \"port\": 48080, \"path\": \"/api/v1/event/scrub\"}' \" http://localhost:48085/api/v1/intervalaction \" This is a Random-Boolean-Device which created by edgex-device-virtual that connects every 20 seconds. : curl -X POST -H \"Content-Type: application/json\" -d '{ : \"name\": \"put-action\", \"interval\": \"every20s\", \"target\": \"edgex-device-modbus\", \"protocol\": \"http\", \"httpMethod\": \"PUT\", \"address\": \"localhost\", \"port\": 49990, \"path\":\"/api/v1/device/name/Random-Boolean-Device/RandomValue_Bool\", \"parameters\": \"{\"RandomValue_Bool\": \"true\",\"EnableRandomization_Bool\": \"true\"}\" }' \" http://localhost:48085/api/v1/intervalaction \"","title":"Examples"},{"location":"design/","text":"Architecture Decision Records Folder This folder contains EdgeX Foundry decision records (ADR) and legacy design / requirement documents. /design /adr (architecture decision Records) /legacy-design (legacy design documents) /legacy-requirements (legacy requirement documents) At the root of the ADR folder (/design/adr) are decisions that are relevant to multiple parts of the project (aka \ufffd cross cutting concerns ). Sub folders under the ADR folder contain decisions relevant to the specific area of the project and essentially set up along working group lines (security, core, application, etc.). Naming and Formatting ADR documents are requested to follow RFC (request for comments) naming standard. Specifically, authors should name their documents with a sequentially increasing integer (or serial number) and then the architectural design topic: (sequence number - topic). Example: 0001-SeparateConfigurationInterface. The sequence is a global sequence for all EdgeX ADR. Per RFC and Michael Nygard suggestions the makeup of the ADR document should generally include: Title Status (proposed, accepted, rejected, deprecated, superseded, etc.) Context and Proposed Design Decision Consequences/considerations References Document history is maintained via Github history. Ownership EdgeX WG chairman own the sub folder and included documents associated to their work group. The EdgeX TSC chair/vice chair are responsible for the root level, cross cutting concern documents. Review and Approval ADR\u2019s shall be submitted as PRs to the appropriate edgex-docs folder based on the Architecture Decision Records Folder section above. The status of the PR (inside the document) shall be listed as proposed during this period. The PRs shall be left open (not merged) so that comments against the PR can be collected during the proposal period. The PRs can be approved and merged only after a formal vote of approval is conducted by the TSC. On approval of the ADR by the TSC, the status of the ADR should be changed to accepted . If the ADR is not approved by the TSC, the status in the document should be changed to rejected and the PR closed. Legacy A separate folder (/design/legacy-design) is used for legacy design/architecture decisions. A separate folder (/design/legacy-requirements) is used for legacy requirements documents. WG chairman take the responsibility for posting legacy material in to the applicable folders. Table of Contents A README with a table of contents for current documents is located here . Legacy Design and Requirements have their own Table of Contents as well and are located in their respective directories at /legacy-design and /legacy-requirements . Document authors are asked to keep the TOC updated with each new document entry.","title":"Architecture Decision Records Folder"},{"location":"design/#architecture-decision-records-folder","text":"This folder contains EdgeX Foundry decision records (ADR) and legacy design / requirement documents. /design /adr (architecture decision Records) /legacy-design (legacy design documents) /legacy-requirements (legacy requirement documents) At the root of the ADR folder (/design/adr) are decisions that are relevant to multiple parts of the project (aka \ufffd cross cutting concerns ). Sub folders under the ADR folder contain decisions relevant to the specific area of the project and essentially set up along working group lines (security, core, application, etc.).","title":"Architecture Decision Records Folder"},{"location":"design/#naming-and-formatting","text":"ADR documents are requested to follow RFC (request for comments) naming standard. Specifically, authors should name their documents with a sequentially increasing integer (or serial number) and then the architectural design topic: (sequence number - topic). Example: 0001-SeparateConfigurationInterface. The sequence is a global sequence for all EdgeX ADR. Per RFC and Michael Nygard suggestions the makeup of the ADR document should generally include: Title Status (proposed, accepted, rejected, deprecated, superseded, etc.) Context and Proposed Design Decision Consequences/considerations References Document history is maintained via Github history.","title":"Naming and Formatting"},{"location":"design/#ownership","text":"EdgeX WG chairman own the sub folder and included documents associated to their work group. The EdgeX TSC chair/vice chair are responsible for the root level, cross cutting concern documents.","title":"Ownership"},{"location":"design/#review-and-approval","text":"ADR\u2019s shall be submitted as PRs to the appropriate edgex-docs folder based on the Architecture Decision Records Folder section above. The status of the PR (inside the document) shall be listed as proposed during this period. The PRs shall be left open (not merged) so that comments against the PR can be collected during the proposal period. The PRs can be approved and merged only after a formal vote of approval is conducted by the TSC. On approval of the ADR by the TSC, the status of the ADR should be changed to accepted . If the ADR is not approved by the TSC, the status in the document should be changed to rejected and the PR closed.","title":"Review and Approval"},{"location":"design/#legacy","text":"A separate folder (/design/legacy-design) is used for legacy design/architecture decisions. A separate folder (/design/legacy-requirements) is used for legacy requirements documents. WG chairman take the responsibility for posting legacy material in to the applicable folders.","title":"Legacy"},{"location":"design/#table-of-contents","text":"A README with a table of contents for current documents is located here . Legacy Design and Requirements have their own Table of Contents as well and are located in their respective directories at /legacy-design and /legacy-requirements . Document authors are asked to keep the TOC updated with each new document entry.","title":"Table of Contents"},{"location":"design/TOC/","text":"ADR Table of Contents Name/Link Short Description 0001 Registry Refactor Separate out Registry and Configuration APIs 0002 Array Datatypes Allow Arrays to be held in Readings 0003 V2 API Principles Principles and Goals of V2 API Design 0004 Feature Flags Feature Flag Implementation 0005 Service Self Config Init Service Self Config Init & Config Seed Removal 0007 Release Automation Overview of Release Automation Flow for EdgeX 0008 Secret Distribution Creation and Distribution of Secrets 0011 Device Service REST API The REST API for Device Services in EdgeX v2.x","title":"ADR Table of Contents"},{"location":"design/TOC/#adr-table-of-contents","text":"Name/Link Short Description 0001 Registry Refactor Separate out Registry and Configuration APIs 0002 Array Datatypes Allow Arrays to be held in Readings 0003 V2 API Principles Principles and Goals of V2 API Design 0004 Feature Flags Feature Flag Implementation 0005 Service Self Config Init Service Self Config Init & Config Seed Removal 0007 Release Automation Overview of Release Automation Flow for EdgeX 0008 Secret Distribution Creation and Distribution of Secrets 0011 Device Service REST API The REST API for Device Services in EdgeX v2.x","title":"ADR Table of Contents"},{"location":"design/adr/0001-Registy-Refactor/","text":"Registry Refactoring Design Status Context Proposed Design Decision Consequences References Status Approved Context Currently the Registry Client in go-mod-registry module provides Service Configuration and Service Registration functionality. The goal of this design is to refactor the go-mod-registry module for separation of concerns. The Service Registry functionality will stay in the go-mod-registry module and the Service Configuration functionality will be separated out into a new go-mod-configuration module. This allows for implementations for deferent providers for each, another aspect of separation of concerns. Proposed Design Provider Connection information An aspect of using the current Registry Client is \" Where do the services get the Registry Provider connection information? \" Currently all services either pull this connection information from the local configuration file or from the edgex_registry environment variable. Device Services also have the option to specify this connection information on the command line. With the refactoring for separation of concerns, this issue changes to \" Where do the services get the Configuration Provider connection information? \" There have been concerns voiced by some in the EdgeX community that storing this Configuration Provider connection information in the configuration which ultimately is provided by that provider is not the right design. This design proposes that all services will use the command line option approach with the ability to override with an environment variable. The Configuration Provider information will not be stored in each service's local configuration file. The edgex_registry environment variable will be deprecated. The Registry Provider connection information will continue to be stored in each service's configuration either locally or from the Configuration Provider same as all other EdgeX Client and Database connection information. Command line option changes The new -cp/-configProvider command line option will be added to each service which will have a value specified using the format {type}.{protocol}://{host}:{port} e.g consul.http://localhost:8500 . This new command line option will be overridden by the edgex_configuration_provider environment variable when it is set. This environment variable's value has the same format as the command line option value. If no value is provided to the -cp/-configProvider option, i.e. just -cp , and no environment variable override is specified, the default value of consul.http://localhost:8500 will be used. if -cp/-configProvider not used and no environment variable override is specified the local configuration file is used, as is it now. All services will log the Configuration Provider connection information that is used. The existing -r/-registry command line option will be retained as a Boolean flag to indicate to use the Registry. Bootstrap Changes All services in the edgex-go mono repo use the new common bootstrap functionality. The plan is to move this code to a go module for the Device Service and App Functions SDKs to also use. The current bootstrap modules pkg/bootstrap/configuration/registry.go and pkg/bootstrap/container/registry.go will be refactored to use the new Configuration Client and be renamed appropriately. New bootstrap modules will be created for using the revised version of Registry Client . The current use of useRegistry and registryClient for service configuration will be change to appropriate names for using the new Configuration Client . The current use of useRegistry and registryClient for service registration will be retained for service registration. Call to the new Unregister() API will be added to shutdown code for all services. Config-Seed Changes The conf-seed service will have similar changes for specifying the Configuration Provider connection information since it doesn't use the common bootstrap package. Beyond that it will have minor changes for switching to using the Configuration Client interface, which will just be imports and appropriate name refactoring. Config Endpoint Changes Since the Configuration Provider connection information will no longer be in the service's configuration struct, the config endpoint processing will be modified to add the Configuration Provider connection information to the resulting JSON create from service's configuration. Client Interfaces changes Current Registry Client This following is the current Registry Client Interface type Client interface { Register () error HasConfiguration () ( bool , error ) PutConfigurationToml ( configuration * toml . Tree , overwrite bool ) error PutConfiguration ( configStruct interface {}, overwrite bool ) error GetConfiguration ( configStruct interface {}) ( interface {}, error ) WatchForChanges ( updateChannel chan <- interface {}, errorChannel chan <- error , configuration interface {}, waitKey string ) IsAlive () bool ConfigurationValueExists ( name string ) ( bool , error ) GetConfigurationValue ( name string ) ([] byte , error ) PutConfigurationValue ( name string , value [] byte ) error GetServiceEndpoint ( serviceId string ) ( types . ServiceEndpoint , error ) IsServiceAvailable ( serviceId string ) error } New Configuration Client This following is the new Configuration Client Interface which contains the Service Configuration specific portion from the above current Registry Client . type Client interface { HasConfiguration () ( bool , error ) PutConfigurationFromToml ( configuration * toml . Tree , overwrite bool ) error PutConfiguration ( configStruct interface {}, overwrite bool ) error GetConfiguration ( configStruct interface {}) ( interface {}, error ) WatchForChanges ( updateChannel chan <- interface {}, errorChannel chan <- error , configuration interface {}, waitKey string ) IsAlive () bool ConfigurationValueExists ( name string ) ( bool , error ) GetConfigurationValue ( name string ) ([] byte , error ) PutConfigurationValue ( name string , value [] byte ) error } Revised Registry Client This following is the revised Registry Client Interface, which contains the Service Registry specific portion from the above current Registry Client . The UnRegister() API has been added per issue #20 type Client interface { Register () error UnRegister () error IsAlive () bool GetServiceEndpoint ( serviceId string ) ( types . ServiceEndpoint , error ) IsServiceAvailable ( serviceId string ) error } Client Configuration Structs Current Registry Client Config The following is the current struct used to configure the current Registry Client type Config struct { Protocol string Host string Port int Type string Stem string ServiceKey string ServiceHost string ServicePort int ServiceProtocol string CheckRoute string CheckInterval string } New Configuration Client Config The following is the new struct the will be used to configure the new Configuration Client from the command line option or environment variable values. The Service Registry portion has been removed from the above existing Registry Client Config type Config struct { Protocol string Host string Port int Type string BasePath string ServiceKey string } New Registry Client Config The following is the revised struct the will be used to configure the new Registry Client from the information in the service's configuration. This is mostly unchanged from the existing Registry Client Config , except that the Stem for configuration has been removed type Config struct { Protocol string Host string Port int Type string ServiceKey string ServiceHost string ServicePort int ServiceProtocol string CheckRoute string CheckInterval string } Provider Implementations The current Consul implementation of the Registry Client will be split up into implementations for the new Configuration Client in the new go-mod-configuration module and the revised Registry Client in the existing go-mod-registry module. Decision It was decided to move forward with the above design After initial ADR was approved, it was decided to retain the -r/--registry command-line flag and not add the Enabled field in the Registry provider configuration. Consequences Once the refactoring of go-mod-registry and go-mod-configuration are complete, they will need to be integrated into the new go-mod-bootstrap. Part of this integration will be the Command line option changes above. At this point the edgex-go services will be integrated with the new Registry and Configuration providers. The App Services SDK and Device Services SDK will then need to integrate go-mod-bootstrap to take advantage of these new providers. References Registry Abstraction - Decouple EdgeX services from Consul (Previous design)","title":"Registry Refactoring Design"},{"location":"design/adr/0001-Registy-Refactor/#registry-refactoring-design","text":"Status Context Proposed Design Decision Consequences References","title":"Registry Refactoring Design"},{"location":"design/adr/0001-Registy-Refactor/#status","text":"Approved","title":"Status"},{"location":"design/adr/0001-Registy-Refactor/#context","text":"Currently the Registry Client in go-mod-registry module provides Service Configuration and Service Registration functionality. The goal of this design is to refactor the go-mod-registry module for separation of concerns. The Service Registry functionality will stay in the go-mod-registry module and the Service Configuration functionality will be separated out into a new go-mod-configuration module. This allows for implementations for deferent providers for each, another aspect of separation of concerns.","title":"Context"},{"location":"design/adr/0001-Registy-Refactor/#proposed-design","text":"","title":"Proposed Design"},{"location":"design/adr/0001-Registy-Refactor/#provider-connection-information","text":"An aspect of using the current Registry Client is \" Where do the services get the Registry Provider connection information? \" Currently all services either pull this connection information from the local configuration file or from the edgex_registry environment variable. Device Services also have the option to specify this connection information on the command line. With the refactoring for separation of concerns, this issue changes to \" Where do the services get the Configuration Provider connection information? \" There have been concerns voiced by some in the EdgeX community that storing this Configuration Provider connection information in the configuration which ultimately is provided by that provider is not the right design. This design proposes that all services will use the command line option approach with the ability to override with an environment variable. The Configuration Provider information will not be stored in each service's local configuration file. The edgex_registry environment variable will be deprecated. The Registry Provider connection information will continue to be stored in each service's configuration either locally or from the Configuration Provider same as all other EdgeX Client and Database connection information.","title":"Provider Connection information"},{"location":"design/adr/0001-Registy-Refactor/#command-line-option-changes","text":"The new -cp/-configProvider command line option will be added to each service which will have a value specified using the format {type}.{protocol}://{host}:{port} e.g consul.http://localhost:8500 . This new command line option will be overridden by the edgex_configuration_provider environment variable when it is set. This environment variable's value has the same format as the command line option value. If no value is provided to the -cp/-configProvider option, i.e. just -cp , and no environment variable override is specified, the default value of consul.http://localhost:8500 will be used. if -cp/-configProvider not used and no environment variable override is specified the local configuration file is used, as is it now. All services will log the Configuration Provider connection information that is used. The existing -r/-registry command line option will be retained as a Boolean flag to indicate to use the Registry.","title":"Command line option changes"},{"location":"design/adr/0001-Registy-Refactor/#bootstrap-changes","text":"All services in the edgex-go mono repo use the new common bootstrap functionality. The plan is to move this code to a go module for the Device Service and App Functions SDKs to also use. The current bootstrap modules pkg/bootstrap/configuration/registry.go and pkg/bootstrap/container/registry.go will be refactored to use the new Configuration Client and be renamed appropriately. New bootstrap modules will be created for using the revised version of Registry Client . The current use of useRegistry and registryClient for service configuration will be change to appropriate names for using the new Configuration Client . The current use of useRegistry and registryClient for service registration will be retained for service registration. Call to the new Unregister() API will be added to shutdown code for all services.","title":"Bootstrap Changes"},{"location":"design/adr/0001-Registy-Refactor/#config-seed-changes","text":"The conf-seed service will have similar changes for specifying the Configuration Provider connection information since it doesn't use the common bootstrap package. Beyond that it will have minor changes for switching to using the Configuration Client interface, which will just be imports and appropriate name refactoring.","title":"Config-Seed Changes"},{"location":"design/adr/0001-Registy-Refactor/#config-endpoint-changes","text":"Since the Configuration Provider connection information will no longer be in the service's configuration struct, the config endpoint processing will be modified to add the Configuration Provider connection information to the resulting JSON create from service's configuration.","title":"Config Endpoint Changes"},{"location":"design/adr/0001-Registy-Refactor/#client-interfaces-changes","text":"","title":"Client Interfaces changes"},{"location":"design/adr/0001-Registy-Refactor/#current-registry-client","text":"This following is the current Registry Client Interface type Client interface { Register () error HasConfiguration () ( bool , error ) PutConfigurationToml ( configuration * toml . Tree , overwrite bool ) error PutConfiguration ( configStruct interface {}, overwrite bool ) error GetConfiguration ( configStruct interface {}) ( interface {}, error ) WatchForChanges ( updateChannel chan <- interface {}, errorChannel chan <- error , configuration interface {}, waitKey string ) IsAlive () bool ConfigurationValueExists ( name string ) ( bool , error ) GetConfigurationValue ( name string ) ([] byte , error ) PutConfigurationValue ( name string , value [] byte ) error GetServiceEndpoint ( serviceId string ) ( types . ServiceEndpoint , error ) IsServiceAvailable ( serviceId string ) error }","title":"Current Registry Client"},{"location":"design/adr/0001-Registy-Refactor/#new-configuration-client","text":"This following is the new Configuration Client Interface which contains the Service Configuration specific portion from the above current Registry Client . type Client interface { HasConfiguration () ( bool , error ) PutConfigurationFromToml ( configuration * toml . Tree , overwrite bool ) error PutConfiguration ( configStruct interface {}, overwrite bool ) error GetConfiguration ( configStruct interface {}) ( interface {}, error ) WatchForChanges ( updateChannel chan <- interface {}, errorChannel chan <- error , configuration interface {}, waitKey string ) IsAlive () bool ConfigurationValueExists ( name string ) ( bool , error ) GetConfigurationValue ( name string ) ([] byte , error ) PutConfigurationValue ( name string , value [] byte ) error }","title":"New Configuration Client"},{"location":"design/adr/0001-Registy-Refactor/#revised-registry-client","text":"This following is the revised Registry Client Interface, which contains the Service Registry specific portion from the above current Registry Client . The UnRegister() API has been added per issue #20 type Client interface { Register () error UnRegister () error IsAlive () bool GetServiceEndpoint ( serviceId string ) ( types . ServiceEndpoint , error ) IsServiceAvailable ( serviceId string ) error }","title":"Revised Registry Client"},{"location":"design/adr/0001-Registy-Refactor/#client-configuration-structs","text":"","title":"Client Configuration Structs"},{"location":"design/adr/0001-Registy-Refactor/#current-registry-client-config","text":"The following is the current struct used to configure the current Registry Client type Config struct { Protocol string Host string Port int Type string Stem string ServiceKey string ServiceHost string ServicePort int ServiceProtocol string CheckRoute string CheckInterval string }","title":"Current Registry Client Config"},{"location":"design/adr/0001-Registy-Refactor/#new-configuration-client-config","text":"The following is the new struct the will be used to configure the new Configuration Client from the command line option or environment variable values. The Service Registry portion has been removed from the above existing Registry Client Config type Config struct { Protocol string Host string Port int Type string BasePath string ServiceKey string }","title":"New Configuration Client Config"},{"location":"design/adr/0001-Registy-Refactor/#new-registry-client-config","text":"The following is the revised struct the will be used to configure the new Registry Client from the information in the service's configuration. This is mostly unchanged from the existing Registry Client Config , except that the Stem for configuration has been removed type Config struct { Protocol string Host string Port int Type string ServiceKey string ServiceHost string ServicePort int ServiceProtocol string CheckRoute string CheckInterval string }","title":"New Registry Client Config"},{"location":"design/adr/0001-Registy-Refactor/#provider-implementations","text":"The current Consul implementation of the Registry Client will be split up into implementations for the new Configuration Client in the new go-mod-configuration module and the revised Registry Client in the existing go-mod-registry module.","title":"Provider Implementations"},{"location":"design/adr/0001-Registy-Refactor/#decision","text":"It was decided to move forward with the above design After initial ADR was approved, it was decided to retain the -r/--registry command-line flag and not add the Enabled field in the Registry provider configuration.","title":"Decision"},{"location":"design/adr/0001-Registy-Refactor/#consequences","text":"Once the refactoring of go-mod-registry and go-mod-configuration are complete, they will need to be integrated into the new go-mod-bootstrap. Part of this integration will be the Command line option changes above. At this point the edgex-go services will be integrated with the new Registry and Configuration providers. The App Services SDK and Device Services SDK will then need to integrate go-mod-bootstrap to take advantage of these new providers.","title":"Consequences"},{"location":"design/adr/0001-Registy-Refactor/#references","text":"Registry Abstraction - Decouple EdgeX services from Consul (Previous design)","title":"References"},{"location":"design/adr/0004-Feature-Flags/","text":"Feature Flag Proposal Status Accepted Context Out of the proposal for releasing on time, the community suggested that we take a closer look at feature-flags. Feature-flags are typically intended for users of an application to turn on or off new or unused features. This gives user more control to adopt a feature-set at their own pace \u2013 i.e disabling store and forward in App Functions SDK without breaking backward compatibility. It can also be used to indicate to developers the features that are more often used than others and can provided valuable feedback to enhance and continue a given feature. To gain that insight of the use of any given feature, we would require not only instrumentation of the code but a central location in the cloud (i.e a TIG stack) for the telemetry to be ingested and in turn reported in order to provide the feedback to the developers. This becomes infeasible primarily because the cloud infrastructure costs, privacy concerns, and other unforeseen legal reasons for sending \u201cUsage Metrics\u201d of an EdgeX installation back to a central entity such as the Linux Foundation, among many others. Without the valuable feedback loop, feature-flags don\u2019t provide much value on their own and they certainly don\u2019t assist in increasing velocity to help us deliver on time. Putting aside one of the major value propositions listed above, feasibility of a feature flag \u201cmodule\u201d was still evaluated. The simplest approach would be to leverage configuration following a certain format such as FF_[NewFeatureName]=true/false. This is similar to what is done today. Turning on/off security is an example, turning on/off the registry is another. Expanding this further with a module could offer standardization of controlling a given feature such as featurepkg.Register(\u201cMyNewFeature\u201d) or featurepkg.IsOn(\u201cMyNewFeature\u201d) . However, this really is just adding complexity on top of the underlying configuration that is already implemented. If we were to consider doing something like this, it lends it self to a central management of features within the EdgeX framework\u2014either its own service or possibly added as part of the SMA. This could help address concerns around feature dependencies and compatibility. Feature A on Service X requires Feature B and Feature C on Service Y. Continuing down this path starts to beget a fairly large impact to EdgeX for value that cannot be fully realized. Decision The community should NOT pursue a full-fledged feature flag implementation either homegrown or off-the-shelf. However, it should be encouraged to develop features with a wholistic perspective and consider leveraging configuration options to turn them on/off. In other words, once a feature compiles, can work under common scenarios, but perhaps isn\u2019t fully tested with edge cases, but doesn\u2019t impact any other functionality, should be encouraged. Consequences Allows more focus on the many more competing priorities for this release. Minimal impact to development cycles and release schedule","title":"Feature Flag Proposal"},{"location":"design/adr/0004-Feature-Flags/#feature-flag-proposal","text":"","title":"Feature Flag Proposal"},{"location":"design/adr/0004-Feature-Flags/#status","text":"Accepted","title":"Status"},{"location":"design/adr/0004-Feature-Flags/#context","text":"Out of the proposal for releasing on time, the community suggested that we take a closer look at feature-flags. Feature-flags are typically intended for users of an application to turn on or off new or unused features. This gives user more control to adopt a feature-set at their own pace \u2013 i.e disabling store and forward in App Functions SDK without breaking backward compatibility. It can also be used to indicate to developers the features that are more often used than others and can provided valuable feedback to enhance and continue a given feature. To gain that insight of the use of any given feature, we would require not only instrumentation of the code but a central location in the cloud (i.e a TIG stack) for the telemetry to be ingested and in turn reported in order to provide the feedback to the developers. This becomes infeasible primarily because the cloud infrastructure costs, privacy concerns, and other unforeseen legal reasons for sending \u201cUsage Metrics\u201d of an EdgeX installation back to a central entity such as the Linux Foundation, among many others. Without the valuable feedback loop, feature-flags don\u2019t provide much value on their own and they certainly don\u2019t assist in increasing velocity to help us deliver on time. Putting aside one of the major value propositions listed above, feasibility of a feature flag \u201cmodule\u201d was still evaluated. The simplest approach would be to leverage configuration following a certain format such as FF_[NewFeatureName]=true/false. This is similar to what is done today. Turning on/off security is an example, turning on/off the registry is another. Expanding this further with a module could offer standardization of controlling a given feature such as featurepkg.Register(\u201cMyNewFeature\u201d) or featurepkg.IsOn(\u201cMyNewFeature\u201d) . However, this really is just adding complexity on top of the underlying configuration that is already implemented. If we were to consider doing something like this, it lends it self to a central management of features within the EdgeX framework\u2014either its own service or possibly added as part of the SMA. This could help address concerns around feature dependencies and compatibility. Feature A on Service X requires Feature B and Feature C on Service Y. Continuing down this path starts to beget a fairly large impact to EdgeX for value that cannot be fully realized.","title":"Context"},{"location":"design/adr/0004-Feature-Flags/#decision","text":"The community should NOT pursue a full-fledged feature flag implementation either homegrown or off-the-shelf. However, it should be encouraged to develop features with a wholistic perspective and consider leveraging configuration options to turn them on/off. In other words, once a feature compiles, can work under common scenarios, but perhaps isn\u2019t fully tested with edge cases, but doesn\u2019t impact any other functionality, should be encouraged.","title":"Decision"},{"location":"design/adr/0004-Feature-Flags/#consequences","text":"Allows more focus on the many more competing priorities for this release. Minimal impact to development cycles and release schedule","title":"Consequences"},{"location":"design/adr/0005-Service-Self-Config/","text":"Service Self Config Init & Config Seed Removal Status approved - TSC vote on 3/25/20 for Geneva release NOTE: this ADR does not address high availability considerations and concerns. EdgeX, in general, has a number of unanswered questions with regard to HA architecture and this design adds to those considerations. Context Since its debut, EdgeX has had a configuration seed service (config-seed) that, on start of EdgeX, deposits configuration for all the services into Consul (our configuration/registry service). For development purposes, or on resource constrained platforms, EdgeX can be run without Consul with services simply reading configuration from the filesystem. While this process has nominally worked for several releases of EdgeX, there has always been some issues with this extra initialization process (config-seed), not least of which are: - race conditions on the part of the services, as they bootstrap, coming up before the config-seed completes its deposit of configuration into Consul - how to deal with \"overrides\" such as environmental variable provided configuration overrides. As the override is often specific to a service but has to be in place for config-seed in order to take effect. - need for an additional service that is only there for init and then dies (confusing to users) NOTE - for historical purposes, it should be noted that config-seed only writes configuration into the configuration/registry service (Consul) once on the first start of EdgeX. On subsequent starts of EdgeX, config-seed checks to see if it has already populated the configuration/registry service and will not rewrite configuration again (unless the --overwrite flag is used). The design/architectural proposal, therefore, is: - removal of the config-seed service (removing cmd/config-seed from the edgex-go repository) - have each EdgeX micro service \"self seed\" - that is seed Consul with their own required configuration on bootstrap of the service. Details of that bootstrapping process are below. Command Line Options All EdgeX services support a common set of command-line options, some combination of which are required on startup for a service to interact with the rest of EdgeX. Command line options are not set by any configuration. Command line options include: --configProvider or -cp (the configuration provider location URL - prefixed with consul. - for example: -cp=consul.http://localhost:8500 ) --overwrite or -o (overwrite the configuration in the configuration provider) --file or -f (the configuration filename - configuration.toml is used by default if the configuration filename is not provided) --profile or -p (the name of a sub directory in the configuration directory in which a profile-specific configuration file is found. This has no default. If not specified, the configuration file is read from the configuration directory) --confdir or -c (the directory where the configuration file is found - ./res is used by default if the confdir is not specified, where \".\" is the convention on Linux/Unix/MacOS which means current directory) --registry or -r (string indicating use of the registry) The distinction of command line options versus configuration will be important later in this ADR. Two command line options (-o for overwrite and -r for registry) are not overridable by environmental variables. NOTES: Use of the --overwrite command line option should be used sparingly and with expert knowledge of EdgeX; in particular knowledge of how it operates and where/how it gets its configuration on restarts, etc. Ordinarily, --overwrite is provided as a means to support development needs. Use of --overwrite permanently in production enviroments is highly discouraged. Configuration Initialization Each service has (or shall have if not providing it already) a local configuration file. The service may use the local configuration file on initialization of the service (aka bootstrap of the service) depending on command line options and environmental variables (see below) provided at startup. Using a configuration provider When the configuration provider is specified, the service will call on the configuration provider (Consul) and check if the top-level (root) namespace for the service exists. If configuratation at the top-level (root) namespace exists, it indicates that the service has already populated its configuration into the configuration provider in a prior startup. If the service finds the top-level (root) namespace is already populated with configuration information it will then read that configuration information from the configuration provider under namespace for that service (and ignore what is in the local configuration file). If the service finds the top-level (root) namespace is not populated with configuration information, it will read its local configuration file and populate the configuration provider (under the namespace for the service) with configuration read from the local configuration file. A configuration provider can be specified with a command line argument (the -cp / --configProvider) or environment variable (the EDGEX_CONFIGURATION_PROVIDER environmental variable which overrides the command line argument). NOTE: the environmental variables are typically uppercase but there have been inconsistencies in environmental variable casing (example: edgex_registry). This should be considered and made consistent in a future major release. Using the local configuration file When a configuration provider isn't specified, the service just uses the configuration in its local configuration file. That is the service uses the configuration in the file associated with the profile, config filename and config file directory command line options or environmental variables. In this case, the service does not contact the configuration service (Consul) for any configuration information. NOTE: As the services now self seed and deployment specific changes can be made via environment overrides, it will no longer be necessary to have a Docker profile configuration file in each of the service directories (example: https://github.com/edgexfoundry/edgex-go/blob/master/cmd/core-data/res/docker/configuration.toml). See Consequences below. It will still be possible for users to use the profile mechanism to specify a Docker configuration, but it will no longer be required and not the recommended approach to providing Docker container specific configuration. Overrides Environment variables used to override configuration always take precedence whether configuration is being sourced locally or read from the config provider/Consul. Note - this means that a configuration value that is being overridden by an environment variable will always be the source of truth, even if the same configuration is changed directly in Consul. The name of the environmental variable must match the path names in Consul. NOTES: - Environmental variables overrides remove the need to change the \"docker\" profile in the res/docker/configuration.toml files - Allowing removal of 50% of the existing configuration.toml files. - The override rules in EdgeX between environmental variables and command line options may be counter intuitive compared to other systems. There appears to be no standard practice. Indeed, web searching \"Reddit & Starting Fights Env Variables vs Command Line Args\" will layout the prevailing differences. - Environment variables used for configuration overrides are named by prepending the the configuration element with the configuration section inclusive of sub-path, where sub-path's \".\"s are replaced with underscores. These configuration environment variable overrides must be specified using camel case. Here are two examples: Registry_Host for [Registry] Host = 'localhost' Clients_CoreData_Host for [Clients] [Clients.CoreData] Host = 'localhost' - Going forward, environmental variables that override command line options should be all uppercase. All values overriden get logged (indicating which configuration value or op param and the new value). Decision These features have been implemented (with some minor changes to be done) for consideration here: https://github.com/edgexfoundry/go-mod-bootstrap/compare/master...lenny-intel:SelfSeed2. This code branch will be removed once this ADR is approved and implemented on master. The implementation for self-seeding services and environmental overrides is already implemented (for Fuji) per this document in the application services and device services (and instituted in the SDKs of each). Backward compatibility Several aspects of this ADR contain backward compatibility issues for the device service and application service SDKs. Therefore, for the upcoming minor release, the following guidelines and expections are added to provide for backward compatibility. --registry= for Device SDKs As earlier versions of the device service SDKs accepted a URI for --registry, if specified on the command line, use the given URI as the address of the configuration provider. If both --configProvider and --registry specify URIs, then the service should log an error and exit. --registry (no \u2018=\u2019) and w/o --configProvider for both SDKs If a configProvider URI isn't specified, but --registry (w/out a URI) is specified, then the service will use the Registry provider information from its local configuration file for both configuration and registry providers. Env Var: edgex_registry= for all services (currently has been removed) Add it back and use value as if it was EDGEX_CONFIGURATION_PROVIDER and enable use of registry with same settings in URL. Default to http as it is in Fuji. Consequences Docker compose files will need to be changed to remove config seed. The main Snap will need to be changed to remove config seed. Config seed code (currently in edgex-go repo) is to be removed. Any service specific environmental overrides currently on config seed need to be moved to the specific service(s). The Docker configuration files and directory (example: https://github.com/edgexfoundry/edgex-go/blob/master/cmd/core-data/res/docker/configuration.toml) that are used to populate the config seed for Docker containers can be eliminated from all the services. In cmd/security-secretstore-setup, there is only a docker configuration.toml. This file will be moved rather than deleted. Documentation would need to reflect removal of config seed and \"self seeding\" process. Removes any potential issue with past race conditions (as experienced with the Edinburgh release) as each service is now responsible for its own configuration. There are still high availability concerns that need to be considered and not covered in this ADR at this time. Removes some confusion on the part of users as to why a service (config-seed) starts and immediately exits. Minimal impact to development cycles and release schedule Configuration endpoints in all services need to ensure the environmental variables are reflected in the configuration data returned (this is a system management impact). Docker files will need to be modified to remove setting profile=docker Docker compose files will need to be changed to add environmental overrides for removal of docker profiles. These should go in the global environment section of the compose files for those overrides that apply to all services. Example: # all common shared environment variables defined here: x-common-env-variables: &common-variables EDGEX_SECURITY_SECRET_STORE: \"false\" EDGEX_CONFIGURATION_PROVIDER: consul.http://edgex-core-consul:8500 Clients_CoreData_Host: edgex-core-data Clients_Logging_Host: edgex-support-logging Logging_EnableRemote: \"true\"","title":"Service Self Config Init & Config Seed Removal"},{"location":"design/adr/0005-Service-Self-Config/#service-self-config-init-config-seed-removal","text":"","title":"Service Self Config Init &amp; Config Seed Removal"},{"location":"design/adr/0005-Service-Self-Config/#status","text":"approved - TSC vote on 3/25/20 for Geneva release NOTE: this ADR does not address high availability considerations and concerns. EdgeX, in general, has a number of unanswered questions with regard to HA architecture and this design adds to those considerations.","title":"Status"},{"location":"design/adr/0005-Service-Self-Config/#context","text":"Since its debut, EdgeX has had a configuration seed service (config-seed) that, on start of EdgeX, deposits configuration for all the services into Consul (our configuration/registry service). For development purposes, or on resource constrained platforms, EdgeX can be run without Consul with services simply reading configuration from the filesystem. While this process has nominally worked for several releases of EdgeX, there has always been some issues with this extra initialization process (config-seed), not least of which are: - race conditions on the part of the services, as they bootstrap, coming up before the config-seed completes its deposit of configuration into Consul - how to deal with \"overrides\" such as environmental variable provided configuration overrides. As the override is often specific to a service but has to be in place for config-seed in order to take effect. - need for an additional service that is only there for init and then dies (confusing to users) NOTE - for historical purposes, it should be noted that config-seed only writes configuration into the configuration/registry service (Consul) once on the first start of EdgeX. On subsequent starts of EdgeX, config-seed checks to see if it has already populated the configuration/registry service and will not rewrite configuration again (unless the --overwrite flag is used). The design/architectural proposal, therefore, is: - removal of the config-seed service (removing cmd/config-seed from the edgex-go repository) - have each EdgeX micro service \"self seed\" - that is seed Consul with their own required configuration on bootstrap of the service. Details of that bootstrapping process are below.","title":"Context"},{"location":"design/adr/0005-Service-Self-Config/#command-line-options","text":"All EdgeX services support a common set of command-line options, some combination of which are required on startup for a service to interact with the rest of EdgeX. Command line options are not set by any configuration. Command line options include: --configProvider or -cp (the configuration provider location URL - prefixed with consul. - for example: -cp=consul.http://localhost:8500 ) --overwrite or -o (overwrite the configuration in the configuration provider) --file or -f (the configuration filename - configuration.toml is used by default if the configuration filename is not provided) --profile or -p (the name of a sub directory in the configuration directory in which a profile-specific configuration file is found. This has no default. If not specified, the configuration file is read from the configuration directory) --confdir or -c (the directory where the configuration file is found - ./res is used by default if the confdir is not specified, where \".\" is the convention on Linux/Unix/MacOS which means current directory) --registry or -r (string indicating use of the registry) The distinction of command line options versus configuration will be important later in this ADR. Two command line options (-o for overwrite and -r for registry) are not overridable by environmental variables. NOTES: Use of the --overwrite command line option should be used sparingly and with expert knowledge of EdgeX; in particular knowledge of how it operates and where/how it gets its configuration on restarts, etc. Ordinarily, --overwrite is provided as a means to support development needs. Use of --overwrite permanently in production enviroments is highly discouraged.","title":"Command Line Options"},{"location":"design/adr/0005-Service-Self-Config/#configuration-initialization","text":"Each service has (or shall have if not providing it already) a local configuration file. The service may use the local configuration file on initialization of the service (aka bootstrap of the service) depending on command line options and environmental variables (see below) provided at startup. Using a configuration provider When the configuration provider is specified, the service will call on the configuration provider (Consul) and check if the top-level (root) namespace for the service exists. If configuratation at the top-level (root) namespace exists, it indicates that the service has already populated its configuration into the configuration provider in a prior startup. If the service finds the top-level (root) namespace is already populated with configuration information it will then read that configuration information from the configuration provider under namespace for that service (and ignore what is in the local configuration file). If the service finds the top-level (root) namespace is not populated with configuration information, it will read its local configuration file and populate the configuration provider (under the namespace for the service) with configuration read from the local configuration file. A configuration provider can be specified with a command line argument (the -cp / --configProvider) or environment variable (the EDGEX_CONFIGURATION_PROVIDER environmental variable which overrides the command line argument). NOTE: the environmental variables are typically uppercase but there have been inconsistencies in environmental variable casing (example: edgex_registry). This should be considered and made consistent in a future major release. Using the local configuration file When a configuration provider isn't specified, the service just uses the configuration in its local configuration file. That is the service uses the configuration in the file associated with the profile, config filename and config file directory command line options or environmental variables. In this case, the service does not contact the configuration service (Consul) for any configuration information. NOTE: As the services now self seed and deployment specific changes can be made via environment overrides, it will no longer be necessary to have a Docker profile configuration file in each of the service directories (example: https://github.com/edgexfoundry/edgex-go/blob/master/cmd/core-data/res/docker/configuration.toml). See Consequences below. It will still be possible for users to use the profile mechanism to specify a Docker configuration, but it will no longer be required and not the recommended approach to providing Docker container specific configuration.","title":"Configuration Initialization"},{"location":"design/adr/0005-Service-Self-Config/#overrides","text":"Environment variables used to override configuration always take precedence whether configuration is being sourced locally or read from the config provider/Consul. Note - this means that a configuration value that is being overridden by an environment variable will always be the source of truth, even if the same configuration is changed directly in Consul. The name of the environmental variable must match the path names in Consul. NOTES: - Environmental variables overrides remove the need to change the \"docker\" profile in the res/docker/configuration.toml files - Allowing removal of 50% of the existing configuration.toml files. - The override rules in EdgeX between environmental variables and command line options may be counter intuitive compared to other systems. There appears to be no standard practice. Indeed, web searching \"Reddit & Starting Fights Env Variables vs Command Line Args\" will layout the prevailing differences. - Environment variables used for configuration overrides are named by prepending the the configuration element with the configuration section inclusive of sub-path, where sub-path's \".\"s are replaced with underscores. These configuration environment variable overrides must be specified using camel case. Here are two examples: Registry_Host for [Registry] Host = 'localhost' Clients_CoreData_Host for [Clients] [Clients.CoreData] Host = 'localhost' - Going forward, environmental variables that override command line options should be all uppercase. All values overriden get logged (indicating which configuration value or op param and the new value).","title":"Overrides"},{"location":"design/adr/0005-Service-Self-Config/#decision","text":"These features have been implemented (with some minor changes to be done) for consideration here: https://github.com/edgexfoundry/go-mod-bootstrap/compare/master...lenny-intel:SelfSeed2. This code branch will be removed once this ADR is approved and implemented on master. The implementation for self-seeding services and environmental overrides is already implemented (for Fuji) per this document in the application services and device services (and instituted in the SDKs of each).","title":"Decision"},{"location":"design/adr/0005-Service-Self-Config/#backward-compatibility","text":"Several aspects of this ADR contain backward compatibility issues for the device service and application service SDKs. Therefore, for the upcoming minor release, the following guidelines and expections are added to provide for backward compatibility. --registry= for Device SDKs As earlier versions of the device service SDKs accepted a URI for --registry, if specified on the command line, use the given URI as the address of the configuration provider. If both --configProvider and --registry specify URIs, then the service should log an error and exit. --registry (no \u2018=\u2019) and w/o --configProvider for both SDKs If a configProvider URI isn't specified, but --registry (w/out a URI) is specified, then the service will use the Registry provider information from its local configuration file for both configuration and registry providers. Env Var: edgex_registry= for all services (currently has been removed) Add it back and use value as if it was EDGEX_CONFIGURATION_PROVIDER and enable use of registry with same settings in URL. Default to http as it is in Fuji.","title":"Backward compatibility"},{"location":"design/adr/0005-Service-Self-Config/#consequences","text":"Docker compose files will need to be changed to remove config seed. The main Snap will need to be changed to remove config seed. Config seed code (currently in edgex-go repo) is to be removed. Any service specific environmental overrides currently on config seed need to be moved to the specific service(s). The Docker configuration files and directory (example: https://github.com/edgexfoundry/edgex-go/blob/master/cmd/core-data/res/docker/configuration.toml) that are used to populate the config seed for Docker containers can be eliminated from all the services. In cmd/security-secretstore-setup, there is only a docker configuration.toml. This file will be moved rather than deleted. Documentation would need to reflect removal of config seed and \"self seeding\" process. Removes any potential issue with past race conditions (as experienced with the Edinburgh release) as each service is now responsible for its own configuration. There are still high availability concerns that need to be considered and not covered in this ADR at this time. Removes some confusion on the part of users as to why a service (config-seed) starts and immediately exits. Minimal impact to development cycles and release schedule Configuration endpoints in all services need to ensure the environmental variables are reflected in the configuration data returned (this is a system management impact). Docker files will need to be modified to remove setting profile=docker Docker compose files will need to be changed to add environmental overrides for removal of docker profiles. These should go in the global environment section of the compose files for those overrides that apply to all services. Example: # all common shared environment variables defined here: x-common-env-variables: &common-variables EDGEX_SECURITY_SECRET_STORE: \"false\" EDGEX_CONFIGURATION_PROVIDER: consul.http://edgex-core-consul:8500 Clients_CoreData_Host: edgex-core-data Clients_Logging_Host: edgex-support-logging Logging_EnableRemote: \"true\"","title":"Consequences"},{"location":"design/adr/core/0003-V2-API-Principles/","text":"Geneva API Guiding Principles Status Accepted by EdgeX Foundry working groups as of Core Working Group meeting 16-Jan-2020 Context A redesign of the EdgeX Foundry API is proposed for the Geneva release. This is understood by the community to warrant a 2.0 release that will not be backward compatible. The goal is to rework the API using solid principles that will allow for extension over the course of several release cycles, avoiding the necessity of yet another major release version in a short period of time. Briefly, this effort grew from the acknowledgement that the current models used to facilitate requests and responses via the EdgeX Foundry API were legacy definitions that were once used as internal representations of state within the EdgeX services themselves. Thus if you want to add or update a device, you populate a full device model rather than a specific Add/UpdateDeviceRequest. Currently, your request model has the same definition, and thus validation constraints, as the response model because they are one and the same! It is desirable to separate and be specific about what is required for a given request, as well as its state validity, and the bare minimum that must be returned within a response. Following from that central need, other considerations have been used when designing this proposed API. These will be enumerated and briefly explained below. 1.) Transport-agnostic Define the request/response data transfer objects (DTO) in a manner whereby they can be used independent of transport. For example, although an OpenAPI doc is implicitly coupled to HTTP/REST, define the DTOs in such a way that they could also be used if the platform were to evolve to a pub/sub architecture. 2.) Support partial updates via PATCH Given a request to, for example, update a device the user should be able to update only some properties of the device. Previously this would require an endpoint for each individual property to be updated since the \"update device\" endpoint, facilitated by a PUT, would perform a complete replacement of the device's data. If you only wanted to update the LastConnected timestamp, then a separate endpoint for that property was required. We will leverage PATCH in order to update an entity and only those properties populated on the request will be considered. Properties that are missing or left blank will not be touched. 3.) Support multiple requests at once Endpoints for the addition or updating of data (POST/PATCH) should accept multiple requests at once. If it were desirable to add or update multiple devices with one request, for example, the API should facilitate this. 4.) Support multiple correlated responses at once Following from #3 above, each request sent to the endpoint must result in a corresponding response. In the case of HTTP/REST, this means if four requests are sent to a POST operation, the return payload will have four responses. Each response must expose a \"code\" property containing a numeric result for what occurred. These could be equivalent to HTTP status codes, for example. So while the overall call might succeed, one or more of the child requests may not have. It is up to the caller to examine each response and handle accordingly. In order to correlate each response to its original request, each request must be assigned its own ID (in GUID format). The caller can then tie a response to an individual request and handle the result accordingly, or otherwise track that a response to a given request was not received. 5.) Use of 207 HTTP Status (Multi-Result) In the case where an endpoint can support multiple responses, the returned HTTP code from a REST API will be 207 (Multi-status) 6.) Each service should provide a \"batch\" request endpoint In addition to use-case specific endpoints that you'd find in any REST API, each service should provide a \"batch\" endpoint that can take any kind of request. This is a generic endpoint that allows you to group requests of different types within a single call. For example, instead of having to call two endpoints to get two jobs done, you can call a single endpoint passing the specific requests and have them routed appropriately within the service. Also, when considering agnostic transport, the batch endpoint would allow for the definition and handling of \"GET\" equivalent DTOs which are now implicit in the format of a URL. 7.) GET endpoints returning a list of items must support pagination URL parameters must be supported for every GET endpoint to support pagination. These parameters should indicate the current page of results and the number of results on a page. Decision Commnunity has accepted the reasoning for the new API and the design principles outlined above. The approach will be to gradually implement the V2 API side-by-side with the current V1 APIs. We believe it will take more than a single release cycle to implement the new specification. Releases of that occur prior to the V2 API implementation completion will continue to be major versioned as 1.x. Subsequent to completion, releases will be major versioned as 2.x. Consequences Backward incompatibility with EdgeX Foundry's V1 API requires a major version increment (e.g. v2.x). Service-level testing (e.g. blackbox tests) needs to be rewritten. Specification-first development allows for different implementations of EdgeX services to be certified as \"EdgeX Compliant\" in reference to an objective standard. Transport-agnostic focus enables different architectural patterns (pub/sub versus REST) using the same data representation.","title":"Geneva API Guiding Principles"},{"location":"design/adr/core/0003-V2-API-Principles/#geneva-api-guiding-principles","text":"","title":"Geneva API Guiding Principles"},{"location":"design/adr/core/0003-V2-API-Principles/#status","text":"Accepted by EdgeX Foundry working groups as of Core Working Group meeting 16-Jan-2020","title":"Status"},{"location":"design/adr/core/0003-V2-API-Principles/#context","text":"A redesign of the EdgeX Foundry API is proposed for the Geneva release. This is understood by the community to warrant a 2.0 release that will not be backward compatible. The goal is to rework the API using solid principles that will allow for extension over the course of several release cycles, avoiding the necessity of yet another major release version in a short period of time. Briefly, this effort grew from the acknowledgement that the current models used to facilitate requests and responses via the EdgeX Foundry API were legacy definitions that were once used as internal representations of state within the EdgeX services themselves. Thus if you want to add or update a device, you populate a full device model rather than a specific Add/UpdateDeviceRequest. Currently, your request model has the same definition, and thus validation constraints, as the response model because they are one and the same! It is desirable to separate and be specific about what is required for a given request, as well as its state validity, and the bare minimum that must be returned within a response. Following from that central need, other considerations have been used when designing this proposed API. These will be enumerated and briefly explained below. 1.) Transport-agnostic Define the request/response data transfer objects (DTO) in a manner whereby they can be used independent of transport. For example, although an OpenAPI doc is implicitly coupled to HTTP/REST, define the DTOs in such a way that they could also be used if the platform were to evolve to a pub/sub architecture. 2.) Support partial updates via PATCH Given a request to, for example, update a device the user should be able to update only some properties of the device. Previously this would require an endpoint for each individual property to be updated since the \"update device\" endpoint, facilitated by a PUT, would perform a complete replacement of the device's data. If you only wanted to update the LastConnected timestamp, then a separate endpoint for that property was required. We will leverage PATCH in order to update an entity and only those properties populated on the request will be considered. Properties that are missing or left blank will not be touched. 3.) Support multiple requests at once Endpoints for the addition or updating of data (POST/PATCH) should accept multiple requests at once. If it were desirable to add or update multiple devices with one request, for example, the API should facilitate this. 4.) Support multiple correlated responses at once Following from #3 above, each request sent to the endpoint must result in a corresponding response. In the case of HTTP/REST, this means if four requests are sent to a POST operation, the return payload will have four responses. Each response must expose a \"code\" property containing a numeric result for what occurred. These could be equivalent to HTTP status codes, for example. So while the overall call might succeed, one or more of the child requests may not have. It is up to the caller to examine each response and handle accordingly. In order to correlate each response to its original request, each request must be assigned its own ID (in GUID format). The caller can then tie a response to an individual request and handle the result accordingly, or otherwise track that a response to a given request was not received. 5.) Use of 207 HTTP Status (Multi-Result) In the case where an endpoint can support multiple responses, the returned HTTP code from a REST API will be 207 (Multi-status) 6.) Each service should provide a \"batch\" request endpoint In addition to use-case specific endpoints that you'd find in any REST API, each service should provide a \"batch\" endpoint that can take any kind of request. This is a generic endpoint that allows you to group requests of different types within a single call. For example, instead of having to call two endpoints to get two jobs done, you can call a single endpoint passing the specific requests and have them routed appropriately within the service. Also, when considering agnostic transport, the batch endpoint would allow for the definition and handling of \"GET\" equivalent DTOs which are now implicit in the format of a URL. 7.) GET endpoints returning a list of items must support pagination URL parameters must be supported for every GET endpoint to support pagination. These parameters should indicate the current page of results and the number of results on a page.","title":"Context"},{"location":"design/adr/core/0003-V2-API-Principles/#decision","text":"Commnunity has accepted the reasoning for the new API and the design principles outlined above. The approach will be to gradually implement the V2 API side-by-side with the current V1 APIs. We believe it will take more than a single release cycle to implement the new specification. Releases of that occur prior to the V2 API implementation completion will continue to be major versioned as 1.x. Subsequent to completion, releases will be major versioned as 2.x.","title":"Decision"},{"location":"design/adr/core/0003-V2-API-Principles/#consequences","text":"Backward incompatibility with EdgeX Foundry's V1 API requires a major version increment (e.g. v2.x). Service-level testing (e.g. blackbox tests) needs to be rewritten. Specification-first development allows for different implementations of EdgeX services to be certified as \"EdgeX Compliant\" in reference to an objective standard. Transport-agnostic focus enables different architectural patterns (pub/sub versus REST) using the same data representation.","title":"Consequences"},{"location":"design/adr/device-service/0002-Array-Datatypes/","text":"Array Datatypes Design Status Context Decision Consequences Status Proposed Context The current data model does not directly provide for devices which provide array data. Small fixed-length arrays may be handled by defining multiple device resources - one for each element - and aggregating them via a resource command. Other array data may be passed using the Binary type. Neither of these approaches is ideal: the binary data is opaque and any service processing it would need specific knowledge to do so, and aggregation presents the device service implementation with a multiple-read request that could in many cases be better handled by a single request. This design adds arrays of primitives to the range of supported types in EdgeX. It comprises an extension of the DeviceProfile model, and an update to the definition of Reading. Decision DeviceProfile extension The permitted values of the Type field in PropertyValue are extended to include: \"BoolArray\", \"Uint8Array\", \"Uint16Array\", \"Uint32Array\", \"Uint64Array\", \"Int8Array\", Int16Array\", \"Int32Array\", \"Int64Array\", \"Float32Array\", \"Float64Array\" Readings Implementation in v2 API The value field of SimpleReading becomes an array of strings. For non-array types, an array of length 1 is created. Fallback position for v1 API In the v1 API, Reading.Value is a string representation of the data. If this is maintained, the representation for Array types will follow the JSON array syntax, ie [\"value1\", \"value2\", ...] Consequences Any service which processes Readings will need to be reworked to account for the new Reading type. Device Service considerations The API used for interfacing between device SDKs and devices service implementations contains a local representation of reading values. This will need to be updated in line with the changes outlined here. For C, this will involve an extension of the existing union type. For Go, additional fields may be added to the CommandValue structure. Processing of numeric data in the device service, ie offset , scale etc will not be applied to the values in an array.","title":"Array Datatypes Design"},{"location":"design/adr/device-service/0002-Array-Datatypes/#array-datatypes-design","text":"Status Context Decision Consequences","title":"Array Datatypes Design"},{"location":"design/adr/device-service/0002-Array-Datatypes/#status","text":"Proposed","title":"Status"},{"location":"design/adr/device-service/0002-Array-Datatypes/#context","text":"The current data model does not directly provide for devices which provide array data. Small fixed-length arrays may be handled by defining multiple device resources - one for each element - and aggregating them via a resource command. Other array data may be passed using the Binary type. Neither of these approaches is ideal: the binary data is opaque and any service processing it would need specific knowledge to do so, and aggregation presents the device service implementation with a multiple-read request that could in many cases be better handled by a single request. This design adds arrays of primitives to the range of supported types in EdgeX. It comprises an extension of the DeviceProfile model, and an update to the definition of Reading.","title":"Context"},{"location":"design/adr/device-service/0002-Array-Datatypes/#decision","text":"","title":"Decision"},{"location":"design/adr/device-service/0002-Array-Datatypes/#deviceprofile-extension","text":"The permitted values of the Type field in PropertyValue are extended to include: \"BoolArray\", \"Uint8Array\", \"Uint16Array\", \"Uint32Array\", \"Uint64Array\", \"Int8Array\", Int16Array\", \"Int32Array\", \"Int64Array\", \"Float32Array\", \"Float64Array\"","title":"DeviceProfile extension"},{"location":"design/adr/device-service/0002-Array-Datatypes/#readings","text":"","title":"Readings"},{"location":"design/adr/device-service/0002-Array-Datatypes/#implementation-in-v2-api","text":"The value field of SimpleReading becomes an array of strings. For non-array types, an array of length 1 is created.","title":"Implementation in v2 API"},{"location":"design/adr/device-service/0002-Array-Datatypes/#fallback-position-for-v1-api","text":"In the v1 API, Reading.Value is a string representation of the data. If this is maintained, the representation for Array types will follow the JSON array syntax, ie [\"value1\", \"value2\", ...]","title":"Fallback position for v1 API"},{"location":"design/adr/device-service/0002-Array-Datatypes/#consequences","text":"Any service which processes Readings will need to be reworked to account for the new Reading type.","title":"Consequences"},{"location":"design/adr/device-service/0002-Array-Datatypes/#device-service-considerations","text":"The API used for interfacing between device SDKs and devices service implementations contains a local representation of reading values. This will need to be updated in line with the changes outlined here. For C, this will involve an extension of the existing union type. For Go, additional fields may be added to the CommandValue structure. Processing of numeric data in the device service, ie offset , scale etc will not be applied to the values in an array.","title":"Device Service considerations"},{"location":"design/adr/device-service/0011-DeviceService-Rest-API/","text":"Device Service REST API Status proposed Context This ADR details the REST API to be provided by Device Service implementations in EdgeX version 2.x. As such, it supercedes the equivalent sections of the earlier \"Device Service Functional Requirements\" document. These requirements should be implemented as far as possible within the Device Service SDKs, but they also apply to any Device Service implementation. Decision Common endpoints The DS should provide the REST endpoints that are expected of all EdgeX microservices, specifically: config metrics ping version Callback Endpoint Methods callback/device PUT and POST callback/device/id/{id} DELETE callback/profile PUT and POST callback/profile/id/{id} DELETE callback/watcher PUT and POST callback/watcher/id/{id} DELETE parameter meaning {id} a database-generated object id These endpoints are used by the Core Metadata service to inform the device service of metadata updates. Endpoints are defined for each of the objects of interest to a device service, ie Devices, Device Profiles and Provision Watchers. On receipt of calls to these endpoints the device service should update its internal state accordingly. Object deletion When an object is deleted, the Metadata service makes a DELETE request to the relevant callback/{type}/id/{id} endpoint. Object creation and updates When an object is created or updated, the Metadata service makes a POST or PUT request respectively to the relevant callback/{type} endpoint. The payload of the request is the new or updated object. Device Endpoint Methods device/name/{name}/{command} GET and PUT device/{id}/{command} GET and PUT parameter meaning {id} a database-generated device id or {name} the name of the device {command} the command name The command specified must match a deviceCommand or deviceResource name in the device's profile body (for PUT ): An application/json SettingRequest, which is a set of key/value pairs where the keys are valid deviceResource names, and the values provide the command argument for that resource. Example: {\"AHU-TargetTemperature\": \"28.5\", \"AHU-TargetBand\": \"4.0\"} Return code Meaning 200 the command was successful 404 the specified device does not exist, or the command/resource is unknown 405 attempted write to a read-only resource 423 the specified device is locked (admin state) or disabled (operating state) 500 the device driver is unable to process the request response body : A successful GET operation will return a JSON-encoded Event, which contains one or more Readings. Example: {\"device\":\"Gyro\",\"origin\":1592405201763915855,\"readings\":[{\"name\":\"Xrotation\",\"value\":\"124\",\"origin\":1592405201763915855,\"valueType\":\"int32\"},{\"name\":\"Yrotation\",\"value\":\"-54\",\"origin\":1592405201763915855,\"valueType\":\"int32\"},{\"name\":\"Zrotation\",\"value\":\"122\",\"origin\":1592405201763915855,\"valueType\":\"int32\"}]} This endpoint is used for obtaining readings from a device, and for writing settings to a device. Data formats The values obtained when readings are taken, or used to make settings, are expressed as strings. Type EdgeX types Representation Boolean bool \"true\" or \"false\" Integer uint8-uint64 , int8-int64 Numeric string, eg \"-132\" Float float32 , float64 base64 encoded little-endian binary or decimal with exponent, eg \"1.234e-5\" String string string Binary bytes octet array Array boolarray , uint8array-uint64array , int8array-int64array , float32array , float64array JSON Array, eg \"[\"1\", \"34\", \"-5\"]\" Notes: - The presence of a Binary reading will cause the entire Event to be encoded using CBOR rather than JSON - The representation of a float is determined by the \"floatEncoding\" attribute of the device resource. \"base64\" is the default, \"eNotation\" will cause the float to be written as a decimal with exponent. Readings and Events A Reading represents a value obtained from a deviceResource. It contains the following fields Field name Description name The name of the deviceResource valueType The type of the data origin A timestamp indicating when the reading was taken value The reading value mediaType (Only for Binary readings) The MIME type of the data floatEncoding (Only for floats and arrays of floats) The float representation in use An Event represents the result of a GET command. If the command names a deviceResource, the Event will contain a single Reading. If the command names a deviceCommand, the Event will contain as many Readings as there are deviceResources listed in the deviceCommand. The fields of an Event are as follows: Field name Description device The name of the Device from which the Readings are taken origin The time at which the Event was created readings An array of Readings Query Parameters Calls to the device endpoints may include a Query String in the URL. This may be used to pass parameters relating to the request to the device service. Individual device services may define their own parameters to control specific behaviors. Parameters beginning with the prefix ds- are reserved to the Device SDKs and the following parameters are defined for GET requests: Parameter Valid Values Default Meaning ds-postevent \"yes\" or \"no\" \"no\" If set to yes, a successful GET will result in an event being posted to core-data ds-returnevent \"yes\" or \"no\" \"yes\" If set to no, there will be no Event returned in the http response Device States A Device in EdgeX has two states associated with it: the Administrative state and the Operational state. The Administrative state may be set to LOCKED (normally UNLOCKED ) to block access to the device for administrative reasons. The Operational state may be set to DISABLED (normally ENABLED ) to indicate that the device is not currently working. In either case access to the device via this endpoint will be denied and HTTP 423 (\"Locked\") will be returned. Data Transformations A number of simple data transformations may be defined in the deviceResource. The table below shows these transformations in the order in which they are applied to outgoing data, ie Readings. The transformations are inverted and applied in reverse order for incoming data. Transform Applicable reading types Effect mask Integers The reading is bitwise masked with the specified value. shift Integers The reading is bit-shifted by the specified value. Positive values indicate right-shift, negative for left. base Integers and Floats The reading is replaced by the specified value raised to the power of the reading. scale Integers and Floats The reading is multiplied by the specified value. offset Integers and Floats The reading is increased by the specified value. The operation of the mask transform on incoming data (a setting) is that the value to be set on the resource is the existing value bitwise-anded with the complement of the mask, bitwise-ored with the value specified in the request. ie, new-value = (current-value & !mask) | request-value The combination of mask and shift can therefore be used to access data contained in a subdivision of an octet. Assertions and Mappings Assertions are another attribute in a device resource's PropertyValue which specify a string value which the result is compared against. If the comparison fails, then the result is set to a string of the form \"Assertion failed for device resource: \\ , with value: \\ \" , this also has a side-effect of setting the device operatingstate to DISABLED . A 500 status code is also returned. Mappings may be defined in a deviceCommand. These allow Readings of string type to be remapped. Mappings are applied after assertions are checked, and are the final transformation before Readings are created. Mappings are also applied, but in reverse, to settings ( PUT request data). lastConnected timestamp Each Device has as part of its metadata a timestamp named lastConnected , this indicates the most recent occasion when the device was successfully interacted with. The device service should update this timestamp every time a GET or PUT operation succeeds, unless it has been configured not to do so (eg for performance reasons). Discovery Endpoint Methods discovery POST A call to this endpoint triggers the device discovery process, if enabled. See Discovery Design for details. Consequences Changes from v1.x API The callback endpoint is split according to the type of object being updated Callbacks for new and updated objects take the object in the request body The device/all form is removed GET requests take parameters controlling what is to be done with resulting Events, and the default behavior does not send the Event to core-data References OpenAPI definition of v2 API : https://github.com/edgexfoundry/device-sdk-go/blob/master/api/oas3.0/v2/device-sdk.yaml Device Service Functional Requirements (Geneva) : https://wiki.edgexfoundry.org/download/attachments/329488/edgex-device-service-requirements-v11.pdf?version=1&modificationDate=1591621033000&api=v2","title":"Device Service REST API"},{"location":"design/adr/device-service/0011-DeviceService-Rest-API/#device-service-rest-api","text":"","title":"Device Service REST API"},{"location":"design/adr/device-service/0011-DeviceService-Rest-API/#status","text":"proposed","title":"Status"},{"location":"design/adr/device-service/0011-DeviceService-Rest-API/#context","text":"This ADR details the REST API to be provided by Device Service implementations in EdgeX version 2.x. As such, it supercedes the equivalent sections of the earlier \"Device Service Functional Requirements\" document. These requirements should be implemented as far as possible within the Device Service SDKs, but they also apply to any Device Service implementation.","title":"Context"},{"location":"design/adr/device-service/0011-DeviceService-Rest-API/#decision","text":"","title":"Decision"},{"location":"design/adr/device-service/0011-DeviceService-Rest-API/#common-endpoints","text":"The DS should provide the REST endpoints that are expected of all EdgeX microservices, specifically: config metrics ping version","title":"Common endpoints"},{"location":"design/adr/device-service/0011-DeviceService-Rest-API/#callback","text":"Endpoint Methods callback/device PUT and POST callback/device/id/{id} DELETE callback/profile PUT and POST callback/profile/id/{id} DELETE callback/watcher PUT and POST callback/watcher/id/{id} DELETE parameter meaning {id} a database-generated object id These endpoints are used by the Core Metadata service to inform the device service of metadata updates. Endpoints are defined for each of the objects of interest to a device service, ie Devices, Device Profiles and Provision Watchers. On receipt of calls to these endpoints the device service should update its internal state accordingly.","title":"Callback"},{"location":"design/adr/device-service/0011-DeviceService-Rest-API/#object-deletion","text":"When an object is deleted, the Metadata service makes a DELETE request to the relevant callback/{type}/id/{id} endpoint.","title":"Object deletion"},{"location":"design/adr/device-service/0011-DeviceService-Rest-API/#object-creation-and-updates","text":"When an object is created or updated, the Metadata service makes a POST or PUT request respectively to the relevant callback/{type} endpoint. The payload of the request is the new or updated object.","title":"Object creation and updates"},{"location":"design/adr/device-service/0011-DeviceService-Rest-API/#device","text":"Endpoint Methods device/name/{name}/{command} GET and PUT device/{id}/{command} GET and PUT parameter meaning {id} a database-generated device id or {name} the name of the device {command} the command name The command specified must match a deviceCommand or deviceResource name in the device's profile body (for PUT ): An application/json SettingRequest, which is a set of key/value pairs where the keys are valid deviceResource names, and the values provide the command argument for that resource. Example: {\"AHU-TargetTemperature\": \"28.5\", \"AHU-TargetBand\": \"4.0\"} Return code Meaning 200 the command was successful 404 the specified device does not exist, or the command/resource is unknown 405 attempted write to a read-only resource 423 the specified device is locked (admin state) or disabled (operating state) 500 the device driver is unable to process the request response body : A successful GET operation will return a JSON-encoded Event, which contains one or more Readings. Example: {\"device\":\"Gyro\",\"origin\":1592405201763915855,\"readings\":[{\"name\":\"Xrotation\",\"value\":\"124\",\"origin\":1592405201763915855,\"valueType\":\"int32\"},{\"name\":\"Yrotation\",\"value\":\"-54\",\"origin\":1592405201763915855,\"valueType\":\"int32\"},{\"name\":\"Zrotation\",\"value\":\"122\",\"origin\":1592405201763915855,\"valueType\":\"int32\"}]} This endpoint is used for obtaining readings from a device, and for writing settings to a device.","title":"Device"},{"location":"design/adr/device-service/0011-DeviceService-Rest-API/#data-formats","text":"The values obtained when readings are taken, or used to make settings, are expressed as strings. Type EdgeX types Representation Boolean bool \"true\" or \"false\" Integer uint8-uint64 , int8-int64 Numeric string, eg \"-132\" Float float32 , float64 base64 encoded little-endian binary or decimal with exponent, eg \"1.234e-5\" String string string Binary bytes octet array Array boolarray , uint8array-uint64array , int8array-int64array , float32array , float64array JSON Array, eg \"[\"1\", \"34\", \"-5\"]\" Notes: - The presence of a Binary reading will cause the entire Event to be encoded using CBOR rather than JSON - The representation of a float is determined by the \"floatEncoding\" attribute of the device resource. \"base64\" is the default, \"eNotation\" will cause the float to be written as a decimal with exponent.","title":"Data formats"},{"location":"design/adr/device-service/0011-DeviceService-Rest-API/#readings-and-events","text":"A Reading represents a value obtained from a deviceResource. It contains the following fields Field name Description name The name of the deviceResource valueType The type of the data origin A timestamp indicating when the reading was taken value The reading value mediaType (Only for Binary readings) The MIME type of the data floatEncoding (Only for floats and arrays of floats) The float representation in use An Event represents the result of a GET command. If the command names a deviceResource, the Event will contain a single Reading. If the command names a deviceCommand, the Event will contain as many Readings as there are deviceResources listed in the deviceCommand. The fields of an Event are as follows: Field name Description device The name of the Device from which the Readings are taken origin The time at which the Event was created readings An array of Readings","title":"Readings and Events"},{"location":"design/adr/device-service/0011-DeviceService-Rest-API/#query-parameters","text":"Calls to the device endpoints may include a Query String in the URL. This may be used to pass parameters relating to the request to the device service. Individual device services may define their own parameters to control specific behaviors. Parameters beginning with the prefix ds- are reserved to the Device SDKs and the following parameters are defined for GET requests: Parameter Valid Values Default Meaning ds-postevent \"yes\" or \"no\" \"no\" If set to yes, a successful GET will result in an event being posted to core-data ds-returnevent \"yes\" or \"no\" \"yes\" If set to no, there will be no Event returned in the http response","title":"Query Parameters"},{"location":"design/adr/device-service/0011-DeviceService-Rest-API/#device-states","text":"A Device in EdgeX has two states associated with it: the Administrative state and the Operational state. The Administrative state may be set to LOCKED (normally UNLOCKED ) to block access to the device for administrative reasons. The Operational state may be set to DISABLED (normally ENABLED ) to indicate that the device is not currently working. In either case access to the device via this endpoint will be denied and HTTP 423 (\"Locked\") will be returned.","title":"Device States"},{"location":"design/adr/device-service/0011-DeviceService-Rest-API/#data-transformations","text":"A number of simple data transformations may be defined in the deviceResource. The table below shows these transformations in the order in which they are applied to outgoing data, ie Readings. The transformations are inverted and applied in reverse order for incoming data. Transform Applicable reading types Effect mask Integers The reading is bitwise masked with the specified value. shift Integers The reading is bit-shifted by the specified value. Positive values indicate right-shift, negative for left. base Integers and Floats The reading is replaced by the specified value raised to the power of the reading. scale Integers and Floats The reading is multiplied by the specified value. offset Integers and Floats The reading is increased by the specified value. The operation of the mask transform on incoming data (a setting) is that the value to be set on the resource is the existing value bitwise-anded with the complement of the mask, bitwise-ored with the value specified in the request. ie, new-value = (current-value & !mask) | request-value The combination of mask and shift can therefore be used to access data contained in a subdivision of an octet.","title":"Data Transformations"},{"location":"design/adr/device-service/0011-DeviceService-Rest-API/#assertions-and-mappings","text":"Assertions are another attribute in a device resource's PropertyValue which specify a string value which the result is compared against. If the comparison fails, then the result is set to a string of the form \"Assertion failed for device resource: \\ , with value: \\ \" , this also has a side-effect of setting the device operatingstate to DISABLED . A 500 status code is also returned. Mappings may be defined in a deviceCommand. These allow Readings of string type to be remapped. Mappings are applied after assertions are checked, and are the final transformation before Readings are created. Mappings are also applied, but in reverse, to settings ( PUT request data).","title":"Assertions and Mappings"},{"location":"design/adr/device-service/0011-DeviceService-Rest-API/#lastconnected-timestamp","text":"Each Device has as part of its metadata a timestamp named lastConnected , this indicates the most recent occasion when the device was successfully interacted with. The device service should update this timestamp every time a GET or PUT operation succeeds, unless it has been configured not to do so (eg for performance reasons).","title":"lastConnected timestamp"},{"location":"design/adr/device-service/0011-DeviceService-Rest-API/#discovery","text":"Endpoint Methods discovery POST A call to this endpoint triggers the device discovery process, if enabled. See Discovery Design for details.","title":"Discovery"},{"location":"design/adr/device-service/0011-DeviceService-Rest-API/#consequences","text":"","title":"Consequences"},{"location":"design/adr/device-service/0011-DeviceService-Rest-API/#changes-from-v1x-api","text":"The callback endpoint is split according to the type of object being updated Callbacks for new and updated objects take the object in the request body The device/all form is removed GET requests take parameters controlling what is to be done with resulting Events, and the default behavior does not send the Event to core-data","title":"Changes from v1.x API"},{"location":"design/adr/device-service/0011-DeviceService-Rest-API/#references","text":"OpenAPI definition of v2 API : https://github.com/edgexfoundry/device-sdk-go/blob/master/api/oas3.0/v2/device-sdk.yaml Device Service Functional Requirements (Geneva) : https://wiki.edgexfoundry.org/download/attachments/329488/edgex-device-service-requirements-v11.pdf?version=1&modificationDate=1591621033000&api=v2","title":"References"},{"location":"design/adr/devops/0007-Release-Automation/","text":"Release Automation Status Approved by TSC 04/08/2020 Context EdgeX Foundry is a framework composed of microservices to ease development of IoT/Edge solutions. With the framework getting richer, project growth, the number of artifacts to be released has increased. This proposal outlines a method for automating the release process for the base artifacts. Requirements Release Artifact Definition For the scope of Geneva release artifact types are defined as: GitHub tags in the repositories. Docker images in our Nexus repository and Docker hub. Snaps in the Snapcraft store. This list is likely to expand in future releases. General Requirements As the EdgeX Release Czar I gathered the following requirements for automating this part of the release. The release automation needs a manual trigger to be triggered by the EdgeX Release Czar or the Linux Foundation Release Engineers. The goal of this automation is to have a \"push button\" release mechanism to reduce human error in our release process. Release artifacts can come from one or more GitHub repositories at a time. GitHub repositories can have one or more release artifact types to release. GitHub repositories can have one or more artifacts of a specific type to release. (For example: The mono repository, edgex-go, has more than 20 docker images to release.) GitHub repositories may be released at different times. (For example: Application and Device service repositories can be released on a different day than the Core services in the mono repository.) Ability to track multiple release streams for the project. An audit trail history for releases. Location The code that will manage the release automation for EdgeX Foundry will live in a repository called cd-management . This repository will have a branch named release that will track the releases of artifacts off the master branch of the EdgeX Foundry repositories. Multiple Release Streams EdgeX Foundry has this idea of multple release streams that basically coincides with different named branches in GitHub. For the majority of the main releases we will be targeting those off the master branch. In our cd-management repository we will have a release branch that will track the master branches EdgeX repositories. In the future we will mark a specific release for long term support (LTS). When this happens we will have to branch off master in the EdgeX repositories and create a separate release stream for the LTS. The suggestion at that point will be to branch off the release branch in cd-management as well and use this new release branch to track the LTS branches in the EdgeX repositories. Release Flow Go Modules, Device and Application SDKs During Development Go modules, Application and Device SDKs only release a GitHub tag as their release. Go modules are set up to automatically release a new patch version on every merge into the master branch of the repository. (IE: 1.0.0 -> 1.0.1) For Application and Device SDKs we increment a developmental version tag. (IE: 1.0.0-dev.1 -> 1.0.0-dev.2) Release The release automation for go modules is used to set a new version that increases the major or minor version for the module. (IE: 1.0.0 -> 1.1.0) For the Application and Device SDKs it is used to set the final release version. (IE: 1.0.0-dev.X -> 1.0.0) Application, Device Services and Supporting Docker Images During Development For the Device, Application services and supporting docker images we release Github tags, docker images and snaps. On every merge to the master branch we will do the following; increment a developmental version tag on GitHub, (IE: 1.0.0-dev.1 -> 1.0.0-dev.2), stage docker images in our Nexus repository (docker.staging) and snaps will be pushed to the edge (experimental) and beta (QA) channels in the Snapcraft store. Release The release automation for the Application and Device services is the same as the services found in the edgex-go repository. Core Services During Development For the Core services we release Github tags, docker images and snaps. On every merge to the master branch we will do the following; increment a developmental version tag on GitHub, (IE: 1.0.0-dev.1 -> 1.0.0-dev.2), stage docker images in our Nexus repository (docker.staging). Snaps will be pushed daily to the edge (experimental) and beta (QA) channels in the Snapcraft store because the core services snap can take up to a hour and half to build. Release The release automation will need to do the following: Set version tag on GitHub. (IE: 1.0.0-dev.X -> 1.0.0) Promote docker images in our Nexus repository from docker.staging to docker.release and public Docker hub. Promote snaps from the beta (QA) channel to the release channel in the Snapcraft store.","title":"Release Automation"},{"location":"design/adr/devops/0007-Release-Automation/#release-automation","text":"","title":"Release Automation"},{"location":"design/adr/devops/0007-Release-Automation/#status","text":"Approved by TSC 04/08/2020","title":"Status"},{"location":"design/adr/devops/0007-Release-Automation/#context","text":"EdgeX Foundry is a framework composed of microservices to ease development of IoT/Edge solutions. With the framework getting richer, project growth, the number of artifacts to be released has increased. This proposal outlines a method for automating the release process for the base artifacts.","title":"Context"},{"location":"design/adr/devops/0007-Release-Automation/#requirements","text":"","title":"Requirements"},{"location":"design/adr/devops/0007-Release-Automation/#release-artifact-definition","text":"For the scope of Geneva release artifact types are defined as: GitHub tags in the repositories. Docker images in our Nexus repository and Docker hub. Snaps in the Snapcraft store. This list is likely to expand in future releases.","title":"Release Artifact Definition"},{"location":"design/adr/devops/0007-Release-Automation/#general-requirements","text":"As the EdgeX Release Czar I gathered the following requirements for automating this part of the release. The release automation needs a manual trigger to be triggered by the EdgeX Release Czar or the Linux Foundation Release Engineers. The goal of this automation is to have a \"push button\" release mechanism to reduce human error in our release process. Release artifacts can come from one or more GitHub repositories at a time. GitHub repositories can have one or more release artifact types to release. GitHub repositories can have one or more artifacts of a specific type to release. (For example: The mono repository, edgex-go, has more than 20 docker images to release.) GitHub repositories may be released at different times. (For example: Application and Device service repositories can be released on a different day than the Core services in the mono repository.) Ability to track multiple release streams for the project. An audit trail history for releases.","title":"General Requirements"},{"location":"design/adr/devops/0007-Release-Automation/#location","text":"The code that will manage the release automation for EdgeX Foundry will live in a repository called cd-management . This repository will have a branch named release that will track the releases of artifacts off the master branch of the EdgeX Foundry repositories.","title":"Location"},{"location":"design/adr/devops/0007-Release-Automation/#multiple-release-streams","text":"EdgeX Foundry has this idea of multple release streams that basically coincides with different named branches in GitHub. For the majority of the main releases we will be targeting those off the master branch. In our cd-management repository we will have a release branch that will track the master branches EdgeX repositories. In the future we will mark a specific release for long term support (LTS). When this happens we will have to branch off master in the EdgeX repositories and create a separate release stream for the LTS. The suggestion at that point will be to branch off the release branch in cd-management as well and use this new release branch to track the LTS branches in the EdgeX repositories.","title":"Multiple Release Streams"},{"location":"design/adr/devops/0007-Release-Automation/#release-flow","text":"","title":"Release Flow"},{"location":"design/adr/devops/0007-Release-Automation/#go-modules-device-and-application-sdks","text":"","title":"Go Modules, Device and Application SDKs"},{"location":"design/adr/devops/0007-Release-Automation/#during-development","text":"Go modules, Application and Device SDKs only release a GitHub tag as their release. Go modules are set up to automatically release a new patch version on every merge into the master branch of the repository. (IE: 1.0.0 -> 1.0.1) For Application and Device SDKs we increment a developmental version tag. (IE: 1.0.0-dev.1 -> 1.0.0-dev.2)","title":"During Development"},{"location":"design/adr/devops/0007-Release-Automation/#release","text":"The release automation for go modules is used to set a new version that increases the major or minor version for the module. (IE: 1.0.0 -> 1.1.0) For the Application and Device SDKs it is used to set the final release version. (IE: 1.0.0-dev.X -> 1.0.0)","title":"Release"},{"location":"design/adr/devops/0007-Release-Automation/#application-device-services-and-supporting-docker-images","text":"","title":"Application, Device Services and Supporting Docker Images"},{"location":"design/adr/devops/0007-Release-Automation/#during-development_1","text":"For the Device, Application services and supporting docker images we release Github tags, docker images and snaps. On every merge to the master branch we will do the following; increment a developmental version tag on GitHub, (IE: 1.0.0-dev.1 -> 1.0.0-dev.2), stage docker images in our Nexus repository (docker.staging) and snaps will be pushed to the edge (experimental) and beta (QA) channels in the Snapcraft store.","title":"During Development"},{"location":"design/adr/devops/0007-Release-Automation/#release_1","text":"The release automation for the Application and Device services is the same as the services found in the edgex-go repository.","title":"Release"},{"location":"design/adr/devops/0007-Release-Automation/#core-services","text":"","title":"Core Services"},{"location":"design/adr/devops/0007-Release-Automation/#during-development_2","text":"For the Core services we release Github tags, docker images and snaps. On every merge to the master branch we will do the following; increment a developmental version tag on GitHub, (IE: 1.0.0-dev.1 -> 1.0.0-dev.2), stage docker images in our Nexus repository (docker.staging). Snaps will be pushed daily to the edge (experimental) and beta (QA) channels in the Snapcraft store because the core services snap can take up to a hour and half to build.","title":"During Development"},{"location":"design/adr/devops/0007-Release-Automation/#release_2","text":"The release automation will need to do the following: Set version tag on GitHub. (IE: 1.0.0-dev.X -> 1.0.0) Promote docker images in our Nexus repository from docker.staging to docker.release and public Docker hub. Promote snaps from the beta (QA) channel to the release channel in the Snapcraft store.","title":"Release"},{"location":"design/adr/devops/0010-Release-Artifacts/","text":"Release Artifacts Status In Review 06/10/2020 Context During the Geneva release of EdgeX Foundry the DevOps WG transformed the CI/CD process with new Jenkins pipeline functionality. After this new functionality was added we also started adding release automation. This new automation is outlined in ADR 0007 Release Automation. However, in ADR 0007 Release Automation only three release artifact types are outlined. This document is meant to be a living document to try to outlines all currently supported artifacts associated with an EdgeX Foundry release, and should be updated if/when this list changes. Release Artifact Types Docker Images Tied to Code Release? Yes Docker images are released for every named release of EdgeX Foundry. During development the community releases images to the docker.staging repository in Nexus . At the time of release we promote the last tested image from docker.staging to docker.release . In addition to that we will publish the docker image on DockerHub . Nexus Retention Policy docker.snapshots Retention Policy: 90 days since last download Contains: Docker images that are not expected to be released. This contains images to optimize the builds in the CI infrastructure. The definitions of these docker images can be found in the edgexfoundry/ci-build-images Github repository. Docker Tags Used: Version, Latest docker.staging Retention Policy: 180 days since last download Contains: Docker images built for potential release and testing purposes during development. Docker Tags Used: Version (ie: v1.x), Release Branch (master, fuji, etc), Latest docker.release Retention Policy: No automatic removal. Requires TSC approval to remove images from this repository. Contains: Officially released docker images for EdgeX. Docker Tags Used:\u2022Version (ie: v1.x), Latest Nexus Cleanup Policies Reference Docker Compose Files Tied to Code Release? Yes Docker compose files are released alongside the docker images for every release of EdgeX Foundry. During development the community maintains compose files a folder named nightly-build . These compose files are meant to be used by our testing frameworks. At the time of release the community makes compose files for that release in a folder matching it's name. (ie: geneva ) Github Page: EdgeX Docs Tied to Code Release? No EdgeX Foundry releases a set of documentation for our project at http://docs.edgexfoundry.org . This page is a Github page that is managed by the edgex/foundry/edgex-docs Github repository. As a community we make our best effort to keep these docs up to date. On this page we are also versioning the docs with the semantic versions of the named releases. As a community we try to version our documentation site shortly after the official release date but documentation changes are addressed as we find them throughout the release cycle. GitHub Tags Tied to Code Release? Yes, for the final semantic version Github tags are used to track the releases of EdgeX Foundry. During development the tags are incremented automatically for each commit using a development suffix (ie: v1.1.1-dev.1 -> v1.1.1-dev.2 ). At the time of release we release a tag with the final semantic version (ie: v1.1.1 ). Snaps Tied to Code Release? Yes Snaps are released for every named release of EdgeX Foundry. During development the community stages snaps to the latest/edge channel of the Snapcraft Store . At the time of code freeze we will promote the snaps from latest/edge to the latest/beta amd latest/candidate channels as beta release. This beta release is to trigger validation of the release candidate. At the time of release we will promote the snaps from latest/beta to latest/stable . In addition we also create a named release track for the release. (ie: geneva/stable ). SwaggerHub API Docs Tied to Code Release? No In addition to our documentation site EdgeX foundry also releases our API specifications on Swaggerhub. Testing Framework Tied to Code Release? Yes The EdgeX Foundry community has a set of tests we maintain to do regression testing during development this framework is tracking the master branch of the components of EdgeX. At the time of release we will update the testing frameworks to point at the released Github tags and add a version tag to the testing frameworks themselves. This creates a snapshot of testing framework at the time of release for validation of the official release. Known Build Dependencies for EdgeX Foundry There are some internal build dependencies within the EdgeX Foundry organization. When building artifacts for validation or a release you will need to take into the account the build dependencies to make sure you build them in the correct order. Edgex-go Snap: Has dependencies on app-service-configurable, device-virtual-go and support-rulesengine because they are included in the snap. Application services have a dependency on the Application services SDK. Go Device services have a dependency on the Go Device SDK. C Device services have a dependency on the C Device SDK. Decision Consequences This document is meant to be a living document of all the release artifacts of EdgeX Foundry. With this ADR we would have a good understanding on what needs to be released and when they are released. Without this document this information will remain tribal knowledge within the community.","title":"Release Artifacts"},{"location":"design/adr/devops/0010-Release-Artifacts/#release-artifacts","text":"","title":"Release Artifacts"},{"location":"design/adr/devops/0010-Release-Artifacts/#status","text":"In Review 06/10/2020","title":"Status"},{"location":"design/adr/devops/0010-Release-Artifacts/#context","text":"During the Geneva release of EdgeX Foundry the DevOps WG transformed the CI/CD process with new Jenkins pipeline functionality. After this new functionality was added we also started adding release automation. This new automation is outlined in ADR 0007 Release Automation. However, in ADR 0007 Release Automation only three release artifact types are outlined. This document is meant to be a living document to try to outlines all currently supported artifacts associated with an EdgeX Foundry release, and should be updated if/when this list changes.","title":"Context"},{"location":"design/adr/devops/0010-Release-Artifacts/#release-artifact-types","text":"","title":"Release Artifact Types"},{"location":"design/adr/devops/0010-Release-Artifacts/#docker-images","text":"Tied to Code Release? Yes Docker images are released for every named release of EdgeX Foundry. During development the community releases images to the docker.staging repository in Nexus . At the time of release we promote the last tested image from docker.staging to docker.release . In addition to that we will publish the docker image on DockerHub .","title":"Docker Images"},{"location":"design/adr/devops/0010-Release-Artifacts/#nexus-retention-policy","text":"","title":"Nexus Retention Policy"},{"location":"design/adr/devops/0010-Release-Artifacts/#dockersnapshots","text":"Retention Policy: 90 days since last download Contains: Docker images that are not expected to be released. This contains images to optimize the builds in the CI infrastructure. The definitions of these docker images can be found in the edgexfoundry/ci-build-images Github repository. Docker Tags Used: Version, Latest","title":"docker.snapshots"},{"location":"design/adr/devops/0010-Release-Artifacts/#dockerstaging","text":"Retention Policy: 180 days since last download Contains: Docker images built for potential release and testing purposes during development. Docker Tags Used: Version (ie: v1.x), Release Branch (master, fuji, etc), Latest","title":"docker.staging"},{"location":"design/adr/devops/0010-Release-Artifacts/#dockerrelease","text":"Retention Policy: No automatic removal. Requires TSC approval to remove images from this repository. Contains: Officially released docker images for EdgeX. Docker Tags Used:\u2022Version (ie: v1.x), Latest Nexus Cleanup Policies Reference","title":"docker.release"},{"location":"design/adr/devops/0010-Release-Artifacts/#docker-compose-files","text":"Tied to Code Release? Yes Docker compose files are released alongside the docker images for every release of EdgeX Foundry. During development the community maintains compose files a folder named nightly-build . These compose files are meant to be used by our testing frameworks. At the time of release the community makes compose files for that release in a folder matching it's name. (ie: geneva )","title":"Docker Compose Files"},{"location":"design/adr/devops/0010-Release-Artifacts/#github-page-edgex-docs","text":"Tied to Code Release? No EdgeX Foundry releases a set of documentation for our project at http://docs.edgexfoundry.org . This page is a Github page that is managed by the edgex/foundry/edgex-docs Github repository. As a community we make our best effort to keep these docs up to date. On this page we are also versioning the docs with the semantic versions of the named releases. As a community we try to version our documentation site shortly after the official release date but documentation changes are addressed as we find them throughout the release cycle.","title":"Github Page: EdgeX Docs"},{"location":"design/adr/devops/0010-Release-Artifacts/#github-tags","text":"Tied to Code Release? Yes, for the final semantic version Github tags are used to track the releases of EdgeX Foundry. During development the tags are incremented automatically for each commit using a development suffix (ie: v1.1.1-dev.1 -> v1.1.1-dev.2 ). At the time of release we release a tag with the final semantic version (ie: v1.1.1 ).","title":"GitHub Tags"},{"location":"design/adr/devops/0010-Release-Artifacts/#snaps","text":"Tied to Code Release? Yes Snaps are released for every named release of EdgeX Foundry. During development the community stages snaps to the latest/edge channel of the Snapcraft Store . At the time of code freeze we will promote the snaps from latest/edge to the latest/beta amd latest/candidate channels as beta release. This beta release is to trigger validation of the release candidate. At the time of release we will promote the snaps from latest/beta to latest/stable . In addition we also create a named release track for the release. (ie: geneva/stable ).","title":"Snaps"},{"location":"design/adr/devops/0010-Release-Artifacts/#swaggerhub-api-docs","text":"Tied to Code Release? No In addition to our documentation site EdgeX foundry also releases our API specifications on Swaggerhub.","title":"SwaggerHub API Docs"},{"location":"design/adr/devops/0010-Release-Artifacts/#testing-framework","text":"Tied to Code Release? Yes The EdgeX Foundry community has a set of tests we maintain to do regression testing during development this framework is tracking the master branch of the components of EdgeX. At the time of release we will update the testing frameworks to point at the released Github tags and add a version tag to the testing frameworks themselves. This creates a snapshot of testing framework at the time of release for validation of the official release.","title":"Testing Framework"},{"location":"design/adr/devops/0010-Release-Artifacts/#known-build-dependencies-for-edgex-foundry","text":"There are some internal build dependencies within the EdgeX Foundry organization. When building artifacts for validation or a release you will need to take into the account the build dependencies to make sure you build them in the correct order. Edgex-go Snap: Has dependencies on app-service-configurable, device-virtual-go and support-rulesengine because they are included in the snap. Application services have a dependency on the Application services SDK. Go Device services have a dependency on the Go Device SDK. C Device services have a dependency on the C Device SDK.","title":"Known Build Dependencies for EdgeX Foundry"},{"location":"design/adr/devops/0010-Release-Artifacts/#decision","text":"","title":"Decision"},{"location":"design/adr/devops/0010-Release-Artifacts/#consequences","text":"This document is meant to be a living document of all the release artifacts of EdgeX Foundry. With this ADR we would have a good understanding on what needs to be released and when they are released. Without this document this information will remain tribal knowledge within the community.","title":"Consequences"},{"location":"design/adr/security/0008-Secret-Creation-and-Distribution/","text":"Creation and Distribution of Secrets Status proposed Context This ADR seeks to clarify and prioritize the secret handling approach taken by EdgeX. EdgeX microservices need a number of secrets to be created and distributed in order to create a functional, secure system. Among these secrets are: Privileged administrator passwords (such as a database superuser password) Service account passwords (e.g. non-privileged database accounts) PKI private keys There is a lack of consistency on how secrets are created and distributed to EdgeX microservices, and when developers need to add new components to the system, it is unclear on what the preferred approach should be. This document assumes a threat model wherein the EdgeX services are sandboxed (such as in a snap or a container) and the host system is trusted, and all services running in a single snap share a trust boundary. Terms The following terms will be helpful for understading the subsequent discussion: SECRETSLOC is a protected file system path where bootstrapping secrets are stored. While EdgeX implements a sophisticated secret handling mechanism, that mechanism itself requires secrets. For example, every microservice that talks to Vault must have its own unique secret to authenticate: Vault itself cannot be used to distribute these secrets. SECRETSLOC fulfills the role that the non-routable instance data IP address, 169.254.169.254, fulfills in the public cloud: delivery of bootstrapping secrets. As EdgeX does not have a hypervisor nor virtual machines for this purpose, a protected file system path is used instead. SECRETSLOC is implementation-dependent. A desirable feature of SECRETSLOC would be that data written here is kept in RAM and is not persisted to storage media. This property is not achieveable in all circumstances. For Docker, a list of suggested paths--in preference order--is: /run/edgex/secrets (a tmpfs volume on a Linux host) /tmp/edgex/secrets (a temporary file area on Linux and MacOS hosts) A persistent docker volume (use when host bind mounts are not available) For snaps, a list of suggested paths-in preference order--is: * /run/snap. $SNAP_NAME / (a tmpfs volume on a Linux host) * $SNAP_DATA /secrets (a snap-specific persistent data area) * TBD (a content interface that allows for sharing of secrets from the core snap) Current practices survey A survey on the existing EdgeX secrets reveals the following appoaches. A designation of \"compliant\" means that the current implementation is aligned with the recommended practices documented in the next section. A designation of \"non-compliant\" means that the current implementation uses an implemention mechanism outside of the recommended practices documented in the next section. A \"non-compliant\" implementation is a candidate for refactoring to bring the implementation into conformance with the recommended practices. System-managed secrets PKI private keys Docker: PKI generated by standalone utility every cold start of the framework. Distribution via SECRETSLOC . (Compliant.) Snaps: PKI generated by standalone utility every cold start of the framework. Deployed to SECRETSLOC . (Compliant.) Secret store master password Docker: Distribution via persistent docker volume. (Non-compliant.) Snaps: Stored in $SNAP_DATA/config/security-secrets-setup/res . (Non-compliant.) Secret store per-service authentication tokens Docker: Distribution via SECRETSLOC generated every cold start of the framework. (Compliant.) Snaps: Distribution via SECRETSLOC , generated every cold start of the framework. (Compliant.) Postgres superuser password Docker: Hard-coded into docker-compose file, checked in to source control. (Non-compliant.) Snaps: Generated at snap install time via \"apg\" (\"automatic password generator\") tool, installed into Postgres, cached to $SNAP_DATA/config/postgres/kongpw (non-compliant), and passed to Kong via $KONG_PG_PASSWORD . MongoDB service account passwords Docker: Direct consumption from secret store. (Compliant.) Snaps: Direct consumption from secret store. (Compliant.) Redis authentication password Docker: Server--staged to secrets volume and injected via command line. (Non-compliant.). Clients--direct consumption from secret store. (Compliant.) Snaps: Server--staged to $SNAP_DATA/secrets/edgex-redis/redis5-password and injected via command line. (Non-compliant.). Clients--direct consumption from secret store. (Compliant.) Kong client authentication tokens Docker: System of reference is unencrypted Postgres database. (Non-compliant.) Snaps: System of reference is unencrypted Postgres database. (Non-compliant.) Note: in the current implementation, Consul is being operated as a public service. Consul will be a subject of a future \"bootstrapping ADR\" due to its role in serivce location. User-managed secrets User-managed secrets functionality is provided by app-functions-sdk-go . If security is enabled, secrets are retrieved from Vault. If security is disabled, secrets are retreived from the configuration provider. If the configuration provider is not available, secrets are read from the underlying .toml . It is taken as granted in this ADR that secrets originating in the configuration provider or from .toml configuration files are not secret. The fallback mechanism is provided as a convienience to the developer, who would otherwise have to litter their code with \"if (isSecurityEnabled())\" logic leading to implementation inconsistencies. The central database credential is supplied by GetDatabaseCredentials() and returns the database credential assigned to app-service-configurable . If security is enabled, database credentials are retreived using the standard flow. If security is disabled, secrets are retreived from the configuration provider from a special section called [Writable.InsecureSecrets] . If not found there, the configuration provider is searched for credentials stored in the legacy [Databases.Primary] section using the Username and Password keys. Each user application has its own exclusive-use area of the secret store that is accessed via GetSecrets() . If security is enabled, secret requests are passed along to go-mod-secrets using an application-specific access token. If security is disabled, secret requets are made to the configuration provider from the [Writable.InsecureSecrets] section. There is no fallback configuration location. As user-managed secrets have no framework support for initialization, a special StoreSecrets() method is made available to the application for the application to initialize its own secrets. This method is only available in security-enabled mode. No changes to user-managed secrets are being proposed in this ADR. Decision Creation of secrets Management of hardware-bound secrets is platform-specific and out-of-scope for the EdgeX framework. EdgeX open source will contain only the necessary hooks to integrate platform-specific functionality. For software-managed secrets, the system of referece of secrets in EdgeX is the EdgeX secret store. The EdgeX secret store provides for encryption of secrets at rest. This term means that if a secret is replicated, the EdgeX secret store is the authoritative source of truth of the secret. Whenever possible, the EdgeX secret store should also be the record of origin of a secret as well. This means creating secrets inside of the EdgeX secret store is preferrable to importing an externally-created secret into the secret store. This can often be done for framework-managed secrets, but not possible for user-managed secrets. Choosing between alternative forms of secrets When given a choice between plain-text secrets and cryptographic keys, cryptographic keys should be preferred. An example situation would be the introduction of an MQTT message broker. A broker may support both TLS client authentication as well as username/password authentication. In such a situation, TLS client authentication would be preferred: The cryptographic key is typically longer in bits than a plain-text secret. A plain-text secret will require transport encryption in order to protect confidentiality of the secret, such as server-side TLS. Use of TLS client authentication typically eliminates the need for additional assets on the server side (such as a password database) to authenticate the client, by relying on digital signature instead. TLS client authentication should not be used unless there is a capability to revoke a compromised certificate, such as by replacing the certificate authority, or providing a certificate revokation list to the server. If certificate revokation is not supported, plain-text secrets (such as username/password) should be used instead, as they are typically easier to revoke. Distribution and consumption of secrets Prohibited practices Use of hard-coded secrets is an instance of CWE-798: Use of hard-coded credentials and is not allowed. A hard-coded secret is a secret that is the same across multiple EdgeX instances. Hard-coded secrets make devices susceptible to BORE (break-once-run-everywhere) attacks, where collections of machines can compromised by a single replicated secret. Specific cases where this is likely to come up are: Secrets embedded in source control EdgeX is an open-source project. Any secret that is present in an EdgeX repository is public to the world, and therefore not a secret, by definition. Configuration files, such as .toml files, .json files, .yaml files (including docker-compose.yml ) are specific instances of this practice. Secrets embedded in binaries Binaries are usually not protected against confidentiality threats, and binaries can be easily reverse-engineered to find any secrets therein. Binaries included compile executables as well as Docker images. Recommended practices Direct consumption from process-to-process interaction with secret store This approach is only possible for components that have native support for Hashicorp Vault . This includes any EdgeX service that links to go-mod-secrets. For example, if secretClient is an instance of the go-mod-secrets secret store client: secrets , err := secretClient . GetSecrets ( \"myservice\" , \"username\" , \"password\" ) The above code will retrieve the username and password properties of the myservice secret. Dynamic injection of secret into process environment space Environment variables are part of a process' environment block and are mapped into a process' memory. In this scenario, an intermediary makes a connection to the secret store to fetch a secret, store it into an environment variable, and then launches a target executable, thereby passing the secret in-memory to the target process. Existing examples of this functionality include vaultenv , envconsul , or env-aws-params . These tools authenticate to a remote network service, inject secrets into the process environment, and then exec's a replacment process that inherits the secret-enriched enviornment block. There are a few potential risks with this approach: Environment blocks are passed to child processes by default. Environment-variable-sniffing malware (introduced by compromised 3rd party libaries) is a proven attack method. Dynamic injection of secret into container-scoped tmpfs volume An example of this approach is consul-template . This approach is useful when a secret is required to be in a configuration file and cannot be passed via an environment variable or directly consumed from a secret store. Distribution via SECRETSLOC This option is the most widely supported secret distribution mechanism by container orchestrators. EdgeX supports runtime environments such as standard Docker and snaps that have no built-in secret management features. Generic Docker does not have a built-in secrets mechanism. Manual configuration of a SECRETSLOC should utilize either a host file file system path or a Docker volume. Snaps also do not have a built-in secrets mechanism. The options for SECRETSLOC are limited to designated snap-writable directories. For comparison: Docker Swarm: Swarm swarm mode is not officially supported by the EdgeX project. Docker Swarm secrets are shared via the /run/secrets volume, which is a Linux tmpfs volume created on the host and shared with the container. For an example of Docker Swarm secrets, see the docker-compose secrets stanza . Secrets distributed in this manner become part of the RaftDB, and thus it becomes necessary to enable swarm autolock mode, which prevents the Raft database encryption key from being stored plaintext on disk. Swarm secrets have an additional limitation in that they are not mutable at runtime. Kubernetes: Kubernetes is not officially supported by the EdgeX project. Kubernetes also supports the secrets volume approach, though the secrets volume can be mounted anywhere in the container namespace. For an example of Kubernetes secrets volumes, see the Kubernetes secrets documentation . Secrets distributed in this manner become part of the etcd database, and thus it becomes necessary to specify a KMS provider for data encryption to prevent etcd from storing plaintext versions of secrets. Consequences As the existing implementation is not fully-compliant with this ADR, significant scope will be added to current and future EdgeX releases in order to bring the project into compliance. List of needed improvements: PKI private keys All: Move to using Vault as system of origin for the PKI instead of the standalone security-secrets-setup utility. All: Cache the PKI for Consul and Vault on persistent disk; rotate occasionally. All: Investigate hardware protection of cached Consul and Vault PKI secret keys. (Vault cannot unseal its own TLS certificate.) Special case: Bring-your-own external Kong certificate and key The Kong external certificate and key is already stored in Vault, however, additional metadata is needed to signal whether these are auto-generated or manually-installed. A manually-installed certificate and key would not be overwritten by the framework bringup logic. Installing a custom certificate and key can then be implemented by overwriting the system-generated ones and setting a flag indicating that they were manually-installed. Secret store master password All: Enable hooks for hardware protection of secret store master password. Secret store per-service authentication tokens No changes required. Postgres superuser password Generate at install time or on cold start of the framework. Cache in Vault and inject into Kong using environment variable injection. MongoDB service account passwords No changes required. Redis(v5) authentication password All: Implement process-to-process injection: start Redis unauthenticated, with a post-start hook to read the secret out of Vault and set the Redis password. (Short race condition between Redis starting, password being set, and dependent services starting.) No changes on client side. Redis(v6) passwords (v6 adds multiple user support) Interim solution: handle like MongoDB service account passwords. Future ADR to propose use of a Vault database secrets engine. No changes on client side (each service accesses its own credential) Kong authentication tokens All: Implement in-transit authentication with TLS-protected Postgres interface. (Subject to change if it is decided not to enable a Postgres backend out of the box.) Additional research needed as PostgreSQL does not support transparent data encryption. References ADR for secret creation and distribution CWE-798: Use of hard-coded credentials Docker Swarm secrets EdgeX go-mod-secrets Hashicorp Vault","title":"Creation and Distribution of Secrets"},{"location":"design/adr/security/0008-Secret-Creation-and-Distribution/#creation-and-distribution-of-secrets","text":"","title":"Creation and Distribution of Secrets"},{"location":"design/adr/security/0008-Secret-Creation-and-Distribution/#status","text":"proposed","title":"Status"},{"location":"design/adr/security/0008-Secret-Creation-and-Distribution/#context","text":"This ADR seeks to clarify and prioritize the secret handling approach taken by EdgeX. EdgeX microservices need a number of secrets to be created and distributed in order to create a functional, secure system. Among these secrets are: Privileged administrator passwords (such as a database superuser password) Service account passwords (e.g. non-privileged database accounts) PKI private keys There is a lack of consistency on how secrets are created and distributed to EdgeX microservices, and when developers need to add new components to the system, it is unclear on what the preferred approach should be. This document assumes a threat model wherein the EdgeX services are sandboxed (such as in a snap or a container) and the host system is trusted, and all services running in a single snap share a trust boundary.","title":"Context"},{"location":"design/adr/security/0008-Secret-Creation-and-Distribution/#terms","text":"The following terms will be helpful for understading the subsequent discussion: SECRETSLOC is a protected file system path where bootstrapping secrets are stored. While EdgeX implements a sophisticated secret handling mechanism, that mechanism itself requires secrets. For example, every microservice that talks to Vault must have its own unique secret to authenticate: Vault itself cannot be used to distribute these secrets. SECRETSLOC fulfills the role that the non-routable instance data IP address, 169.254.169.254, fulfills in the public cloud: delivery of bootstrapping secrets. As EdgeX does not have a hypervisor nor virtual machines for this purpose, a protected file system path is used instead. SECRETSLOC is implementation-dependent. A desirable feature of SECRETSLOC would be that data written here is kept in RAM and is not persisted to storage media. This property is not achieveable in all circumstances. For Docker, a list of suggested paths--in preference order--is: /run/edgex/secrets (a tmpfs volume on a Linux host) /tmp/edgex/secrets (a temporary file area on Linux and MacOS hosts) A persistent docker volume (use when host bind mounts are not available) For snaps, a list of suggested paths-in preference order--is: * /run/snap. $SNAP_NAME / (a tmpfs volume on a Linux host) * $SNAP_DATA /secrets (a snap-specific persistent data area) * TBD (a content interface that allows for sharing of secrets from the core snap)","title":"Terms"},{"location":"design/adr/security/0008-Secret-Creation-and-Distribution/#current-practices-survey","text":"A survey on the existing EdgeX secrets reveals the following appoaches. A designation of \"compliant\" means that the current implementation is aligned with the recommended practices documented in the next section. A designation of \"non-compliant\" means that the current implementation uses an implemention mechanism outside of the recommended practices documented in the next section. A \"non-compliant\" implementation is a candidate for refactoring to bring the implementation into conformance with the recommended practices.","title":"Current practices survey"},{"location":"design/adr/security/0008-Secret-Creation-and-Distribution/#system-managed-secrets","text":"PKI private keys Docker: PKI generated by standalone utility every cold start of the framework. Distribution via SECRETSLOC . (Compliant.) Snaps: PKI generated by standalone utility every cold start of the framework. Deployed to SECRETSLOC . (Compliant.) Secret store master password Docker: Distribution via persistent docker volume. (Non-compliant.) Snaps: Stored in $SNAP_DATA/config/security-secrets-setup/res . (Non-compliant.) Secret store per-service authentication tokens Docker: Distribution via SECRETSLOC generated every cold start of the framework. (Compliant.) Snaps: Distribution via SECRETSLOC , generated every cold start of the framework. (Compliant.) Postgres superuser password Docker: Hard-coded into docker-compose file, checked in to source control. (Non-compliant.) Snaps: Generated at snap install time via \"apg\" (\"automatic password generator\") tool, installed into Postgres, cached to $SNAP_DATA/config/postgres/kongpw (non-compliant), and passed to Kong via $KONG_PG_PASSWORD . MongoDB service account passwords Docker: Direct consumption from secret store. (Compliant.) Snaps: Direct consumption from secret store. (Compliant.) Redis authentication password Docker: Server--staged to secrets volume and injected via command line. (Non-compliant.). Clients--direct consumption from secret store. (Compliant.) Snaps: Server--staged to $SNAP_DATA/secrets/edgex-redis/redis5-password and injected via command line. (Non-compliant.). Clients--direct consumption from secret store. (Compliant.) Kong client authentication tokens Docker: System of reference is unencrypted Postgres database. (Non-compliant.) Snaps: System of reference is unencrypted Postgres database. (Non-compliant.) Note: in the current implementation, Consul is being operated as a public service. Consul will be a subject of a future \"bootstrapping ADR\" due to its role in serivce location.","title":"System-managed secrets"},{"location":"design/adr/security/0008-Secret-Creation-and-Distribution/#user-managed-secrets","text":"User-managed secrets functionality is provided by app-functions-sdk-go . If security is enabled, secrets are retrieved from Vault. If security is disabled, secrets are retreived from the configuration provider. If the configuration provider is not available, secrets are read from the underlying .toml . It is taken as granted in this ADR that secrets originating in the configuration provider or from .toml configuration files are not secret. The fallback mechanism is provided as a convienience to the developer, who would otherwise have to litter their code with \"if (isSecurityEnabled())\" logic leading to implementation inconsistencies. The central database credential is supplied by GetDatabaseCredentials() and returns the database credential assigned to app-service-configurable . If security is enabled, database credentials are retreived using the standard flow. If security is disabled, secrets are retreived from the configuration provider from a special section called [Writable.InsecureSecrets] . If not found there, the configuration provider is searched for credentials stored in the legacy [Databases.Primary] section using the Username and Password keys. Each user application has its own exclusive-use area of the secret store that is accessed via GetSecrets() . If security is enabled, secret requests are passed along to go-mod-secrets using an application-specific access token. If security is disabled, secret requets are made to the configuration provider from the [Writable.InsecureSecrets] section. There is no fallback configuration location. As user-managed secrets have no framework support for initialization, a special StoreSecrets() method is made available to the application for the application to initialize its own secrets. This method is only available in security-enabled mode. No changes to user-managed secrets are being proposed in this ADR.","title":"User-managed secrets"},{"location":"design/adr/security/0008-Secret-Creation-and-Distribution/#decision","text":"","title":"Decision"},{"location":"design/adr/security/0008-Secret-Creation-and-Distribution/#creation-of-secrets","text":"Management of hardware-bound secrets is platform-specific and out-of-scope for the EdgeX framework. EdgeX open source will contain only the necessary hooks to integrate platform-specific functionality. For software-managed secrets, the system of referece of secrets in EdgeX is the EdgeX secret store. The EdgeX secret store provides for encryption of secrets at rest. This term means that if a secret is replicated, the EdgeX secret store is the authoritative source of truth of the secret. Whenever possible, the EdgeX secret store should also be the record of origin of a secret as well. This means creating secrets inside of the EdgeX secret store is preferrable to importing an externally-created secret into the secret store. This can often be done for framework-managed secrets, but not possible for user-managed secrets.","title":"Creation of secrets"},{"location":"design/adr/security/0008-Secret-Creation-and-Distribution/#choosing-between-alternative-forms-of-secrets","text":"When given a choice between plain-text secrets and cryptographic keys, cryptographic keys should be preferred. An example situation would be the introduction of an MQTT message broker. A broker may support both TLS client authentication as well as username/password authentication. In such a situation, TLS client authentication would be preferred: The cryptographic key is typically longer in bits than a plain-text secret. A plain-text secret will require transport encryption in order to protect confidentiality of the secret, such as server-side TLS. Use of TLS client authentication typically eliminates the need for additional assets on the server side (such as a password database) to authenticate the client, by relying on digital signature instead. TLS client authentication should not be used unless there is a capability to revoke a compromised certificate, such as by replacing the certificate authority, or providing a certificate revokation list to the server. If certificate revokation is not supported, plain-text secrets (such as username/password) should be used instead, as they are typically easier to revoke.","title":"Choosing between alternative forms of secrets"},{"location":"design/adr/security/0008-Secret-Creation-and-Distribution/#distribution-and-consumption-of-secrets","text":"","title":"Distribution and consumption of secrets"},{"location":"design/adr/security/0008-Secret-Creation-and-Distribution/#prohibited-practices","text":"Use of hard-coded secrets is an instance of CWE-798: Use of hard-coded credentials and is not allowed. A hard-coded secret is a secret that is the same across multiple EdgeX instances. Hard-coded secrets make devices susceptible to BORE (break-once-run-everywhere) attacks, where collections of machines can compromised by a single replicated secret. Specific cases where this is likely to come up are: Secrets embedded in source control EdgeX is an open-source project. Any secret that is present in an EdgeX repository is public to the world, and therefore not a secret, by definition. Configuration files, such as .toml files, .json files, .yaml files (including docker-compose.yml ) are specific instances of this practice. Secrets embedded in binaries Binaries are usually not protected against confidentiality threats, and binaries can be easily reverse-engineered to find any secrets therein. Binaries included compile executables as well as Docker images.","title":"Prohibited practices"},{"location":"design/adr/security/0008-Secret-Creation-and-Distribution/#recommended-practices","text":"Direct consumption from process-to-process interaction with secret store This approach is only possible for components that have native support for Hashicorp Vault . This includes any EdgeX service that links to go-mod-secrets. For example, if secretClient is an instance of the go-mod-secrets secret store client: secrets , err := secretClient . GetSecrets ( \"myservice\" , \"username\" , \"password\" ) The above code will retrieve the username and password properties of the myservice secret. Dynamic injection of secret into process environment space Environment variables are part of a process' environment block and are mapped into a process' memory. In this scenario, an intermediary makes a connection to the secret store to fetch a secret, store it into an environment variable, and then launches a target executable, thereby passing the secret in-memory to the target process. Existing examples of this functionality include vaultenv , envconsul , or env-aws-params . These tools authenticate to a remote network service, inject secrets into the process environment, and then exec's a replacment process that inherits the secret-enriched enviornment block. There are a few potential risks with this approach: Environment blocks are passed to child processes by default. Environment-variable-sniffing malware (introduced by compromised 3rd party libaries) is a proven attack method. Dynamic injection of secret into container-scoped tmpfs volume An example of this approach is consul-template . This approach is useful when a secret is required to be in a configuration file and cannot be passed via an environment variable or directly consumed from a secret store. Distribution via SECRETSLOC This option is the most widely supported secret distribution mechanism by container orchestrators. EdgeX supports runtime environments such as standard Docker and snaps that have no built-in secret management features. Generic Docker does not have a built-in secrets mechanism. Manual configuration of a SECRETSLOC should utilize either a host file file system path or a Docker volume. Snaps also do not have a built-in secrets mechanism. The options for SECRETSLOC are limited to designated snap-writable directories. For comparison: Docker Swarm: Swarm swarm mode is not officially supported by the EdgeX project. Docker Swarm secrets are shared via the /run/secrets volume, which is a Linux tmpfs volume created on the host and shared with the container. For an example of Docker Swarm secrets, see the docker-compose secrets stanza . Secrets distributed in this manner become part of the RaftDB, and thus it becomes necessary to enable swarm autolock mode, which prevents the Raft database encryption key from being stored plaintext on disk. Swarm secrets have an additional limitation in that they are not mutable at runtime. Kubernetes: Kubernetes is not officially supported by the EdgeX project. Kubernetes also supports the secrets volume approach, though the secrets volume can be mounted anywhere in the container namespace. For an example of Kubernetes secrets volumes, see the Kubernetes secrets documentation . Secrets distributed in this manner become part of the etcd database, and thus it becomes necessary to specify a KMS provider for data encryption to prevent etcd from storing plaintext versions of secrets.","title":"Recommended practices"},{"location":"design/adr/security/0008-Secret-Creation-and-Distribution/#consequences","text":"As the existing implementation is not fully-compliant with this ADR, significant scope will be added to current and future EdgeX releases in order to bring the project into compliance. List of needed improvements: PKI private keys All: Move to using Vault as system of origin for the PKI instead of the standalone security-secrets-setup utility. All: Cache the PKI for Consul and Vault on persistent disk; rotate occasionally. All: Investigate hardware protection of cached Consul and Vault PKI secret keys. (Vault cannot unseal its own TLS certificate.) Special case: Bring-your-own external Kong certificate and key The Kong external certificate and key is already stored in Vault, however, additional metadata is needed to signal whether these are auto-generated or manually-installed. A manually-installed certificate and key would not be overwritten by the framework bringup logic. Installing a custom certificate and key can then be implemented by overwriting the system-generated ones and setting a flag indicating that they were manually-installed. Secret store master password All: Enable hooks for hardware protection of secret store master password. Secret store per-service authentication tokens No changes required. Postgres superuser password Generate at install time or on cold start of the framework. Cache in Vault and inject into Kong using environment variable injection. MongoDB service account passwords No changes required. Redis(v5) authentication password All: Implement process-to-process injection: start Redis unauthenticated, with a post-start hook to read the secret out of Vault and set the Redis password. (Short race condition between Redis starting, password being set, and dependent services starting.) No changes on client side. Redis(v6) passwords (v6 adds multiple user support) Interim solution: handle like MongoDB service account passwords. Future ADR to propose use of a Vault database secrets engine. No changes on client side (each service accesses its own credential) Kong authentication tokens All: Implement in-transit authentication with TLS-protected Postgres interface. (Subject to change if it is decided not to enable a Postgres backend out of the box.) Additional research needed as PostgreSQL does not support transparent data encryption.","title":"Consequences"},{"location":"design/adr/security/0008-Secret-Creation-and-Distribution/#references","text":"ADR for secret creation and distribution CWE-798: Use of hard-coded credentials Docker Swarm secrets EdgeX go-mod-secrets Hashicorp Vault","title":"References"},{"location":"design/legacy-design/","text":"Legacy Design Documents Name/Link Short Description Registry Abstraction Decouple EdgeX services from Consul device-service/Discovery Dynamically discover new devices","title":"Legacy Design Documents"},{"location":"design/legacy-design/#legacy-design-documents","text":"Name/Link Short Description Registry Abstraction Decouple EdgeX services from Consul device-service/Discovery Dynamically discover new devices","title":"Legacy Design Documents"},{"location":"design/legacy-design/device-service/discovery/","text":"Dynamic Device Discovery Overview Some device protocols allow for devices to be discovered automatically. A Device Service may include a capability for discovering devices and creating the corresponding Device objects within EdgeX. A framework for doing so will be implemented in the Device Service SDKs. The discovery process will operate as follows: Discovery is triggered either on an internal timer or by a call to a REST endpoint The SDK will call a function provided by the DS implementation to request a device scan The implementation calls back to the SDK with details of devices which it has found The SDK filters these devices against a set of acceptance criteria The SDK adds accepted devices in core-metadata. These are now available in the EdgeX system Triggering Discovery A boolean configuration value Device/Discovery/Enabled defaults to false. If this value is set true, and the DS implementation supports discovery, discovery is enabled. The SDK will respond to POST requests on the the /discovery endpoint. No content is required in the request. This call will return one of the following codes: 202: discovery has been triggered or is already running. The response should indicate which, and contain the correlation id that will be used by any resulting requests for device addition 423: the service is locked (admin state) or disabled (operating state) 500: unknown or unanticipated issues exist 501: discovery is not supported by this protocol implementation 503: discovery is disabled by configuration In each of the failure cases a meaningful error message should be returned. In the case where discovery is triggered, the discovery process will run in a new thread or goroutine, so that the REST call may return immediately. An integer configuration value Device/Discovery/Interval defaults to zero. If this value is set to a positive value, and discovery is enabled, the discovery process will be triggered at the specified interval (in seconds). Finding Devices When discovery is triggered, the SDK calls the implementation function provided by the Device Service. This should perform whatever protocol-specific procedure is necessary to find devices, and pass these devices into the SDK by calling the SDK's filtered device addition function. Note: The implementation should call back for every device found. The SDK is to take responsibility for filtering out devices which have already been added. The information required for a found device is as follows: An autogenerated device name The Protocol Properties of the device Optionally, a description string Optionally, a list of label strings The filtered device addition function will take as an argument a collection of structs containing the above data. An implementation may choose to make one call per discovered device, but implementors are encouraged to batch the devices if practical, as in future EdgeX versions it will be possible for the SDK to create all required new devices in a single call to core-metadata. Rationale: An alternative design would have the implementation function return the collection of discovered devices to the SDK. Using a callback mechanism instead has the following advantages: Allows for asynchronous operation. In this mode the DS implementation will intiate discovery and return immediately. For example discovery may be initiated by sending a broadcast packet. Devices will then send return packets indicating their existence. The thread handling inbound network traffic can on receipt of such packets call the filtered device addition function directly. Allows DS implementations where devices self-announce to call the filtered device addition function independent of the discovery process Filtered Device Addition The filter criteria for discovered devices are represented by Provision Watchers. A Provision Watcher contains the following fields: Identifiers : A set of name-value pairs against which a new device's ProtocolProperties are matched BlockingIdentifiers : A further set of name-value pairs which are also matched against a new device's ProtocolProperties Profile : The name of a DeviceProfile which should be assigned to new devices which pass this ProvisionWatcher AdminState : The initial Administrative State for new devices which pass this ProvisionWatcher A candidate new device passes a ProvisionWatcher if all of the Identifiers match, and none of the BlockingIdentifiers . The values specified in Identifiers are regular expressions. Note: the above is a whitelist+blacklist scheme. If a discovered Device is manually removed from EdgeX, it will be necessary to adjust the ProvisionWatcher via which it was added, either by making the Identifiers more specific or by adding BlockingIdentifiers , otherwise the Device will be re-added the next time Discovery is initiated. Note: ProvisionWatchers are stored in core-metadata. A facility for managing ProvisionWatchers is needed, eg edgex-cli could be extended","title":"Discovery"},{"location":"design/legacy-design/device-service/discovery/#dynamic-device-discovery","text":"","title":"Dynamic Device Discovery"},{"location":"design/legacy-design/device-service/discovery/#overview","text":"Some device protocols allow for devices to be discovered automatically. A Device Service may include a capability for discovering devices and creating the corresponding Device objects within EdgeX. A framework for doing so will be implemented in the Device Service SDKs. The discovery process will operate as follows: Discovery is triggered either on an internal timer or by a call to a REST endpoint The SDK will call a function provided by the DS implementation to request a device scan The implementation calls back to the SDK with details of devices which it has found The SDK filters these devices against a set of acceptance criteria The SDK adds accepted devices in core-metadata. These are now available in the EdgeX system","title":"Overview"},{"location":"design/legacy-design/device-service/discovery/#triggering-discovery","text":"A boolean configuration value Device/Discovery/Enabled defaults to false. If this value is set true, and the DS implementation supports discovery, discovery is enabled. The SDK will respond to POST requests on the the /discovery endpoint. No content is required in the request. This call will return one of the following codes: 202: discovery has been triggered or is already running. The response should indicate which, and contain the correlation id that will be used by any resulting requests for device addition 423: the service is locked (admin state) or disabled (operating state) 500: unknown or unanticipated issues exist 501: discovery is not supported by this protocol implementation 503: discovery is disabled by configuration In each of the failure cases a meaningful error message should be returned. In the case where discovery is triggered, the discovery process will run in a new thread or goroutine, so that the REST call may return immediately. An integer configuration value Device/Discovery/Interval defaults to zero. If this value is set to a positive value, and discovery is enabled, the discovery process will be triggered at the specified interval (in seconds).","title":"Triggering Discovery"},{"location":"design/legacy-design/device-service/discovery/#finding-devices","text":"When discovery is triggered, the SDK calls the implementation function provided by the Device Service. This should perform whatever protocol-specific procedure is necessary to find devices, and pass these devices into the SDK by calling the SDK's filtered device addition function. Note: The implementation should call back for every device found. The SDK is to take responsibility for filtering out devices which have already been added. The information required for a found device is as follows: An autogenerated device name The Protocol Properties of the device Optionally, a description string Optionally, a list of label strings The filtered device addition function will take as an argument a collection of structs containing the above data. An implementation may choose to make one call per discovered device, but implementors are encouraged to batch the devices if practical, as in future EdgeX versions it will be possible for the SDK to create all required new devices in a single call to core-metadata. Rationale: An alternative design would have the implementation function return the collection of discovered devices to the SDK. Using a callback mechanism instead has the following advantages: Allows for asynchronous operation. In this mode the DS implementation will intiate discovery and return immediately. For example discovery may be initiated by sending a broadcast packet. Devices will then send return packets indicating their existence. The thread handling inbound network traffic can on receipt of such packets call the filtered device addition function directly. Allows DS implementations where devices self-announce to call the filtered device addition function independent of the discovery process","title":"Finding Devices"},{"location":"design/legacy-design/device-service/discovery/#filtered-device-addition","text":"The filter criteria for discovered devices are represented by Provision Watchers. A Provision Watcher contains the following fields: Identifiers : A set of name-value pairs against which a new device's ProtocolProperties are matched BlockingIdentifiers : A further set of name-value pairs which are also matched against a new device's ProtocolProperties Profile : The name of a DeviceProfile which should be assigned to new devices which pass this ProvisionWatcher AdminState : The initial Administrative State for new devices which pass this ProvisionWatcher A candidate new device passes a ProvisionWatcher if all of the Identifiers match, and none of the BlockingIdentifiers . The values specified in Identifiers are regular expressions. Note: the above is a whitelist+blacklist scheme. If a discovered Device is manually removed from EdgeX, it will be necessary to adjust the ProvisionWatcher via which it was added, either by making the Identifiers more specific or by adding BlockingIdentifiers , otherwise the Device will be re-added the next time Discovery is initiated. Note: ProvisionWatchers are stored in core-metadata. A facility for managing ProvisionWatchers is needed, eg edgex-cli could be extended","title":"Filtered Device Addition"},{"location":"design/legacy-requirements/","text":"Legacy Requirements Name/Link Short Description Device Service Device Service SDK required functionality","title":"Legacy Requirements"},{"location":"design/legacy-requirements/#legacy-requirements","text":"Name/Link Short Description Device Service Device Service SDK required functionality","title":"Legacy Requirements"},{"location":"design/legacy-requirements/device-service/","text":"Device SDK Required Functionality Overview This document sets out the required functionality of a Device SDK other than the implementation of its REST API (see ADR 0011 ) and the Dynamic Discovery mechanism (see Discovery ). This functionality is categorised into three areas - actions required at startup, configuration options to be supported, and support for push-style event generation. Startup When the device service is started, in addition to any actions required to support functionality defined elsewhere, the SDK must: Manage the device service's registration in metadata Provide initialization information to the protocol-specific implementation Registration The core-metadata service maintains an extent of device service registrations so that it may route requests relating to particular devices to the correct device service. The SDK should create (on first run) or update its record appropriately. Device service registrations contain the following fields: Name - the name of the device service Description - an optional brief description of the service Labels - optional string labels BaseAddress - URL of the base of the service's REST API The default device service Name is to be hardcoded into every device service implementation. A suffix may be added to this name at runtime by means of commandline option or environment variable. Service names must be unique in a particular EdgeX instance; the suffix mechanism allows for running multiple instances of a given device service. The Description and Labels are configured in the [Service] section of the device service configuration. BaseAddress may be constructed using the [Service]/Host and [Service]/Port entries in the device service configuration. Initialization During startup the SDK must supply to the implementation that part of the service configuration which is specific to the implementation. This configuration is held in the Driver section of the configuration file or registry. The SDK must also supply a logging facility at this stage. This facility should by default emit logs locally (configurable to file or to stdout) but instead should use the optional logging service if the configuration element Logging/EnableRemote is set true . Note: the logging service is deprecated and support for it will be removed in EdgeX v2.0 The implementation on receipt of its configuration should perform any necessary initialization of its own. It may return an error in the event of unrecoverable problems, this should cause the service startup itself to fail. Configuration Configuration should be supported by the SDK, in accordance with ADR 0005 Commandline processing The SDK should handle commandline processing on behalf of the device service. In addition to the common EdgeX service options, the --instance / -i flag should be supported. This specifies a suffix to append to the device service name. Environment variables The SDK should also handle environment variables. In addition to the common EdgeX variables, EDGEX_INSTANCE_NAME should if set override the --instance setting. Configuration file and Registry The SDK should use (or for non-Go implementations, re-implement) the standard mechanisms for obtaining configuration from a file or registry. The configuration parameters to be supported are: Service section Option Type Notes Host String This is the hostname to use when registering the service in core-metadata. As such it is used by other services to connect to the device service, and therefore must be resolvable by other services in the EdgeX deployment. Port Int Port on which to accept the device service's REST API. The assigned port for experimental / in-development device services is 49999. Timeout Int Time (in milliseconds) to wait between attempts to contact core-data and core-metadata when starting up. ConnectRetries Int Number of times to attempt to contact core-data and core-metadata when starting up. StartupMsg String Message to log on successful startup. CheckInterval String The checking interval to request if registering with Consul. Consul will ping the service at this interval to monitor its liveliness. ServerBindAddr String The interface on which the service's REST server should listen. By default the server is to listen on the interface to which the Host option resolves. A value of 0.0.0.0 means listen on all available interfaces. Clients section Defines the endpoints for other microservices in an EdgeX system. Not required when using Registry. Data Option Type Notes Host String Hostname on which to contact the core-data service. Port Int Port on which to contact the core-data service. Metadata Option Type Notes Host String Hostname on which to contact the core-metadata service. Port Int Port on which to contact the core-metadata service. Device section Option Type Notes DataTransform Bool For enabling/disabling transformations on data between the device and EdgeX. Defaults to true (enabled). Discovery/Enabled Bool For enabling/disabling device discovery. Defaults to true (enabled). Discovery/Interval Int Time between automatic discovery runs, in seconds. Defaults to zero (do not run discovery automatically). MaxCmdOps Int Defines the maximum number of resource operations that can be sent to the driver in a single command. MaxCmdResultLen Int Maximum string length for command results returned from the driver. UpdateLastConnected Bool If true, update the LastConnected attribute of a device whenever it is successfully accessed (read or write). Defaults to false. Logging section Option Type Notes LogLevel String Sets the logging level. Available settings in order of increasing severity are: TRACE , DEBUG , INFO , WARNING , ERROR . Driver section This section is for options specific to the protocol driver. Any configuration specified here will be passed to the driver implementation during initialization. Push Events The SDK should implement methods for generating Events other than on receipt of device GET requests. The AutoEvent mechanism provides for generating Events at fixed intervals. The asynchronous event queue enables the device service to generate events at arbitrary times, according to implementation-specific logic. AutoEvents Each device may have as part of its definition in Metadata a number of AutoEvents associated with it. An AutoEvent has the following fields: resource : the name of a deviceResource or deviceCommand indicating what to read. frequency : a string indicating the time to wait between reading events, expressed as an integer followed by units of ms, s, m or h. onchange : a boolean: if set to true, only generate new events if one or more of the contained readings has changed since the last event. The device SDK should schedule device readings from the implementation according to these AutoEvent defininitions. It should use the same logic as it would if the readings were being requested via REST. Asynchronous Event Queue The SDK should provide a mechanism whereby the implementation may submit device readings at any time without blocking. This may be done in a manner appropriate to the implementation language, eg the Go SDK provides a channel on which readings may be pushed, the C SDK provides a function which submits readings to a workqueue.","title":"Device SDK Required Functionality"},{"location":"design/legacy-requirements/device-service/#device-sdk-required-functionality","text":"","title":"Device SDK Required Functionality"},{"location":"design/legacy-requirements/device-service/#overview","text":"This document sets out the required functionality of a Device SDK other than the implementation of its REST API (see ADR 0011 ) and the Dynamic Discovery mechanism (see Discovery ). This functionality is categorised into three areas - actions required at startup, configuration options to be supported, and support for push-style event generation.","title":"Overview"},{"location":"design/legacy-requirements/device-service/#startup","text":"When the device service is started, in addition to any actions required to support functionality defined elsewhere, the SDK must: Manage the device service's registration in metadata Provide initialization information to the protocol-specific implementation","title":"Startup"},{"location":"design/legacy-requirements/device-service/#registration","text":"The core-metadata service maintains an extent of device service registrations so that it may route requests relating to particular devices to the correct device service. The SDK should create (on first run) or update its record appropriately. Device service registrations contain the following fields: Name - the name of the device service Description - an optional brief description of the service Labels - optional string labels BaseAddress - URL of the base of the service's REST API The default device service Name is to be hardcoded into every device service implementation. A suffix may be added to this name at runtime by means of commandline option or environment variable. Service names must be unique in a particular EdgeX instance; the suffix mechanism allows for running multiple instances of a given device service. The Description and Labels are configured in the [Service] section of the device service configuration. BaseAddress may be constructed using the [Service]/Host and [Service]/Port entries in the device service configuration.","title":"Registration"},{"location":"design/legacy-requirements/device-service/#initialization","text":"During startup the SDK must supply to the implementation that part of the service configuration which is specific to the implementation. This configuration is held in the Driver section of the configuration file or registry. The SDK must also supply a logging facility at this stage. This facility should by default emit logs locally (configurable to file or to stdout) but instead should use the optional logging service if the configuration element Logging/EnableRemote is set true . Note: the logging service is deprecated and support for it will be removed in EdgeX v2.0 The implementation on receipt of its configuration should perform any necessary initialization of its own. It may return an error in the event of unrecoverable problems, this should cause the service startup itself to fail.","title":"Initialization"},{"location":"design/legacy-requirements/device-service/#configuration","text":"Configuration should be supported by the SDK, in accordance with ADR 0005","title":"Configuration"},{"location":"design/legacy-requirements/device-service/#commandline-processing","text":"The SDK should handle commandline processing on behalf of the device service. In addition to the common EdgeX service options, the --instance / -i flag should be supported. This specifies a suffix to append to the device service name.","title":"Commandline processing"},{"location":"design/legacy-requirements/device-service/#environment-variables","text":"The SDK should also handle environment variables. In addition to the common EdgeX variables, EDGEX_INSTANCE_NAME should if set override the --instance setting.","title":"Environment variables"},{"location":"design/legacy-requirements/device-service/#configuration-file-and-registry","text":"The SDK should use (or for non-Go implementations, re-implement) the standard mechanisms for obtaining configuration from a file or registry. The configuration parameters to be supported are:","title":"Configuration file and Registry"},{"location":"design/legacy-requirements/device-service/#service-section","text":"Option Type Notes Host String This is the hostname to use when registering the service in core-metadata. As such it is used by other services to connect to the device service, and therefore must be resolvable by other services in the EdgeX deployment. Port Int Port on which to accept the device service's REST API. The assigned port for experimental / in-development device services is 49999. Timeout Int Time (in milliseconds) to wait between attempts to contact core-data and core-metadata when starting up. ConnectRetries Int Number of times to attempt to contact core-data and core-metadata when starting up. StartupMsg String Message to log on successful startup. CheckInterval String The checking interval to request if registering with Consul. Consul will ping the service at this interval to monitor its liveliness. ServerBindAddr String The interface on which the service's REST server should listen. By default the server is to listen on the interface to which the Host option resolves. A value of 0.0.0.0 means listen on all available interfaces.","title":"Service section"},{"location":"design/legacy-requirements/device-service/#clients-section","text":"Defines the endpoints for other microservices in an EdgeX system. Not required when using Registry.","title":"Clients section"},{"location":"design/legacy-requirements/device-service/#data","text":"Option Type Notes Host String Hostname on which to contact the core-data service. Port Int Port on which to contact the core-data service.","title":"Data"},{"location":"design/legacy-requirements/device-service/#metadata","text":"Option Type Notes Host String Hostname on which to contact the core-metadata service. Port Int Port on which to contact the core-metadata service.","title":"Metadata"},{"location":"design/legacy-requirements/device-service/#device-section","text":"Option Type Notes DataTransform Bool For enabling/disabling transformations on data between the device and EdgeX. Defaults to true (enabled). Discovery/Enabled Bool For enabling/disabling device discovery. Defaults to true (enabled). Discovery/Interval Int Time between automatic discovery runs, in seconds. Defaults to zero (do not run discovery automatically). MaxCmdOps Int Defines the maximum number of resource operations that can be sent to the driver in a single command. MaxCmdResultLen Int Maximum string length for command results returned from the driver. UpdateLastConnected Bool If true, update the LastConnected attribute of a device whenever it is successfully accessed (read or write). Defaults to false.","title":"Device section"},{"location":"design/legacy-requirements/device-service/#logging-section","text":"Option Type Notes LogLevel String Sets the logging level. Available settings in order of increasing severity are: TRACE , DEBUG , INFO , WARNING , ERROR .","title":"Logging section"},{"location":"design/legacy-requirements/device-service/#driver-section","text":"This section is for options specific to the protocol driver. Any configuration specified here will be passed to the driver implementation during initialization.","title":"Driver section"},{"location":"design/legacy-requirements/device-service/#push-events","text":"The SDK should implement methods for generating Events other than on receipt of device GET requests. The AutoEvent mechanism provides for generating Events at fixed intervals. The asynchronous event queue enables the device service to generate events at arbitrary times, according to implementation-specific logic.","title":"Push Events"},{"location":"design/legacy-requirements/device-service/#autoevents","text":"Each device may have as part of its definition in Metadata a number of AutoEvents associated with it. An AutoEvent has the following fields: resource : the name of a deviceResource or deviceCommand indicating what to read. frequency : a string indicating the time to wait between reading events, expressed as an integer followed by units of ms, s, m or h. onchange : a boolean: if set to true, only generate new events if one or more of the contained readings has changed since the last event. The device SDK should schedule device readings from the implementation according to these AutoEvent defininitions. It should use the same logic as it would if the readings were being requested via REST.","title":"AutoEvents"},{"location":"design/legacy-requirements/device-service/#asynchronous-event-queue","text":"The SDK should provide a mechanism whereby the implementation may submit device readings at any time without blocking. This may be done in a manner appropriate to the implementation language, eg the Go SDK provides a channel on which readings may be pushed, the C SDK provides a function which submits readings to a workqueue.","title":"Asynchronous Event Queue"},{"location":"examples/AppServiceExamples/","text":"App Service Examples The following is a list of examples we currently have available that demonstrate various ways that the Application Functions SDK can be used. All of the examples can be found in https://github.com/edgexfoundry/edgex-examples/tree/master/application-services . They focus on how to leverage various built in provided functions as mentioned above as well as how to write your own in the case that the SDK does not provide what is needed. Example Name Description Simple Filter XML Demonstrates Filter of data by device ID and transforming data to XML Simple Filter XML HTTP Same example as #1, but result published to HTTP Endpoint Simple Filter XML MQTT Same example as #1, but result published to MQTT Broker Advanced Filter Convert Publish Advanced Target Type App Functions AWS App Functions Azure Cloud Event Transforms Send Command Secrets Simple CBOR Filter","title":"App Service Examples"},{"location":"examples/AppServiceExamples/#app-service-examples","text":"The following is a list of examples we currently have available that demonstrate various ways that the Application Functions SDK can be used. All of the examples can be found in https://github.com/edgexfoundry/edgex-examples/tree/master/application-services . They focus on how to leverage various built in provided functions as mentioned above as well as how to write your own in the case that the SDK does not provide what is needed. Example Name Description Simple Filter XML Demonstrates Filter of data by device ID and transforming data to XML Simple Filter XML HTTP Same example as #1, but result published to HTTP Endpoint Simple Filter XML MQTT Same example as #1, but result published to MQTT Broker Advanced Filter Convert Publish Advanced Target Type App Functions AWS App Functions Azure Cloud Event Transforms Send Command Secrets Simple CBOR Filter","title":"App Service Examples"},{"location":"examples/Ch-CommandingDeviceThroughRulesEngine/","text":"Command Devices with Kuiper Rules Engine Overview This document describes how to actuate a device with rules trigger by the Kuiper rules engine. To make the example simple, the virtual device device-virtual is used as the actuated device. The Kuiper rules engine analyzes the data sent from device-virtual services, and then sends a command to virtual device based a rule firing in Kuiper based on that analysis. It should be noted that an application service is used to route core data through the rules engine. Use Case Scenarios Rules will be created in Kuiper to watch for two circumstances: monitor for events coming from the Random-UnsignedInteger-Device device (one of the default virtual device managed devices), and if a uint8 reading value is found larger than 20 in the event, then send a command to Random-Boolean-Device device to start generating random numbers (specifically - set random generation bool to true). monitor for events coming from the Random-Integer-Device device (another of the default virtual device managed devices), and if the average for int8 reading values (within 20 seconds) is larger than 0, then send a command to Random-Boolean-Device device to stop generating random numbers (specifically - set random generation bool to false). These use case scenarios do not have any real business meaning, but easily demonstrate the features of EdgeX automatic actuation accomplished via the Kuiper rule engine. Prerequisite Knowledge This document will not cover basic operations of EdgeX or EMQ X Kuiper. Readers should have basic knowledge of: Get and start EdgeX. Refer to Quick Start for how to get and start EdgeX with the virtual device service. Run the Kuiper Rules Engine. Refer to EdgeX Kuiper Rule Engine Tutorial to understand the basics of Kuiper and EdgeX. Start Kuiper and Create an EdgeX Stream Make sure you read the EdgeX Kuiper Rule Engine Tutorial and successfully run Kuiper with EdgeX. First create a stream that can consume streaming data from the EdgeX application service (rules engine profile). This step is not required if you already finished the EdgeX Kuiper Rule Engine Tutorial . curl -X POST \\ http:// $kuiper_docker :48075/streams \\ -H 'Content-Type: application/json' \\ -d '{\"sql\": \"create stream demo() WITH (FORMAT=\\\"JSON\\\", TYPE=\\\"edgex\\\")\"}' Get and Test the Command URL Since both use case scenario rules will send commands to the Random-Boolean-Device virtual device, use the curl request below to get a list of available commands for this device. curl http://localhost:48082/api/v1/device/name/Random-Boolean-Device | jq It should print results like those below. { \"id\" : \"9b051411-ca20-4556-bd3e-7f52475764ff\" , \"name\" : \"Random-Boolean-Device\" , \"adminState\" : \"UNLOCKED\" , \"operatingState\" : \"ENABLED\" , \"labels\" : [ \"device-virtual-example\" ], \"commands\" : [ { \"created\" : 1589052044139 , \"modified\" : 1589052044139 , \"id\" : \"28d88bb3-e280-46f7-949f-37cc411757f5\" , \"name\" : \"Bool\" , \"get\" : { \"path\" : \"/api/v1/device/{deviceId}/Bool\" , \"responses\" : [ { \"code\" : \"200\" , \"expectedValues\" : [ \"Bool\" ] }, { \"code\" : \"503\" , \"description\" : \"service unavailable\" } ], \"url\" : \"http://edgex-core-command:48082/api/v1/device/bcd18c02-b187-4f29-8265-8312dc5d794d/command/d6d3007d-c4ce-472f-a117-820b5410e498\" }, \"put\" : { \"path\" : \"/api/v1/device/{deviceId}/Bool\" , \"responses\" : [ { \"code\" : \"200\" }, { \"code\" : \"503\" , \"description\" : \"service unavailable\" } ], \"url\" : \"http://edgex-core-command:48082/api/v1/device/bcd18c02-b187-4f29-8265-8312dc5d794d/command/d6d3007d-c4ce-472f-a117-820b5410e498\" , \"parameterNames\" : [ \"Bool\" , \"EnableRandomization_Bool\" ] } } ] } From this output, look for the URL associated to the PUT command (the second URL listed). This is the command Kuiper will used to call on the device. There are two parameters for this command: Bool : Set the returned value when other services want to get device data. The parameter will be used only when EnableRandomization_Bool is set to false. EnableRandomization_Bool : Enable/disable the randomization generation of bool values. If this value is set to true, then the 1st parameter will be ignored. You can test calling this command with its parameters using curl as shown below. curl -X PUT \\ http://edgex-core-command:48082/api/v1/device/bcd18c02-b187-4f29-8265-8312dc5d794d/command/d6d3007d-c4ce-472f-a117-820b5410e498 \\ -H 'Content-Type: application/json' \\ -d '{\"Bool\":\"true\", \"EnableRandomization_Bool\": \"true\"}' Warning The URL used in this example will not be the same as the URL for you command service. EdgeX provides a different UUID for each command. The example above shows you what to look for and how to make the request, but the URL will be unique to your system. Create rules Now that you have EdgeX and Kuiper running, the EdgeX stream defined, and you know the command to actuate Random-Boolean-Device , it is time to build the Kuiper rules. The first rule Again, the 1st rule is to monitor for events coming from the Random-UnsignedInteger-Device device (one of the default virtual device managed devices), and if a uint8 reading value is found larger than 20 in the event, then send the command to Random-Boolean-Device device to start generating random numbers (specifically - set random generation bool to true). Given the URL and parameters to the command, below is the curl command to declare the first rule in Kuiper. curl -X POST \\ http:// $kuiper_server :48075/rules \\ -H 'Content-Type: application/json' \\ -d '{ \"id\": \"rule1\", \"sql\": \"SELECT uint8 FROM demo WHERE uint8 > 20\", \"actions\": [ { \"rest\": { \"url\": \"http://edgex-core-command:48082/api/v1/device/bcd18c02-b187-4f29-8265-8312dc5d794d/command/d6d3007d-c4ce-472f-a117-820b5410e498\", \"method\": \"put\", \"dataTemplate\": \"{\\\"Bool\\\":\\\"true\\\", \\\"EnableRandomization_Bool\\\": \\\"true\\\"}\", \"sendSingle\": true } }, { \"log\":{} } ] }' The second rule The 2nd rule is to monitor for events coming from the Random-Integer-Device device (another of the default virtual device managed devices), and if the average for int8 reading values (within 20 seconds) is larger than 0, then send a command to Random-Boolean-Device device to stop generating random numbers (specifically - set random generation bool to false). Here is the curl request to setup the second rule in Kuiper. The same command URL is used as the same device action ( Random-Boolean-Device's PUT bool command ) is being actuated, but with different parameters. curl -X POST \\ http:// $kuiper_server :48075/rules \\ -H 'Content-Type: application/json' \\ -d '{ \"id\": \"rule2\", \"sql\": \"SELECT avg(int8) AS avg_int8 FROM demo WHERE int8 != nil GROUP BY TUMBLINGWINDOW(ss, 20) HAVING avg(int8) > 0\", \"actions\": [ { \"rest\": { \"url\": \"http://edgex-core-command:48082/api/v1/device/bcd18c02-b187-4f29-8265-8312dc5d794d/command/d6d3007d-c4ce-472f-a117-820b5410e498\", \"method\": \"put\", \"dataTemplate\": \"{\\\"Bool\\\":\\\"false\\\", \\\"EnableRandomization_Bool\\\": \\\"false\\\"}\", \"sendSingle\": true } }, { \"log\":{} } ] }' Watch the Kuiper Logs Both rules are now created in Kuiper. Kuiper is busy analyzing the event data coming for the virtual devices looking for readings that match the rules you created. You can watch the edgex-kuiper container logs for the rule triggering and command execution. docker logs edgex-kuiper Explore the Results You can also explore the Kuiper analysis that caused the commands to be sent to the service. To see the the data from the analysis, use the SQL below to query Kuiper filtering data. SELECT int8 , \"true\" AS randomization FROM demo WHERE uint8 > 20 The output of the SQL should look similar to the results below. [{ \"int8\" : -75 , \"randomization\" : \"true\" }] Extended Reading Use these resouces to learn more about the features of EMQ X Kuiper. Kuiper Github code repository Kuiper reference guide","title":"Command Devices with Kuiper Rules Engine"},{"location":"examples/Ch-CommandingDeviceThroughRulesEngine/#command-devices-with-kuiper-rules-engine","text":"","title":"Command Devices with Kuiper Rules Engine"},{"location":"examples/Ch-CommandingDeviceThroughRulesEngine/#overview","text":"This document describes how to actuate a device with rules trigger by the Kuiper rules engine. To make the example simple, the virtual device device-virtual is used as the actuated device. The Kuiper rules engine analyzes the data sent from device-virtual services, and then sends a command to virtual device based a rule firing in Kuiper based on that analysis. It should be noted that an application service is used to route core data through the rules engine.","title":"Overview"},{"location":"examples/Ch-CommandingDeviceThroughRulesEngine/#use-case-scenarios","text":"Rules will be created in Kuiper to watch for two circumstances: monitor for events coming from the Random-UnsignedInteger-Device device (one of the default virtual device managed devices), and if a uint8 reading value is found larger than 20 in the event, then send a command to Random-Boolean-Device device to start generating random numbers (specifically - set random generation bool to true). monitor for events coming from the Random-Integer-Device device (another of the default virtual device managed devices), and if the average for int8 reading values (within 20 seconds) is larger than 0, then send a command to Random-Boolean-Device device to stop generating random numbers (specifically - set random generation bool to false). These use case scenarios do not have any real business meaning, but easily demonstrate the features of EdgeX automatic actuation accomplished via the Kuiper rule engine.","title":"Use Case Scenarios"},{"location":"examples/Ch-CommandingDeviceThroughRulesEngine/#prerequisite-knowledge","text":"This document will not cover basic operations of EdgeX or EMQ X Kuiper. Readers should have basic knowledge of: Get and start EdgeX. Refer to Quick Start for how to get and start EdgeX with the virtual device service. Run the Kuiper Rules Engine. Refer to EdgeX Kuiper Rule Engine Tutorial to understand the basics of Kuiper and EdgeX.","title":"Prerequisite Knowledge"},{"location":"examples/Ch-CommandingDeviceThroughRulesEngine/#start-kuiper-and-create-an-edgex-stream","text":"Make sure you read the EdgeX Kuiper Rule Engine Tutorial and successfully run Kuiper with EdgeX. First create a stream that can consume streaming data from the EdgeX application service (rules engine profile). This step is not required if you already finished the EdgeX Kuiper Rule Engine Tutorial . curl -X POST \\ http:// $kuiper_docker :48075/streams \\ -H 'Content-Type: application/json' \\ -d '{\"sql\": \"create stream demo() WITH (FORMAT=\\\"JSON\\\", TYPE=\\\"edgex\\\")\"}'","title":"Start Kuiper and Create an EdgeX Stream"},{"location":"examples/Ch-CommandingDeviceThroughRulesEngine/#get-and-test-the-command-url","text":"Since both use case scenario rules will send commands to the Random-Boolean-Device virtual device, use the curl request below to get a list of available commands for this device. curl http://localhost:48082/api/v1/device/name/Random-Boolean-Device | jq It should print results like those below. { \"id\" : \"9b051411-ca20-4556-bd3e-7f52475764ff\" , \"name\" : \"Random-Boolean-Device\" , \"adminState\" : \"UNLOCKED\" , \"operatingState\" : \"ENABLED\" , \"labels\" : [ \"device-virtual-example\" ], \"commands\" : [ { \"created\" : 1589052044139 , \"modified\" : 1589052044139 , \"id\" : \"28d88bb3-e280-46f7-949f-37cc411757f5\" , \"name\" : \"Bool\" , \"get\" : { \"path\" : \"/api/v1/device/{deviceId}/Bool\" , \"responses\" : [ { \"code\" : \"200\" , \"expectedValues\" : [ \"Bool\" ] }, { \"code\" : \"503\" , \"description\" : \"service unavailable\" } ], \"url\" : \"http://edgex-core-command:48082/api/v1/device/bcd18c02-b187-4f29-8265-8312dc5d794d/command/d6d3007d-c4ce-472f-a117-820b5410e498\" }, \"put\" : { \"path\" : \"/api/v1/device/{deviceId}/Bool\" , \"responses\" : [ { \"code\" : \"200\" }, { \"code\" : \"503\" , \"description\" : \"service unavailable\" } ], \"url\" : \"http://edgex-core-command:48082/api/v1/device/bcd18c02-b187-4f29-8265-8312dc5d794d/command/d6d3007d-c4ce-472f-a117-820b5410e498\" , \"parameterNames\" : [ \"Bool\" , \"EnableRandomization_Bool\" ] } } ] } From this output, look for the URL associated to the PUT command (the second URL listed). This is the command Kuiper will used to call on the device. There are two parameters for this command: Bool : Set the returned value when other services want to get device data. The parameter will be used only when EnableRandomization_Bool is set to false. EnableRandomization_Bool : Enable/disable the randomization generation of bool values. If this value is set to true, then the 1st parameter will be ignored. You can test calling this command with its parameters using curl as shown below. curl -X PUT \\ http://edgex-core-command:48082/api/v1/device/bcd18c02-b187-4f29-8265-8312dc5d794d/command/d6d3007d-c4ce-472f-a117-820b5410e498 \\ -H 'Content-Type: application/json' \\ -d '{\"Bool\":\"true\", \"EnableRandomization_Bool\": \"true\"}' Warning The URL used in this example will not be the same as the URL for you command service. EdgeX provides a different UUID for each command. The example above shows you what to look for and how to make the request, but the URL will be unique to your system.","title":"Get and Test the Command URL"},{"location":"examples/Ch-CommandingDeviceThroughRulesEngine/#create-rules","text":"Now that you have EdgeX and Kuiper running, the EdgeX stream defined, and you know the command to actuate Random-Boolean-Device , it is time to build the Kuiper rules.","title":"Create rules"},{"location":"examples/Ch-CommandingDeviceThroughRulesEngine/#the-first-rule","text":"Again, the 1st rule is to monitor for events coming from the Random-UnsignedInteger-Device device (one of the default virtual device managed devices), and if a uint8 reading value is found larger than 20 in the event, then send the command to Random-Boolean-Device device to start generating random numbers (specifically - set random generation bool to true). Given the URL and parameters to the command, below is the curl command to declare the first rule in Kuiper. curl -X POST \\ http:// $kuiper_server :48075/rules \\ -H 'Content-Type: application/json' \\ -d '{ \"id\": \"rule1\", \"sql\": \"SELECT uint8 FROM demo WHERE uint8 > 20\", \"actions\": [ { \"rest\": { \"url\": \"http://edgex-core-command:48082/api/v1/device/bcd18c02-b187-4f29-8265-8312dc5d794d/command/d6d3007d-c4ce-472f-a117-820b5410e498\", \"method\": \"put\", \"dataTemplate\": \"{\\\"Bool\\\":\\\"true\\\", \\\"EnableRandomization_Bool\\\": \\\"true\\\"}\", \"sendSingle\": true } }, { \"log\":{} } ] }'","title":"The first rule"},{"location":"examples/Ch-CommandingDeviceThroughRulesEngine/#the-second-rule","text":"The 2nd rule is to monitor for events coming from the Random-Integer-Device device (another of the default virtual device managed devices), and if the average for int8 reading values (within 20 seconds) is larger than 0, then send a command to Random-Boolean-Device device to stop generating random numbers (specifically - set random generation bool to false). Here is the curl request to setup the second rule in Kuiper. The same command URL is used as the same device action ( Random-Boolean-Device's PUT bool command ) is being actuated, but with different parameters. curl -X POST \\ http:// $kuiper_server :48075/rules \\ -H 'Content-Type: application/json' \\ -d '{ \"id\": \"rule2\", \"sql\": \"SELECT avg(int8) AS avg_int8 FROM demo WHERE int8 != nil GROUP BY TUMBLINGWINDOW(ss, 20) HAVING avg(int8) > 0\", \"actions\": [ { \"rest\": { \"url\": \"http://edgex-core-command:48082/api/v1/device/bcd18c02-b187-4f29-8265-8312dc5d794d/command/d6d3007d-c4ce-472f-a117-820b5410e498\", \"method\": \"put\", \"dataTemplate\": \"{\\\"Bool\\\":\\\"false\\\", \\\"EnableRandomization_Bool\\\": \\\"false\\\"}\", \"sendSingle\": true } }, { \"log\":{} } ] }'","title":"The second rule"},{"location":"examples/Ch-CommandingDeviceThroughRulesEngine/#watch-the-kuiper-logs","text":"Both rules are now created in Kuiper. Kuiper is busy analyzing the event data coming for the virtual devices looking for readings that match the rules you created. You can watch the edgex-kuiper container logs for the rule triggering and command execution. docker logs edgex-kuiper","title":"Watch the Kuiper Logs"},{"location":"examples/Ch-CommandingDeviceThroughRulesEngine/#explore-the-results","text":"You can also explore the Kuiper analysis that caused the commands to be sent to the service. To see the the data from the analysis, use the SQL below to query Kuiper filtering data. SELECT int8 , \"true\" AS randomization FROM demo WHERE uint8 > 20 The output of the SQL should look similar to the results below. [{ \"int8\" : -75 , \"randomization\" : \"true\" }]","title":"Explore the Results"},{"location":"examples/Ch-CommandingDeviceThroughRulesEngine/#extended-reading","text":"Use these resouces to learn more about the features of EMQ X Kuiper. Kuiper Github code repository Kuiper reference guide","title":"Extended Reading"},{"location":"examples/Ch-ExamplesAddingMQTTDevice/","text":"MQTT EdgeX - Edinburgh Release Overview In this example, we use the simulator instead of real device. This provides a straight-forward way to test the device-mqtt features. Run an MQTT Broker Eclipse Mosquitto is an open source (EPL/EDL licensed) message broker that implements the MQTT protocol versions 5.0, 3.1.1 and 3.1. Run Mosquitto using the following docker command: docker run -d --rm --name broker -p 1883:1883 eclipse-mosquitto Run an MQTT Device Simulator This simulator has three behaviors: Publish random number data every 15 seconds Receive the reading request, then return the response Receive the put request, then change the device value We created the following script to simulate the MQTT device: // mock - device . js function getRandomFloat ( min , max ) { return Math . random () * ( max - min ) + min ; } const deviceName = \"MQ_DEVICE\" ; let message = \"test-message\" ; // 1. Publish random number every 15 seconds schedule ( '*/15 * * * * *' , () => { let body = { \"name\" : deviceName , \"cmd\" : \"randnum\" , \"randnum\" : getRandomFloat ( 25 , 29 ) . toFixed ( 1 ) }; publish ( 'DataTopic' , JSON . stringify ( body )); }); // 2. Receive the reading request , then return the response // 3. Receive the put request , then change the device value subscribe ( \"CommandTopic\" , ( topic , val ) => { var data = val ; if ( data . method == \"set\" ) { message = data [ data . cmd ] } else { switch ( data . cmd ) { case \"ping\" : data . ping = \"pong\" ; break ; case \"message\" : data . message = message ; break ; case \"randnum\" : data . randnum = 12.123 ; break ; } } publish ( \"ResponseTopic\" , JSON . stringify ( data )); }); To run the device simulator, enter the commands shown below with the following changes: Replace the /path/to/mqtt-scripts in the example mv command with the correct path Replace the mqtt-broker-ip in the example docker run command with the correct broker IP: mv mock-device.js /path/to/mqtt-scripts docker run -d --restart=always --name=mqtt-scripts \\ -v /path/to/mqtt-scripts:/scripts \\ dersimn/mqtt-scripts --url mqtt://mqtt-broker-ip --dir /scripts Setup In this section, we create a folder that contains files required for deployment: - device-service-demo |- docker-compose.yml |- mqtt |- configuration.toml |- mqtt.test.device.profile.yml Device Profile (mqtt.test.device.profile.yml) The DeviceProfile defines the device's values and operation method, which can be Read or Write. Create a device profile, named mqtt.test.device.profile.yml, with the following content: # mqtt . test . device . profile . yml name : \"Test.Device.MQTT.Profile\" manufacturer : \"iot\" model : \"MQTT-DEVICE\" description : \"Test device profile\" labels : - \"mqtt\" - \"test\" deviceResources : - name : randnum description : \"device random number\" properties : value : { type : \"Float64\" , size : \"4\" , readWrite : \"R\" , floatEncoding : \"eNotation\" } units : { type : \"String\" , readWrite : \"R\" , defaultValue : \"\" } - name : ping description : \"device awake\" properties : value : { type : \"String\" , size : \"0\" , readWrite : \"R\" , defaultValue : \"pong\" } units : { type : \"String\" , readWrite : \"R\" , defaultValue : \"\" } - name : message description : \"device message\" properties : value : { type : \"String\" , size : \"0\" , readWrite : \"W\" , scale : \"\" , offset : \"\" , base : \"\" } units : { type : \"String\" , readWrite : \"R\" , defaultValue : \"\" } deviceCommands : - name : testrandnum get : - { index : \"1\" , operation : \"get\" , object : \"randnum\" , parameter : \"randnum\" } - name : testping get : - { index : \"1\" , operation : \"get\" , object : \"ping\" , parameter : \"ping\" } - name : testmessage get : - { index : \"1\" , operation : \"get\" , object : \"message\" , parameter : \"message\" } set : - { index : \"1\" , operation : \"set\" , object : \"message\" , parameter : \"message\" } coreCommands : - name : testrandnum get : path : \"/api/v1/device/{deviceId}/testrandnum\" responses : - code : \"200\" description : \"get the random value\" expectedValues : [ \"randnum\" ] - code : \"503\" description : \"service unavailable\" expectedValues : [] - name : testping get : path : \"/api/v1/device/{deviceId}/testping\" responses : - code : \"200\" description : \"ping the device\" expectedValues : [ \"ping\" ] - code : \"503\" description : \"service unavailable\" expectedValues : [] - name : testmessage get : path : \"/api/v1/device/{deviceId}/testmessage\" responses : - code : \"200\" description : \"get the message\" expectedValues : [ \"message\" ] - code : \"503\" description : \"service unavailable\" expectedValues : [] put : path : \"/api/v1/device/{deviceId}/testmessage\" parameterNames : [ \"message\" ] responses : - code : \"204\" description : \"set the message.\" expectedValues : [] - code : \"503\" description : \"service unavailable\" expectedValues : [] Device Service Configuration (configuration.toml) Use this configuration file to define devices and schedule jobs. device-mqtt generates a relative instance on start-up. MQTT is subscribe/publish pattern, so we must define the MQTT connection information in the [DeviceList.Protocols] section of the configuration file. Create the configuration file, named configuration.toml, as shown below replacing the host IP with your host address: # configuration . toml [ Writable ] LogLevel = 'DEBUG' [ Service ] Host = \"edgex-device-mqtt\" Port = 49982 ConnectRetries = 3 Labels = [] OpenMsg = \"device mqtt started\" Timeout = 5000 EnableAsyncReadings = true AsyncBufferSize = 16 [ Registry ] Host = \"edgex-core-consul\" Port = 8500 CheckInterval = \"10s\" FailLimit = 3 FailWaitTime = 10 Type = \"consul\" [ Logging ] EnableRemote = false File = \"./device-mqtt.log\" [ Clients ] [ Clients.Data ] Name = \"edgex-core-data\" Protocol = \"http\" Host = \"edgex-core-data\" Port = 48080 Timeout = 50000 [ Clients.Metadata ] Name = \"edgex-core-metadata\" Protocol = \"http\" Host = \"edgex-core-metadata\" Port = 48081 Timeout = 50000 [ Clients.Logging ] Name = \"edgex-support-logging\" Protocol = \"http\" Host = \"edgex-support-logging\" Port = 48061 [ Device ] DataTransform = true InitCmd = \"\" InitCmdArgs = \"\" MaxCmdOps = 128 MaxCmdValueLen = 256 RemoveCmd = \"\" RemoveCmdArgs = \"\" ProfilesDir = \"/custom-config\" # Pre - define Devices [ [DeviceList ] ] Name = \"MQ_DEVICE\" Profile = \"Test.Device.MQTT.Profile\" Description = \"General MQTT device\" Labels = [ \"MQTT\" ] [ DeviceList.Protocols ] [ DeviceList.Protocols.mqtt ] Schema = \"tcp\" Host = \"192.168.16.68\" Port = \"1883\" ClientId = \"CommandPublisher\" User = \"\" Password = \"\" Topic = \"CommandTopic\" [ [DeviceList.AutoEvents ] ] Frequency = \"30s\" OnChange = false Resource = \"testrandnum\" # Driver configs [ Driver ] IncomingSchema = \"tcp\" IncomingHost = \"192.168.16.68\" IncomingPort = \"1883\" IncomingUser = \"\" IncomingPassword = \"\" IncomingQos = \"0\" IncomingKeepAlive = \"3600\" IncomingClientId = \"IncomingDataSubscriber\" IncomingTopic = \"DataTopic\" ResponseSchema = \"tcp\" ResponseHost = \"192.168.16.68\" ResponsePort = \"1883\" ResponseUser = \"\" ResponsePassword = \"\" ResponseQos = \"0\" ResponseKeepAlive = \"3600\" ResponseClientId = \"CommandResponseSubscriber\" ResponseTopic = \"ResponseTopic\" In the Driver configs section : IncomingXxx defines the DataTopic for receiving an async value from the device ResponseXxx defines the ResponseTopic for receiving a command response from the device Add Device Service to docker-compose File (docker-compose.yml) Download the Geneva release docker-compose file from https://github.com/edgexfoundry/developer-scripts/blob/master/releases/geneva/compose-files/docker-compose-geneva-redis.yml . Because we deploy EdgeX using docker-compose, we must add device-mqtt to the docker-compose file. If you have prepared configuration files, you can mount them using volumes and change the entrypoint for device-mqtt internal use. This is illustrated in the following docker-compose file snippet: device-mqtt: image: edgexfoundry/docker-device-mqtt-go:1.0.0 ports: - \"49982:49982\" container_name: edgex-device-mqtt hostname: edgex-device-mqtt networks: - edgex-network volumes: - db-data:/data/db - log-data:/edgex/logs - consul-config:/consul/config - consul-data:/consul/data - ./mqtt:/custom-config depends_on: - data - command entrypoint: - /device-mqtt - --registry=consul://edgex-core-consul:8500 - --confdir=/custom-config When using Device Services, the user has to provide the registry URL in --registry argument. Start EdgeX Foundry on Docker Once the following folder has been populated, we can deploy EdgeX: - device-service-demo |- docker-compose.yml |- mqtt |- configuration.toml |- mqtt.test.device.profile.yml Deploy EdgeX using the following commands: cd path/to/device-service-demo docker-compose pull docker-compose up -d After the services start, check the consul dashboard as follows: Execute Commands Now we're ready to run some commands. Find Executable Commands Use the following query to find executable commands: $ curl http : // your - edgex - server - ip : 48082 / api / v1 / device | json_pp % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 1972 100 1972 0 0 64349 0 --:--:-- --:--:-- --:--:-- 65733 [ { \"location\" : null , \"adminState\" : \"UNLOCKED\" , \"commands\" : [ { ... }, { ... }, { \"get\" : { \"responses\" : [ { \"code\" : \"503\" , \"description\" : \"service unavailable\" } ], \"path\" : \"/api/v1/device/{deviceId}/testmessage\" , \"url\" : \"http://edgex-core-command:48082/api/v1/device/ddb2f5cf-eec2-4345-86ee-f0d87e6f77ff/command/0c257a37-2f72-4d23-b2b1-2c08e895060a\" }, \"modified\" : 1559195042046 , \"name\" : \"testmessage\" , \"put\" : { \"parameterNames\" : [ \"message\" ], \"path\" : \"/api/v1/device/{deviceId}/testmessage\" , \"url\" : \"http://edgex-core-command:48082/api/v1/device/ddb2f5cf-eec2-4345-86ee-f0d87e6f77ff/command/0c257a37-2f72-4d23-b2b1-2c08e895060a\" }, \"created\" : 1559195042046 , \"id\" : \"0c257a37-2f72-4d23-b2b1-2c08e895060a\" } ], \"lastReported\" : 0 , \"operatingState\" : \"ENABLED\" , \"name\" : \"MQ_DEVICE\" , \"lastConnected\" : 0 , \"id\" : \"ddb2f5cf-eec2-4345-86ee-f0d87e6f77ff\" , \"labels\" : [ \"MQTT\" ] } ] Execute put Command Execute a put command according to the url and parameterNames, replacing [host] with the server IP when running the edgex-core-command. This can be done in either of the following ways: $ curl http://your-edgex-server-ip:48082/api/v1/device/ddb2f5cf-eec2-4345-86ee-f0d87e6f77ff/command/0c257a37-2f72-4d23-b2b1-2c08e895060a \\ -H \"Content-Type:application/json\" -X PUT \\ -d '{\"message\":\"Hello!\"}' or \\$ curl \" http://your-edgex-server-ip:48082/api/v1/device/name/MQ_DEVICE/command/testmessage \" -H \"Content-Type:application/json\" -X PUT -d '{\"message\":\"Hello!\"}' Execute get Command Execute a get command as follows: $ curl \"http://your-edgex-server-ip:48082/api/v1/device/name/MQ_DEVICE/command/testmessage\" | json_pp % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 139 100 139 0 0 132 0 0 : 00 : 01 0 : 00 : 01 --:--:-- 132 { \"readings\" : [ { \"name\" : \"message\" , \"device\" : \"MQ_DEVICE\" , \"value\" : \"Hello!\" , \"origin\" : 1559196276732 } ], \"device\" : \"MQ_DEVICE\" , \"origin\" : 1559196276738 } Schedule Job The schedule job is defined in the [[DeviceList.AutoEvents]] section of the TOML configuration file: # Pre - define Devices [ [DeviceList ] ] Name = \"MQ_DEVICE\" Profile = \"Test.Device.MQTT.Profile\" Description = \"General MQTT device\" Labels = [ \"MQTT\" ] [ DeviceList.Protocols ] [ DeviceList.Protocols.mqtt ] Schema = \"tcp\" Host = \"192.168.16.68\" Port = \"1883\" ClientId = \"CommandPublisher\" User = \"\" Password = \"\" Topic = \"CommandTopic\" [ [DeviceList.AutoEvents ] ] Frequency = \"30s\" OnChange = false Resource = \"testrandnum\" After the service starts, query core-data's reading API. The results show that the service auto-executes the command every 30 secs, as shown below: $ curl http : // your - edgex - server - ip : 48080 / api / v1 / reading | json_pp % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 1613 100 1613 0 0 372 k 0 --:--:-- --:--:-- --:--:-- 393 k [ { \"value\" : \"1.212300e+01\" , \"origin\" : 1559197206092 , \"modified\" : 1559197206104 , \"id\" : \"59f2a768-ad72-49a1-9df9-700d8599a890\" , \"created\" : 1559197206104 , \"device\" : \"MQ_DEVICE\" , \"name\" : \"randnum\" }, { ... }, { \"name\" : \"randnum\" , \"device\" : \"MQ_DEVICE\" , \"modified\" : 1559197175109 , \"created\" : 1559197175109 , \"id\" : \"f9dc39e0-5326-45d0-831d-fd0cd106fe2f\" , \"origin\" : 1559197175098 , \"value\" : \"1.212300e+01\" }, ] Async Device Reading device-mqtt subscribes to a DataTopic , which is wait for real device* to send value to broker , then device-mqtt parses the value and sends it back to core-data . The data format contains the following values: name = device name cmd = deviceResource name method = get or put cmd = device reading You must define this connection information in the driver configuration file, as follows: [Driver] IncomingSchema = \"tcp\" IncomingHost = \"192.168.16.68\" IncomingPort = \"1883\" IncomingUser = \"\" IncomingPassword = \"\" IncomingQos = \"0\" IncomingKeepAlive = \"3600\" IncomingClientId = \"IncomingDataSubscriber\" IncomingTopic = \"DataTopic\" The following results show that the mock device sent the reading every 15 secs: $ curl http : // your - edgex - server - ip : 48080 / api / v1 / reading | json_pp % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 539 100 539 0 0 169 k 0 --:--:-- --:--:-- --:--:-- 175 k [ { ... }, { \"name\" : \"randnum\" , \"created\" : 1559197140013 , \"origin\" : 1559197140006 , \"modified\" : 1559197140013 , \"id\" : \"286cc305-42f6-4bca-ad41-3af52301c9f7\" , \"value\" : \"2.830000e+01\" , \"device\" : \"MQ_DEVICE\" }, { \"modified\" : 1559197125011 , \"name\" : \"randnum\" , \"created\" : 1559197125011 , \"origin\" : 1559197125004 , \"device\" : \"MQ_DEVICE\" , \"value\" : \"2.690000e+01\" , \"id\" : \"c243e8c6-a904-4102-baff-8a5e4829c4f6\" } ]","title":"MQTT"},{"location":"examples/Ch-ExamplesAddingMQTTDevice/#mqtt","text":"EdgeX - Edinburgh Release","title":"MQTT"},{"location":"examples/Ch-ExamplesAddingMQTTDevice/#overview","text":"In this example, we use the simulator instead of real device. This provides a straight-forward way to test the device-mqtt features.","title":"Overview"},{"location":"examples/Ch-ExamplesAddingMQTTDevice/#run-an-mqtt-broker","text":"Eclipse Mosquitto is an open source (EPL/EDL licensed) message broker that implements the MQTT protocol versions 5.0, 3.1.1 and 3.1. Run Mosquitto using the following docker command: docker run -d --rm --name broker -p 1883:1883 eclipse-mosquitto","title":"Run an MQTT Broker"},{"location":"examples/Ch-ExamplesAddingMQTTDevice/#run-an-mqtt-device-simulator","text":"This simulator has three behaviors: Publish random number data every 15 seconds Receive the reading request, then return the response Receive the put request, then change the device value We created the following script to simulate the MQTT device: // mock - device . js function getRandomFloat ( min , max ) { return Math . random () * ( max - min ) + min ; } const deviceName = \"MQ_DEVICE\" ; let message = \"test-message\" ; // 1. Publish random number every 15 seconds schedule ( '*/15 * * * * *' , () => { let body = { \"name\" : deviceName , \"cmd\" : \"randnum\" , \"randnum\" : getRandomFloat ( 25 , 29 ) . toFixed ( 1 ) }; publish ( 'DataTopic' , JSON . stringify ( body )); }); // 2. Receive the reading request , then return the response // 3. Receive the put request , then change the device value subscribe ( \"CommandTopic\" , ( topic , val ) => { var data = val ; if ( data . method == \"set\" ) { message = data [ data . cmd ] } else { switch ( data . cmd ) { case \"ping\" : data . ping = \"pong\" ; break ; case \"message\" : data . message = message ; break ; case \"randnum\" : data . randnum = 12.123 ; break ; } } publish ( \"ResponseTopic\" , JSON . stringify ( data )); }); To run the device simulator, enter the commands shown below with the following changes: Replace the /path/to/mqtt-scripts in the example mv command with the correct path Replace the mqtt-broker-ip in the example docker run command with the correct broker IP: mv mock-device.js /path/to/mqtt-scripts docker run -d --restart=always --name=mqtt-scripts \\ -v /path/to/mqtt-scripts:/scripts \\ dersimn/mqtt-scripts --url mqtt://mqtt-broker-ip --dir /scripts","title":"Run an MQTT Device Simulator"},{"location":"examples/Ch-ExamplesAddingMQTTDevice/#setup","text":"In this section, we create a folder that contains files required for deployment: - device-service-demo |- docker-compose.yml |- mqtt |- configuration.toml |- mqtt.test.device.profile.yml","title":"Setup"},{"location":"examples/Ch-ExamplesAddingMQTTDevice/#device-profile-mqtttestdeviceprofileyml","text":"The DeviceProfile defines the device's values and operation method, which can be Read or Write. Create a device profile, named mqtt.test.device.profile.yml, with the following content: # mqtt . test . device . profile . yml name : \"Test.Device.MQTT.Profile\" manufacturer : \"iot\" model : \"MQTT-DEVICE\" description : \"Test device profile\" labels : - \"mqtt\" - \"test\" deviceResources : - name : randnum description : \"device random number\" properties : value : { type : \"Float64\" , size : \"4\" , readWrite : \"R\" , floatEncoding : \"eNotation\" } units : { type : \"String\" , readWrite : \"R\" , defaultValue : \"\" } - name : ping description : \"device awake\" properties : value : { type : \"String\" , size : \"0\" , readWrite : \"R\" , defaultValue : \"pong\" } units : { type : \"String\" , readWrite : \"R\" , defaultValue : \"\" } - name : message description : \"device message\" properties : value : { type : \"String\" , size : \"0\" , readWrite : \"W\" , scale : \"\" , offset : \"\" , base : \"\" } units : { type : \"String\" , readWrite : \"R\" , defaultValue : \"\" } deviceCommands : - name : testrandnum get : - { index : \"1\" , operation : \"get\" , object : \"randnum\" , parameter : \"randnum\" } - name : testping get : - { index : \"1\" , operation : \"get\" , object : \"ping\" , parameter : \"ping\" } - name : testmessage get : - { index : \"1\" , operation : \"get\" , object : \"message\" , parameter : \"message\" } set : - { index : \"1\" , operation : \"set\" , object : \"message\" , parameter : \"message\" } coreCommands : - name : testrandnum get : path : \"/api/v1/device/{deviceId}/testrandnum\" responses : - code : \"200\" description : \"get the random value\" expectedValues : [ \"randnum\" ] - code : \"503\" description : \"service unavailable\" expectedValues : [] - name : testping get : path : \"/api/v1/device/{deviceId}/testping\" responses : - code : \"200\" description : \"ping the device\" expectedValues : [ \"ping\" ] - code : \"503\" description : \"service unavailable\" expectedValues : [] - name : testmessage get : path : \"/api/v1/device/{deviceId}/testmessage\" responses : - code : \"200\" description : \"get the message\" expectedValues : [ \"message\" ] - code : \"503\" description : \"service unavailable\" expectedValues : [] put : path : \"/api/v1/device/{deviceId}/testmessage\" parameterNames : [ \"message\" ] responses : - code : \"204\" description : \"set the message.\" expectedValues : [] - code : \"503\" description : \"service unavailable\" expectedValues : []","title":"Device Profile (mqtt.test.device.profile.yml)"},{"location":"examples/Ch-ExamplesAddingMQTTDevice/#device-service-configuration-configurationtoml","text":"Use this configuration file to define devices and schedule jobs. device-mqtt generates a relative instance on start-up. MQTT is subscribe/publish pattern, so we must define the MQTT connection information in the [DeviceList.Protocols] section of the configuration file. Create the configuration file, named configuration.toml, as shown below replacing the host IP with your host address: # configuration . toml [ Writable ] LogLevel = 'DEBUG' [ Service ] Host = \"edgex-device-mqtt\" Port = 49982 ConnectRetries = 3 Labels = [] OpenMsg = \"device mqtt started\" Timeout = 5000 EnableAsyncReadings = true AsyncBufferSize = 16 [ Registry ] Host = \"edgex-core-consul\" Port = 8500 CheckInterval = \"10s\" FailLimit = 3 FailWaitTime = 10 Type = \"consul\" [ Logging ] EnableRemote = false File = \"./device-mqtt.log\" [ Clients ] [ Clients.Data ] Name = \"edgex-core-data\" Protocol = \"http\" Host = \"edgex-core-data\" Port = 48080 Timeout = 50000 [ Clients.Metadata ] Name = \"edgex-core-metadata\" Protocol = \"http\" Host = \"edgex-core-metadata\" Port = 48081 Timeout = 50000 [ Clients.Logging ] Name = \"edgex-support-logging\" Protocol = \"http\" Host = \"edgex-support-logging\" Port = 48061 [ Device ] DataTransform = true InitCmd = \"\" InitCmdArgs = \"\" MaxCmdOps = 128 MaxCmdValueLen = 256 RemoveCmd = \"\" RemoveCmdArgs = \"\" ProfilesDir = \"/custom-config\" # Pre - define Devices [ [DeviceList ] ] Name = \"MQ_DEVICE\" Profile = \"Test.Device.MQTT.Profile\" Description = \"General MQTT device\" Labels = [ \"MQTT\" ] [ DeviceList.Protocols ] [ DeviceList.Protocols.mqtt ] Schema = \"tcp\" Host = \"192.168.16.68\" Port = \"1883\" ClientId = \"CommandPublisher\" User = \"\" Password = \"\" Topic = \"CommandTopic\" [ [DeviceList.AutoEvents ] ] Frequency = \"30s\" OnChange = false Resource = \"testrandnum\" # Driver configs [ Driver ] IncomingSchema = \"tcp\" IncomingHost = \"192.168.16.68\" IncomingPort = \"1883\" IncomingUser = \"\" IncomingPassword = \"\" IncomingQos = \"0\" IncomingKeepAlive = \"3600\" IncomingClientId = \"IncomingDataSubscriber\" IncomingTopic = \"DataTopic\" ResponseSchema = \"tcp\" ResponseHost = \"192.168.16.68\" ResponsePort = \"1883\" ResponseUser = \"\" ResponsePassword = \"\" ResponseQos = \"0\" ResponseKeepAlive = \"3600\" ResponseClientId = \"CommandResponseSubscriber\" ResponseTopic = \"ResponseTopic\" In the Driver configs section : IncomingXxx defines the DataTopic for receiving an async value from the device ResponseXxx defines the ResponseTopic for receiving a command response from the device","title":"Device Service Configuration (configuration.toml)"},{"location":"examples/Ch-ExamplesAddingMQTTDevice/#add-device-service-to-docker-compose-file-docker-composeyml","text":"Download the Geneva release docker-compose file from https://github.com/edgexfoundry/developer-scripts/blob/master/releases/geneva/compose-files/docker-compose-geneva-redis.yml . Because we deploy EdgeX using docker-compose, we must add device-mqtt to the docker-compose file. If you have prepared configuration files, you can mount them using volumes and change the entrypoint for device-mqtt internal use. This is illustrated in the following docker-compose file snippet: device-mqtt: image: edgexfoundry/docker-device-mqtt-go:1.0.0 ports: - \"49982:49982\" container_name: edgex-device-mqtt hostname: edgex-device-mqtt networks: - edgex-network volumes: - db-data:/data/db - log-data:/edgex/logs - consul-config:/consul/config - consul-data:/consul/data - ./mqtt:/custom-config depends_on: - data - command entrypoint: - /device-mqtt - --registry=consul://edgex-core-consul:8500 - --confdir=/custom-config When using Device Services, the user has to provide the registry URL in --registry argument.","title":"Add Device Service to docker-compose File (docker-compose.yml)"},{"location":"examples/Ch-ExamplesAddingMQTTDevice/#start-edgex-foundry-on-docker","text":"Once the following folder has been populated, we can deploy EdgeX: - device-service-demo |- docker-compose.yml |- mqtt |- configuration.toml |- mqtt.test.device.profile.yml Deploy EdgeX using the following commands: cd path/to/device-service-demo docker-compose pull docker-compose up -d After the services start, check the consul dashboard as follows:","title":"Start EdgeX Foundry on Docker"},{"location":"examples/Ch-ExamplesAddingMQTTDevice/#execute-commands","text":"Now we're ready to run some commands.","title":"Execute Commands"},{"location":"examples/Ch-ExamplesAddingMQTTDevice/#find-executable-commands","text":"Use the following query to find executable commands: $ curl http : // your - edgex - server - ip : 48082 / api / v1 / device | json_pp % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 1972 100 1972 0 0 64349 0 --:--:-- --:--:-- --:--:-- 65733 [ { \"location\" : null , \"adminState\" : \"UNLOCKED\" , \"commands\" : [ { ... }, { ... }, { \"get\" : { \"responses\" : [ { \"code\" : \"503\" , \"description\" : \"service unavailable\" } ], \"path\" : \"/api/v1/device/{deviceId}/testmessage\" , \"url\" : \"http://edgex-core-command:48082/api/v1/device/ddb2f5cf-eec2-4345-86ee-f0d87e6f77ff/command/0c257a37-2f72-4d23-b2b1-2c08e895060a\" }, \"modified\" : 1559195042046 , \"name\" : \"testmessage\" , \"put\" : { \"parameterNames\" : [ \"message\" ], \"path\" : \"/api/v1/device/{deviceId}/testmessage\" , \"url\" : \"http://edgex-core-command:48082/api/v1/device/ddb2f5cf-eec2-4345-86ee-f0d87e6f77ff/command/0c257a37-2f72-4d23-b2b1-2c08e895060a\" }, \"created\" : 1559195042046 , \"id\" : \"0c257a37-2f72-4d23-b2b1-2c08e895060a\" } ], \"lastReported\" : 0 , \"operatingState\" : \"ENABLED\" , \"name\" : \"MQ_DEVICE\" , \"lastConnected\" : 0 , \"id\" : \"ddb2f5cf-eec2-4345-86ee-f0d87e6f77ff\" , \"labels\" : [ \"MQTT\" ] } ]","title":"Find Executable Commands"},{"location":"examples/Ch-ExamplesAddingMQTTDevice/#execute-put-command","text":"Execute a put command according to the url and parameterNames, replacing [host] with the server IP when running the edgex-core-command. This can be done in either of the following ways: $ curl http://your-edgex-server-ip:48082/api/v1/device/ddb2f5cf-eec2-4345-86ee-f0d87e6f77ff/command/0c257a37-2f72-4d23-b2b1-2c08e895060a \\ -H \"Content-Type:application/json\" -X PUT \\ -d '{\"message\":\"Hello!\"}' or \\$ curl \" http://your-edgex-server-ip:48082/api/v1/device/name/MQ_DEVICE/command/testmessage \" -H \"Content-Type:application/json\" -X PUT -d '{\"message\":\"Hello!\"}'","title":"Execute put Command"},{"location":"examples/Ch-ExamplesAddingMQTTDevice/#execute-get-command","text":"Execute a get command as follows: $ curl \"http://your-edgex-server-ip:48082/api/v1/device/name/MQ_DEVICE/command/testmessage\" | json_pp % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 139 100 139 0 0 132 0 0 : 00 : 01 0 : 00 : 01 --:--:-- 132 { \"readings\" : [ { \"name\" : \"message\" , \"device\" : \"MQ_DEVICE\" , \"value\" : \"Hello!\" , \"origin\" : 1559196276732 } ], \"device\" : \"MQ_DEVICE\" , \"origin\" : 1559196276738 }","title":"Execute get Command"},{"location":"examples/Ch-ExamplesAddingMQTTDevice/#schedule-job","text":"The schedule job is defined in the [[DeviceList.AutoEvents]] section of the TOML configuration file: # Pre - define Devices [ [DeviceList ] ] Name = \"MQ_DEVICE\" Profile = \"Test.Device.MQTT.Profile\" Description = \"General MQTT device\" Labels = [ \"MQTT\" ] [ DeviceList.Protocols ] [ DeviceList.Protocols.mqtt ] Schema = \"tcp\" Host = \"192.168.16.68\" Port = \"1883\" ClientId = \"CommandPublisher\" User = \"\" Password = \"\" Topic = \"CommandTopic\" [ [DeviceList.AutoEvents ] ] Frequency = \"30s\" OnChange = false Resource = \"testrandnum\" After the service starts, query core-data's reading API. The results show that the service auto-executes the command every 30 secs, as shown below: $ curl http : // your - edgex - server - ip : 48080 / api / v1 / reading | json_pp % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 1613 100 1613 0 0 372 k 0 --:--:-- --:--:-- --:--:-- 393 k [ { \"value\" : \"1.212300e+01\" , \"origin\" : 1559197206092 , \"modified\" : 1559197206104 , \"id\" : \"59f2a768-ad72-49a1-9df9-700d8599a890\" , \"created\" : 1559197206104 , \"device\" : \"MQ_DEVICE\" , \"name\" : \"randnum\" }, { ... }, { \"name\" : \"randnum\" , \"device\" : \"MQ_DEVICE\" , \"modified\" : 1559197175109 , \"created\" : 1559197175109 , \"id\" : \"f9dc39e0-5326-45d0-831d-fd0cd106fe2f\" , \"origin\" : 1559197175098 , \"value\" : \"1.212300e+01\" }, ]","title":"Schedule Job"},{"location":"examples/Ch-ExamplesAddingMQTTDevice/#async-device-reading","text":"device-mqtt subscribes to a DataTopic , which is wait for real device* to send value to broker , then device-mqtt parses the value and sends it back to core-data . The data format contains the following values: name = device name cmd = deviceResource name method = get or put cmd = device reading You must define this connection information in the driver configuration file, as follows: [Driver] IncomingSchema = \"tcp\" IncomingHost = \"192.168.16.68\" IncomingPort = \"1883\" IncomingUser = \"\" IncomingPassword = \"\" IncomingQos = \"0\" IncomingKeepAlive = \"3600\" IncomingClientId = \"IncomingDataSubscriber\" IncomingTopic = \"DataTopic\" The following results show that the mock device sent the reading every 15 secs: $ curl http : // your - edgex - server - ip : 48080 / api / v1 / reading | json_pp % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 539 100 539 0 0 169 k 0 --:--:-- --:--:-- --:--:-- 175 k [ { ... }, { \"name\" : \"randnum\" , \"created\" : 1559197140013 , \"origin\" : 1559197140006 , \"modified\" : 1559197140013 , \"id\" : \"286cc305-42f6-4bca-ad41-3af52301c9f7\" , \"value\" : \"2.830000e+01\" , \"device\" : \"MQ_DEVICE\" }, { \"modified\" : 1559197125011 , \"name\" : \"randnum\" , \"created\" : 1559197125011 , \"origin\" : 1559197125004 , \"device\" : \"MQ_DEVICE\" , \"value\" : \"2.690000e+01\" , \"id\" : \"c243e8c6-a904-4102-baff-8a5e4829c4f6\" } ]","title":"Async Device Reading"},{"location":"examples/Ch-ExamplesAddingModbusDevice/","text":"Modbus EdgeX - Delhi Release PowerScout 3037 Power Submeter https://shop.dentinstruments.com/products/powerscout-3037-ps3037 https://www.dentinstruments.com/hs-fs/hub/472997/file-2378482732-pdf/Pdf_Files/PS3037_Manual.pdf In this example, we simulate the PowerScout meter instead of using a real device. This provides a straight-forward way to test the device-modbus features. Environment You can use any operating system that can install docker and docker-compose. In this example, we use Photon OS to delpoy EdgeX using docker. The system requirements can be found at https://docs.edgexfoundry.org/Ch-GettingStartedUsers.html#what-you-need . Modbus Device (Simulator) http://modbuspal.sourceforge.net/ To simulate sensors, such as temperature and humidity, do the following: Add two mock devices: Add registers according to the device manual: Add the ModbusPal support value auto-generator, which can bind to registers: Set Up Before Starting Services The following sections describe how to complete the set up before starting the services. If you prefer to start the services and then add the device, see Set Up After Starting Services Set Up Device Profile The DeviceProfile defines the device's values and operation method, which can be Read or Write. In the Modbus protocol, we must define attributes: primaryTable : HOLDING_REGISTERS, INPUT_REGISTERS, COILS, DISCRETES_INPUT startingAddress specifies the address in Modbus device The Property value type decides how many registers will be read. Like Holding registers, a register has 16 bits. If the device manual specifies that a value has two registers, define it as FLOAT32 or INT32 or UINT32 in the deviceProfile. Once we execute a command, device-modbus knows its value type and register type, startingAddress, and register length. So it can read or write value using the modbus protocol. Create the device profile, as shown below: name: \"Network Power Meter\" manufacturer: \"Dent Instruments\" model: \"PS3037\" description: \"Power Scout Meter\" labels: - \"modbus\" - \"powerscout\" deviceResources: - name: \"Current\" description: \"Average current of all phases\" attributes: { primaryTable: \"HOLDING_REGISTERS\", startingAddress: \"9\" } properties: value: { type: \"UINT16\", scale: \"1\"} units: { type: \"String\", readWrite: \"R\", defaultValue: \"min\"} - name: \"Energy\" description: \"System Total True Energy\" attributes: { primaryTable: \"HOLDING_REGISTERS\", startingAddress: \"4001\" } properties: value: { type: \"FLOAT32\", scale: \"1\"} units: { type: \"String\", readWrite: \"R\", defaultValue: \"min\"} - name: \"Power\" description: \"System Total True Power \" attributes: { primaryTable: \"HOLDING_REGISTERS\", startingAddress: \"4003\" } properties: value: { type: \"UINT16\", scale: \"1\"} units: { type: \"String\", readWrite: \"R\", defaultValue: \"min\"} - name: \"Voltage\" description: \"Voltage Line to line (Volts) Average\" attributes: { primaryTable: \"HOLDING_REGISTERS\", startingAddress: \"4017\" } properties: value: { type: \"UINT16\", scale: \"1\"} units: { type: \"String\", readWrite: \"R\", defaultValue: \"min\"} - name: \"DemandWindowSize\" description: \"Demand window size in minutes; default is 15 min\" attributes: { primaryTable: \"HOLDING_REGISTERS\", startingAddress: \"4603\" } properties: value: { type: \"UINT16\", readWrite: \"R\", scale: \"1\"} units: { type: \"String\", readWrite: \"R\", defaultValue: \"min\"} - name: \"LineFrequency\" description: \"Line frequency setting for metering: 50=50 Hz, 60=60Hz\" attributes: { primaryTable: \"HOLDING_REGISTERS\", startingAddress: \"4609\" } properties: value: { type: \"UINT16\", readWrite: \"R\", scale: \"1\"} units: { type: \"String\", readWrite: \"R\", defaultValue: \"Hz\"} deviceCommands: - name: \"Current\" get: - { index: \"1\", operation: \"get\", deviceResource: \"Current\" } - name: \"Values\" get: - { index: \"1\", operation: \"get\", deviceResource: \"Energy\" } - { index: \"2\", operation: \"get\", deviceResource: \"Power\" } - { index: \"3\", operation: \"get\", deviceResource: \"Voltage\" } - name: \"Configuration\" set: - { index: \"1\", operation: \"set\", deviceResource: \"DemandWindowSize\" } - { index: \"2\", operation: \"set\", deviceResource: \"LineFrequency\" } get: - { index: \"1\", operation: \"get\", deviceResource: \"DemandWindowSize\" } - { index: \"2\", operation: \"get\", deviceResource: \"LineFrequency\" } coreCommands: - name: \"Current\" get: path: \"/api/v1/device/{deviceId}/Current\" responses: - code: \"200\" description: \"Get the Current\" expectedValues: [\"Current\"] - code: \"500\" description: \"internal server error\" expectedValues: [] - name: \"Values\" get: path: \"/api/v1/device/{deviceId}/Values\" responses: - code: \"200\" description: \"Get the Values\" expectedValues: [\"Energy\",\"Power\",\"Voltage\"] - code: \"500\" description: \"internal server error\" expectedValues: [] - name: \"Configuration\" get: path: \"/api/v1/device/{deviceId}/Configuration\" responses: - code: \"200\" description: \"Get the Configuration\" expectedValues: [\"DemandWindowSize\",\"LineFrequency\"] - code: \"500\" description: \"internal server error\" expectedValues: [] put: path: \"/api/v1/device/{deviceId}/Configuration\" parameterNames: [\"DemandWindowSize\",\"LineFrequency\"] responses: - code: \"204\" description: \"Set the Configuration\" expectedValues: [] - code: \"500\" description: \"internal server error\" expectedValues: [] Set Up Device Service Configuration Use this configuration file to define devices and AutoEvent. The device-modbus generates a relative instance on startup. device-modbus offers two types of protocol, Modbus TCP and Modbus RTU, which can be defined as shown below: protocol Name Protocol Address Port UnitID BaudRate DataBits StopBits Parity Modbus TCP Gateway address TCP 10.211.55.6 502 1 Modbus RTU Gateway address RTU /tmp/slave 502 2 19200 8 1 N In the RTU protocol, Parity can be: * N - None is 0 * O - Odd is 1 * E - Even is 2, default is E Create the configuration.toml file, as shown below: [Writable] LogLevel = 'DEBUG' [Service] BootTimeout = 30000 CheckInterval = '10s' Host = 'localhost' ServerBindAddr = '' # blank value defaults to Service.Host value Port = 49991 Protocol = 'http' StartupMsg = 'device modbus started' Timeout = 5000 ConnectRetries = 10 Labels = [] EnableAsyncReadings = true AsyncBufferSize = 16 [Registry] Host = 'localhost' Port = 8500 Type = 'consul' [Logging] EnableRemote = false File = '' [Clients] [Clients.Data] Protocol = 'http' Host = 'localhost' Port = 48080 [Clients.Metadata] Protocol = 'http' Host = 'localhost' Port = 48081 [Clients.Logging] Protocol = 'http' Host = 'localhost' Port = 48061 [Device] DataTransform = true InitCmd = '' InitCmdArgs = '' MaxCmdOps = 128 MaxCmdValueLen = 256 RemoveCmd = '' RemoveCmdArgs = '' ProfilesDir = './res/example' UpdateLastConnected = false # Pre-define Devices [[DeviceList]] Name = 'Modbus TCP test device' Profile = 'Test.Device.Modbus.Profile' Description = 'This device is a product for monitoring and controlling digital inputs and outputs over a LAN.' labels = [ 'Air conditioner','modbus TCP' ] [DeviceList.Protocols] [DeviceList.Protocols.modbus-tcp] Address = '0.0.0.0' Port = '1502' UnitID = '1' [[DeviceList.AutoEvents]] Frequency = '20s' OnChange = false Resource = 'Configuration' [[DeviceList.AutoEvents]] Frequency = '20s' OnChange = true Resource = 'Values' [[DeviceList]] Name = 'Modbus RTU test device' Profile = 'Test.Device.Modbus.Profile' Description = 'This device is a product for monitoring and controlling digital inputs and outputs over a LAN.' labels = [ 'Air conditioner','modbus RTU' ] [DeviceList.Protocols] [DeviceList.Protocols.modbus-rtu] Address = '/tmp/slave' BaudRate = '19200' DataBits = '8' StopBits = '1' Parity = 'N' UnitID = '1' Add Device Service to docker-compose File Because we deploy EdgeX using docker-compose, we must add the device-modbus to the docker-compose file ( https://github.com/edgexfoundry/developer-scripts/blob/master/releases/geneva/compose-files/docker-compose-geneva-redis.yml ). If you have prepared configuration files, you can mount them using volumes and change the entrypoint for device-modbus internal use. Start EdgeX Foundry on Docker Finally, we can deploy EdgeX in the Photon OS. Prepare configuration files by moving the files to the Photon OS Deploy EdgeX using the following commands: docker-compose pull docker-compose up -d Check the consul dashboard Set Up After Starting Services If the services are already running and you want to add a device, you can use the Core Metadata API as outlined in this section. If you set up the device profile and Service as described in Set Up Before Starting Services , you can skip this section. To add a device after starting the services, complete the following steps: Upload the device profile above to metadata with a POST to http://localhost:48081/api/v1/deviceprofile/uploadfile and add the file as key \"file\" to the body in form-data format, and the created ID will be returned. The following example command uses curl to send the request: $ curl http://your-edgex-server-ip:48081/api/v1/deviceprofile/uploadfile \\ -F \"file=@DENT.Mod.PS6037.profile.yaml\" Ensure the Modbus device service is running, adjust the service name below to match if necessary or if using other device services. Add the device with a POST to http://localhost:48081/api/v1/device , the body will look something like: $ curl http://your-edgex-server-ip:48081/api/v1/device -H \"Content-Type:application/json\" -X POST \\ -d '{ \"name\" :\"Modbus-TCP-Device-2\", \"description\":\"Power Submeter device.\", \"adminState\":\"UNLOCKED\", \"operatingState\":\"ENABLED\", \"protocols\":{ \"modbus-tcp\":{ \"Address\" : \"your-device-ip\", \"Port\" : \"1502\", \"UnitID\" : \"2\" } }, \"labels\":[ \"power submeter\", \"modbus TCP\" ], \"service\":{\"name\":\"edgex-device-modbus\"}, \"profile\":{\"name\":\"Network Power Meter\"}, \"autoEvents\":[ { \"frequency\":\"50s\", \"onChange\":false, \"resource\":\"Configuration\" }, { \"frequency\":\"5s\", \"onChange\":true, \"resource\":\"Values\" } ] }' The service name must match/refer to the target device service, and the profile name must match the device profile name from Step 1. Execute Commands Now we're ready to run some commands. Find Executable Commands Use the following query to find executable commands: $ curl http://your-edgex-server-ip:48082/api/v1/device | json_pp % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 1718 100 1718 0 0 14081 0 --:--:-- --:--:-- --:--:-- 14081 [ { \"id\" : \"56dcf3ad-52d8-4d12-a2d0-ae53c177ae3d\", \"commands\" : [ { \"put\" : { \"url\" : \"http://edgex-core-command:48082/api/v1/device/56dcf3ad-52d8-4d12-a2d0-ae53c177ae3d/command/67b35f63-8f94-427b-a60c-188bf9e0633a\", \"parameterNames\" : [ \"DemandWindowSize\", \"LineFrequency\" ], \"path\" : \"/api/v1/device/{deviceId}/Configuration\" }, \"id\" : \"67b35f63-8f94-427b-a60c-188bf9e0633a\", \"get\" : { \"url\" : \"http://edgex-core-command:48082/api/v1/device/56dcf3ad-52d8-4d12-a2d0-ae53c177ae3d/command/67b35f63-8f94-427b-a60c-188bf9e0633a\", \"responses\" : [ { \"description\" : \"service unavailable\", \"code\" : \"503\" } ], \"path\" : \"/api/v1/device/{deviceId}/Configuration\" }, ... \"name\" : \"Configuration\" } ], ... }, { .... } ] Execute PUT command Execute PUT command according to url and parameterNames , replacing [host] with the server IP when running the edgex-core-command. This can be done in either of the following ways: $ curl http://your-edgex-server-ip:48082/api/v1/device/56dcf3ad-52d8-4d12-a2d0-ae53c177ae3d/command/67b35f63-8f94-427b-a60c-188bf9e0633a \\ -H \"Content-Type:application/json\" -X PUT \\ -d '{\"DemandWindowSize\":\"1122\",\"LineFrequency\":\"1012\"}' Aside from using device id and command id in the URL, use the following API with device name and command is another approach. Refer to Core Command API for more details. $ curl \"http://your-edgex-server-ip:48082/api/v1/device/name/Modbus-TCP-Device/command/Configuration\" \\ -H \"Content-Type:application/json\" -X PUT \\ -d '{\"DemandWindowSize\":\"1122\",\"LineFrequency\":\"1012\"}' Check the result from Modbus simulator: Execute GET command Replace \\<host> with the server IP when running the edgex-core-command. $ curl \"http://your-edgex-server-ip:48082/api/v1/device/name/Modbus-TCP-Device/command/Configuration\" | json_pp % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 320 100 320 0 0 12800 0 --:--:-- --:--:-- --:--:-- 12307 { \"device\" : \"Modbus-TCP-Device\", \"EncodedEvent\" : null, \"readings\" : [ { \"device\" : \"Modbus-TCP-Device\", \"origin\" : 1574314180435573491, \"name\" : \"DemandWindowSize\", \"value\" : \"1122\" }, { \"origin\" : 1574314180435578175, \"device\" : \"Modbus-TCP-Device\", \"value\" : \"1012\", \"name\" : \"LineFrequency\" } ], \"origin\" : 1574314180435629113 } AutoEvent The AutoEvent is defined in the [[DeviceList.AutoEvents]] section of the TOML configuration file: # Pre-define Devices [[DeviceList]] Name = 'Modbus TCP test device' Profile = 'Test.Device.Modbus.Profile' Description = 'This device is a product for monitoring and controlling digital inputs and outputs over a LAN.' labels = [ 'Air conditioner','modbus TCP' ] [DeviceList.Protocols] [DeviceList.Protocols.modbus-tcp] Address = '0.0.0.0' Port = '1502' UnitID = '1' [[DeviceList.AutoEvents]] Frequency = '20s' OnChange = false Resource = 'HVACValues' After service startup, query core-data's reading API. The results show that the service auto-executes the command every 20 seconds. $ curl \"http://your-edgex-server-ip:48080/api/v1/event/device/Modbus-TCP-Device/10\" | json_pp % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 1997 100 1997 0 0 216k 0 --:--:-- --:--:-- --:--:-- 216k [ { \"origin\" : 1574313452749054661, \"id\" : \"a066d154-fe44-4572-9870-8790017b9c59\", \"created\" : 1574313452750, \"device\" : \"Modbus-TCP-Device\", \"readings\" : [ ... ] }, { \"device\" : \"Modbus-TCP-Device\", \"readings\" : [ ... ], \"created\" : 1574313457759, \"id\" : \"25314175-d6f5-461e-8be4-94129fbf94c6\", \"origin\" : 1574313457757445677 }, ... ]","title":"Modbus"},{"location":"examples/Ch-ExamplesAddingModbusDevice/#modbus","text":"EdgeX - Delhi Release PowerScout 3037 Power Submeter https://shop.dentinstruments.com/products/powerscout-3037-ps3037 https://www.dentinstruments.com/hs-fs/hub/472997/file-2378482732-pdf/Pdf_Files/PS3037_Manual.pdf In this example, we simulate the PowerScout meter instead of using a real device. This provides a straight-forward way to test the device-modbus features.","title":"Modbus"},{"location":"examples/Ch-ExamplesAddingModbusDevice/#environment","text":"You can use any operating system that can install docker and docker-compose. In this example, we use Photon OS to delpoy EdgeX using docker. The system requirements can be found at https://docs.edgexfoundry.org/Ch-GettingStartedUsers.html#what-you-need .","title":"Environment"},{"location":"examples/Ch-ExamplesAddingModbusDevice/#modbus-device-simulator","text":"http://modbuspal.sourceforge.net/ To simulate sensors, such as temperature and humidity, do the following: Add two mock devices: Add registers according to the device manual: Add the ModbusPal support value auto-generator, which can bind to registers:","title":"Modbus Device (Simulator)"},{"location":"examples/Ch-ExamplesAddingModbusDevice/#set-up-before-starting-services","text":"The following sections describe how to complete the set up before starting the services. If you prefer to start the services and then add the device, see Set Up After Starting Services","title":"Set Up Before Starting Services"},{"location":"examples/Ch-ExamplesAddingModbusDevice/#set-up-device-profile","text":"The DeviceProfile defines the device's values and operation method, which can be Read or Write. In the Modbus protocol, we must define attributes: primaryTable : HOLDING_REGISTERS, INPUT_REGISTERS, COILS, DISCRETES_INPUT startingAddress specifies the address in Modbus device The Property value type decides how many registers will be read. Like Holding registers, a register has 16 bits. If the device manual specifies that a value has two registers, define it as FLOAT32 or INT32 or UINT32 in the deviceProfile. Once we execute a command, device-modbus knows its value type and register type, startingAddress, and register length. So it can read or write value using the modbus protocol. Create the device profile, as shown below: name: \"Network Power Meter\" manufacturer: \"Dent Instruments\" model: \"PS3037\" description: \"Power Scout Meter\" labels: - \"modbus\" - \"powerscout\" deviceResources: - name: \"Current\" description: \"Average current of all phases\" attributes: { primaryTable: \"HOLDING_REGISTERS\", startingAddress: \"9\" } properties: value: { type: \"UINT16\", scale: \"1\"} units: { type: \"String\", readWrite: \"R\", defaultValue: \"min\"} - name: \"Energy\" description: \"System Total True Energy\" attributes: { primaryTable: \"HOLDING_REGISTERS\", startingAddress: \"4001\" } properties: value: { type: \"FLOAT32\", scale: \"1\"} units: { type: \"String\", readWrite: \"R\", defaultValue: \"min\"} - name: \"Power\" description: \"System Total True Power \" attributes: { primaryTable: \"HOLDING_REGISTERS\", startingAddress: \"4003\" } properties: value: { type: \"UINT16\", scale: \"1\"} units: { type: \"String\", readWrite: \"R\", defaultValue: \"min\"} - name: \"Voltage\" description: \"Voltage Line to line (Volts) Average\" attributes: { primaryTable: \"HOLDING_REGISTERS\", startingAddress: \"4017\" } properties: value: { type: \"UINT16\", scale: \"1\"} units: { type: \"String\", readWrite: \"R\", defaultValue: \"min\"} - name: \"DemandWindowSize\" description: \"Demand window size in minutes; default is 15 min\" attributes: { primaryTable: \"HOLDING_REGISTERS\", startingAddress: \"4603\" } properties: value: { type: \"UINT16\", readWrite: \"R\", scale: \"1\"} units: { type: \"String\", readWrite: \"R\", defaultValue: \"min\"} - name: \"LineFrequency\" description: \"Line frequency setting for metering: 50=50 Hz, 60=60Hz\" attributes: { primaryTable: \"HOLDING_REGISTERS\", startingAddress: \"4609\" } properties: value: { type: \"UINT16\", readWrite: \"R\", scale: \"1\"} units: { type: \"String\", readWrite: \"R\", defaultValue: \"Hz\"} deviceCommands: - name: \"Current\" get: - { index: \"1\", operation: \"get\", deviceResource: \"Current\" } - name: \"Values\" get: - { index: \"1\", operation: \"get\", deviceResource: \"Energy\" } - { index: \"2\", operation: \"get\", deviceResource: \"Power\" } - { index: \"3\", operation: \"get\", deviceResource: \"Voltage\" } - name: \"Configuration\" set: - { index: \"1\", operation: \"set\", deviceResource: \"DemandWindowSize\" } - { index: \"2\", operation: \"set\", deviceResource: \"LineFrequency\" } get: - { index: \"1\", operation: \"get\", deviceResource: \"DemandWindowSize\" } - { index: \"2\", operation: \"get\", deviceResource: \"LineFrequency\" } coreCommands: - name: \"Current\" get: path: \"/api/v1/device/{deviceId}/Current\" responses: - code: \"200\" description: \"Get the Current\" expectedValues: [\"Current\"] - code: \"500\" description: \"internal server error\" expectedValues: [] - name: \"Values\" get: path: \"/api/v1/device/{deviceId}/Values\" responses: - code: \"200\" description: \"Get the Values\" expectedValues: [\"Energy\",\"Power\",\"Voltage\"] - code: \"500\" description: \"internal server error\" expectedValues: [] - name: \"Configuration\" get: path: \"/api/v1/device/{deviceId}/Configuration\" responses: - code: \"200\" description: \"Get the Configuration\" expectedValues: [\"DemandWindowSize\",\"LineFrequency\"] - code: \"500\" description: \"internal server error\" expectedValues: [] put: path: \"/api/v1/device/{deviceId}/Configuration\" parameterNames: [\"DemandWindowSize\",\"LineFrequency\"] responses: - code: \"204\" description: \"Set the Configuration\" expectedValues: [] - code: \"500\" description: \"internal server error\" expectedValues: []","title":"Set Up Device Profile"},{"location":"examples/Ch-ExamplesAddingModbusDevice/#set-up-device-service-configuration","text":"Use this configuration file to define devices and AutoEvent. The device-modbus generates a relative instance on startup. device-modbus offers two types of protocol, Modbus TCP and Modbus RTU, which can be defined as shown below: protocol Name Protocol Address Port UnitID BaudRate DataBits StopBits Parity Modbus TCP Gateway address TCP 10.211.55.6 502 1 Modbus RTU Gateway address RTU /tmp/slave 502 2 19200 8 1 N In the RTU protocol, Parity can be: * N - None is 0 * O - Odd is 1 * E - Even is 2, default is E Create the configuration.toml file, as shown below: [Writable] LogLevel = 'DEBUG' [Service] BootTimeout = 30000 CheckInterval = '10s' Host = 'localhost' ServerBindAddr = '' # blank value defaults to Service.Host value Port = 49991 Protocol = 'http' StartupMsg = 'device modbus started' Timeout = 5000 ConnectRetries = 10 Labels = [] EnableAsyncReadings = true AsyncBufferSize = 16 [Registry] Host = 'localhost' Port = 8500 Type = 'consul' [Logging] EnableRemote = false File = '' [Clients] [Clients.Data] Protocol = 'http' Host = 'localhost' Port = 48080 [Clients.Metadata] Protocol = 'http' Host = 'localhost' Port = 48081 [Clients.Logging] Protocol = 'http' Host = 'localhost' Port = 48061 [Device] DataTransform = true InitCmd = '' InitCmdArgs = '' MaxCmdOps = 128 MaxCmdValueLen = 256 RemoveCmd = '' RemoveCmdArgs = '' ProfilesDir = './res/example' UpdateLastConnected = false # Pre-define Devices [[DeviceList]] Name = 'Modbus TCP test device' Profile = 'Test.Device.Modbus.Profile' Description = 'This device is a product for monitoring and controlling digital inputs and outputs over a LAN.' labels = [ 'Air conditioner','modbus TCP' ] [DeviceList.Protocols] [DeviceList.Protocols.modbus-tcp] Address = '0.0.0.0' Port = '1502' UnitID = '1' [[DeviceList.AutoEvents]] Frequency = '20s' OnChange = false Resource = 'Configuration' [[DeviceList.AutoEvents]] Frequency = '20s' OnChange = true Resource = 'Values' [[DeviceList]] Name = 'Modbus RTU test device' Profile = 'Test.Device.Modbus.Profile' Description = 'This device is a product for monitoring and controlling digital inputs and outputs over a LAN.' labels = [ 'Air conditioner','modbus RTU' ] [DeviceList.Protocols] [DeviceList.Protocols.modbus-rtu] Address = '/tmp/slave' BaudRate = '19200' DataBits = '8' StopBits = '1' Parity = 'N' UnitID = '1'","title":"Set Up Device Service Configuration"},{"location":"examples/Ch-ExamplesAddingModbusDevice/#add-device-service-to-docker-compose-file","text":"Because we deploy EdgeX using docker-compose, we must add the device-modbus to the docker-compose file ( https://github.com/edgexfoundry/developer-scripts/blob/master/releases/geneva/compose-files/docker-compose-geneva-redis.yml ). If you have prepared configuration files, you can mount them using volumes and change the entrypoint for device-modbus internal use.","title":"Add Device Service to docker-compose File"},{"location":"examples/Ch-ExamplesAddingModbusDevice/#start-edgex-foundry-on-docker","text":"Finally, we can deploy EdgeX in the Photon OS. Prepare configuration files by moving the files to the Photon OS Deploy EdgeX using the following commands: docker-compose pull docker-compose up -d Check the consul dashboard","title":"Start EdgeX Foundry on Docker"},{"location":"examples/Ch-ExamplesAddingModbusDevice/#set-up-after-starting-services","text":"If the services are already running and you want to add a device, you can use the Core Metadata API as outlined in this section. If you set up the device profile and Service as described in Set Up Before Starting Services , you can skip this section. To add a device after starting the services, complete the following steps: Upload the device profile above to metadata with a POST to http://localhost:48081/api/v1/deviceprofile/uploadfile and add the file as key \"file\" to the body in form-data format, and the created ID will be returned. The following example command uses curl to send the request: $ curl http://your-edgex-server-ip:48081/api/v1/deviceprofile/uploadfile \\ -F \"file=@DENT.Mod.PS6037.profile.yaml\" Ensure the Modbus device service is running, adjust the service name below to match if necessary or if using other device services. Add the device with a POST to http://localhost:48081/api/v1/device , the body will look something like: $ curl http://your-edgex-server-ip:48081/api/v1/device -H \"Content-Type:application/json\" -X POST \\ -d '{ \"name\" :\"Modbus-TCP-Device-2\", \"description\":\"Power Submeter device.\", \"adminState\":\"UNLOCKED\", \"operatingState\":\"ENABLED\", \"protocols\":{ \"modbus-tcp\":{ \"Address\" : \"your-device-ip\", \"Port\" : \"1502\", \"UnitID\" : \"2\" } }, \"labels\":[ \"power submeter\", \"modbus TCP\" ], \"service\":{\"name\":\"edgex-device-modbus\"}, \"profile\":{\"name\":\"Network Power Meter\"}, \"autoEvents\":[ { \"frequency\":\"50s\", \"onChange\":false, \"resource\":\"Configuration\" }, { \"frequency\":\"5s\", \"onChange\":true, \"resource\":\"Values\" } ] }' The service name must match/refer to the target device service, and the profile name must match the device profile name from Step 1.","title":"Set Up After Starting Services"},{"location":"examples/Ch-ExamplesAddingModbusDevice/#execute-commands","text":"Now we're ready to run some commands.","title":"Execute Commands"},{"location":"examples/Ch-ExamplesAddingModbusDevice/#find-executable-commands","text":"Use the following query to find executable commands: $ curl http://your-edgex-server-ip:48082/api/v1/device | json_pp % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 1718 100 1718 0 0 14081 0 --:--:-- --:--:-- --:--:-- 14081 [ { \"id\" : \"56dcf3ad-52d8-4d12-a2d0-ae53c177ae3d\", \"commands\" : [ { \"put\" : { \"url\" : \"http://edgex-core-command:48082/api/v1/device/56dcf3ad-52d8-4d12-a2d0-ae53c177ae3d/command/67b35f63-8f94-427b-a60c-188bf9e0633a\", \"parameterNames\" : [ \"DemandWindowSize\", \"LineFrequency\" ], \"path\" : \"/api/v1/device/{deviceId}/Configuration\" }, \"id\" : \"67b35f63-8f94-427b-a60c-188bf9e0633a\", \"get\" : { \"url\" : \"http://edgex-core-command:48082/api/v1/device/56dcf3ad-52d8-4d12-a2d0-ae53c177ae3d/command/67b35f63-8f94-427b-a60c-188bf9e0633a\", \"responses\" : [ { \"description\" : \"service unavailable\", \"code\" : \"503\" } ], \"path\" : \"/api/v1/device/{deviceId}/Configuration\" }, ... \"name\" : \"Configuration\" } ], ... }, { .... } ]","title":"Find Executable Commands"},{"location":"examples/Ch-ExamplesAddingModbusDevice/#execute-put-command","text":"Execute PUT command according to url and parameterNames , replacing [host] with the server IP when running the edgex-core-command. This can be done in either of the following ways: $ curl http://your-edgex-server-ip:48082/api/v1/device/56dcf3ad-52d8-4d12-a2d0-ae53c177ae3d/command/67b35f63-8f94-427b-a60c-188bf9e0633a \\ -H \"Content-Type:application/json\" -X PUT \\ -d '{\"DemandWindowSize\":\"1122\",\"LineFrequency\":\"1012\"}' Aside from using device id and command id in the URL, use the following API with device name and command is another approach. Refer to Core Command API for more details. $ curl \"http://your-edgex-server-ip:48082/api/v1/device/name/Modbus-TCP-Device/command/Configuration\" \\ -H \"Content-Type:application/json\" -X PUT \\ -d '{\"DemandWindowSize\":\"1122\",\"LineFrequency\":\"1012\"}' Check the result from Modbus simulator:","title":"Execute PUT command"},{"location":"examples/Ch-ExamplesAddingModbusDevice/#execute-get-command","text":"Replace \\<host> with the server IP when running the edgex-core-command. $ curl \"http://your-edgex-server-ip:48082/api/v1/device/name/Modbus-TCP-Device/command/Configuration\" | json_pp % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 320 100 320 0 0 12800 0 --:--:-- --:--:-- --:--:-- 12307 { \"device\" : \"Modbus-TCP-Device\", \"EncodedEvent\" : null, \"readings\" : [ { \"device\" : \"Modbus-TCP-Device\", \"origin\" : 1574314180435573491, \"name\" : \"DemandWindowSize\", \"value\" : \"1122\" }, { \"origin\" : 1574314180435578175, \"device\" : \"Modbus-TCP-Device\", \"value\" : \"1012\", \"name\" : \"LineFrequency\" } ], \"origin\" : 1574314180435629113 }","title":"Execute GET command"},{"location":"examples/Ch-ExamplesAddingModbusDevice/#autoevent","text":"The AutoEvent is defined in the [[DeviceList.AutoEvents]] section of the TOML configuration file: # Pre-define Devices [[DeviceList]] Name = 'Modbus TCP test device' Profile = 'Test.Device.Modbus.Profile' Description = 'This device is a product for monitoring and controlling digital inputs and outputs over a LAN.' labels = [ 'Air conditioner','modbus TCP' ] [DeviceList.Protocols] [DeviceList.Protocols.modbus-tcp] Address = '0.0.0.0' Port = '1502' UnitID = '1' [[DeviceList.AutoEvents]] Frequency = '20s' OnChange = false Resource = 'HVACValues' After service startup, query core-data's reading API. The results show that the service auto-executes the command every 20 seconds. $ curl \"http://your-edgex-server-ip:48080/api/v1/event/device/Modbus-TCP-Device/10\" | json_pp % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 1997 100 1997 0 0 216k 0 --:--:-- --:--:-- --:--:-- 216k [ { \"origin\" : 1574313452749054661, \"id\" : \"a066d154-fe44-4572-9870-8790017b9c59\", \"created\" : 1574313452750, \"device\" : \"Modbus-TCP-Device\", \"readings\" : [ ... ] }, { \"device\" : \"Modbus-TCP-Device\", \"readings\" : [ ... ], \"created\" : 1574313457759, \"id\" : \"25314175-d6f5-461e-8be4-94129fbf94c6\", \"origin\" : 1574313457757445677 }, ... ]","title":"AutoEvent"},{"location":"examples/Ch-ExamplesAddingSNMPDevice/","text":"SNMP EdgeX - Barcelona Release Ubuntu Desktop 16.04 with Docker/Docker-Compose Adding a new SNMP Device Moxa ioLogik E2210 Smart Ethernet Remote I/O with 12 DIs, 8 Dos Project Components Needed Hardware needed X86 computer with native RS485 communication device or RS485 adapter Moxa E2210 Ethernet IO -- https://www.moxa.com/product/ioLogik-E2210.htm Software needed Ubuntu Desktop 16.04 - new installation The following software was installed via the \"apt-get install\" command (ubuntu default) git curl vim (or your favorite editor) java (I used openjdk-8-jdk - 1.8.0_131) maven docker docker-compose The following software was installed from 3rd parties Postman (Linux 64bit) -- https://www.getpostman.com/ EdgeX - barcelona-docker-compose.yaml -- https://github.com/edgexfoundry/developer-scripts/blob/master/releases/barcelona/compose-files/docker-compose-barcelona-0.2.1.yml SNMP - Device documentation Device: Moxa E2210 (Smart Ethernet Remote I/O with 12 DIs, 8 DOs) https://www.moxa.com/product/ioLogik-E2210.htm Ensuring success Verify the following, prior to following the instruction on the following pages Do you know the IP address of the E2210? Do you know what port number of the E2210 is using? Does the E2210 power on? With a separate utility, can you read(from)/write(to) the E2210? Creating the Modbus yaml file An example SNMP device yaml file can be found here: SNMP device yaml . The SNMP device yaml file used in this example can be found here: this example SNMP device yaml . When you are creating your yaml file you will need to know what command options are available to use, they can be found here: https://github.com/edgexfoundry/core-domain/blob/master/src/main/java/org/edgexfoundry/domain/meta/PropertyValue.java With your favorite file editor, open the file Modify the following fields name \\<-- A/a \\~Z/z and 0 \\~ 9 && this will be needed in the future manufacturer \\<-- A/a \\~Z/z and 0 \\~ 9 model \\<-- A/a \\~Z/z and 0 \\~ 9 description \\<-- A/a \\~Z/z and 0 \\~ 9 labels \\<-- A/a \\~Z/z and 0 \\~ 9 deviceResources name: \\<-- A/a \\~Z/z and 0 \\~ 9 description: \\<-- A/a \\~Z/z and 0 \\~ 9 attributes: only edit the text inside the parenthesis value: only edit the text inside the parenthesis units: only edit the text inside the parenthesis resources name: \\<-- A/a \\~Z/z and 0 \\~ 9 get : only edit the text inside the parenthesis set: only edit the text inside the parenthesis commands name: \\<-- A/a \\~Z/z and 0 \\~ 9 path: \"/api/v1/device/{deviceId}/OnlyEditThisWord\" \\<-- A/a \\~Z/z and 0 \\~ 9 Code \"200\" expectedvalues: [make same as OnlyEditThisWord] Code \"500\" Do not edit this section Bringing up EdgeX via Docker Starting with following system configuration: A fresh installation of Ubuntu Desktop 16.04 with all the available system updates. A working directory > /home/tester/Development/edgex Verify your Docker installation Verify that Docker is installed and working as expected. >\\$ sudo docker run hello-world Verify that the image is on the system >\\$ sudo docker ps -a Download docker-compose file Download the barcelona-docker-compose.yaml file from the EdgeX Wiki Go to \" https://wiki.edgexfoundry.org/display/FA/Barcelona \" Scroll to the bottom a look for the \"barcelona-docker-compose.yml\" file. Once downloaded, rename the file to \"docker-compose.yml\" Once the file is download, move the file into your desired working directory. Create a copy of the file and rename the copy \"docker-compose.yml\" Verify the version of dockerized EdgeX that you will be running With your favorite file editor, open the docker-compose.yml file Within the first couple of lines you will see the word \"Version\", next to that you will see a number - it should be \"2\". Version 2 refers to the Barcelona release Enable SNMP in the Docker Compose file With your favorite file editor, open the docker-compose file Find the section \"device-snmp\" section, which will be commented out with \"#\" symbols. Uncomment the entire section Save your changes and exit out of the editor Starting EdgeX Docker components Start EdgeX by using the following commands Docker Command Description Suggested Wait Time After Completing docker-compose pull Pull down, but don\u2019t start, all the EdgeX Foundry microservices Docker Compose will indicate when all the containers have been pulled successfully docker-compose up -d volume Start the EdgeX Foundry file volume\u2013must be done before the other services are started A couple of seconds docker-compose up -d config-seed Start and populate the configuration/registry microservice which all services must register with and get their configuration from 60 seconds docker-compose up -d mongo Start the NoSQL MongoDB container 10 seconds docker-compose up -d logging Start the logging microservice - used by all micro services that make log entries 1 minute docker-compose up -d notifications Start the notifications and alerts microservice\u2013used by many of the microservices 30 seconds docker-compose up -d metadata Start the Core Metadata microservice 1 minute docker-compose up -d data Start the Core Data microservice 1 minute docker-compose up -d command Start the Core Command microservice 1 minute docker-compose up -d scheduler Start the scheduling microservice -used by many of the microservices 1 minute docker-compose up -d export -client Start the Export Client registration microservice 1 minute docker-compose up -d export -distro Start the Export Distribution microservice 1 minute docker-compose up -d rulesengine Start the Rules Engine microservice 1 minute docker-compose up -d device -virtual Start the virtual device service 1 minute docker-compose up -d device -snmp Start the SNMP device service 1 minute Check the containers status Run a \"docker ps -a\" command to confirm that all the containers have been downloaded and started Show containers To get a list of all the EdgeX containers, you can use \"docker-compose config --services\" Stop Containers To stop (but not remove) all containers, issue \"docker-compose stop\". To stop an individual container, you can use \"docker-compose stop [compose-container-name]\". Start Containers To start all the containers (after a stop) issue \"docker-compose start\" to re-start To start an individual container, you can use \"docker-compose start [compose-container-name]\" (after that container has been stopped). Delete Containers * DANGER * To stop all the containers running and DELETE them, you can use \"docker-compose down\" EdgeX Foundry Container Logs To view the log of any container, use the command: \"docker-compose logs -f compose-container-name\" (ex. docker-compose logs -f edgex-device-snmp) At this point the Dockerized version of EdgeX is running. Adding the Device to EdgeX Importing APIs In this section you will be using the program Postman to interact with EdgeX. You will also need to have the file \"core-metadata.raml\" available to load into the Postman application. The file \"core-metadata.raml\" can be found here: \"edgex/core-metadata..../src/test/resources/raml/core-metadata.raml\" Viewing available APIs Open Postman Click on the Import button Add the file to the import dialog box - the application will take a about 30 seconds to digest the file you added. If a list of API commands do not show up on the left hand side of the application then click on the \"Collections\" tab to the right of the \"History\" tab. Create an addressable In the \"Collections\" tab, select the option \"POST /addressable action Open the body tab Modify its contents name: moxa-e2210-address protocol: HTTP (needs to be in ALL CAPS) address: 192.168.1.103 (IPV4 address) port: 161 (port # of snmp) path: empty (remove all text between parentheses) publisher, user, password, topic - do not need to be modified Press the \"Send\" button when you are finished Note the addressable id Upload the profile In the \"Collections\" tab select the option \"POST /deviceprofile/uploadfile Open the body tab Under \"Key\", look for the drop down menu for \"text\". Be sure to write \"file\" in the open box. Under \"Value\" click \"Choose Files\", locate your profile file. Press Upload Press the \"Send\" button when you are finished Note the profile id Post the device In the \"Collections\" tab select the option \"POST /device Click on the \"Body\" tab Modify its contents There are three components that are required to be modified. They are: \"Service\" \"Profile\" \"Addressable\" The others can be modified, however they are not required for operation name: moxa-e2210-device description: snmp smart ethernet io addressable: name: moxa-e2210-address (same as used in addressable) labels: labels: \"snmp\", \"rtu\",\"io\" (same as used in snmp device profile) service: name: edgex-device-snmp profile: name: name: moxa-iologik-e2210 (same as used in snmp device profile) Press the \"Send\" button when you are finished Note the addressable id What if a Mistake is Made Get device id Delete device id Get device profile id Delete device profile id Get addressable id Delete addressable id Verify Device Added Check the edgex-device-snmp logs to see if the device was added without issue \"sudo docker logs -f --tail 100 edgex-device-snmp\" Verify device is sending data In the \"Collections\" tab select the option \"GET /device Change the port number form \"48081\" http://localhost:48081/api/v1/device to port number \"48082\" http://localhost:48082/api/v1/device Press Send You should see something similar to { \"id\" : \"5a1d6f8ae4b0c3936013120f\" , \"name\" : \"diStatus0\" , \"get\" : { \"url\" : \"http://localhost:48082/api/v1/device/5a1d7134e4b0c39360131212/command/5a1d6f8ae4b0c3936013120f\" , < -- This \"responses\" : [ { \"code\" : \"200\" , \"description\" : \"Get di 0 Status.\" , \"expectedValues\" : [ \"diStatus0\" ] } , { \"code\" : \"503\" , \"description\" : \"service unavailable\" , \"expectedValues\" : [] } ] } , \"put\" : null } , Double click on the \"url\" and a new tab within Postman should open, Press Send If all went well you should see something similar to the following: {\"diStatus0\":\"0\"} If all did not go well the you will see an error or may \"{ }\" then you will need check the information you entered. If the data/result displayed was as expected, go ahead and proceed to creating a scheduled event Creating a Scheduled Event This is used to regularly get & push data to another service or for regularly viewing data. Gathering information for the addressable Got to http://localhost:48082/api/v1/device Look for the id or the device that you want to schedule an event for [ { \"name\" : \"moxa-e2210-device\" , \"id\" : \"5a280a0be4b0c39393ec7780\" , < --- This \"description\" : \"snmp smart ethernet io\" , \"labels\" : [ \"snmp\" , \"rtu\" , \"io\" ], \"adminState\" : \"unlocked\" , In this case the id is \"5a280a0be4b0c39393ec7780\" Next you want to get the \"name\" of the command you want to schedule an event for \"commands\" : [ { \"id\" : \"5a2808e6e4b0c39393ec777c\" , \"name\" : \"serverModel\" , \"get\" : { \"url\" : \"http://localhost:48082/api/v1/device/5a280a0be4b0c39393ec7780/command/5a2808e6e4b0c39393ec777c\" , \"responses\" : [ { \"code\" : \"200\" , \"description\" : \"Get server model number.\" , \"expectedValues\" : [ \"serverModel\" ] } , { \"code\" : \"503\" , \"description\" : \"service unavailable\" , \"expectedValues\" : [] } ] } , \"put\" : null } , { \"id\" : \"5a2808e6e4b0c39393ec777d\" , \"name\" : \"diStatus0\" , < --- This \"get\" : { \"url\" : \"http://localhost:48082/api/v1/device/5a280a0be4b0c39393ec7780/command/5a2808e6e4b0c39393ec777d\" , \"responses\" : [ { \"code\" : \"200\" , \"description\" : \"Get di 0 Status.\" , \"expectedValues\" : [ \"diStatus0\" ] In this example the name is \"diStatus0\". Create addressable In this section you will need to supply a path the the item you want to schedule. The path outline is: /api/v1/device/{device id}/{command name} In this case, the address would be / api / v1 / device / XXXX / diStatus0 / POST addressable \u201c name \u201d : \u201d schedule - moxa - di \u201d \u201c protocol \u201d : \u201c HTTP \u201d \u201c address \u201d : \u201c edgex - device - snmp \u201d \u201c port \u201d : \u201c xxxxx \u201d \u201c path \u201d : \u201d / api / v1 / device / { device id } / { command name }\u201d \u201c method \u201d : \u201c GET \u201d *** This will need to be added *** Create a schedule / POST schedule \u201c name \u201d : \u201d interval - moxa - di0 \u201d \u201c start \u201d : null ( remove parenthesis and replace ) \u201c end \u201d : null ( remove parenthesis and replace ) \u201c frequency \u201d : \u201c PT5S \u201d Create an event that will use the schedule / POST scheduleevent \u201c name \u201d : \u201c device - moxa - di0 \u201d \u201c addressable \u201d : {\u201c name \u201d : \u201d schedule - moxa - di \u201d} \u201c schedule \u201d : \u201d interval - moxa - di0 \u201d \u201c service \u201d : \u201c edgex - device - snmp \u201d *** This will need to be added ***","title":"SNMP"},{"location":"examples/Ch-ExamplesAddingSNMPDevice/#snmp","text":"EdgeX - Barcelona Release Ubuntu Desktop 16.04 with Docker/Docker-Compose Adding a new SNMP Device Moxa ioLogik E2210 Smart Ethernet Remote I/O with 12 DIs, 8 Dos","title":"SNMP"},{"location":"examples/Ch-ExamplesAddingSNMPDevice/#project-components-needed","text":"Hardware needed X86 computer with native RS485 communication device or RS485 adapter Moxa E2210 Ethernet IO -- https://www.moxa.com/product/ioLogik-E2210.htm Software needed Ubuntu Desktop 16.04 - new installation The following software was installed via the \"apt-get install\" command (ubuntu default) git curl vim (or your favorite editor) java (I used openjdk-8-jdk - 1.8.0_131) maven docker docker-compose The following software was installed from 3rd parties Postman (Linux 64bit) -- https://www.getpostman.com/ EdgeX - barcelona-docker-compose.yaml -- https://github.com/edgexfoundry/developer-scripts/blob/master/releases/barcelona/compose-files/docker-compose-barcelona-0.2.1.yml SNMP - Device documentation Device: Moxa E2210 (Smart Ethernet Remote I/O with 12 DIs, 8 DOs) https://www.moxa.com/product/ioLogik-E2210.htm Ensuring success Verify the following, prior to following the instruction on the following pages Do you know the IP address of the E2210? Do you know what port number of the E2210 is using? Does the E2210 power on? With a separate utility, can you read(from)/write(to) the E2210? Creating the Modbus yaml file An example SNMP device yaml file can be found here: SNMP device yaml . The SNMP device yaml file used in this example can be found here: this example SNMP device yaml . When you are creating your yaml file you will need to know what command options are available to use, they can be found here: https://github.com/edgexfoundry/core-domain/blob/master/src/main/java/org/edgexfoundry/domain/meta/PropertyValue.java With your favorite file editor, open the file Modify the following fields name \\<-- A/a \\~Z/z and 0 \\~ 9 && this will be needed in the future manufacturer \\<-- A/a \\~Z/z and 0 \\~ 9 model \\<-- A/a \\~Z/z and 0 \\~ 9 description \\<-- A/a \\~Z/z and 0 \\~ 9 labels \\<-- A/a \\~Z/z and 0 \\~ 9 deviceResources name: \\<-- A/a \\~Z/z and 0 \\~ 9 description: \\<-- A/a \\~Z/z and 0 \\~ 9 attributes: only edit the text inside the parenthesis value: only edit the text inside the parenthesis units: only edit the text inside the parenthesis resources name: \\<-- A/a \\~Z/z and 0 \\~ 9 get : only edit the text inside the parenthesis set: only edit the text inside the parenthesis commands name: \\<-- A/a \\~Z/z and 0 \\~ 9 path: \"/api/v1/device/{deviceId}/OnlyEditThisWord\" \\<-- A/a \\~Z/z and 0 \\~ 9 Code \"200\" expectedvalues: [make same as OnlyEditThisWord] Code \"500\" Do not edit this section Bringing up EdgeX via Docker Starting with following system configuration: A fresh installation of Ubuntu Desktop 16.04 with all the available system updates. A working directory > /home/tester/Development/edgex Verify your Docker installation Verify that Docker is installed and working as expected. >\\$ sudo docker run hello-world Verify that the image is on the system >\\$ sudo docker ps -a Download docker-compose file Download the barcelona-docker-compose.yaml file from the EdgeX Wiki Go to \" https://wiki.edgexfoundry.org/display/FA/Barcelona \" Scroll to the bottom a look for the \"barcelona-docker-compose.yml\" file. Once downloaded, rename the file to \"docker-compose.yml\" Once the file is download, move the file into your desired working directory. Create a copy of the file and rename the copy \"docker-compose.yml\" Verify the version of dockerized EdgeX that you will be running With your favorite file editor, open the docker-compose.yml file Within the first couple of lines you will see the word \"Version\", next to that you will see a number - it should be \"2\". Version 2 refers to the Barcelona release Enable SNMP in the Docker Compose file With your favorite file editor, open the docker-compose file Find the section \"device-snmp\" section, which will be commented out with \"#\" symbols. Uncomment the entire section Save your changes and exit out of the editor Starting EdgeX Docker components Start EdgeX by using the following commands Docker Command Description Suggested Wait Time After Completing docker-compose pull Pull down, but don\u2019t start, all the EdgeX Foundry microservices Docker Compose will indicate when all the containers have been pulled successfully docker-compose up -d volume Start the EdgeX Foundry file volume\u2013must be done before the other services are started A couple of seconds docker-compose up -d config-seed Start and populate the configuration/registry microservice which all services must register with and get their configuration from 60 seconds docker-compose up -d mongo Start the NoSQL MongoDB container 10 seconds docker-compose up -d logging Start the logging microservice - used by all micro services that make log entries 1 minute docker-compose up -d notifications Start the notifications and alerts microservice\u2013used by many of the microservices 30 seconds docker-compose up -d metadata Start the Core Metadata microservice 1 minute docker-compose up -d data Start the Core Data microservice 1 minute docker-compose up -d command Start the Core Command microservice 1 minute docker-compose up -d scheduler Start the scheduling microservice -used by many of the microservices 1 minute docker-compose up -d export -client Start the Export Client registration microservice 1 minute docker-compose up -d export -distro Start the Export Distribution microservice 1 minute docker-compose up -d rulesengine Start the Rules Engine microservice 1 minute docker-compose up -d device -virtual Start the virtual device service 1 minute docker-compose up -d device -snmp Start the SNMP device service 1 minute Check the containers status Run a \"docker ps -a\" command to confirm that all the containers have been downloaded and started Show containers To get a list of all the EdgeX containers, you can use \"docker-compose config --services\" Stop Containers To stop (but not remove) all containers, issue \"docker-compose stop\". To stop an individual container, you can use \"docker-compose stop [compose-container-name]\". Start Containers To start all the containers (after a stop) issue \"docker-compose start\" to re-start To start an individual container, you can use \"docker-compose start [compose-container-name]\" (after that container has been stopped). Delete Containers * DANGER * To stop all the containers running and DELETE them, you can use \"docker-compose down\" EdgeX Foundry Container Logs To view the log of any container, use the command: \"docker-compose logs -f compose-container-name\" (ex. docker-compose logs -f edgex-device-snmp) At this point the Dockerized version of EdgeX is running. Adding the Device to EdgeX Importing APIs In this section you will be using the program Postman to interact with EdgeX. You will also need to have the file \"core-metadata.raml\" available to load into the Postman application. The file \"core-metadata.raml\" can be found here: \"edgex/core-metadata..../src/test/resources/raml/core-metadata.raml\" Viewing available APIs Open Postman Click on the Import button Add the file to the import dialog box - the application will take a about 30 seconds to digest the file you added. If a list of API commands do not show up on the left hand side of the application then click on the \"Collections\" tab to the right of the \"History\" tab. Create an addressable In the \"Collections\" tab, select the option \"POST /addressable action Open the body tab Modify its contents name: moxa-e2210-address protocol: HTTP (needs to be in ALL CAPS) address: 192.168.1.103 (IPV4 address) port: 161 (port # of snmp) path: empty (remove all text between parentheses) publisher, user, password, topic - do not need to be modified Press the \"Send\" button when you are finished Note the addressable id Upload the profile In the \"Collections\" tab select the option \"POST /deviceprofile/uploadfile Open the body tab Under \"Key\", look for the drop down menu for \"text\". Be sure to write \"file\" in the open box. Under \"Value\" click \"Choose Files\", locate your profile file. Press Upload Press the \"Send\" button when you are finished Note the profile id Post the device In the \"Collections\" tab select the option \"POST /device Click on the \"Body\" tab Modify its contents There are three components that are required to be modified. They are: \"Service\" \"Profile\" \"Addressable\" The others can be modified, however they are not required for operation name: moxa-e2210-device description: snmp smart ethernet io addressable: name: moxa-e2210-address (same as used in addressable) labels: labels: \"snmp\", \"rtu\",\"io\" (same as used in snmp device profile) service: name: edgex-device-snmp profile: name: name: moxa-iologik-e2210 (same as used in snmp device profile) Press the \"Send\" button when you are finished Note the addressable id What if a Mistake is Made Get device id Delete device id Get device profile id Delete device profile id Get addressable id Delete addressable id Verify Device Added Check the edgex-device-snmp logs to see if the device was added without issue \"sudo docker logs -f --tail 100 edgex-device-snmp\" Verify device is sending data In the \"Collections\" tab select the option \"GET /device Change the port number form \"48081\" http://localhost:48081/api/v1/device to port number \"48082\" http://localhost:48082/api/v1/device Press Send You should see something similar to { \"id\" : \"5a1d6f8ae4b0c3936013120f\" , \"name\" : \"diStatus0\" , \"get\" : { \"url\" : \"http://localhost:48082/api/v1/device/5a1d7134e4b0c39360131212/command/5a1d6f8ae4b0c3936013120f\" , < -- This \"responses\" : [ { \"code\" : \"200\" , \"description\" : \"Get di 0 Status.\" , \"expectedValues\" : [ \"diStatus0\" ] } , { \"code\" : \"503\" , \"description\" : \"service unavailable\" , \"expectedValues\" : [] } ] } , \"put\" : null } , Double click on the \"url\" and a new tab within Postman should open, Press Send If all went well you should see something similar to the following: {\"diStatus0\":\"0\"} If all did not go well the you will see an error or may \"{ }\" then you will need check the information you entered. If the data/result displayed was as expected, go ahead and proceed to creating a scheduled event Creating a Scheduled Event This is used to regularly get & push data to another service or for regularly viewing data. Gathering information for the addressable Got to http://localhost:48082/api/v1/device Look for the id or the device that you want to schedule an event for [ { \"name\" : \"moxa-e2210-device\" , \"id\" : \"5a280a0be4b0c39393ec7780\" , < --- This \"description\" : \"snmp smart ethernet io\" , \"labels\" : [ \"snmp\" , \"rtu\" , \"io\" ], \"adminState\" : \"unlocked\" , In this case the id is \"5a280a0be4b0c39393ec7780\" Next you want to get the \"name\" of the command you want to schedule an event for \"commands\" : [ { \"id\" : \"5a2808e6e4b0c39393ec777c\" , \"name\" : \"serverModel\" , \"get\" : { \"url\" : \"http://localhost:48082/api/v1/device/5a280a0be4b0c39393ec7780/command/5a2808e6e4b0c39393ec777c\" , \"responses\" : [ { \"code\" : \"200\" , \"description\" : \"Get server model number.\" , \"expectedValues\" : [ \"serverModel\" ] } , { \"code\" : \"503\" , \"description\" : \"service unavailable\" , \"expectedValues\" : [] } ] } , \"put\" : null } , { \"id\" : \"5a2808e6e4b0c39393ec777d\" , \"name\" : \"diStatus0\" , < --- This \"get\" : { \"url\" : \"http://localhost:48082/api/v1/device/5a280a0be4b0c39393ec7780/command/5a2808e6e4b0c39393ec777d\" , \"responses\" : [ { \"code\" : \"200\" , \"description\" : \"Get di 0 Status.\" , \"expectedValues\" : [ \"diStatus0\" ] In this example the name is \"diStatus0\". Create addressable In this section you will need to supply a path the the item you want to schedule. The path outline is: /api/v1/device/{device id}/{command name} In this case, the address would be / api / v1 / device / XXXX / diStatus0 / POST addressable \u201c name \u201d : \u201d schedule - moxa - di \u201d \u201c protocol \u201d : \u201c HTTP \u201d \u201c address \u201d : \u201c edgex - device - snmp \u201d \u201c port \u201d : \u201c xxxxx \u201d \u201c path \u201d : \u201d / api / v1 / device / { device id } / { command name }\u201d \u201c method \u201d : \u201c GET \u201d *** This will need to be added *** Create a schedule / POST schedule \u201c name \u201d : \u201d interval - moxa - di0 \u201d \u201c start \u201d : null ( remove parenthesis and replace ) \u201c end \u201d : null ( remove parenthesis and replace ) \u201c frequency \u201d : \u201c PT5S \u201d Create an event that will use the schedule / POST scheduleevent \u201c name \u201d : \u201c device - moxa - di0 \u201d \u201c addressable \u201d : {\u201c name \u201d : \u201d schedule - moxa - di \u201d} \u201c schedule \u201d : \u201d interval - moxa - di0 \u201d \u201c service \u201d : \u201c edgex - device - snmp \u201d *** This will need to be added ***","title":"Project Components Needed"},{"location":"examples/Ch-ExamplesModbusdatatypeconversion/","text":"Modbus - Data Type Conversion In use cases where the device resource uses an integer data type with a float scale, precision can be lost following transformation. For example, a Modbus device stores the temperature and humidity in an INT16 data type with a float scale of 0.01. If the temperature is 26.53, the read value is 2653. However, following transformation, the value is 26. To avoid this scenario, the device resource data type must differ from the value descriptor data type. This is achieved using the optional rawType attribute in the device profile to define the binary data read from the Modbus device, and a value type to indicate what data type the user wants to receive. If the rawType attribute exists, the device service parses the binary data according to the defined rawType , then casts the value according to the value type defined in the properties of the device resources. The following extract from a device profile defines the rawType as INT16 and the value type as FLOAT32: deviceResources : - name : \"humidity\" description : \"The response value is the result of the original value multiplied by 100.\" attributes : { primaryTable : \"HOLDING_REGISTERS\" , startingAddress : \"1\" , rawType : \"INT16\" } properties : value : { type : \"FLOAT32\" , readWrite : \"RW\" , scale : \"0.01\" } units : { type : \"String\" , readWrite : \"R\" , defaultValue : \"%RH\" } - name : \"temperature\" description : \"The response value is the result of the original value multiplied by 100.\" attributes : { primaryTable : \"HOLDING_REGISTERS\" , startingAddress : \"2\" , rawType : \"INT16\" } properties : value : { type : \"FLOAT32\" , readWrite : \"RW\" , scale : \"0.01\" } units : { type : \"String\" , readWrite : \"R\" , defaultValue : \"degrees Celsius\" } Read Command A Read command is executed as follows: The device service executes the Read command to read binary data The binary reading data is parsed as an INT16 data type The integer value is cast to a FLOAT32 value Write Command A Write command is executed as follows: The device service cast the requested FLOAT32 value to an integer value The integer value is converted to binary data The device service executes the Write command When to Transform Data You generally need to transform data when scaling readings between a 16-bit integer and a float value. The following limitations apply: rawType supports only INT16 and UINT16 data types The corresponding value type must be FLOAT32 or FLOAT64 If an unsupported data type is defined for the rawType attribute, the device service throws an exception similar to the following: Handler - execReadCmd: error for device: Modbus-TCP-Device cmd: readAll, the raw type INT32 is not supported /api/v1/device/91f6430d-9268-43e3-88a6-19dbe7f98dad/readAll Supported Transformations The supported transformations are as follows: From rawType To value type INT16 FLOAT32 INT16 FLOAT64 UINT16 FLOAT32 UINT16 FLOAT64","title":"Modbus - Data Type Conversion"},{"location":"examples/Ch-ExamplesModbusdatatypeconversion/#modbus-data-type-conversion","text":"In use cases where the device resource uses an integer data type with a float scale, precision can be lost following transformation. For example, a Modbus device stores the temperature and humidity in an INT16 data type with a float scale of 0.01. If the temperature is 26.53, the read value is 2653. However, following transformation, the value is 26. To avoid this scenario, the device resource data type must differ from the value descriptor data type. This is achieved using the optional rawType attribute in the device profile to define the binary data read from the Modbus device, and a value type to indicate what data type the user wants to receive. If the rawType attribute exists, the device service parses the binary data according to the defined rawType , then casts the value according to the value type defined in the properties of the device resources. The following extract from a device profile defines the rawType as INT16 and the value type as FLOAT32: deviceResources : - name : \"humidity\" description : \"The response value is the result of the original value multiplied by 100.\" attributes : { primaryTable : \"HOLDING_REGISTERS\" , startingAddress : \"1\" , rawType : \"INT16\" } properties : value : { type : \"FLOAT32\" , readWrite : \"RW\" , scale : \"0.01\" } units : { type : \"String\" , readWrite : \"R\" , defaultValue : \"%RH\" } - name : \"temperature\" description : \"The response value is the result of the original value multiplied by 100.\" attributes : { primaryTable : \"HOLDING_REGISTERS\" , startingAddress : \"2\" , rawType : \"INT16\" } properties : value : { type : \"FLOAT32\" , readWrite : \"RW\" , scale : \"0.01\" } units : { type : \"String\" , readWrite : \"R\" , defaultValue : \"degrees Celsius\" }","title":"Modbus - Data Type Conversion"},{"location":"examples/Ch-ExamplesModbusdatatypeconversion/#read-command","text":"A Read command is executed as follows: The device service executes the Read command to read binary data The binary reading data is parsed as an INT16 data type The integer value is cast to a FLOAT32 value","title":"Read Command"},{"location":"examples/Ch-ExamplesModbusdatatypeconversion/#write-command","text":"A Write command is executed as follows: The device service cast the requested FLOAT32 value to an integer value The integer value is converted to binary data The device service executes the Write command","title":"Write Command"},{"location":"examples/Ch-ExamplesModbusdatatypeconversion/#when-to-transform-data","text":"You generally need to transform data when scaling readings between a 16-bit integer and a float value. The following limitations apply: rawType supports only INT16 and UINT16 data types The corresponding value type must be FLOAT32 or FLOAT64 If an unsupported data type is defined for the rawType attribute, the device service throws an exception similar to the following: Handler - execReadCmd: error for device: Modbus-TCP-Device cmd: readAll, the raw type INT32 is not supported /api/v1/device/91f6430d-9268-43e3-88a6-19dbe7f98dad/readAll","title":"When to Transform Data"},{"location":"examples/Ch-ExamplesModbusdatatypeconversion/#supported-transformations","text":"The supported transformations are as follows: From rawType To value type INT16 FLOAT32 INT16 FLOAT64 UINT16 FLOAT32 UINT16 FLOAT64","title":"Supported Transformations"},{"location":"examples/Ch-ExamplesRandomDeviceService/","text":"Random Integer Device Service Introduction The Random Integer device service is a simple device service that works quickly and easily with EdgeX. It simulates a single device ( Random-Integer-Generator01 ) that generates a collection of random integer numbers every 20 seconds by default. It initializes with a pre-defined device profile, device, and auto events schedule. EdgeX APIs related to Random Integer Device Service Once the Random Integer device service is started, the table below provides a list of various EdgeX APIs that can be explored to learn more about the device service, the device, its commands and see the data the simulated device generates. Core Service API URL Description Core Metadata http://[host]:48081/api/v1/deviceservice/name/device-random Device Service created Core Metadata http://[host]:48081/api/v1/deviceprofile/name/Random-Integer-Generator Device profile created Core Metadata http://[host]:48081/api/v1/device/name/Random-Integer-Generator01 Device created Core Data http://[host]:48080/api/v1/event Events created by the random integer generator device Core Command http://[host]:48082/api/v1/device/name/Random-Integer-Generator01 Commands for the random integer generator device Running Commands Use the examples below to exercise the Random Integer device service's command set against the simulated device - the Random-Integer-Generator01 device. Find the GET and PUT Commands The Random Integer device service is configured to send simulated data to core data every few seconds (20 seconds by default) - see the [configuration file](https://github.com/edgexfoundry/device-random/blob/master/cmd/res/configuration.toml for default details. It will send three different deviceResources of data - Int8, Int16 and Int32. You can excersice the GET and PUT requests on the command service to trigger the Random-Integer-Generator01 device to generate values for any one of the deviceResources or to set the min/max random number generated for any of the deviceResources. First, use the curl command below to exercise the command service API to get a list of commands (both GET and PUT ) for the Random-Integer-Generator01 device. curl -X GET localhost:48082/api/v1/device/name/Random-Integer-Generator01 | json_pp Warning The example above assumes your core command service is available on localhost at the default service port of 48082. The result should look something like that displayed below. { \"name\" : \"Random-Integer-Generator01\" , \"labels\" : [ \"device-random-example\" ], \"adminState\" : \"UNLOCKED\" , \"id\" : \"ec7a7586-875e-4bb4-aa46-836d9e04514b\" , \"operatingState\" : \"ENABLED\" , \"commands\" : [ { \"id\" : \"7dc0478d-29dd-4f6e-945d-85e4ad848bb1\" , \"put\" : { \"responses\" : [ { \"code\" : \"200\" }, { \"code\" : \"503\" , \"description\" : \"service unavailable\" } ], \"url\" : \"http://edgex-core-command:48082/api/v1/device/ec7a7586-875e-4bb4-aa46-836d9e04514b/command/7dc0478d-29dd-4f6e-945d-85e4ad848bb1\" , \"parameterNames\" : [ \"Min_Int32\" , \"Max_Int32\" ], \"path\" : \"/api/v1/device/{deviceId}/GenerateRandomValue_Int32\" }, \"created\" : 1596666924062 , \"get\" : { \"url\" : \"http://edgex-core-command:48082/api/v1/device/ec7a7586-875e-4bb4-aa46-836d9e04514b/command/7dc0478d-29dd-4f6e-945d-85e4ad848bb1\" , \"responses\" : [ { \"expectedValues\" : [ \"RandomValue_Int32\" ], \"code\" : \"200\" }, { \"code\" : \"503\" , \"description\" : \"service unavailable\" } ], \"path\" : \"/api/v1/device/{deviceId}/GenerateRandomValue_Int32\" }, \"modified\" : 1596666924062 , \"name\" : \"GenerateRandomValue_Int32\" }, { \"put\" : { \"path\" : \"/api/v1/device/{deviceId}/GenerateRandomValue_Int8\" , \"parameterNames\" : [ \"Min_Int8\" , \"Max_Int8\" ], \"url\" : \"http://edgex-core-command:48082/api/v1/device/ec7a7586-875e-4bb4-aa46-836d9e04514b/command/ab8e16f9-2e94-4c10-b600-858ea1087cdf\" , \"responses\" : [ { \"code\" : \"200\" }, { \"description\" : \"service unavailable\" , \"code\" : \"503\" } ] }, \"created\" : 1596666924062 , \"get\" : { \"responses\" : [ { \"expectedValues\" : [ \"RandomValue_Int8\" ], \"code\" : \"200\" }, { \"description\" : \"service unavailable\" , \"code\" : \"503\" } ], \"url\" : \"http://edgex-core-command:48082/api/v1/device/ec7a7586-875e-4bb4-aa46-836d9e04514b/command/ab8e16f9-2e94-4c10-b600-858ea1087cdf\" , \"path\" : \"/api/v1/device/{deviceId}/GenerateRandomValue_Int8\" }, \"id\" : \"ab8e16f9-2e94-4c10-b600-858ea1087cdf\" , \"modified\" : 1596666924062 , \"name\" : \"GenerateRandomValue_Int8\" }, { \"name\" : \"GenerateRandomValue_Int16\" , \"id\" : \"cfa21103-8ec9-44a0-9c55-25f9cc653dc0\" , \"get\" : { \"url\" : \"http://edgex-core-command:48082/api/v1/device/ec7a7586-875e-4bb4-aa46-836d9e04514b/command/cfa21103-8ec9-44a0-9c55-25f9cc653dc0\" , \"responses\" : [ { \"expectedValues\" : [ \"RandomValue_Int16\" ], \"code\" : \"200\" }, { \"description\" : \"service unavailable\" , \"code\" : \"503\" } ], \"path\" : \"/api/v1/device/{deviceId}/GenerateRandomValue_Int16\" }, \"put\" : { \"responses\" : [ { \"code\" : \"200\" }, { \"description\" : \"service unavailable\" , \"code\" : \"503\" } ], \"url\" : \"http://edgex-core-command:48082/api/v1/device/ec7a7586-875e-4bb4-aa46-836d9e04514b/command/cfa21103-8ec9-44a0-9c55-25f9cc653dc0\" , \"parameterNames\" : [ \"Min_Int16\" , \"Max_Int16\" ], \"path\" : \"/api/v1/device/{deviceId}/GenerateRandomValue_Int16\" }, \"created\" : 1596666924062 , \"modified\" : 1596666924062 } ] } Note The identifiers and URLs will look different in your result as the unique identifiers for devices, commands, etc. will be different in each EdgeX instance. GET Command Example Locate the GET URL for one of the deviceResources in your JSON produced by the curl command above. Use another curl command to trigger a GET command against that URL for the Random-Integer-Generator01 device. In the example below, a GET is called for the GenerateRandomValue_Int16 deviceResource. curl -X GET localhost:48082/api/v1/device/ec7a7586-875e-4bb4-aa46-836d9e04514b/command/cfa21103-8ec9-44a0-9c55-25f9cc653dc0 | json_pp Note Importantly, notice that the host name provided in the JSON is always edgex-core-command . This is the host name of the command service when running in Docker. Use localhost in your curl commands to exercise the APIs. You are not running your curl command inside of Docker. The curl command will fire a request to the core command service which will relay the request to the Random-Integer-Generator device and return results of the GET request. The results should look similar to the JSON below (except that the random number generated will return a differnt value). The random number is the 'value' property of the reading - -14351 in this example. { \"device\" : \"Random-Integer-Generator01\" , \"EncodedEvent\" : null , \"origin\" : 1596669607120457092 , \"readings\" : [ { \"valueType\" : \"Int16\" , \"origin\" : 1596669607120421119 , \"value\" : \"-14351\" , \"device\" : \"Random-Integer-Generator01\" , \"name\" : \"RandomValue_Int16\" } ] } PUT Command Example PUT commands can adjust the minimum and maximum values for future random readings, but they must be valid values for the data type. For example, the minimum value for GenerateRandomValue_Int16 cannot be more than 32767 and less than -32768. Below, the PUT command limits the future reading value of GenerateRandomValue_Int16 to a range of -2 to 2: curl -X PUT -d '{\"Min_Int16\": \"-2\", \"Max_Int16\": \"2\"}' localhost:48082/api/v1/device/ec7a7586-875e-4bb4-aa46-836d9e04514b/command/cfa21103-8ec9-44a0-9c55-25f9cc653dc0 Info Nothing will be returned by the PUT curl call above unless you have and error. After running the command above, if you rerun the GET request for the same deviceResource ( GenerateRandomValue\\_Int16 ) you should only get values between -2 and 2. { \"readings\" : [ { \"device\" : \"Random-Integer-Generator01\" , \"origin\" : 1596670608709647108 , \"value\" : \"0\" , \"name\" : \"RandomValue_Int16\" , \"valueType\" : \"Int16\" } ], \"origin\" : 1596670608709698016 , \"EncodedEvent\" : null , \"device\" : \"Random-Integer-Generator01\" }","title":"Random Integer Device Service"},{"location":"examples/Ch-ExamplesRandomDeviceService/#random-integer-device-service","text":"","title":"Random Integer Device Service"},{"location":"examples/Ch-ExamplesRandomDeviceService/#introduction","text":"The Random Integer device service is a simple device service that works quickly and easily with EdgeX. It simulates a single device ( Random-Integer-Generator01 ) that generates a collection of random integer numbers every 20 seconds by default. It initializes with a pre-defined device profile, device, and auto events schedule.","title":"Introduction"},{"location":"examples/Ch-ExamplesRandomDeviceService/#edgex-apis-related-to-random-integer-device-service","text":"Once the Random Integer device service is started, the table below provides a list of various EdgeX APIs that can be explored to learn more about the device service, the device, its commands and see the data the simulated device generates. Core Service API URL Description Core Metadata http://[host]:48081/api/v1/deviceservice/name/device-random Device Service created Core Metadata http://[host]:48081/api/v1/deviceprofile/name/Random-Integer-Generator Device profile created Core Metadata http://[host]:48081/api/v1/device/name/Random-Integer-Generator01 Device created Core Data http://[host]:48080/api/v1/event Events created by the random integer generator device Core Command http://[host]:48082/api/v1/device/name/Random-Integer-Generator01 Commands for the random integer generator device","title":"EdgeX APIs related to Random Integer Device Service"},{"location":"examples/Ch-ExamplesRandomDeviceService/#running-commands","text":"Use the examples below to exercise the Random Integer device service's command set against the simulated device - the Random-Integer-Generator01 device.","title":"Running Commands"},{"location":"examples/Ch-ExamplesRandomDeviceService/#find-the-get-and-put-commands","text":"The Random Integer device service is configured to send simulated data to core data every few seconds (20 seconds by default) - see the [configuration file](https://github.com/edgexfoundry/device-random/blob/master/cmd/res/configuration.toml for default details. It will send three different deviceResources of data - Int8, Int16 and Int32. You can excersice the GET and PUT requests on the command service to trigger the Random-Integer-Generator01 device to generate values for any one of the deviceResources or to set the min/max random number generated for any of the deviceResources. First, use the curl command below to exercise the command service API to get a list of commands (both GET and PUT ) for the Random-Integer-Generator01 device. curl -X GET localhost:48082/api/v1/device/name/Random-Integer-Generator01 | json_pp Warning The example above assumes your core command service is available on localhost at the default service port of 48082. The result should look something like that displayed below. { \"name\" : \"Random-Integer-Generator01\" , \"labels\" : [ \"device-random-example\" ], \"adminState\" : \"UNLOCKED\" , \"id\" : \"ec7a7586-875e-4bb4-aa46-836d9e04514b\" , \"operatingState\" : \"ENABLED\" , \"commands\" : [ { \"id\" : \"7dc0478d-29dd-4f6e-945d-85e4ad848bb1\" , \"put\" : { \"responses\" : [ { \"code\" : \"200\" }, { \"code\" : \"503\" , \"description\" : \"service unavailable\" } ], \"url\" : \"http://edgex-core-command:48082/api/v1/device/ec7a7586-875e-4bb4-aa46-836d9e04514b/command/7dc0478d-29dd-4f6e-945d-85e4ad848bb1\" , \"parameterNames\" : [ \"Min_Int32\" , \"Max_Int32\" ], \"path\" : \"/api/v1/device/{deviceId}/GenerateRandomValue_Int32\" }, \"created\" : 1596666924062 , \"get\" : { \"url\" : \"http://edgex-core-command:48082/api/v1/device/ec7a7586-875e-4bb4-aa46-836d9e04514b/command/7dc0478d-29dd-4f6e-945d-85e4ad848bb1\" , \"responses\" : [ { \"expectedValues\" : [ \"RandomValue_Int32\" ], \"code\" : \"200\" }, { \"code\" : \"503\" , \"description\" : \"service unavailable\" } ], \"path\" : \"/api/v1/device/{deviceId}/GenerateRandomValue_Int32\" }, \"modified\" : 1596666924062 , \"name\" : \"GenerateRandomValue_Int32\" }, { \"put\" : { \"path\" : \"/api/v1/device/{deviceId}/GenerateRandomValue_Int8\" , \"parameterNames\" : [ \"Min_Int8\" , \"Max_Int8\" ], \"url\" : \"http://edgex-core-command:48082/api/v1/device/ec7a7586-875e-4bb4-aa46-836d9e04514b/command/ab8e16f9-2e94-4c10-b600-858ea1087cdf\" , \"responses\" : [ { \"code\" : \"200\" }, { \"description\" : \"service unavailable\" , \"code\" : \"503\" } ] }, \"created\" : 1596666924062 , \"get\" : { \"responses\" : [ { \"expectedValues\" : [ \"RandomValue_Int8\" ], \"code\" : \"200\" }, { \"description\" : \"service unavailable\" , \"code\" : \"503\" } ], \"url\" : \"http://edgex-core-command:48082/api/v1/device/ec7a7586-875e-4bb4-aa46-836d9e04514b/command/ab8e16f9-2e94-4c10-b600-858ea1087cdf\" , \"path\" : \"/api/v1/device/{deviceId}/GenerateRandomValue_Int8\" }, \"id\" : \"ab8e16f9-2e94-4c10-b600-858ea1087cdf\" , \"modified\" : 1596666924062 , \"name\" : \"GenerateRandomValue_Int8\" }, { \"name\" : \"GenerateRandomValue_Int16\" , \"id\" : \"cfa21103-8ec9-44a0-9c55-25f9cc653dc0\" , \"get\" : { \"url\" : \"http://edgex-core-command:48082/api/v1/device/ec7a7586-875e-4bb4-aa46-836d9e04514b/command/cfa21103-8ec9-44a0-9c55-25f9cc653dc0\" , \"responses\" : [ { \"expectedValues\" : [ \"RandomValue_Int16\" ], \"code\" : \"200\" }, { \"description\" : \"service unavailable\" , \"code\" : \"503\" } ], \"path\" : \"/api/v1/device/{deviceId}/GenerateRandomValue_Int16\" }, \"put\" : { \"responses\" : [ { \"code\" : \"200\" }, { \"description\" : \"service unavailable\" , \"code\" : \"503\" } ], \"url\" : \"http://edgex-core-command:48082/api/v1/device/ec7a7586-875e-4bb4-aa46-836d9e04514b/command/cfa21103-8ec9-44a0-9c55-25f9cc653dc0\" , \"parameterNames\" : [ \"Min_Int16\" , \"Max_Int16\" ], \"path\" : \"/api/v1/device/{deviceId}/GenerateRandomValue_Int16\" }, \"created\" : 1596666924062 , \"modified\" : 1596666924062 } ] } Note The identifiers and URLs will look different in your result as the unique identifiers for devices, commands, etc. will be different in each EdgeX instance.","title":"Find the GET and PUT Commands"},{"location":"examples/Ch-ExamplesRandomDeviceService/#get-command-example","text":"Locate the GET URL for one of the deviceResources in your JSON produced by the curl command above. Use another curl command to trigger a GET command against that URL for the Random-Integer-Generator01 device. In the example below, a GET is called for the GenerateRandomValue_Int16 deviceResource. curl -X GET localhost:48082/api/v1/device/ec7a7586-875e-4bb4-aa46-836d9e04514b/command/cfa21103-8ec9-44a0-9c55-25f9cc653dc0 | json_pp Note Importantly, notice that the host name provided in the JSON is always edgex-core-command . This is the host name of the command service when running in Docker. Use localhost in your curl commands to exercise the APIs. You are not running your curl command inside of Docker. The curl command will fire a request to the core command service which will relay the request to the Random-Integer-Generator device and return results of the GET request. The results should look similar to the JSON below (except that the random number generated will return a differnt value). The random number is the 'value' property of the reading - -14351 in this example. { \"device\" : \"Random-Integer-Generator01\" , \"EncodedEvent\" : null , \"origin\" : 1596669607120457092 , \"readings\" : [ { \"valueType\" : \"Int16\" , \"origin\" : 1596669607120421119 , \"value\" : \"-14351\" , \"device\" : \"Random-Integer-Generator01\" , \"name\" : \"RandomValue_Int16\" } ] }","title":"GET Command Example"},{"location":"examples/Ch-ExamplesRandomDeviceService/#put-command-example","text":"PUT commands can adjust the minimum and maximum values for future random readings, but they must be valid values for the data type. For example, the minimum value for GenerateRandomValue_Int16 cannot be more than 32767 and less than -32768. Below, the PUT command limits the future reading value of GenerateRandomValue_Int16 to a range of -2 to 2: curl -X PUT -d '{\"Min_Int16\": \"-2\", \"Max_Int16\": \"2\"}' localhost:48082/api/v1/device/ec7a7586-875e-4bb4-aa46-836d9e04514b/command/cfa21103-8ec9-44a0-9c55-25f9cc653dc0 Info Nothing will be returned by the PUT curl call above unless you have and error. After running the command above, if you rerun the GET request for the same deviceResource ( GenerateRandomValue\\_Int16 ) you should only get values between -2 and 2. { \"readings\" : [ { \"device\" : \"Random-Integer-Generator01\" , \"origin\" : 1596670608709647108 , \"value\" : \"0\" , \"name\" : \"RandomValue_Int16\" , \"valueType\" : \"Int16\" } ], \"origin\" : 1596670608709698016 , \"EncodedEvent\" : null , \"device\" : \"Random-Integer-Generator01\" }","title":"PUT Command Example"},{"location":"examples/Ch-ExamplesSendingAndConsumingBinary/","text":"Sending and Consuming Binary Data From EdgeX Device Services EdgeX - Fuji Release Overview In this example, we will demonstrate how to send EdgeX Events and Readings that contain arbitrary binary data. DeviceService Implementation Device Profile To indicate that a deviceResource represents a Binary type, the following format is used: - name : \"camera_snapshot\" description : \"snapshot from camera\" properties : value : { type : \"Binary\" , readWrite : \"R\" } units : { type : \"Binary\" , readWrite : \"R\" , defaultValue : \"CameraSnapshot\" } Device Service Here is a snippet from a hypothetical Device Service's HandleReadCommands() method that produces an event that represents a JPEG image captured from a camera: if req.DeviceResourceName == \"camera_snapshot\" { data, err := cameraClient.GetSnapshot() // returns ([]byte, error) check(err) cv, err := sdkModel.NewBinaryValue(reqs[i].DeviceResourceName, 0, data) check(err) responses[i] = cv } Calling Device Service Command Querying core-metadata for the Device's Commands and DeviceID provides the following as the URL to request a reading from the snapshot command: http://localhost:49990/api/v1/device/3469a658-c3b8-46f1-9098-7d19973af402/OnvifSnapshot Unlike with non-binary Events, making a request to this URL will return an event in CBOR representation. CBOR is a representation of binary data loosely based off of the JSON data model. This Event will not be human-readable. Parsing CBOR Encoded Events To access the data enclosed in these Events and Readings, they will first need to be decoded from CBOR. The following is a simple Go program that reads in the CBOR response from a file containing the response from the previous HTTP request. The Go library recommended for parsing these events can be found at https://github.com/ugorji/go package main import ( \u201cio/ioutil\u201d contracts \u201cgithub.com/edgexfoundry/go-mod-core-contracts/models\u201d \u201cgithub.com/ugorji/go/codec\u201d ) func check(e error) { if e != nil { panic(e) } } func main() { // Read in our cbor data fileBytes, err := ioutil.ReadFile(\u201c/Users/johndoe/Desktop/image.cbor\u201d) check(err) // Create a cbor decoder from the cbor bytes and a cbor code handle var h codec.Handle = new(codec.CborHandle) var dec *codec.Decoder = codec.NewDecoderBytes(fileBytes, h) // Decode into an EdgeX Event var event contracts.Event err = dec.Decode(&event) check(err) // Grab binary data and write to a file imgBytes := event.Readings[0].BinaryValue ioutil.WriteFile(\u201c/Users/johndoe/Desktop/image.jpeg\u201d, imgBytes, 0644) } In the code above, the CBOR data is read into a buffer, a code.Decoder is created to decode the CBOR data, an EdgeX Event struct is created, and a pointer is passed into the decoder's Decode() method to be filled in. Finally, the binary payload is written to a file from the BinaryValue field of the Reading. This method would work as well for decoding Events off the EdgeX message bus. Encoding Arbitrary Structures in Events The Device SDK's NewBinaryValue() function above only accepts a byte slice as binary data. Any arbitrary Go structure can be encoded in a binary reading by first encoding the structure into a byte slice using CBOR. The following illustrates this method: // DeviceService HandleReadCommands() code: foo := struct { X int Y int Z int Bar string } { X: 7, Y: 3, Z: 100, Bar: \"Hello world!\", } buffer := new(bytes.Buffer) ch := new(codec.CborHandle) encoder := codec.NewEncoder(buffer, ch) err = encoder.Encode(&foo) check(err) cv, err := sdkModel.NewBinaryValue(reqs[i].DeviceResourceName, 0, buffer.Bytes()) responses[i] = cv This code takes the anonymous struct with fields X, Y, Z, and Bar (of different types) and serializes it into a byte slice using the same codec library, and passing the output to NewBinaryValue() . When consuming these events, another level of decoding will need to take place to get the structure out of the binary payload. func main() { // Read in our cbor data fileBytes, err := ioutil.ReadFile(\u201c/Users/johndoe/Desktop/image.cbor\u201d) check(err) // Create a cbor decoder from the cbor bytes and a cbor code handle var h codec.Handle = new(codec.CborHandle) var dec *codec.Decoder = codec.NewDecoderBytes(fileBytes, h) // Decode into an EdgeX Event var event contracts.Event err = dec.Decode(&event) check(err) // Decode into arbitrary type foo := struct { X int Y int Z int Bar string }{} dec = codec.NewDecoderBytes(event.Readings[0].BinaryValue, h) err = dec.Decode(&foo) check(err) fmt.Println(foo) } This code takes a command response in the same format as the previous example, but uses the codec library to decode the CBOR data inside the EdgeX Reading's BinaryValue field. Using this approach, an Event can be sent containing data containing an arbitrary, flexible structure. Use cases could be a Reading containing multiple images, a variable length list of integer read-outs, etc. Creating a CBOR Payload for use with PUT Commands To create a CBOR payload that, for example, can be used with PUT commands, we first need to set up some content which will be used to create the CBOR data. Then we encode that content and finally write the CBOR-encoded data to a file, followed by using that file with an example PUT command. The relevant data structures are as follows, containing details of the key and the corresponding value, where you should note in particular the Put field in the Command struct, and below the Command struct is the Put struct itself. More details available at https://github.com/edgexfoundry/go-mod-core-contracts/blob/master/models/put.go: type Command struct { Timestamps `yaml:\",inline\"` Id string `json:\"id\" yaml:\"id,omitempty\"` // Id is a unique identifier, such as a UUID Name string `json:\"name\" yaml:\"name,omitempty\"` // Command name (unique on the profile) Get Get `json:\"get\" yaml:\"get,omitempty\"` // Get Command Put Put `json:\"put\" yaml:\"put,omitempty\"` // Put Command isValidated bool // internal member used for validation check } type Put struct { Action `yaml:\",inline\"` ParameterNames []string `json:\"parameterNames,omitempty\" yaml:\"parameterNames,omitempty\"` } What follows below is the accompanying golang code that accomplishes the steps above: package main import ( \"io/ioutil\" \"github.com/ugorji/go/codec\" ) const ( fileLocation = \"/Users/johnpoe/Desktop/CBOR_Binary\" ) const ( enableRandomizationBinary = \"EnableRandomization_Binary\" path = \"Path\" url = \"Url\" ) func main() { // Set up some records which will be used to create the CBOR data cborContents := make(map[string]string) // The user should put values in the cborContents variable above, which will // be converted to CBOR. Please refer to the earlier note containing details // of the key and the corresponding value each keys represent. What follows // below is an example of populating the \"ParameterNames\" (aka \"Put\") cborContents[enableRandomizationBinary] = \"true\" cborContents[path] = \"/api/v1/device/9f872d68/Binary\" cborContents[url] = \"http://localhost:48082/api/v1/device/9f872d68/command/7ff8d51ea50d\" // Encode the contents that were set up above. input := make([]byte, 0) check(codec.NewEncoderBytes(&input, &codec.CborHandle{}).Encode(cborContents)) // Write the CBOR-encoded data to a file. ioutil.WriteFile(fileLocation, input, 0644) } func check(e error) { if e != nil { panic(e) } } In the code above, as a final step, the CBOR payload has been written to the filesystem, into a file that we are calling CBOR_Binary . Here is how to use the PUT command: Via the --data-binary flag in cURL , supply as follows the CBOR-encoded file created above. You will want to replace the fileLocation (i.e. '@/Users/johnpoe/Desktop/CBOR_Binary' by a suitably-located local file on your filesystem: curl --location --request PUT 'http://localhost:48082/api/v1/device/9f872d68-2281-4af4-959d-29e4d51c2192/command/b349df4a-6c3d-4218-b8bc-7ff8d51ea50d' \\ --header 'Content-Type: application/cbor' \\ --data-binary '@/Users/johnpoe/Desktop/CBOR_Binary'","title":"Sending and Consuming Binary Data From EdgeX Device Services"},{"location":"examples/Ch-ExamplesSendingAndConsumingBinary/#sending-and-consuming-binary-data-from-edgex-device-services","text":"EdgeX - Fuji Release","title":"Sending and Consuming Binary Data From EdgeX Device Services"},{"location":"examples/Ch-ExamplesSendingAndConsumingBinary/#overview","text":"In this example, we will demonstrate how to send EdgeX Events and Readings that contain arbitrary binary data.","title":"Overview"},{"location":"examples/Ch-ExamplesSendingAndConsumingBinary/#deviceservice-implementation","text":"","title":"DeviceService Implementation"},{"location":"examples/Ch-ExamplesSendingAndConsumingBinary/#device-profile","text":"To indicate that a deviceResource represents a Binary type, the following format is used: - name : \"camera_snapshot\" description : \"snapshot from camera\" properties : value : { type : \"Binary\" , readWrite : \"R\" } units : { type : \"Binary\" , readWrite : \"R\" , defaultValue : \"CameraSnapshot\" }","title":"Device Profile"},{"location":"examples/Ch-ExamplesSendingAndConsumingBinary/#device-service","text":"Here is a snippet from a hypothetical Device Service's HandleReadCommands() method that produces an event that represents a JPEG image captured from a camera: if req.DeviceResourceName == \"camera_snapshot\" { data, err := cameraClient.GetSnapshot() // returns ([]byte, error) check(err) cv, err := sdkModel.NewBinaryValue(reqs[i].DeviceResourceName, 0, data) check(err) responses[i] = cv }","title":"Device Service"},{"location":"examples/Ch-ExamplesSendingAndConsumingBinary/#calling-device-service-command","text":"Querying core-metadata for the Device's Commands and DeviceID provides the following as the URL to request a reading from the snapshot command: http://localhost:49990/api/v1/device/3469a658-c3b8-46f1-9098-7d19973af402/OnvifSnapshot Unlike with non-binary Events, making a request to this URL will return an event in CBOR representation. CBOR is a representation of binary data loosely based off of the JSON data model. This Event will not be human-readable.","title":"Calling Device Service Command"},{"location":"examples/Ch-ExamplesSendingAndConsumingBinary/#parsing-cbor-encoded-events","text":"To access the data enclosed in these Events and Readings, they will first need to be decoded from CBOR. The following is a simple Go program that reads in the CBOR response from a file containing the response from the previous HTTP request. The Go library recommended for parsing these events can be found at https://github.com/ugorji/go package main import ( \u201cio/ioutil\u201d contracts \u201cgithub.com/edgexfoundry/go-mod-core-contracts/models\u201d \u201cgithub.com/ugorji/go/codec\u201d ) func check(e error) { if e != nil { panic(e) } } func main() { // Read in our cbor data fileBytes, err := ioutil.ReadFile(\u201c/Users/johndoe/Desktop/image.cbor\u201d) check(err) // Create a cbor decoder from the cbor bytes and a cbor code handle var h codec.Handle = new(codec.CborHandle) var dec *codec.Decoder = codec.NewDecoderBytes(fileBytes, h) // Decode into an EdgeX Event var event contracts.Event err = dec.Decode(&event) check(err) // Grab binary data and write to a file imgBytes := event.Readings[0].BinaryValue ioutil.WriteFile(\u201c/Users/johndoe/Desktop/image.jpeg\u201d, imgBytes, 0644) } In the code above, the CBOR data is read into a buffer, a code.Decoder is created to decode the CBOR data, an EdgeX Event struct is created, and a pointer is passed into the decoder's Decode() method to be filled in. Finally, the binary payload is written to a file from the BinaryValue field of the Reading. This method would work as well for decoding Events off the EdgeX message bus.","title":"Parsing CBOR Encoded Events"},{"location":"examples/Ch-ExamplesSendingAndConsumingBinary/#encoding-arbitrary-structures-in-events","text":"The Device SDK's NewBinaryValue() function above only accepts a byte slice as binary data. Any arbitrary Go structure can be encoded in a binary reading by first encoding the structure into a byte slice using CBOR. The following illustrates this method: // DeviceService HandleReadCommands() code: foo := struct { X int Y int Z int Bar string } { X: 7, Y: 3, Z: 100, Bar: \"Hello world!\", } buffer := new(bytes.Buffer) ch := new(codec.CborHandle) encoder := codec.NewEncoder(buffer, ch) err = encoder.Encode(&foo) check(err) cv, err := sdkModel.NewBinaryValue(reqs[i].DeviceResourceName, 0, buffer.Bytes()) responses[i] = cv This code takes the anonymous struct with fields X, Y, Z, and Bar (of different types) and serializes it into a byte slice using the same codec library, and passing the output to NewBinaryValue() . When consuming these events, another level of decoding will need to take place to get the structure out of the binary payload. func main() { // Read in our cbor data fileBytes, err := ioutil.ReadFile(\u201c/Users/johndoe/Desktop/image.cbor\u201d) check(err) // Create a cbor decoder from the cbor bytes and a cbor code handle var h codec.Handle = new(codec.CborHandle) var dec *codec.Decoder = codec.NewDecoderBytes(fileBytes, h) // Decode into an EdgeX Event var event contracts.Event err = dec.Decode(&event) check(err) // Decode into arbitrary type foo := struct { X int Y int Z int Bar string }{} dec = codec.NewDecoderBytes(event.Readings[0].BinaryValue, h) err = dec.Decode(&foo) check(err) fmt.Println(foo) } This code takes a command response in the same format as the previous example, but uses the codec library to decode the CBOR data inside the EdgeX Reading's BinaryValue field. Using this approach, an Event can be sent containing data containing an arbitrary, flexible structure. Use cases could be a Reading containing multiple images, a variable length list of integer read-outs, etc.","title":"Encoding Arbitrary Structures in Events"},{"location":"examples/Ch-ExamplesSendingAndConsumingBinary/#creating-a-cbor-payload-for-use-with-put-commands","text":"To create a CBOR payload that, for example, can be used with PUT commands, we first need to set up some content which will be used to create the CBOR data. Then we encode that content and finally write the CBOR-encoded data to a file, followed by using that file with an example PUT command. The relevant data structures are as follows, containing details of the key and the corresponding value, where you should note in particular the Put field in the Command struct, and below the Command struct is the Put struct itself. More details available at https://github.com/edgexfoundry/go-mod-core-contracts/blob/master/models/put.go: type Command struct { Timestamps `yaml:\",inline\"` Id string `json:\"id\" yaml:\"id,omitempty\"` // Id is a unique identifier, such as a UUID Name string `json:\"name\" yaml:\"name,omitempty\"` // Command name (unique on the profile) Get Get `json:\"get\" yaml:\"get,omitempty\"` // Get Command Put Put `json:\"put\" yaml:\"put,omitempty\"` // Put Command isValidated bool // internal member used for validation check } type Put struct { Action `yaml:\",inline\"` ParameterNames []string `json:\"parameterNames,omitempty\" yaml:\"parameterNames,omitempty\"` } What follows below is the accompanying golang code that accomplishes the steps above: package main import ( \"io/ioutil\" \"github.com/ugorji/go/codec\" ) const ( fileLocation = \"/Users/johnpoe/Desktop/CBOR_Binary\" ) const ( enableRandomizationBinary = \"EnableRandomization_Binary\" path = \"Path\" url = \"Url\" ) func main() { // Set up some records which will be used to create the CBOR data cborContents := make(map[string]string) // The user should put values in the cborContents variable above, which will // be converted to CBOR. Please refer to the earlier note containing details // of the key and the corresponding value each keys represent. What follows // below is an example of populating the \"ParameterNames\" (aka \"Put\") cborContents[enableRandomizationBinary] = \"true\" cborContents[path] = \"/api/v1/device/9f872d68/Binary\" cborContents[url] = \"http://localhost:48082/api/v1/device/9f872d68/command/7ff8d51ea50d\" // Encode the contents that were set up above. input := make([]byte, 0) check(codec.NewEncoderBytes(&input, &codec.CborHandle{}).Encode(cborContents)) // Write the CBOR-encoded data to a file. ioutil.WriteFile(fileLocation, input, 0644) } func check(e error) { if e != nil { panic(e) } } In the code above, as a final step, the CBOR payload has been written to the filesystem, into a file that we are calling CBOR_Binary . Here is how to use the PUT command: Via the --data-binary flag in cURL , supply as follows the CBOR-encoded file created above. You will want to replace the fileLocation (i.e. '@/Users/johnpoe/Desktop/CBOR_Binary' by a suitably-located local file on your filesystem: curl --location --request PUT 'http://localhost:48082/api/v1/device/9f872d68-2281-4af4-959d-29e4d51c2192/command/b349df4a-6c3d-4218-b8bc-7ff8d51ea50d' \\ --header 'Content-Type: application/cbor' \\ --data-binary '@/Users/johnpoe/Desktop/CBOR_Binary'","title":"Creating a CBOR Payload for use with PUT Commands"},{"location":"examples/Ch-ExamplesVirtualDeviceService/","text":"Using the Virtual Device Service Overview The Virtual Device Service GO can simulate different kinds of devices to generate Events and Readings to the Core Data Micro Service. Furthermore, users can send commands and get responses through the Command and Control Micro Service. The Virtual Device Service allows you to execute functional or performance tests without any real devices. This version of the Virtual Device Service is implemented based on Device SDK GO , and uses ql (an embedded SQL database engine) to simulate virtual resources. Introduction For information on the virtual device service see virtual device under the Microservices tab. Working with the Virtual Device Service Running the Virtual Device Service Container The virtual device service depends on the EdgeX core services. By default, the virtual device service is part of the EdgeX community provided Docker Compose files. If you use one of the community provide Compose files , you can pull and run EdgeX inclusive of the virtual device service without having to make any changes. Running the Virtual Device Service Natively (in development mode) If you're going to download the source code and run the virtual device service in development mode, make sure that the EdgeX core service containers are up before starting the virtual device service. See how to work with EdgeX in a hybrid environment in order to run the virtual device service outside of containers. This same file will instruct you on how to get and run the virtual device service code . GET command example The virtual device service is configured to send simulated data to core data every few seconds (from 10-30 seconds depending on device - see the configuration file for AutoEvent details). You can excersice the GET request on the command service to see the generated value produced by any of the virtual device's simulated devices. Use the curl command below to exercise the virtual device service API (via core command service). curl -X GET localhost:48082/api/v1/device/1bd5d4c3-9d43-42f2-8c4a-f32f5999edf7/command/e5d7c2b8-eab7-4da4-9d41-388da05979a4 ` Warning The example above assumes your core command service is available on localhost at the default service port of 48082. Also, you must replace your device ID and command ID in the example above with your virtual device service's identifiers. If you are not sure of the identifiers to use, query the command service for the full list of commands and devices at http://localhost:48082/api/v1/device . The virtual device should respond (via the core command service) with event/reading JSON similar to that below. { \"device\" : \"Random-Integer-Device\" , \"origin\" : 1574325994604494491 , \"readings\" : [ { \"origin\" : 1574325994572380549 , \"device\" : \"Random-Integer-Device\" , \"name\" : \"Int8\" , \"value\" : \"42\" } ], \"EncodedEvent\" : null } PUT command example - Assign a value to a resource The virtual devices managed by the virtual device can also be actuated. The virtual device can be told to enable or disable random number generation. When disabled, the virtual device services can be told what value to respond with for all GET operations. When setting the fixed value, the value must be valid for the data type of the virtual device. For example, the minimum value of Int8 cannot be less than -128 and the maximum value cannot be greater than 127. Below is example actuation of one of the virtual devices. In this example, it sets the fixed GET return value to 123 and turns off random generation. curl -X PUT -d '{\"Int8\": \"123\", \"EnableRandomization_Int8\": \"false\"}' localhost:48082/api/v1/device/1bd5d4c3-9d43-42f2-8c4a-f32f5999edf7/command/e5d7c2b8-eab7-4da4-9d41-388da05979a4 Note The value of the resource's EnableRandomization property is simultaneously updated to false when sending a put command to assign a specified value to the resource. Therefore, the need to set EnableRandomization_Int8 to false is not actually required in the call above Return the virtual device to randomly generating numbers with another PUT call. curl -X PUT -d '{\"EnableRandomization_Int8\": \"true\"}' 48082 /api/v1/device/1bd5d4c3-9d43-42f2-8c4a-f32f5999edf7/command/e5d7c2b8-eab7-4da4-9d41-388da05979a4 Manipulate Virtual Resources Using the command ql Tool The virtual device service utilizes the ql database under he covers to store parameters for virtual device operations. The values a virtual device generates can be controlled by changing these parameters in the embedded database (versus calling on the API). You will need a command line tool to interact with the ql database. Install command ql . Depending on whether you are running the virtual device service in a Docker container or in development mode (\"natively\"), you will need access to the ql database directory (see the tabs below). Execute ql commands to execute SQL commands to see the virtual device configuration in the database or change the values returned. Query all data: ql -db /path-to-the-ql-db-folder/deviceVirtual.db -fld \"select * from VIRTUAL_RESOURCE\" Update Enable_Randomization: ql -db /path-to-the-ql-db-folder/deviceVirtual.db \"update VIRTUAL_RESOURCE set ENABLE_RANDOMIZATION=false where DEVICE_NAME=\" Random-Integer-Device \" and DEVICE_RESOURCE_NAME=\" Int8 \" \" Note When running the virtual device service in a container, make sure to run these commands as root using sudo. Running Containerized If the virtual device service runs in a Docker container, it must mount the directory (/db) that contains the ql database in the container. For example: device-virtual : image : edgexfoundry/docker-device-virtual-go:1.2.1 ports : - \"127.0.0.1:49990:49990\" container_name : edgex-device-virtual hostname : edgex-device-virtual networks : - edgex-network environment : << : *common-variables Service_Host : edgex-device-virtual depends_on : - consul # - logging # uncomment if re-enabled remote logging - data - metadata volumes : - /mnt/hgfs/EdgeX/DeviceVirtualDB:/db # Mount ql database directory Running in Development Mode If the virtual device service runs in development mode, the ql database is under the device-virtual-go/cmd/db directory. Reference Architectural Diagram Sequence Diagram Virtual Resource Table Schema Column Type DEVICE_NAME STRING COMMAND_NAME STRING DEVICE_RESOURCE_NAME STRING ENABLE_RANDOMIZATION BOOL DATA_TYPE STRING VALUE STRING","title":"Using the Virtual Device Service"},{"location":"examples/Ch-ExamplesVirtualDeviceService/#using-the-virtual-device-service","text":"","title":"Using the Virtual Device Service"},{"location":"examples/Ch-ExamplesVirtualDeviceService/#overview","text":"The Virtual Device Service GO can simulate different kinds of devices to generate Events and Readings to the Core Data Micro Service. Furthermore, users can send commands and get responses through the Command and Control Micro Service. The Virtual Device Service allows you to execute functional or performance tests without any real devices. This version of the Virtual Device Service is implemented based on Device SDK GO , and uses ql (an embedded SQL database engine) to simulate virtual resources.","title":"Overview"},{"location":"examples/Ch-ExamplesVirtualDeviceService/#introduction","text":"For information on the virtual device service see virtual device under the Microservices tab.","title":"Introduction"},{"location":"examples/Ch-ExamplesVirtualDeviceService/#working-with-the-virtual-device-service","text":"","title":"Working with the Virtual Device Service"},{"location":"examples/Ch-ExamplesVirtualDeviceService/#running-the-virtual-device-service-container","text":"The virtual device service depends on the EdgeX core services. By default, the virtual device service is part of the EdgeX community provided Docker Compose files. If you use one of the community provide Compose files , you can pull and run EdgeX inclusive of the virtual device service without having to make any changes.","title":"Running the Virtual Device Service Container"},{"location":"examples/Ch-ExamplesVirtualDeviceService/#running-the-virtual-device-service-natively-in-development-mode","text":"If you're going to download the source code and run the virtual device service in development mode, make sure that the EdgeX core service containers are up before starting the virtual device service. See how to work with EdgeX in a hybrid environment in order to run the virtual device service outside of containers. This same file will instruct you on how to get and run the virtual device service code .","title":"Running the Virtual Device Service Natively (in development mode)"},{"location":"examples/Ch-ExamplesVirtualDeviceService/#get-command-example","text":"The virtual device service is configured to send simulated data to core data every few seconds (from 10-30 seconds depending on device - see the configuration file for AutoEvent details). You can excersice the GET request on the command service to see the generated value produced by any of the virtual device's simulated devices. Use the curl command below to exercise the virtual device service API (via core command service). curl -X GET localhost:48082/api/v1/device/1bd5d4c3-9d43-42f2-8c4a-f32f5999edf7/command/e5d7c2b8-eab7-4da4-9d41-388da05979a4 ` Warning The example above assumes your core command service is available on localhost at the default service port of 48082. Also, you must replace your device ID and command ID in the example above with your virtual device service's identifiers. If you are not sure of the identifiers to use, query the command service for the full list of commands and devices at http://localhost:48082/api/v1/device . The virtual device should respond (via the core command service) with event/reading JSON similar to that below. { \"device\" : \"Random-Integer-Device\" , \"origin\" : 1574325994604494491 , \"readings\" : [ { \"origin\" : 1574325994572380549 , \"device\" : \"Random-Integer-Device\" , \"name\" : \"Int8\" , \"value\" : \"42\" } ], \"EncodedEvent\" : null }","title":"GET command example"},{"location":"examples/Ch-ExamplesVirtualDeviceService/#put-command-example-assign-a-value-to-a-resource","text":"The virtual devices managed by the virtual device can also be actuated. The virtual device can be told to enable or disable random number generation. When disabled, the virtual device services can be told what value to respond with for all GET operations. When setting the fixed value, the value must be valid for the data type of the virtual device. For example, the minimum value of Int8 cannot be less than -128 and the maximum value cannot be greater than 127. Below is example actuation of one of the virtual devices. In this example, it sets the fixed GET return value to 123 and turns off random generation. curl -X PUT -d '{\"Int8\": \"123\", \"EnableRandomization_Int8\": \"false\"}' localhost:48082/api/v1/device/1bd5d4c3-9d43-42f2-8c4a-f32f5999edf7/command/e5d7c2b8-eab7-4da4-9d41-388da05979a4 Note The value of the resource's EnableRandomization property is simultaneously updated to false when sending a put command to assign a specified value to the resource. Therefore, the need to set EnableRandomization_Int8 to false is not actually required in the call above Return the virtual device to randomly generating numbers with another PUT call. curl -X PUT -d '{\"EnableRandomization_Int8\": \"true\"}' 48082 /api/v1/device/1bd5d4c3-9d43-42f2-8c4a-f32f5999edf7/command/e5d7c2b8-eab7-4da4-9d41-388da05979a4","title":"PUT command example - Assign a value to a resource"},{"location":"examples/Ch-ExamplesVirtualDeviceService/#manipulate-virtual-resources-using-the-command-ql-tool","text":"The virtual device service utilizes the ql database under he covers to store parameters for virtual device operations. The values a virtual device generates can be controlled by changing these parameters in the embedded database (versus calling on the API). You will need a command line tool to interact with the ql database. Install command ql . Depending on whether you are running the virtual device service in a Docker container or in development mode (\"natively\"), you will need access to the ql database directory (see the tabs below). Execute ql commands to execute SQL commands to see the virtual device configuration in the database or change the values returned. Query all data: ql -db /path-to-the-ql-db-folder/deviceVirtual.db -fld \"select * from VIRTUAL_RESOURCE\" Update Enable_Randomization: ql -db /path-to-the-ql-db-folder/deviceVirtual.db \"update VIRTUAL_RESOURCE set ENABLE_RANDOMIZATION=false where DEVICE_NAME=\" Random-Integer-Device \" and DEVICE_RESOURCE_NAME=\" Int8 \" \" Note When running the virtual device service in a container, make sure to run these commands as root using sudo. Running Containerized If the virtual device service runs in a Docker container, it must mount the directory (/db) that contains the ql database in the container. For example: device-virtual : image : edgexfoundry/docker-device-virtual-go:1.2.1 ports : - \"127.0.0.1:49990:49990\" container_name : edgex-device-virtual hostname : edgex-device-virtual networks : - edgex-network environment : << : *common-variables Service_Host : edgex-device-virtual depends_on : - consul # - logging # uncomment if re-enabled remote logging - data - metadata volumes : - /mnt/hgfs/EdgeX/DeviceVirtualDB:/db # Mount ql database directory Running in Development Mode If the virtual device service runs in development mode, the ql database is under the device-virtual-go/cmd/db directory.","title":"Manipulate Virtual Resources Using the command ql Tool"},{"location":"examples/Ch-ExamplesVirtualDeviceService/#reference","text":"","title":"Reference"},{"location":"examples/Ch-ExamplesVirtualDeviceService/#architectural-diagram","text":"","title":"Architectural Diagram"},{"location":"examples/Ch-ExamplesVirtualDeviceService/#sequence-diagram","text":"","title":"Sequence Diagram"},{"location":"examples/Ch-ExamplesVirtualDeviceService/#virtual-resource-table-schema","text":"Column Type DEVICE_NAME STRING COMMAND_NAME STRING DEVICE_RESOURCE_NAME STRING ENABLE_RANDOMIZATION BOOL DATA_TYPE STRING VALUE STRING","title":"Virtual Resource Table Schema"},{"location":"examples/LinuxTutorial/LinuxTutorial/","text":"EdgeX Foundry Hands On Tutorial Provided by Jonas Werner, Cloud Solutions Architect, CTO, Dell Technologies Download Tutorial (in PDF format) Scope and Format This is meant to be a beginners guide to EdgeX Foundry it assumes nothing but some basic Linux command line experience. While the level of detail is aimed to support new Linux users, the content will be applicable also to experienced users who wish to get into open source IoT and perhaps who want to learn more about technologies such as docker-compose, etc. Topics Covered Installation of EdgeX Foundry Starting / stopping micro services How to add / enable services Interacting with EdgeX using Postman, cURL and Python Creating devices (sources of sensor data) Sending data to EdgeX using REST Exporting a stream of data using MQTT How to issue commands from EdgeX to devices Creating rules Debug flags and container logs","title":"EdgeX Foundry Hands On Tutorial"},{"location":"examples/LinuxTutorial/LinuxTutorial/#edgex-foundry-hands-on-tutorial","text":"Provided by Jonas Werner, Cloud Solutions Architect, CTO, Dell Technologies","title":"EdgeX Foundry Hands On Tutorial"},{"location":"examples/LinuxTutorial/LinuxTutorial/#download","text":"Tutorial (in PDF format)","title":"Download"},{"location":"examples/LinuxTutorial/LinuxTutorial/#scope-and-format","text":"This is meant to be a beginners guide to EdgeX Foundry it assumes nothing but some basic Linux command line experience. While the level of detail is aimed to support new Linux users, the content will be applicable also to experienced users who wish to get into open source IoT and perhaps who want to learn more about technologies such as docker-compose, etc.","title":"Scope and Format"},{"location":"examples/LinuxTutorial/LinuxTutorial/#topics-covered","text":"Installation of EdgeX Foundry Starting / stopping micro services How to add / enable services Interacting with EdgeX using Postman, cURL and Python Creating devices (sources of sensor data) Sending data to EdgeX using REST Exporting a stream of data using MQTT How to issue commands from EdgeX to devices Creating rules Debug flags and container logs","title":"Topics Covered"},{"location":"general/ContainerNames/","text":"EdgeX Container Names The following table provides the list of the default EdgeX Docker image names to the Docker container name and Docker Compose names. Core Docker image name Docker container name Docker Compose service name docker-core-data-go edgex-core-data data docker-core-metadata-go edgex-core-metadata metadata docker-core-command-go edgex-core-command command Supporting Docker image name Docker container name Docker Compose service name docker-support-notifications-go edgex-support-notifications notifications docker-support-logging-go edgex-support-logging logging docker-support-scheduler-go edgex-support-scheduler scheduler Application & Analytics Docker image name Docker container name Docker Compose service name docker-app-service-configurable edgex-app-service-configurable-rules app-service-rules emqx/kuiper edgex-kuiper rulesengine Device Docker image name Docker container name Docker Compose service name docker-device-virtual-go edgex-device-virtual device-virtual docker-device-random-go edgex-device-random device-random docker-device-mqtt-go edgex-device-mqtt device-mqtt docker-device-rest-go edgex-device-rest device-rest docker-device-modbus-go edgex-device-modbus device-modbus docker-device-snmp-go edgex-device-snmp device-snmp Security Docker image name Docker container name Docker Compose service name vault edgex-vault vault postgress kong-db kong-db kong kong kong docker-edgex-security-proxy-setup-go edgex-proxy edgex-proxy Miscellaneous Docker image name Docker container name Docker Compose service name docker-edgex-consul edgex-core-consul consul mongo edgex-mongo mongo redis edgex-redis redis docker-sys-mgmt-agent-go edgex-sys-mgmt-agent system","title":"EdgeX Container Names"},{"location":"general/ContainerNames/#edgex-container-names","text":"The following table provides the list of the default EdgeX Docker image names to the Docker container name and Docker Compose names. Core Docker image name Docker container name Docker Compose service name docker-core-data-go edgex-core-data data docker-core-metadata-go edgex-core-metadata metadata docker-core-command-go edgex-core-command command Supporting Docker image name Docker container name Docker Compose service name docker-support-notifications-go edgex-support-notifications notifications docker-support-logging-go edgex-support-logging logging docker-support-scheduler-go edgex-support-scheduler scheduler Application & Analytics Docker image name Docker container name Docker Compose service name docker-app-service-configurable edgex-app-service-configurable-rules app-service-rules emqx/kuiper edgex-kuiper rulesengine Device Docker image name Docker container name Docker Compose service name docker-device-virtual-go edgex-device-virtual device-virtual docker-device-random-go edgex-device-random device-random docker-device-mqtt-go edgex-device-mqtt device-mqtt docker-device-rest-go edgex-device-rest device-rest docker-device-modbus-go edgex-device-modbus device-modbus docker-device-snmp-go edgex-device-snmp device-snmp Security Docker image name Docker container name Docker Compose service name vault edgex-vault vault postgress kong-db kong-db kong kong kong docker-edgex-security-proxy-setup-go edgex-proxy edgex-proxy Miscellaneous Docker image name Docker container name Docker Compose service name docker-edgex-consul edgex-core-consul consul mongo edgex-mongo mongo redis edgex-redis redis docker-sys-mgmt-agent-go edgex-sys-mgmt-agent system","title":"EdgeX Container Names"},{"location":"general/Definitions/","text":"Definitions The following glossary provides terms used in EdgeX Foundry. The definition are based on how EdgeX and its community use the term versus any strict technical or industry definition. Actuate To cause a machine or device to operate. In EdgeX terms, to command a device or sensor under management of EdgeX to do something (example: stop a motor) or to reconfigure itself (example: set a thermostat's cooling point). Brownfield and Greenfield Brownfield refers to older legacy equipment (nodes, devices, sensors) in an edge/IoT deployment, which typically uses older protocols. Greenfield refers to, typically, new equipment with modern protocols. Containerized EdgeX micro services and infrastructure (i.e. databases, registry, etc.) are built as executable programs, put into Docker images, and made available via Docker Hub (and Nexus repository for nightly builds). A service (or infrastructure element) that is available in Docker Hub (or Nexus) is said to be containerized. Docker images can be quickly downloaded and new Docker containers created from the images. Contributor/Developer If you want to change, add to or at least build the existing EdgeX code base, then you are a \"Developer\". \"Contributors\" are developers that further wish to contribute their code back into the EdgeX open source effort. Created time stamp The Created time stamp is the time the data was created in the database and is unchangeable. The Origin time stamp is the time the data is created on the device, device services, sensor, or object that collected the data before the data was sent to EdgeX Foundry and the database. Usually, the Origin and Created time stamps are the same, or very close to being the same. On occasion the sensor may be a long way from the gateway or even in a different time zone, and the Origin and Created time stamps may be quite different. If persistence is disable in core-data, the time stamp will default to 0. Device In EdgeX parlance, \"device\" is used to refer to a sensor, actuator, or IoT \"thing\". A sensor generally collects information from the physical world - like a temperature or vibration sensor. Actuators are machines that can be told to do something. Actuators move or otherwise control a mechanism or system - like a value on a pump. While there may be some technical differences, for the purposes of EdgeX documentation, device will refer to a sensor, actuator or \"thing\". Edge Analytics The terms edge or local analytics (the terms are used interchangeably and have the same meaning in this context) for the purposes of edge computing (and EdgeX), refers to an \u201canalytics\u201d service is that: - Receives and interprets the EdgeX sensor data to some degree; some analytics services are more sophisticated and able to provide more insights than others - Make determinations on what actions and actuations need to occur based on the insights it has achieved, thereby driving actuation requests to EdgeX associated devices or other services (like notifications) The analytics service could be some simple logic built into an app service, a rules engine package, or an agent of some artificial intelligence/machine learning system. From an EdgeX perspective, actionable intelligence generation is all the same. From an EdgeX perspective, edge analytics = seeing the edge data and be able to make requests to act on what is seen. While EdgeX provides a rules engine service as its reference implementation of local analytics, app services and its data preparation capability allow sensor data to be streamed to any analytics package. Because of EdgeX\u2019s micro service architecture and distributed nature, the analytics service would not necessarily have to run local to the devices / sensors. In other words, it would not have to run at the edge. App services could deliver the edge data to analytics living in the cloud. However, in these scenarios, the insight intelligence would not be considered local or edge in context. Because of latency concerns, data security and privacy needs, intermittent connectivity of edge systems, and other reasons, it is often vital for edge platforms to retain an analytic capability at the edge or local. Gateway An IoT gateway is a compute platform at the farthest ends of an edge or IoT network. It is the host or \u201cbox\u201d to which physical sensors and devices connect and that is, in turn, connected to the networks (wired or wirelessly) of the information technology realm. IoT or edge gateways are compute platforms that connect \u201cthings\u201d (sensors and devices) to IT networks and systems. Micro service In a micro service architecture, each component has its own process. This is in contrast to a monolithic architecture in which all components of the application run in the same process. Benefits of micro service architectures include: - Allow any one service to be replaced and upgraded more easily - Allow services to be programmed using different programming languages and underlying technical solutions (use the best technology for each specific service) - Ex: services written in C can communicate and work with services written in Go - This allows organizations building solutions to maximize available developer resources and some legacy code - Allow services to be distributed across host compute platforms - allowing better utilization of available compute resources - Allow for more scalable solutions by adding copies of services when needed Origin time stamp The Origin time stamp is the time the data is created on the device, device services, sensor, or object that collected the data before the data is sent to EdgeX Foundry and the database. The Created time stamp is the time the data was created in the database. Usually, the Origin and Created time stamps are the same or very close to the same. On occasion the sensor may be a long way from the gateway or even in a different time zone, and the Origin and Created time stamps may be quite different. Reference Implementation Default and example implementation(s) offered by the EdgeX community. Other implementations may be offered by 3rd parties or for specialization. Rules Engine Rules engines are important to the IoT edge system. A rules engine is a software system that is connected to a collection of data (either database or data stream). The rules engine examines various elements of the data and monitors the data, and then triggers some action based on the results of the monitoring of the data it. A rules engine is a collection of \"If-Then\" conditional statements. The \"If\" informs the rules engine what data to look at and what ranges or values of data must match in order to trigger the \"Then\" part of the statement, which then informs the rules engine what action to take or what external resource to call on, when the data is a match to the \"If\" statement. Most rules engines can be dynamically programmed meaning that new \"If-Then\" statements or rules, can be provided while the engine is running. The rules are often defined by some type of rule language with simple syntax to enable non-Developers to provide the new rules. Rules engines are one of the simplest forms of \"edge analytics\" provided in IoT systems. Rules engines enable data picked up by IoT sensors to be monitored and acted upon (actuated). Typically, the actuation is accomplished on another IoT device or sensor. For example, a temperature sensor in an equipment enclosure may be monitored by a rules engine to detect when the temperature is getting too warm (or too cold) for safe or optimum operation of the equipment. The rules engine, upon detecting temperatures outside of the acceptable range, shuts off the equipment in the enclosure. Software Development Kit In EdgeX, a software development kit (or SDK) is a library or module to be incorporated into a new micro service. It provides a lot of the boilerplate code and scaffolding associated with the type of service being created. The SDK allows the developer to focus on the details of the service functionality and not have to worry about the mundane tasks associated with EdgeX services. South and North Side South Side: All IoT objects, within the physical realm, and the edge of the network that communicates directly with those devices, sensors, actuators, and other IoT objects, and collects the data from them, is known collectively as the \"south side.\" North Side: The cloud (or enterprise system) where data is collected, stored, aggregated, analyzed, and turned into information, and the part of the network that communicates with the cloud, is referred to as the \"north side\" of the network. EdgeX enables data to be sent \"north, \" \"south, \" or laterally as needed and as directed. \"Snappy\" / Ubuntu Core & Snaps A Linux-based Operating System provided by Ubuntu - formally called Ubuntu Core but often referred to as \"Snappy\". The packages are called 'snaps' and the tool for using them 'snapd', and works for phone, cloud, internet of things, and desktop computers. The \"Snap\" packages are self-contained and have no dependency on external stores. \"Snaps\" can be used to create command line tools, background services, and desktop applications. User If you want to get the EdgeX platform and run it (but do not intend to change or add to the existing code base now) then you are considered a \"User\".","title":"Definitions"},{"location":"general/Definitions/#definitions","text":"The following glossary provides terms used in EdgeX Foundry. The definition are based on how EdgeX and its community use the term versus any strict technical or industry definition.","title":"Definitions"},{"location":"general/Definitions/#actuate","text":"To cause a machine or device to operate. In EdgeX terms, to command a device or sensor under management of EdgeX to do something (example: stop a motor) or to reconfigure itself (example: set a thermostat's cooling point).","title":"Actuate"},{"location":"general/Definitions/#brownfield-and-greenfield","text":"Brownfield refers to older legacy equipment (nodes, devices, sensors) in an edge/IoT deployment, which typically uses older protocols. Greenfield refers to, typically, new equipment with modern protocols.","title":"Brownfield and Greenfield"},{"location":"general/Definitions/#containerized","text":"EdgeX micro services and infrastructure (i.e. databases, registry, etc.) are built as executable programs, put into Docker images, and made available via Docker Hub (and Nexus repository for nightly builds). A service (or infrastructure element) that is available in Docker Hub (or Nexus) is said to be containerized. Docker images can be quickly downloaded and new Docker containers created from the images.","title":"Containerized"},{"location":"general/Definitions/#contributordeveloper","text":"If you want to change, add to or at least build the existing EdgeX code base, then you are a \"Developer\". \"Contributors\" are developers that further wish to contribute their code back into the EdgeX open source effort.","title":"Contributor/Developer"},{"location":"general/Definitions/#created-time-stamp","text":"The Created time stamp is the time the data was created in the database and is unchangeable. The Origin time stamp is the time the data is created on the device, device services, sensor, or object that collected the data before the data was sent to EdgeX Foundry and the database. Usually, the Origin and Created time stamps are the same, or very close to being the same. On occasion the sensor may be a long way from the gateway or even in a different time zone, and the Origin and Created time stamps may be quite different. If persistence is disable in core-data, the time stamp will default to 0.","title":"Created time stamp"},{"location":"general/Definitions/#device","text":"In EdgeX parlance, \"device\" is used to refer to a sensor, actuator, or IoT \"thing\". A sensor generally collects information from the physical world - like a temperature or vibration sensor. Actuators are machines that can be told to do something. Actuators move or otherwise control a mechanism or system - like a value on a pump. While there may be some technical differences, for the purposes of EdgeX documentation, device will refer to a sensor, actuator or \"thing\".","title":"Device"},{"location":"general/Definitions/#edge-analytics","text":"The terms edge or local analytics (the terms are used interchangeably and have the same meaning in this context) for the purposes of edge computing (and EdgeX), refers to an \u201canalytics\u201d service is that: - Receives and interprets the EdgeX sensor data to some degree; some analytics services are more sophisticated and able to provide more insights than others - Make determinations on what actions and actuations need to occur based on the insights it has achieved, thereby driving actuation requests to EdgeX associated devices or other services (like notifications) The analytics service could be some simple logic built into an app service, a rules engine package, or an agent of some artificial intelligence/machine learning system. From an EdgeX perspective, actionable intelligence generation is all the same. From an EdgeX perspective, edge analytics = seeing the edge data and be able to make requests to act on what is seen. While EdgeX provides a rules engine service as its reference implementation of local analytics, app services and its data preparation capability allow sensor data to be streamed to any analytics package. Because of EdgeX\u2019s micro service architecture and distributed nature, the analytics service would not necessarily have to run local to the devices / sensors. In other words, it would not have to run at the edge. App services could deliver the edge data to analytics living in the cloud. However, in these scenarios, the insight intelligence would not be considered local or edge in context. Because of latency concerns, data security and privacy needs, intermittent connectivity of edge systems, and other reasons, it is often vital for edge platforms to retain an analytic capability at the edge or local.","title":"Edge Analytics"},{"location":"general/Definitions/#gateway","text":"An IoT gateway is a compute platform at the farthest ends of an edge or IoT network. It is the host or \u201cbox\u201d to which physical sensors and devices connect and that is, in turn, connected to the networks (wired or wirelessly) of the information technology realm. IoT or edge gateways are compute platforms that connect \u201cthings\u201d (sensors and devices) to IT networks and systems.","title":"Gateway"},{"location":"general/Definitions/#micro-service","text":"In a micro service architecture, each component has its own process. This is in contrast to a monolithic architecture in which all components of the application run in the same process. Benefits of micro service architectures include: - Allow any one service to be replaced and upgraded more easily - Allow services to be programmed using different programming languages and underlying technical solutions (use the best technology for each specific service) - Ex: services written in C can communicate and work with services written in Go - This allows organizations building solutions to maximize available developer resources and some legacy code - Allow services to be distributed across host compute platforms - allowing better utilization of available compute resources - Allow for more scalable solutions by adding copies of services when needed","title":"Micro service"},{"location":"general/Definitions/#origin-time-stamp","text":"The Origin time stamp is the time the data is created on the device, device services, sensor, or object that collected the data before the data is sent to EdgeX Foundry and the database. The Created time stamp is the time the data was created in the database. Usually, the Origin and Created time stamps are the same or very close to the same. On occasion the sensor may be a long way from the gateway or even in a different time zone, and the Origin and Created time stamps may be quite different.","title":"Origin time stamp"},{"location":"general/Definitions/#reference-implementation","text":"Default and example implementation(s) offered by the EdgeX community. Other implementations may be offered by 3rd parties or for specialization.","title":"Reference Implementation"},{"location":"general/Definitions/#rules-engine","text":"Rules engines are important to the IoT edge system. A rules engine is a software system that is connected to a collection of data (either database or data stream). The rules engine examines various elements of the data and monitors the data, and then triggers some action based on the results of the monitoring of the data it. A rules engine is a collection of \"If-Then\" conditional statements. The \"If\" informs the rules engine what data to look at and what ranges or values of data must match in order to trigger the \"Then\" part of the statement, which then informs the rules engine what action to take or what external resource to call on, when the data is a match to the \"If\" statement. Most rules engines can be dynamically programmed meaning that new \"If-Then\" statements or rules, can be provided while the engine is running. The rules are often defined by some type of rule language with simple syntax to enable non-Developers to provide the new rules. Rules engines are one of the simplest forms of \"edge analytics\" provided in IoT systems. Rules engines enable data picked up by IoT sensors to be monitored and acted upon (actuated). Typically, the actuation is accomplished on another IoT device or sensor. For example, a temperature sensor in an equipment enclosure may be monitored by a rules engine to detect when the temperature is getting too warm (or too cold) for safe or optimum operation of the equipment. The rules engine, upon detecting temperatures outside of the acceptable range, shuts off the equipment in the enclosure.","title":"Rules Engine"},{"location":"general/Definitions/#software-development-kit","text":"In EdgeX, a software development kit (or SDK) is a library or module to be incorporated into a new micro service. It provides a lot of the boilerplate code and scaffolding associated with the type of service being created. The SDK allows the developer to focus on the details of the service functionality and not have to worry about the mundane tasks associated with EdgeX services.","title":"Software Development Kit"},{"location":"general/Definitions/#south-and-north-side","text":"South Side: All IoT objects, within the physical realm, and the edge of the network that communicates directly with those devices, sensors, actuators, and other IoT objects, and collects the data from them, is known collectively as the \"south side.\" North Side: The cloud (or enterprise system) where data is collected, stored, aggregated, analyzed, and turned into information, and the part of the network that communicates with the cloud, is referred to as the \"north side\" of the network. EdgeX enables data to be sent \"north, \" \"south, \" or laterally as needed and as directed.","title":"South and North Side"},{"location":"general/Definitions/#snappy-ubuntu-core-snaps","text":"A Linux-based Operating System provided by Ubuntu - formally called Ubuntu Core but often referred to as \"Snappy\". The packages are called 'snaps' and the tool for using them 'snapd', and works for phone, cloud, internet of things, and desktop computers. The \"Snap\" packages are self-contained and have no dependency on external stores. \"Snaps\" can be used to create command line tools, background services, and desktop applications.","title":"\"Snappy\" / Ubuntu Core &amp; Snaps"},{"location":"general/Definitions/#user","text":"If you want to get the EdgeX platform and run it (but do not intend to change or add to the existing code base now) then you are considered a \"User\".","title":"User"},{"location":"general/PlatformRequirements/","text":"Platform Requirements EdgeX Foundry is an operating system (OS)-agnostic and hardware (HW)-agnostic IoT edge platform. At this time the following platform minimums are recommended: Memory Memory: minimum of 1 GB When considering memory for your EdgeX platform consider your use of database - Redis is the current default. Redis is an open source (BSD licensed), in-memory data structure store, used as a database and message broker in EdgeX. Redis is durable and uses persistence only for recovering state; the only data Redis operates on is in-memory. Redis uses a number of techniques to optimize memory utilization. Antirez and Redis Labs have written a number of articles on the underlying details (see list below). Those strategies has continued to evolve . When thinking about your system architecture, consider how long data will be living at the edge and consuming memory (physical or physical + virtual). Antirez Redis RAM Ramifications Redis IO Memory Optimization Storage Hard drive space: minimum of 3 GB of space to run the EdgeX Foundry containers, but you may want more depending on how long sensor and device data is to be retained. Approximately 32GB of storage is minimally recommended to start. Operating Systems EdgeX Foundry has been run successfully on many systems, including, but not limited to the following systems Windows (ver 7 - 10) Ubuntu Desktop (ver 14-20) Ubuntu Server (ver 14-20) Ubuntu Core (ver 16-18) Mac OS X 10 Info EdgeX is agnostic with regards to hardware (x86 and ARM), but only release artifacts for x86 and ARM 64 systems. EdgeX has been successfully run on ARM 32 platforms but has required users to build their own executable from source. EdgeX does not officially support ARM 32.","title":"Platform Requirements"},{"location":"general/PlatformRequirements/#platform-requirements","text":"EdgeX Foundry is an operating system (OS)-agnostic and hardware (HW)-agnostic IoT edge platform. At this time the following platform minimums are recommended: Memory Memory: minimum of 1 GB When considering memory for your EdgeX platform consider your use of database - Redis is the current default. Redis is an open source (BSD licensed), in-memory data structure store, used as a database and message broker in EdgeX. Redis is durable and uses persistence only for recovering state; the only data Redis operates on is in-memory. Redis uses a number of techniques to optimize memory utilization. Antirez and Redis Labs have written a number of articles on the underlying details (see list below). Those strategies has continued to evolve . When thinking about your system architecture, consider how long data will be living at the edge and consuming memory (physical or physical + virtual). Antirez Redis RAM Ramifications Redis IO Memory Optimization Storage Hard drive space: minimum of 3 GB of space to run the EdgeX Foundry containers, but you may want more depending on how long sensor and device data is to be retained. Approximately 32GB of storage is minimally recommended to start. Operating Systems EdgeX Foundry has been run successfully on many systems, including, but not limited to the following systems Windows (ver 7 - 10) Ubuntu Desktop (ver 14-20) Ubuntu Server (ver 14-20) Ubuntu Core (ver 16-18) Mac OS X 10 Info EdgeX is agnostic with regards to hardware (x86 and ARM), but only release artifacts for x86 and ARM 64 systems. EdgeX has been successfully run on ARM 32 platforms but has required users to build their own executable from source. EdgeX does not officially support ARM 32.","title":"Platform Requirements"},{"location":"general/ServiceConfiguration/","text":"Service Configuration Each EdgeX micro service requires configuration (i.e. - a repository of initialization and operating values). The configuration is initially provided by a TOML file but a service can utilize the centralized configuration management provided by EdgeX for its configuration. See the Configuration and Registry documentation for more details about initialization of services and the use of the configuration service. Please refer to the EdgeX Foundry architectural decision record for details (and design decisions) behind the configuration in EdgeX. Please refer to the general Configuration documentation for configuration properties common to all services. Find service specific configuration references in the tabs below. Core Service Name Configuration Reference core-data Core Data Configuration core-metadata Core Metadata Configuration core-command Core Command Configuration Supporting Service Name Configuration Reference support-notifications Support Notifications Configuration support-scheduler Support Scheduler Configuration Application & Analytics Services Name Configuration Reference app-service General Application Service Configuration app-service-configurable Configurable Application Service Configuration Kuiper rules engine/Kuiper Basic Kuiper Configuration Device Services Name Configuration Reference device-service General Device Service Configuration device-virtual Virtual Device Service Configuration Security Services Name Configuration Reference API Gateway Kong Configuration System Management Services Name Configuration Reference system management System Management Agent Configuration","title":"Service Configuration"},{"location":"general/ServiceConfiguration/#service-configuration","text":"Each EdgeX micro service requires configuration (i.e. - a repository of initialization and operating values). The configuration is initially provided by a TOML file but a service can utilize the centralized configuration management provided by EdgeX for its configuration. See the Configuration and Registry documentation for more details about initialization of services and the use of the configuration service. Please refer to the EdgeX Foundry architectural decision record for details (and design decisions) behind the configuration in EdgeX. Please refer to the general Configuration documentation for configuration properties common to all services. Find service specific configuration references in the tabs below. Core Service Name Configuration Reference core-data Core Data Configuration core-metadata Core Metadata Configuration core-command Core Command Configuration Supporting Service Name Configuration Reference support-notifications Support Notifications Configuration support-scheduler Support Scheduler Configuration Application & Analytics Services Name Configuration Reference app-service General Application Service Configuration app-service-configurable Configurable Application Service Configuration Kuiper rules engine/Kuiper Basic Kuiper Configuration Device Services Name Configuration Reference device-service General Device Service Configuration device-virtual Virtual Device Service Configuration Security Services Name Configuration Reference API Gateway Kong Configuration System Management Services Name Configuration Reference system management System Management Agent Configuration","title":"Service Configuration"},{"location":"general/ServicePorts/","text":"Default Service Ports The following tables (organized by type of service) capture the default service ports. These default ports are also used in the EdgeX provided service routes defined in the Kong API Gateway for access control. Core Services Name Port Definition core-data 48080 5563 core-metadata 48001 core-command 48082 Supporting Services Name Port Definition support-notifications 48060 support-logging 48061 support-scheduler 48085 Application & Analytics Services Name Port Definition app-service-rules 48095 rules engine/Kuiper 48075 20498 Device Services Name Port Definition device-virtual 49990 device-random 49988 device-mqtt 49982 device-rest 49986 device-modbus 49991 device-snmp 49993 Security Services Name Port Definition vault 8200 kong-db 5432 kong 8000 8001 8443 8444 Miscellaneous Services Name Port Definition consul 8400 8500 8600 mongo 27017 redis 6379 system management 48090","title":"Default Service Ports"},{"location":"general/ServicePorts/#default-service-ports","text":"The following tables (organized by type of service) capture the default service ports. These default ports are also used in the EdgeX provided service routes defined in the Kong API Gateway for access control. Core Services Name Port Definition core-data 48080 5563 core-metadata 48001 core-command 48082 Supporting Services Name Port Definition support-notifications 48060 support-logging 48061 support-scheduler 48085 Application & Analytics Services Name Port Definition app-service-rules 48095 rules engine/Kuiper 48075 20498 Device Services Name Port Definition device-virtual 49990 device-random 49988 device-mqtt 49982 device-rest 49986 device-modbus 49991 device-snmp 49993 Security Services Name Port Definition vault 8200 kong-db 5432 kong 8000 8001 8443 8444 Miscellaneous Services Name Port Definition consul 8400 8500 8600 mongo 27017 redis 6379 system management 48090","title":"Default Service Ports"},{"location":"getting-started/","text":"Getting Started To get started you need to get EdgeX Foundry either as a User or as a Developer/Contributor. User If you want to get the EdgeX platform and run it (but do not intend to change or add to the existing code base now) then you are considered a \"User\". You will want to follow the Getting Started Users guide. The Getting Started Users guide takes you through the process of getting the latest release EdgeX Docker Containers from Docker Hub. If you wish to get the latest EdgeX containers (those built from the current ongoing development efforts prior to release), then see Getting Started Users - Nexus . Warning Containers used from Nexus are considered \"work in progress\". There is no guarantee that these containers will function properly or function properly with other containers from the current release. Snap User As an alternative to Docker containers, users may wish to use Canonical's EdgeX Foundry 'snap'. Snap is a software deployment and package management system developed by Canonical for the Linux operating system. The packages, called snaps, and the tool for using them, snapd, work across a range of Linux distributions allowing distribution-agnostic upstream software packaging. The EdgeX snap is published by EdgeX Foundry and made available through the snap store . If you wish to get the latest EdgeX release snap, follow the Getting Started Snap Users guide. Developer and Contributor If you want to change, add to or at least build the existing EdgeX code base, then you are a \"Developer\". \"Contributors\" are developers that further wish to contribute their code back into the EdgeX open source effort. You will want to follow the Getting Started for Developers guide. Hybrid See Getting Started Hybrid if you are developing or working on a particular micro service, but want to run the other micro services via Docker Containers. When working on something like an analytics service (as a developer or contributor) you may not wish to download, build and run all the EdgeX code - you only want to work with the code of your service. Your new service may still need to communicate with other services while you test your new service. Unless you want to get and build all the services, developers will often get and run the containers for the other EdgeX micro services and run only their service natively in a development environment. The EdgeX community refers to this as \"Hybrid\" development. Device Service Developer As a developer, if you intend to connect IoT objects (device, sensor or other \"thing\") that are not currently connected to EdgeX Foundry, you may also want to obtain the Device Service Software Development Kit (DS SDK) and create new device services. The DS SDK creates all the scaffolding code for a new EdgeX Foundry device service; allowing you to focus on the details of interfacing with the device in its native protocol. See Getting Started with Device SDK for help on using the DS SDK to create a new device service. Learn more about Device Services and the Device Service SDK at Device Services . Application Service Developer As a developer, if you intend to get EdgeX sensor data to external systems (be that an enterprise application, on-prem server or Cloud platform like Azure IoT Hub, AWS IoT, Google Cloud IOT, etc.), you will likely want to obtain the Application Functions SDK (App Func SDK) and create new application services. The App Func SDK creates all the scaffolding code for a new EdgeX Foundry application service; allowing you to focus on the details of data transformation, filtering, and otherwise prepare the sensor data for the external endpoint. Learn more about Application Services and the Application Functions SDK at Application Services . Versioning Please refer to the EdgeX Foundry versioning policy for information on how EdgeX services are released and how EdgeX services are compatible with one another. Specifically, device services (and the associated SDK), application services (and the associated app functions SDK), and client tools (like the EdgeX CLI and UI) can have independent minor releases, but these services must be compatible with the latest major release of EdgeX. Long Term Support Please refer to the EdgeX Foundry LTS policy for information on support of EdgeX releases. The EdgeX community does not offer support on any non-LTS release outside of the latest release.","title":"Getting Started"},{"location":"getting-started/#getting-started","text":"To get started you need to get EdgeX Foundry either as a User or as a Developer/Contributor.","title":"Getting Started"},{"location":"getting-started/#user","text":"If you want to get the EdgeX platform and run it (but do not intend to change or add to the existing code base now) then you are considered a \"User\". You will want to follow the Getting Started Users guide. The Getting Started Users guide takes you through the process of getting the latest release EdgeX Docker Containers from Docker Hub. If you wish to get the latest EdgeX containers (those built from the current ongoing development efforts prior to release), then see Getting Started Users - Nexus . Warning Containers used from Nexus are considered \"work in progress\". There is no guarantee that these containers will function properly or function properly with other containers from the current release.","title":"User"},{"location":"getting-started/#snap-user","text":"As an alternative to Docker containers, users may wish to use Canonical's EdgeX Foundry 'snap'. Snap is a software deployment and package management system developed by Canonical for the Linux operating system. The packages, called snaps, and the tool for using them, snapd, work across a range of Linux distributions allowing distribution-agnostic upstream software packaging. The EdgeX snap is published by EdgeX Foundry and made available through the snap store . If you wish to get the latest EdgeX release snap, follow the Getting Started Snap Users guide.","title":"Snap User"},{"location":"getting-started/#developer-and-contributor","text":"If you want to change, add to or at least build the existing EdgeX code base, then you are a \"Developer\". \"Contributors\" are developers that further wish to contribute their code back into the EdgeX open source effort. You will want to follow the Getting Started for Developers guide.","title":"Developer and Contributor"},{"location":"getting-started/#hybrid","text":"See Getting Started Hybrid if you are developing or working on a particular micro service, but want to run the other micro services via Docker Containers. When working on something like an analytics service (as a developer or contributor) you may not wish to download, build and run all the EdgeX code - you only want to work with the code of your service. Your new service may still need to communicate with other services while you test your new service. Unless you want to get and build all the services, developers will often get and run the containers for the other EdgeX micro services and run only their service natively in a development environment. The EdgeX community refers to this as \"Hybrid\" development.","title":"Hybrid"},{"location":"getting-started/#device-service-developer","text":"As a developer, if you intend to connect IoT objects (device, sensor or other \"thing\") that are not currently connected to EdgeX Foundry, you may also want to obtain the Device Service Software Development Kit (DS SDK) and create new device services. The DS SDK creates all the scaffolding code for a new EdgeX Foundry device service; allowing you to focus on the details of interfacing with the device in its native protocol. See Getting Started with Device SDK for help on using the DS SDK to create a new device service. Learn more about Device Services and the Device Service SDK at Device Services .","title":"Device Service Developer"},{"location":"getting-started/#application-service-developer","text":"As a developer, if you intend to get EdgeX sensor data to external systems (be that an enterprise application, on-prem server or Cloud platform like Azure IoT Hub, AWS IoT, Google Cloud IOT, etc.), you will likely want to obtain the Application Functions SDK (App Func SDK) and create new application services. The App Func SDK creates all the scaffolding code for a new EdgeX Foundry application service; allowing you to focus on the details of data transformation, filtering, and otherwise prepare the sensor data for the external endpoint. Learn more about Application Services and the Application Functions SDK at Application Services .","title":"Application Service Developer"},{"location":"getting-started/#versioning","text":"Please refer to the EdgeX Foundry versioning policy for information on how EdgeX services are released and how EdgeX services are compatible with one another. Specifically, device services (and the associated SDK), application services (and the associated app functions SDK), and client tools (like the EdgeX CLI and UI) can have independent minor releases, but these services must be compatible with the latest major release of EdgeX.","title":"Versioning"},{"location":"getting-started/#long-term-support","text":"Please refer to the EdgeX Foundry LTS policy for information on support of EdgeX releases. The EdgeX community does not offer support on any non-LTS release outside of the latest release.","title":"Long Term Support"},{"location":"getting-started/ApplicationFunctionsSDK/","text":"Getting Started The Application Functions SDK The SDK is built around the idea of a \"Functions Pipeline\". A functions pipeline is a collection of various functions that process the data in the order that you've specified. The functions pipeline is executed by the specified trigger in the configuration.toml . The first function in the pipeline is called with the event that triggered the pipeline (ex. events.Model ). Each successive call in the pipeline is called with the return result of the previous function. Let's take a look at a simple example that creates a pipeline to filter particular device ids and subsequently transform the data to XML: package main import ( \"fmt\" \"github.com/edgexfoundry/app-functions-sdk-go/appsdk\" \"github.com/edgexfoundry/app-functions-sdk-go/pkg/transforms\" \"os\" ) func main () { // 1) First thing to do is to create an instance of the EdgeX SDK, giving it a service key edgexSdk := & appsdk . AppFunctionsSDK { ServiceKey : \"SimpleFilterXMLApp\" , // Key used by Registry (Aka Consul) } // 2) Next, we need to initialize the SDK if err := edgexSdk . Initialize (); err != nil { message := fmt . Sprintf ( \"SDK initialization failed: %v\\n\" , err ) if edgexSdk . LoggingClient != nil { edgexSdk . LoggingClient . Error ( message ) } else { fmt . Println ( message ) } os . Exit ( - 1 ) } // 3) Shows how to access the application's specific configuration settings. deviceNames , err := edgexSdk . GetAppSettingStrings ( \"DeviceNames\" ) if err != nil { edgexSdk . LoggingClient . Error ( err . Error ()) os . Exit ( - 1 ) } // 4) This is our pipeline configuration, the collection of functions to // execute every time an event is triggered. if err = edgexSdk . SetFunctionsPipeline ( transforms . NewFilter ( deviceNames ). FilterByDeviceName , transforms . NewConversion (). TransformToXML , ); err != nil { edgexSdk . LoggingClient . Error ( fmt . Sprintf ( \"SDK SetPipeline failed: %v\\n\" , err )) os . Exit ( - 1 ) } // 5) Lastly, we'll go ahead and tell the SDK to \"start\" and begin listening for events to trigger the pipeline. err = edgexSdk . MakeItRun () if err != nil { edgexSdk . LoggingClient . Error ( \"MakeItRun returned error: \" , err . Error ()) os . Exit ( - 1 ) } // Do any required cleanup here os . Exit ( 0 ) } The above example is meant to merely demonstrate the structure of your application. Notice that the output of the last function is not available anywhere inside this application. You must provide a function in order to work with the data from the previous function. Let's go ahead and add the following function that prints the output to the console. func printXMLToConsole ( edgexcontext * appcontext . Context , params ... interface {}) ( bool , interface {}) { if len ( params ) < 1 { // We didn't receive a result return false , errors . New ( \"No Data Received\" ) } println ( params [ 0 ].( string )) return true , nil } After placing the above function in your code, the next step is to modify the pipeline to call this function: Note You can find this example called \"Simple Filter XML\" and more located in the examples section. Up until this point, the pipeline has been triggered by an event over HTTP and the data at the end of that pipeline lands in the last function specified. In the example, data ends up printed to the console. Perhaps we'd like to send the data back to where it came from. In the case of an HTTP trigger, this would be the HTTP response. In the case of a message bus, this could be a new topic to send the data back to for other applications that wish to receive it. To do this, simply call edgexcontext.Complete([]byte outputData) passing in the data you wish to \"respond\" with. In the above printXMLToConsole(...) function, replace println(params[0].(string)) with edgexcontext.Complete([]byte(params[0].(string))) . You should now see the response in your postman window when testing the pipeline.","title":"Application Functions SDK"},{"location":"getting-started/ApplicationFunctionsSDK/#getting-started","text":"","title":"Getting Started"},{"location":"getting-started/ApplicationFunctionsSDK/#the-application-functions-sdk","text":"The SDK is built around the idea of a \"Functions Pipeline\". A functions pipeline is a collection of various functions that process the data in the order that you've specified. The functions pipeline is executed by the specified trigger in the configuration.toml . The first function in the pipeline is called with the event that triggered the pipeline (ex. events.Model ). Each successive call in the pipeline is called with the return result of the previous function. Let's take a look at a simple example that creates a pipeline to filter particular device ids and subsequently transform the data to XML: package main import ( \"fmt\" \"github.com/edgexfoundry/app-functions-sdk-go/appsdk\" \"github.com/edgexfoundry/app-functions-sdk-go/pkg/transforms\" \"os\" ) func main () { // 1) First thing to do is to create an instance of the EdgeX SDK, giving it a service key edgexSdk := & appsdk . AppFunctionsSDK { ServiceKey : \"SimpleFilterXMLApp\" , // Key used by Registry (Aka Consul) } // 2) Next, we need to initialize the SDK if err := edgexSdk . Initialize (); err != nil { message := fmt . Sprintf ( \"SDK initialization failed: %v\\n\" , err ) if edgexSdk . LoggingClient != nil { edgexSdk . LoggingClient . Error ( message ) } else { fmt . Println ( message ) } os . Exit ( - 1 ) } // 3) Shows how to access the application's specific configuration settings. deviceNames , err := edgexSdk . GetAppSettingStrings ( \"DeviceNames\" ) if err != nil { edgexSdk . LoggingClient . Error ( err . Error ()) os . Exit ( - 1 ) } // 4) This is our pipeline configuration, the collection of functions to // execute every time an event is triggered. if err = edgexSdk . SetFunctionsPipeline ( transforms . NewFilter ( deviceNames ). FilterByDeviceName , transforms . NewConversion (). TransformToXML , ); err != nil { edgexSdk . LoggingClient . Error ( fmt . Sprintf ( \"SDK SetPipeline failed: %v\\n\" , err )) os . Exit ( - 1 ) } // 5) Lastly, we'll go ahead and tell the SDK to \"start\" and begin listening for events to trigger the pipeline. err = edgexSdk . MakeItRun () if err != nil { edgexSdk . LoggingClient . Error ( \"MakeItRun returned error: \" , err . Error ()) os . Exit ( - 1 ) } // Do any required cleanup here os . Exit ( 0 ) } The above example is meant to merely demonstrate the structure of your application. Notice that the output of the last function is not available anywhere inside this application. You must provide a function in order to work with the data from the previous function. Let's go ahead and add the following function that prints the output to the console. func printXMLToConsole ( edgexcontext * appcontext . Context , params ... interface {}) ( bool , interface {}) { if len ( params ) < 1 { // We didn't receive a result return false , errors . New ( \"No Data Received\" ) } println ( params [ 0 ].( string )) return true , nil } After placing the above function in your code, the next step is to modify the pipeline to call this function: Note You can find this example called \"Simple Filter XML\" and more located in the examples section. Up until this point, the pipeline has been triggered by an event over HTTP and the data at the end of that pipeline lands in the last function specified. In the example, data ends up printed to the console. Perhaps we'd like to send the data back to where it came from. In the case of an HTTP trigger, this would be the HTTP response. In the case of a message bus, this could be a new topic to send the data back to for other applications that wish to receive it. To do this, simply call edgexcontext.Complete([]byte outputData) passing in the data you wish to \"respond\" with. In the above printXMLToConsole(...) function, replace println(params[0].(string)) with edgexcontext.Complete([]byte(params[0].(string))) . You should now see the response in your postman window when testing the pipeline.","title":"The Application Functions SDK"},{"location":"getting-started/Ch-GettingStartedCDevelopers/","text":"Getting Started - C Developers Introduction These instructions are for C Developers and Contributors to get, run and otherwise work with C-based EdgeX Foundry micro services. Before reading this guide, review the general developer requirements . If you want to get the EdgeX platform and run it (but do not intend to change or add to the existing code base now) then you are considered a \"User\". Users should read: Getting Started Users ) What You Need For C Development Many of EdgeX device services are built in C. In the future, other services could be built in C. In additional to the hardware and software listed in the Developers guide , to build EdgeX C services, you will need the following: libmicrohttpd libcurl libyaml libcbor You can install these on Ubuntu by running: sudo apt-get install libcurl4-openssl-dev libmicrohttpd-dev libyaml-dev libcbor-dev CMake is required to build the SDKs. Version 3 or better is required. You can install CMAKE on Ubuntu by running: sudo apt install cmake Check that your C development environment includes the following: a version of GCC supporting C11 CMake version 3 or greater Development libraries and headers for: curl (version 7.32 or later) microhttpd (version 0.9) libyaml (version 0.1.6 or later) libcbor (version 0.5) libuuid (from util-linux v2.x) Next Steps To explore how to create and build EdgeX device services in C, head to the Device Services, C SDK guide .","title":"Getting Started - C Developers"},{"location":"getting-started/Ch-GettingStartedCDevelopers/#getting-started-c-developers","text":"","title":"Getting Started - C Developers"},{"location":"getting-started/Ch-GettingStartedCDevelopers/#introduction","text":"These instructions are for C Developers and Contributors to get, run and otherwise work with C-based EdgeX Foundry micro services. Before reading this guide, review the general developer requirements . If you want to get the EdgeX platform and run it (but do not intend to change or add to the existing code base now) then you are considered a \"User\". Users should read: Getting Started Users )","title":"Introduction"},{"location":"getting-started/Ch-GettingStartedCDevelopers/#what-you-need-for-c-development","text":"Many of EdgeX device services are built in C. In the future, other services could be built in C. In additional to the hardware and software listed in the Developers guide , to build EdgeX C services, you will need the following: libmicrohttpd libcurl libyaml libcbor You can install these on Ubuntu by running: sudo apt-get install libcurl4-openssl-dev libmicrohttpd-dev libyaml-dev libcbor-dev CMake is required to build the SDKs. Version 3 or better is required. You can install CMAKE on Ubuntu by running: sudo apt install cmake Check that your C development environment includes the following: a version of GCC supporting C11 CMake version 3 or greater Development libraries and headers for: curl (version 7.32 or later) microhttpd (version 0.9) libyaml (version 0.1.6 or later) libcbor (version 0.5) libuuid (from util-linux v2.x)","title":"What You Need For C Development"},{"location":"getting-started/Ch-GettingStartedCDevelopers/#next-steps","text":"To explore how to create and build EdgeX device services in C, head to the Device Services, C SDK guide .","title":"Next Steps"},{"location":"getting-started/Ch-GettingStartedDevelopers/","text":"Getting Started - Developers Introduction These instructions are for Developers and Contributors to get and run EdgeX Foundry. If you want to get the EdgeX platform and run it (but do not intend to change or add to the existing code base now) then you are considered a \"User\". Users should read: Getting Started Users ) EdgeX is a collection of more than a dozen micro services that are deployed to provide a minimal edge platform capability. EdgeX consists of a collection of reference implementation services and SDK tools. The micro services and SDKs are written in Go or C. These documentation pages provide a developer with the information and instructions to get and run EdgeX Foundry in development mode - that is running natively outside of containers and with the intent of adding to or changing the existing code base. What You Need Hardware EdgeX Foundry is an operating system (OS) and hardware (HW)-agnostic edge software platform. See the reference page for platform requirements . These provide guidance on a minimal platform to run the EdgeX platform. However, as a developer, you may find that additional memory, disk space, and improved CPU are essential to building and debugging. Software Developers need to install the following software to get, run and develop EdgeX Foundry micro services: Git Use this free and open source version control (SVC) system to download (and upload) the EdgeX Foundry source code from the project's GitHub repositories. See https://git-scm.com/downloads for download and install instructions. Alternative tools (Easy Git for example) could be used, but this document assumes use of git and leaves how to use alternative SVC tools to the reader. Redis By default, EdgeX Foundry uses Redis (version 5 starting with the Geneva release) as the persistence mechanism for sensor data as well as metadata about the devices/sensors that are connected. See https://redis.io/ for download and installation instructions. MongoDB As an alternative, EdgeX Foundry allows use of MongoDB (version 4.2 as of Geneva) as the alternative persistence mechanism in place of Redis for sensor data as well as metadata about the connected devices/sensors. See https://www.mongodb.com/download-center?jmp=nav#community for download and installation instructions. Warning Use of MongoDB is deprecated with the Geneva release. EdgeX will remove MongoDB support in a future release. Developers should start to migrate to Redis in all development efforts targeting future EdgeX releases. ZeroMQ Several EdgeX Foundry services depend on ZeroMQ for communications by default. See the installation for your OS. Linux/Unix The easiest way to get and install ZeroMQ on Linux is to use this setup script: https://gist.github.com/katopz/8b766a5cb0ca96c816658e9407e83d00 . Note The 0MQ install script above assumes bash is available on your system and the bash executable is in /usr/bin. Before running the script at the link, run which bash at your Linux terminal to insure that bash is in /usr/bin. If not, change the first line of the script so that it points to the correct location of bash. MacOS For MacOS, use brew to install ZeroMQ. brew install zeromq Windows For directions installing ZeroMQ on Windows, please see the Windows documentation: https://github.com/edgexfoundry/edgex-go/blob/master/ZMQWindows.md Docker (Optional) If you intend to create Docker images for your updated or newly created EdgeX services, you need to install Docker. See https://docs.docker.com/install/ to learn how to install Docker. If you are new to Docker, the same web site provides you educational information. Additional Programming Tools and Next Steps Depending on which part of EdgeX you work on, you need to install one or more programming languages (Go Lang, Gnu C, etc.) and associated tooling. These tools are covered under the documentation specific to each type of development. Go Lang C Versioning Please refer to the EdgeX Foundry versioning policy for information on how EdgeX services are released and how EdgeX services are compatible with one another. Specifically, device services (and the associated SDK), application services (and the associated app functions SDK), and client tools (like the EdgeX CLI and UI) can have independent minor releases, but these services must be compatible with the latest major release of EdgeX. Long Term Support Please refer to the EdgeX Foundry LTS policy for information on support of EdgeX releases. The EdgeX community does not offer support on any non-LTS release outside of the latest release.","title":"Getting Started - Developers"},{"location":"getting-started/Ch-GettingStartedDevelopers/#getting-started-developers","text":"","title":"Getting Started - Developers"},{"location":"getting-started/Ch-GettingStartedDevelopers/#introduction","text":"These instructions are for Developers and Contributors to get and run EdgeX Foundry. If you want to get the EdgeX platform and run it (but do not intend to change or add to the existing code base now) then you are considered a \"User\". Users should read: Getting Started Users ) EdgeX is a collection of more than a dozen micro services that are deployed to provide a minimal edge platform capability. EdgeX consists of a collection of reference implementation services and SDK tools. The micro services and SDKs are written in Go or C. These documentation pages provide a developer with the information and instructions to get and run EdgeX Foundry in development mode - that is running natively outside of containers and with the intent of adding to or changing the existing code base.","title":"Introduction"},{"location":"getting-started/Ch-GettingStartedDevelopers/#what-you-need","text":"","title":"What You Need"},{"location":"getting-started/Ch-GettingStartedDevelopers/#hardware","text":"EdgeX Foundry is an operating system (OS) and hardware (HW)-agnostic edge software platform. See the reference page for platform requirements . These provide guidance on a minimal platform to run the EdgeX platform. However, as a developer, you may find that additional memory, disk space, and improved CPU are essential to building and debugging.","title":"Hardware"},{"location":"getting-started/Ch-GettingStartedDevelopers/#software","text":"Developers need to install the following software to get, run and develop EdgeX Foundry micro services:","title":"Software"},{"location":"getting-started/Ch-GettingStartedDevelopers/#git","text":"Use this free and open source version control (SVC) system to download (and upload) the EdgeX Foundry source code from the project's GitHub repositories. See https://git-scm.com/downloads for download and install instructions. Alternative tools (Easy Git for example) could be used, but this document assumes use of git and leaves how to use alternative SVC tools to the reader.","title":"Git"},{"location":"getting-started/Ch-GettingStartedDevelopers/#redis","text":"By default, EdgeX Foundry uses Redis (version 5 starting with the Geneva release) as the persistence mechanism for sensor data as well as metadata about the devices/sensors that are connected. See https://redis.io/ for download and installation instructions.","title":"Redis"},{"location":"getting-started/Ch-GettingStartedDevelopers/#mongodb","text":"As an alternative, EdgeX Foundry allows use of MongoDB (version 4.2 as of Geneva) as the alternative persistence mechanism in place of Redis for sensor data as well as metadata about the connected devices/sensors. See https://www.mongodb.com/download-center?jmp=nav#community for download and installation instructions. Warning Use of MongoDB is deprecated with the Geneva release. EdgeX will remove MongoDB support in a future release. Developers should start to migrate to Redis in all development efforts targeting future EdgeX releases.","title":"MongoDB"},{"location":"getting-started/Ch-GettingStartedDevelopers/#zeromq","text":"Several EdgeX Foundry services depend on ZeroMQ for communications by default. See the installation for your OS. Linux/Unix The easiest way to get and install ZeroMQ on Linux is to use this setup script: https://gist.github.com/katopz/8b766a5cb0ca96c816658e9407e83d00 . Note The 0MQ install script above assumes bash is available on your system and the bash executable is in /usr/bin. Before running the script at the link, run which bash at your Linux terminal to insure that bash is in /usr/bin. If not, change the first line of the script so that it points to the correct location of bash. MacOS For MacOS, use brew to install ZeroMQ. brew install zeromq Windows For directions installing ZeroMQ on Windows, please see the Windows documentation: https://github.com/edgexfoundry/edgex-go/blob/master/ZMQWindows.md","title":"ZeroMQ"},{"location":"getting-started/Ch-GettingStartedDevelopers/#docker-optional","text":"If you intend to create Docker images for your updated or newly created EdgeX services, you need to install Docker. See https://docs.docker.com/install/ to learn how to install Docker. If you are new to Docker, the same web site provides you educational information.","title":"Docker (Optional)"},{"location":"getting-started/Ch-GettingStartedDevelopers/#additional-programming-tools-and-next-steps","text":"Depending on which part of EdgeX you work on, you need to install one or more programming languages (Go Lang, Gnu C, etc.) and associated tooling. These tools are covered under the documentation specific to each type of development. Go Lang C","title":"Additional Programming Tools and Next Steps"},{"location":"getting-started/Ch-GettingStartedDevelopers/#versioning","text":"Please refer to the EdgeX Foundry versioning policy for information on how EdgeX services are released and how EdgeX services are compatible with one another. Specifically, device services (and the associated SDK), application services (and the associated app functions SDK), and client tools (like the EdgeX CLI and UI) can have independent minor releases, but these services must be compatible with the latest major release of EdgeX.","title":"Versioning"},{"location":"getting-started/Ch-GettingStartedDevelopers/#long-term-support","text":"Please refer to the EdgeX Foundry LTS policy for information on support of EdgeX releases. The EdgeX community does not offer support on any non-LTS release outside of the latest release.","title":"Long Term Support"},{"location":"getting-started/Ch-GettingStartedGoDevelopers/","text":"Getting Started - Go Developers Introduction These instructions are for Go Lang Developers and Contributors to get, run and otherwise work with Go-based EdgeX Foundry micro services. Before reading this guide, review the general developer requirements . If you want to get the EdgeX platform and run it (but do not intend to change or add to the existing code base now) then you are considered a \"User\". Users should read: Getting Started Users ) What You Need For Go Development In additional to the hardware and software listed in the Developers guide , you will need the following to work with the EdgeX Go-based micro services. Go The open sourced micro services of EdgeX Foundry are written in Go 1.15. See https://golang.org/dl/ for download and installation instructions. Newer versions of Go are available and may work, but the project has not built and tested to these newer versions of the language. Older versions of Go, especially 1.10 or older, are likely to cause issues (EdgeX now uses Go Modules which were introduced with Go Lang 1.11). Build Essentials In order to compile and build some elements of EdgeX, Gnu C compiler, utilities (like make), and associated librarires need to be installed. Some IDEs may already come with these tools. Some OS environments may already come with these tools. Others environments may require you install them. For Ubuntu environments, you can install a convenience package called Build Essentials . Note If you are installing Build Essentials, note that there is a build-essential pacakge for each Ubuntu release. Search for 'build-essential' associated to your Ubuntu version via Ubuntu Packages Search . IDE (Optional) There are many tool options for writing and editing Go Lang code. You could use a simple text editor. For more convenience, you may choose to use an integrated development environment (IDE). The list below highlights IDEs used by some of the EdgeX community (without any project endorsement). GoLand GoLand is a popular, although subscription-fee based, Go specific IDE. Learn how to purchase and download Go Land here: https://www.jetbrains.com/go/ . Visual Studio Code Visual Studio Code is a free, open source IDE developed by Microsoft. Find and download Visual Studio Code here: https://code.visualstudio.com/ . Atom Atom is also a free, open source IDE used with many languages. Find and download Atom here: https://ide.atom.io/ . Get the code This part of the documentation assumes you wish to get and work with the key EdgeX services. This includes but is not limited to Core, Supporting, some security, and system management services. To work with other Go-based security services, device services, application services, SDKs, user interface, or other service you may need to pull in other EdgeX repository code. See other getting started guides for working with other Go-based services. As you will see below, you do not need to explicitly pull in dependency modules (whether EdgeX or 3rd party provided). Dependencies will automatically be pulled through the building process. To work with the key services, you will need to download the source code from the EdgeX Go repository. The EdgeX Go-based micro services are all available in a single GitHub repository download. Once the code is pulled, the Go micro services are built and packaged as platform dependent executables. If Docker is installed, the executable can also be containerized for end user deployment/use. The EdgeX Foundry Go Lang micro service code is hosted at https://github.com/edgexfoundry/edgex-go . To download the EdgeX Go code, first change directories to the location where you want to download the code (to edgex in the image below). Then use your git tool and request to clone this repository with the following command: git clone <https://github.com/edgexfoundry/edgex-go.git> Note If you plan to contribute code back to the EdgeX project (as a Contributor), you are going to want to fork the repositories you plan to work with and then pull your fork versus the EdgeX repositories directly. This documentation does not address the process and procedures for working with an EdgeX fork, committing changes and submitting contribution pull requests (PRs). See some of the links below in the EdgeX Wiki for help on how to fork and contribute EdgeX code. https://wiki.edgexfoundry.org/display/FA/Contributor%27s+Guide https://wiki.edgexfoundry.org/display/FA/Contributor%27s+Guide+-+Go+Lang https://wiki.edgexfoundry.org/display/FA/Contributor+Process?searchId=AW768BAW7 Build EdgeX Foundry To build the Go Lang services found in edgex-go, first change directories to the root of the edgex-go code cd edgex-go Second, use the community provided Makefile to build all the services in a single call make build Info The first time EdgeX builds, it will take longer than other builds as it has to download all dependencies. Depending on the size of your host machine, an initial build can take several minutes. Make sure the build completes and has no errors. If it does build, you should find new service executables in each of the service folders under the service directories found in the /edgex-go/cmd folder. Run EdgeX Foundry Run the Database Several of the EdgeX Foundry micro services use a database. This includes core-data, core-metadata, support-scheduler, among others. Therefore, when working with EdgeX Foundry its a good idea to have the database up and running as a general rule. See the Redis Quick Start Guide for how to run Redis in a Linux environment (or find similar documentation for other environments). Note MongoDB can run in place of Redis with the Geneva release or earlier. MongoDB is deprecated and developers should transition to Redis. See the Run MongoDB documenation for how to run Mongo in a Linux environment (or find similar documentation for other environments). Running MongoDB in place of Redis will also require that you alter the configuration for all services that need the database to use MongoDB instead of Redis. As an example, the configuration of core-data is located in the file edgex-go/cmd/core-data/res/configuration.toml. In the configuration.toml file of the affected services, find the [Databases] section and change the \"Type\" to 'mongodb' along with any associated connection information similar to that shown below Host = 'localhost' Name = 'coredata' Password = 'password' Port = 27017 Username = 'core' Timeout = 5000 Type = 'mongodb' Run EdgeX Services With the services built, and the database up and running, you can now run all the services via second make command. Simply call make run This will start the EdgeX go services and leave them running until you terminate the process (with Ctrl-C). The log entries from each service will start to display in the terminal. Watch the log entries for any ERROR indicators. While the EdgeX services are running you can make EdgeX API calls to localhost . Note Use the ampersand ('&') sign at the end of make run if you wish to run the services in the background in detached mode. In so doing, Ctrl-C will not stop the services. You will have to kill the services by other means. Info No sensor data will flow yet as this just gets the key services up and running. To get sensor data flowing into EdgeX, you will need to get, build and run an EdgeX device service in a similar fashion. The community provides a virtual device service to test and experiment with ( https://github.com/edgexfoundry/device-virtual-go ). Verify EdgeX is Working Each EdgeX micro service has a built-in respond to a \"ping\" HTTP request. In networking environments, use a ping request to check the reach-ability of a network resource. EdgeX uses the same concept to check the availability or reach-ability of a micro service. After the EdgeX micro services are running, you can \"ping\" any one of the micro services to check that it is running. Open a browser or HTTP REST client tool and use the service's ping address (outlined below) to check that is available. http://localhost:[port]/api/v1/ping See EdgeX Default Service Ports for a list of the EdgeX default service ports. \"Pinging\" an EdgeX micro service allows you to check on its availability. If the service does not respond to ping, the service is down or having issues. Next Steps Application services and some device services are also built in Go. To explore how to create and build EdgeX application and devices services in Go, head to SDK documentation covering these EdgeX elements. Application Services and the Application Functions SDK Device Services in Go EdgeX Foundry in GoLand IDEs offer many code editing conveniences. Go Land was specifically built to edit and work with Go code. So if you are doing any significant code work with the EdgeX Go micro services, you will likely find it convenient to edit, build, run, test, etc. from GoLand or other IDE. Import EdgeX To bring in the EdgeX repository code into Go Land, use the File \u2192 Open... menu option in Go Land to open the Open File or Project Window. In the \"Open File or Project\" popup, select the location of the folder containing your cloned edgex-go repo. Open the Terminal From the View menu in Go Land, select the Terminal menu option. This will open a command terminal from which you can issue commands to install the dependencies, build the micro services, run the micro services, etc. Build the EdgeX Micro Services Run \"make build\" in the Terminal view (as shown below) to build the services. This can take a few minutes to build all the services. Warning In some cases, Go Land IDE may encounter an error (go: parsing \\$GOFLAGS: non-flag \"\"-X\") when building as shown below. If you encounter this issue, unset the GOFLAGS env var in GoLand. Make a call to unset GOFLAGS as shown below and then call make build again. Just as when running make build from the command line in a terminal, the micro service executables that get built in Go Land's terminal will be created in each of the service folders under the service directories found in the /edgex-go/cmd folder.. Run EdgeX With all the micro services built, you can now run EdgeX. You may first want to make sure the database is running. Then issue the command make run in the terminal. You can now call on the service APIs to make sure they are running correctly. Namely, call on localhost:[service port]/api/v1/ping to see each service respond to the simplest of requests.","title":"Getting Started - Go Developers"},{"location":"getting-started/Ch-GettingStartedGoDevelopers/#getting-started-go-developers","text":"","title":"Getting Started - Go Developers"},{"location":"getting-started/Ch-GettingStartedGoDevelopers/#introduction","text":"These instructions are for Go Lang Developers and Contributors to get, run and otherwise work with Go-based EdgeX Foundry micro services. Before reading this guide, review the general developer requirements . If you want to get the EdgeX platform and run it (but do not intend to change or add to the existing code base now) then you are considered a \"User\". Users should read: Getting Started Users )","title":"Introduction"},{"location":"getting-started/Ch-GettingStartedGoDevelopers/#what-you-need-for-go-development","text":"In additional to the hardware and software listed in the Developers guide , you will need the following to work with the EdgeX Go-based micro services.","title":"What You Need For Go Development"},{"location":"getting-started/Ch-GettingStartedGoDevelopers/#go","text":"The open sourced micro services of EdgeX Foundry are written in Go 1.15. See https://golang.org/dl/ for download and installation instructions. Newer versions of Go are available and may work, but the project has not built and tested to these newer versions of the language. Older versions of Go, especially 1.10 or older, are likely to cause issues (EdgeX now uses Go Modules which were introduced with Go Lang 1.11).","title":"Go"},{"location":"getting-started/Ch-GettingStartedGoDevelopers/#build-essentials","text":"In order to compile and build some elements of EdgeX, Gnu C compiler, utilities (like make), and associated librarires need to be installed. Some IDEs may already come with these tools. Some OS environments may already come with these tools. Others environments may require you install them. For Ubuntu environments, you can install a convenience package called Build Essentials . Note If you are installing Build Essentials, note that there is a build-essential pacakge for each Ubuntu release. Search for 'build-essential' associated to your Ubuntu version via Ubuntu Packages Search .","title":"Build Essentials"},{"location":"getting-started/Ch-GettingStartedGoDevelopers/#ide-optional","text":"There are many tool options for writing and editing Go Lang code. You could use a simple text editor. For more convenience, you may choose to use an integrated development environment (IDE). The list below highlights IDEs used by some of the EdgeX community (without any project endorsement).","title":"IDE (Optional)"},{"location":"getting-started/Ch-GettingStartedGoDevelopers/#goland","text":"GoLand is a popular, although subscription-fee based, Go specific IDE. Learn how to purchase and download Go Land here: https://www.jetbrains.com/go/ .","title":"GoLand"},{"location":"getting-started/Ch-GettingStartedGoDevelopers/#visual-studio-code","text":"Visual Studio Code is a free, open source IDE developed by Microsoft. Find and download Visual Studio Code here: https://code.visualstudio.com/ .","title":"Visual Studio Code"},{"location":"getting-started/Ch-GettingStartedGoDevelopers/#atom","text":"Atom is also a free, open source IDE used with many languages. Find and download Atom here: https://ide.atom.io/ .","title":"Atom"},{"location":"getting-started/Ch-GettingStartedGoDevelopers/#get-the-code","text":"This part of the documentation assumes you wish to get and work with the key EdgeX services. This includes but is not limited to Core, Supporting, some security, and system management services. To work with other Go-based security services, device services, application services, SDKs, user interface, or other service you may need to pull in other EdgeX repository code. See other getting started guides for working with other Go-based services. As you will see below, you do not need to explicitly pull in dependency modules (whether EdgeX or 3rd party provided). Dependencies will automatically be pulled through the building process. To work with the key services, you will need to download the source code from the EdgeX Go repository. The EdgeX Go-based micro services are all available in a single GitHub repository download. Once the code is pulled, the Go micro services are built and packaged as platform dependent executables. If Docker is installed, the executable can also be containerized for end user deployment/use. The EdgeX Foundry Go Lang micro service code is hosted at https://github.com/edgexfoundry/edgex-go . To download the EdgeX Go code, first change directories to the location where you want to download the code (to edgex in the image below). Then use your git tool and request to clone this repository with the following command: git clone <https://github.com/edgexfoundry/edgex-go.git> Note If you plan to contribute code back to the EdgeX project (as a Contributor), you are going to want to fork the repositories you plan to work with and then pull your fork versus the EdgeX repositories directly. This documentation does not address the process and procedures for working with an EdgeX fork, committing changes and submitting contribution pull requests (PRs). See some of the links below in the EdgeX Wiki for help on how to fork and contribute EdgeX code. https://wiki.edgexfoundry.org/display/FA/Contributor%27s+Guide https://wiki.edgexfoundry.org/display/FA/Contributor%27s+Guide+-+Go+Lang https://wiki.edgexfoundry.org/display/FA/Contributor+Process?searchId=AW768BAW7","title":"Get the code"},{"location":"getting-started/Ch-GettingStartedGoDevelopers/#build-edgex-foundry","text":"To build the Go Lang services found in edgex-go, first change directories to the root of the edgex-go code cd edgex-go Second, use the community provided Makefile to build all the services in a single call make build Info The first time EdgeX builds, it will take longer than other builds as it has to download all dependencies. Depending on the size of your host machine, an initial build can take several minutes. Make sure the build completes and has no errors. If it does build, you should find new service executables in each of the service folders under the service directories found in the /edgex-go/cmd folder.","title":"Build EdgeX Foundry"},{"location":"getting-started/Ch-GettingStartedGoDevelopers/#run-edgex-foundry","text":"","title":"Run EdgeX Foundry"},{"location":"getting-started/Ch-GettingStartedGoDevelopers/#run-the-database","text":"Several of the EdgeX Foundry micro services use a database. This includes core-data, core-metadata, support-scheduler, among others. Therefore, when working with EdgeX Foundry its a good idea to have the database up and running as a general rule. See the Redis Quick Start Guide for how to run Redis in a Linux environment (or find similar documentation for other environments). Note MongoDB can run in place of Redis with the Geneva release or earlier. MongoDB is deprecated and developers should transition to Redis. See the Run MongoDB documenation for how to run Mongo in a Linux environment (or find similar documentation for other environments). Running MongoDB in place of Redis will also require that you alter the configuration for all services that need the database to use MongoDB instead of Redis. As an example, the configuration of core-data is located in the file edgex-go/cmd/core-data/res/configuration.toml. In the configuration.toml file of the affected services, find the [Databases] section and change the \"Type\" to 'mongodb' along with any associated connection information similar to that shown below Host = 'localhost' Name = 'coredata' Password = 'password' Port = 27017 Username = 'core' Timeout = 5000 Type = 'mongodb'","title":"Run the Database"},{"location":"getting-started/Ch-GettingStartedGoDevelopers/#run-edgex-services","text":"With the services built, and the database up and running, you can now run all the services via second make command. Simply call make run This will start the EdgeX go services and leave them running until you terminate the process (with Ctrl-C). The log entries from each service will start to display in the terminal. Watch the log entries for any ERROR indicators. While the EdgeX services are running you can make EdgeX API calls to localhost . Note Use the ampersand ('&') sign at the end of make run if you wish to run the services in the background in detached mode. In so doing, Ctrl-C will not stop the services. You will have to kill the services by other means. Info No sensor data will flow yet as this just gets the key services up and running. To get sensor data flowing into EdgeX, you will need to get, build and run an EdgeX device service in a similar fashion. The community provides a virtual device service to test and experiment with ( https://github.com/edgexfoundry/device-virtual-go ).","title":"Run EdgeX Services"},{"location":"getting-started/Ch-GettingStartedGoDevelopers/#verify-edgex-is-working","text":"Each EdgeX micro service has a built-in respond to a \"ping\" HTTP request. In networking environments, use a ping request to check the reach-ability of a network resource. EdgeX uses the same concept to check the availability or reach-ability of a micro service. After the EdgeX micro services are running, you can \"ping\" any one of the micro services to check that it is running. Open a browser or HTTP REST client tool and use the service's ping address (outlined below) to check that is available. http://localhost:[port]/api/v1/ping See EdgeX Default Service Ports for a list of the EdgeX default service ports. \"Pinging\" an EdgeX micro service allows you to check on its availability. If the service does not respond to ping, the service is down or having issues.","title":"Verify EdgeX is Working"},{"location":"getting-started/Ch-GettingStartedGoDevelopers/#next-steps","text":"Application services and some device services are also built in Go. To explore how to create and build EdgeX application and devices services in Go, head to SDK documentation covering these EdgeX elements. Application Services and the Application Functions SDK Device Services in Go","title":"Next Steps"},{"location":"getting-started/Ch-GettingStartedGoDevelopers/#edgex-foundry-in-goland","text":"IDEs offer many code editing conveniences. Go Land was specifically built to edit and work with Go code. So if you are doing any significant code work with the EdgeX Go micro services, you will likely find it convenient to edit, build, run, test, etc. from GoLand or other IDE.","title":"EdgeX Foundry in GoLand"},{"location":"getting-started/Ch-GettingStartedGoDevelopers/#import-edgex","text":"To bring in the EdgeX repository code into Go Land, use the File \u2192 Open... menu option in Go Land to open the Open File or Project Window. In the \"Open File or Project\" popup, select the location of the folder containing your cloned edgex-go repo.","title":"Import EdgeX"},{"location":"getting-started/Ch-GettingStartedGoDevelopers/#open-the-terminal","text":"From the View menu in Go Land, select the Terminal menu option. This will open a command terminal from which you can issue commands to install the dependencies, build the micro services, run the micro services, etc.","title":"Open the Terminal"},{"location":"getting-started/Ch-GettingStartedGoDevelopers/#build-the-edgex-micro-services","text":"Run \"make build\" in the Terminal view (as shown below) to build the services. This can take a few minutes to build all the services. Warning In some cases, Go Land IDE may encounter an error (go: parsing \\$GOFLAGS: non-flag \"\"-X\") when building as shown below. If you encounter this issue, unset the GOFLAGS env var in GoLand. Make a call to unset GOFLAGS as shown below and then call make build again. Just as when running make build from the command line in a terminal, the micro service executables that get built in Go Land's terminal will be created in each of the service folders under the service directories found in the /edgex-go/cmd folder..","title":"Build the EdgeX Micro Services"},{"location":"getting-started/Ch-GettingStartedGoDevelopers/#run-edgex","text":"With all the micro services built, you can now run EdgeX. You may first want to make sure the database is running. Then issue the command make run in the terminal. You can now call on the service APIs to make sure they are running correctly. Namely, call on localhost:[service port]/api/v1/ping to see each service respond to the simplest of requests.","title":"Run EdgeX"},{"location":"getting-started/Ch-GettingStartedHybrid/","text":"Working in a Hybrid Environment In some cases, as a developer or contributor , you want to work on a particular micro service. Yet, you don't want to have to download all the source code, and then build and run for all the micro services. In this case, you can download and run the EdgeX Docker containers for all the micro services you need and run your single micro service (the one you are presumably working on) natively or from a developer tool of choice outside of a container. Within EdgeX, we call this a \"hybrid\" environment - where part of your EdgeX platform is running from a development environment, while other parts are running from the Dockerized containers. This page outlines how to do hybrid development. As an example of this process, let's say you want to do coding work with/on the Virtual Device service. You want the rest of the EdgeX environment up and running via Docker containers. How would you set up this hybrid environment? Let's take a look. Get and Run the EdgeX Docker Containers If you haven't already, follow the Getting Started with Docker Guide before continuing. Since you plan to work with the virtual device service, you probably don't need or want to run all the micro services. You just need the few that the Virtual Device will be communicating with or that will be required to run a minimal EdgeX environment. So you will need to run Consul, Redis, Core Data, Core Metadata, Support Notifications, and Core Command. Based on the instructions found in the Getting Started with Docker , locate and download the appropriate Docker Compose file for your development environment. Next, issue the following commands to start this set of EdgeX containers - providing a minimal functioning EdgeX environment. docker-compose up -d consul docker-compose up -d redis docker-compose up -d notifications docker-compose up -d metadata docker-compose up -d data docker-compose up -d command Note These notes assume you are working with the EdgeX Genva release. Some versions of EdgeX may require other or additional containers to run. Run the command below to confirm that all the containers have started. docker-compose ps Get, Build and Run the (non-Docker) Service With the EdgeX containers running, you can now download, build and run natively (outside of a container) the service you want to work on. In this example, the virtual device service is used to exemplify the steps necessary to get, build and run the native service with the EdgeX containerized services. However, the practice could be applied to any service. Get the service code Per Getting Started Go Developers , pull the micro service code you want to work on from GitHub. In this example, we assume you want to get the device-virtual-go. git clone https://github.com/edgexfoundry/device-virtual-go.git Build the service code At this time, you can add or modify the code to make the service changes you need. Once ready, you must compile and build the service into an executable. Change folders to the cloned micro service directory and build the service. cd device-virtual-go/ make build Change the configuration Depending on the service you are working on, you may need to change the configuration of the service to point to and use the other services that are containerized (running in Docker). In particular, if the service you are working on is not on the same host as the Docker Engine running the containerized services, you will likely need to change the configuration. Examine the configuration.toml file in the cmd/res folder of the device-virtual-go. Note that the Registry (located in the [Registry] section of the configuration) and all the \"clients\" (located in the [clients] section of the configuration file) suggest that the \"Host\" of these services is \"localhost\". These and other host configuration elements need to change when the services are not running on the same host. If you do have to change the configuration, save the configuration.toml file after making changes. Run the service code natively. The executable created by the make command is usually found in the cmd folder of the service. cd cmd ./device-virtual Check the results At this time, your virtual device micro service should be communicating with the other EdgeX micro services running in their Docker containers. Give the virtual device a few seconds or so to initialize itself and start sending data to Core Data. To check that it is working properly, open a browser and point your browser to Core Data to check that events are being deposited. You can do this by calling on the Core Data API that checks the count of events in Core Data http://[host].48080/api/v1/event/count. Note If you choose, you can also import the service into GoLand and then code and run the service from GoLand. Follow the instructions in the Getting Started - Go Developers to learn how to import, build and run a service in GoLand.","title":"Working in a Hybrid Environment"},{"location":"getting-started/Ch-GettingStartedHybrid/#working-in-a-hybrid-environment","text":"In some cases, as a developer or contributor , you want to work on a particular micro service. Yet, you don't want to have to download all the source code, and then build and run for all the micro services. In this case, you can download and run the EdgeX Docker containers for all the micro services you need and run your single micro service (the one you are presumably working on) natively or from a developer tool of choice outside of a container. Within EdgeX, we call this a \"hybrid\" environment - where part of your EdgeX platform is running from a development environment, while other parts are running from the Dockerized containers. This page outlines how to do hybrid development. As an example of this process, let's say you want to do coding work with/on the Virtual Device service. You want the rest of the EdgeX environment up and running via Docker containers. How would you set up this hybrid environment? Let's take a look.","title":"Working in a Hybrid Environment"},{"location":"getting-started/Ch-GettingStartedHybrid/#get-and-run-the-edgex-docker-containers","text":"If you haven't already, follow the Getting Started with Docker Guide before continuing. Since you plan to work with the virtual device service, you probably don't need or want to run all the micro services. You just need the few that the Virtual Device will be communicating with or that will be required to run a minimal EdgeX environment. So you will need to run Consul, Redis, Core Data, Core Metadata, Support Notifications, and Core Command. Based on the instructions found in the Getting Started with Docker , locate and download the appropriate Docker Compose file for your development environment. Next, issue the following commands to start this set of EdgeX containers - providing a minimal functioning EdgeX environment. docker-compose up -d consul docker-compose up -d redis docker-compose up -d notifications docker-compose up -d metadata docker-compose up -d data docker-compose up -d command Note These notes assume you are working with the EdgeX Genva release. Some versions of EdgeX may require other or additional containers to run. Run the command below to confirm that all the containers have started. docker-compose ps","title":"Get and Run the EdgeX Docker Containers"},{"location":"getting-started/Ch-GettingStartedHybrid/#get-build-and-run-the-non-docker-service","text":"With the EdgeX containers running, you can now download, build and run natively (outside of a container) the service you want to work on. In this example, the virtual device service is used to exemplify the steps necessary to get, build and run the native service with the EdgeX containerized services. However, the practice could be applied to any service.","title":"Get, Build and Run the (non-Docker) Service"},{"location":"getting-started/Ch-GettingStartedHybrid/#get-the-service-code","text":"Per Getting Started Go Developers , pull the micro service code you want to work on from GitHub. In this example, we assume you want to get the device-virtual-go. git clone https://github.com/edgexfoundry/device-virtual-go.git","title":"Get the service code"},{"location":"getting-started/Ch-GettingStartedHybrid/#build-the-service-code","text":"At this time, you can add or modify the code to make the service changes you need. Once ready, you must compile and build the service into an executable. Change folders to the cloned micro service directory and build the service. cd device-virtual-go/ make build","title":"Build the service code"},{"location":"getting-started/Ch-GettingStartedHybrid/#change-the-configuration","text":"Depending on the service you are working on, you may need to change the configuration of the service to point to and use the other services that are containerized (running in Docker). In particular, if the service you are working on is not on the same host as the Docker Engine running the containerized services, you will likely need to change the configuration. Examine the configuration.toml file in the cmd/res folder of the device-virtual-go. Note that the Registry (located in the [Registry] section of the configuration) and all the \"clients\" (located in the [clients] section of the configuration file) suggest that the \"Host\" of these services is \"localhost\". These and other host configuration elements need to change when the services are not running on the same host. If you do have to change the configuration, save the configuration.toml file after making changes.","title":"Change the configuration"},{"location":"getting-started/Ch-GettingStartedHybrid/#run-the-service-code-natively","text":"The executable created by the make command is usually found in the cmd folder of the service. cd cmd ./device-virtual","title":"Run the service code natively."},{"location":"getting-started/Ch-GettingStartedHybrid/#check-the-results","text":"At this time, your virtual device micro service should be communicating with the other EdgeX micro services running in their Docker containers. Give the virtual device a few seconds or so to initialize itself and start sending data to Core Data. To check that it is working properly, open a browser and point your browser to Core Data to check that events are being deposited. You can do this by calling on the Core Data API that checks the count of events in Core Data http://[host].48080/api/v1/event/count. Note If you choose, you can also import the service into GoLand and then code and run the service from GoLand. Follow the instructions in the Getting Started - Go Developers to learn how to import, build and run a service in GoLand.","title":"Check the results"},{"location":"getting-started/Ch-GettingStartedSDK-C/","text":"C SDK In this guide, you create a simple device service that generates a random number as a means to simulate getting data from an actual device. In this way, you explore some of the SDK framework and work necessary to complete a device service without actually having a device to talk to. Install dependencies See the Getting Started - C Developers guide to install the necessary tools and infrastructure needed to develop a C service. Get the EdgeX Device SDK for C The next step is to download and build the EdgeX device service SDK for C. First, clone the device-sdk-c from Github: git clone -b v1.2.1 https://github.com/edgexfoundry/device-sdk-c.git cd ./device-sdk-c Note The clone command above has you pull v1.2.1 of the C SDK which is the version compatible with the Geneva release. Then, build the device-sdk-c: make Starting a new Device Service For this guide, you use the example template provided by the C SDK as a starting point for a new device service. You modify the device service to generate random integer values. Begin by copying the template example source into a new directory named example-device-c : mkdir -p ../example-device-c/res cp ./src/c/examples/template.c ../example-device-c cd ../example-device-c Build your Device Service Now you are ready to build your new device service using the C SDK you compiled in an earlier step. Tell the compiler where to find the C SDK files: export CSDK_DIR = ../device-sdk-c/build/release/_CPack_Packages/Linux/TGZ/csdk-1.2.1 Note The exact path to your compiled CSDK_DIR may differ depending on the tagged version number on the SDK. The version of the SDK can be found in the VERSION file located in the ./device-sdk-c/VERSION file. In the example above, the Geneva release of 1.2.1 is used. Now build your device service executable: gcc -I $CSDK_DIR /include -L $CSDK_DIR /lib -o device-example-c template.c -lcsdk If everything is working properly, a device-example-c executable will be created in the directory. Customize your Device Service Up to now you've been building the example device service provided by the C SDK. In order to change it to a device service that generates random numbers, you need to modify your template.c method template_get_handler . Replace the following code: for ( uint32_t i = 0 ; i < nreadings ; i ++ ) { /* Log the attributes for each requested resource */ iot_log_debug ( driver -> lc , \" Requested reading %u:\" , i ); dump_nvpairs ( driver -> lc , requests [ i ]. attributes ); /* Fill in a result regardless */ readings [ i ]. type = String ; /* NB String (and binary) readings get deallocated in the SDK */ readings [ i ]. value . string_result = strdup ( \"Template result\" ); } return true ; with this code: for ( uint32_t i = 0 ; i < nreadings ; i ++ ) { const char * rdtype = edgex_nvpairs_value ( requests [ i ]. attributes , \"type\" ); if ( rdtype ) { if ( strcmp ( rdtype , \"random\" ) == 0 ) { /* Set the resulting reading type as Uint64 */ readings [ i ]. type = Edgex_Uint64 ; /* Set the reading as a random value between 0 and 100 */ readings [ i ]. value . ui64_result = rand () % 100 ; } else { iot_log_error ( driver -> lc , \"Unknown sensor type \\\" %s \\\" requested\" , rdtype ); return false ; } } else { iot_log_error ( driver -> lc , \"Unable to read value, no \\\" type \\\" attribute given\" ); return false ; } } return true ; Creating your Device Profile A device profile is a YAML file that describes a class of device to EdgeX. General characteristics about the type of device, the data these devices provide, and how to command the device are all in a device profile. The device profile tells the device service what data gets collected from the the device and how to get it. Follow these steps to create a device profile for the simple random number generating device service. Explore the files in the device-sdk-c/src/c/examples/res folder. Note the example TemplateProfile.yaml device profile that is already in this folder. Open the file with your favorite editor and explore its contents. Note how deviceResources in the file represent properties of a device (properties like SensorOne, SensorTwo and Switch). Similarly, coreCommands specify commands that get issued to the device. A pre-created device profile for the random number device is provided in this documentation. Download random-generator-device.yaml and save the file to the ./res folder. Open the random-generator-device.yaml file in a text editor. In this device profile, the device described has a deviceResource: randomnumber . Note how the association of a type to the deviceResource. In this case, the device profile informs EdgeX that randomnumber will be a INT32. In real world IoT situations, this deviceResource list could be extensive and filled with many deviceResources all different types of data. Note also how the device profile describes a REST command (GET Random) to call to get the random number from the device service. Configuring your Device Service Now update the configuration for the new device service. This documentation provides a new configuration.toml file. This configuration file: - changes the port the service operates on so as not to conflict with other device services - alters the the auto event frequency, which determines when the device service collects data from the simulated device (every 10 seconds) - sets up the initial provisioning of the random number generating device when the service starts Download configuration.toml and save the file to the ./res folder. Rebuild your Device Service Now you have your new device service, modified to return a random number, a device profile that will tell EdgeX how to read that random number, as well as a configuration file that will let your device service register itself and its device profile with EdgeX, and begin taking readings every 10 seconds. Rebuild your Device Service to reflect the changes that you have made: gcc -I $CSDK_DIR /include -L $CSDK_DIR /lib -o device-example-c template.c -lcsdk Run your Device Service Allow your newly created Device Service, which was formed out of the Device Service C SDK, to create sensor mimicking data which it then sends to EdgeX. Follow the Getting Started with Docker guide to start all of EdgeX. From the folder containing the docker-compose file, start EdgeX with the following call: docker-compose up -d Back in your custom device service directory, tell your device service where to find the libcsdk.so : export LD_LIBRARY_PATH = $CSDK_DIR /lib Run your device service: ./device-example-c You should now see your device service having its /Random command called every 10 seconds. You can verify that it is sending data into EdgeX by watching the logs of the edgex-core-data service: docker logs -f edgex-core-data Which would print an event record every time your device service is called. You can manually generate an event using curl to query the device service directly: curl 0 :49992/api/v1/device/name/RandNum-Device01/randomnumber Using a browser, enter the following URL to see the event/reading data that the service is generating and sending to EdgeX: http://localhost:48080/api/v1/event/device/RandNum-Device01/100 This request asks core data to provide the last 100 events/readings associated to the RandNum-Device-01.","title":"C SDK"},{"location":"getting-started/Ch-GettingStartedSDK-C/#c-sdk","text":"In this guide, you create a simple device service that generates a random number as a means to simulate getting data from an actual device. In this way, you explore some of the SDK framework and work necessary to complete a device service without actually having a device to talk to.","title":"C SDK"},{"location":"getting-started/Ch-GettingStartedSDK-C/#install-dependencies","text":"See the Getting Started - C Developers guide to install the necessary tools and infrastructure needed to develop a C service.","title":"Install dependencies"},{"location":"getting-started/Ch-GettingStartedSDK-C/#get-the-edgex-device-sdk-for-c","text":"The next step is to download and build the EdgeX device service SDK for C. First, clone the device-sdk-c from Github: git clone -b v1.2.1 https://github.com/edgexfoundry/device-sdk-c.git cd ./device-sdk-c Note The clone command above has you pull v1.2.1 of the C SDK which is the version compatible with the Geneva release. Then, build the device-sdk-c: make","title":"Get the EdgeX Device SDK for C"},{"location":"getting-started/Ch-GettingStartedSDK-C/#starting-a-new-device-service","text":"For this guide, you use the example template provided by the C SDK as a starting point for a new device service. You modify the device service to generate random integer values. Begin by copying the template example source into a new directory named example-device-c : mkdir -p ../example-device-c/res cp ./src/c/examples/template.c ../example-device-c cd ../example-device-c","title":"Starting a new Device Service"},{"location":"getting-started/Ch-GettingStartedSDK-C/#build-your-device-service","text":"Now you are ready to build your new device service using the C SDK you compiled in an earlier step. Tell the compiler where to find the C SDK files: export CSDK_DIR = ../device-sdk-c/build/release/_CPack_Packages/Linux/TGZ/csdk-1.2.1 Note The exact path to your compiled CSDK_DIR may differ depending on the tagged version number on the SDK. The version of the SDK can be found in the VERSION file located in the ./device-sdk-c/VERSION file. In the example above, the Geneva release of 1.2.1 is used. Now build your device service executable: gcc -I $CSDK_DIR /include -L $CSDK_DIR /lib -o device-example-c template.c -lcsdk If everything is working properly, a device-example-c executable will be created in the directory.","title":"Build your Device Service"},{"location":"getting-started/Ch-GettingStartedSDK-C/#customize-your-device-service","text":"Up to now you've been building the example device service provided by the C SDK. In order to change it to a device service that generates random numbers, you need to modify your template.c method template_get_handler . Replace the following code: for ( uint32_t i = 0 ; i < nreadings ; i ++ ) { /* Log the attributes for each requested resource */ iot_log_debug ( driver -> lc , \" Requested reading %u:\" , i ); dump_nvpairs ( driver -> lc , requests [ i ]. attributes ); /* Fill in a result regardless */ readings [ i ]. type = String ; /* NB String (and binary) readings get deallocated in the SDK */ readings [ i ]. value . string_result = strdup ( \"Template result\" ); } return true ; with this code: for ( uint32_t i = 0 ; i < nreadings ; i ++ ) { const char * rdtype = edgex_nvpairs_value ( requests [ i ]. attributes , \"type\" ); if ( rdtype ) { if ( strcmp ( rdtype , \"random\" ) == 0 ) { /* Set the resulting reading type as Uint64 */ readings [ i ]. type = Edgex_Uint64 ; /* Set the reading as a random value between 0 and 100 */ readings [ i ]. value . ui64_result = rand () % 100 ; } else { iot_log_error ( driver -> lc , \"Unknown sensor type \\\" %s \\\" requested\" , rdtype ); return false ; } } else { iot_log_error ( driver -> lc , \"Unable to read value, no \\\" type \\\" attribute given\" ); return false ; } } return true ;","title":"Customize your Device Service"},{"location":"getting-started/Ch-GettingStartedSDK-C/#creating-your-device-profile","text":"A device profile is a YAML file that describes a class of device to EdgeX. General characteristics about the type of device, the data these devices provide, and how to command the device are all in a device profile. The device profile tells the device service what data gets collected from the the device and how to get it. Follow these steps to create a device profile for the simple random number generating device service. Explore the files in the device-sdk-c/src/c/examples/res folder. Note the example TemplateProfile.yaml device profile that is already in this folder. Open the file with your favorite editor and explore its contents. Note how deviceResources in the file represent properties of a device (properties like SensorOne, SensorTwo and Switch). Similarly, coreCommands specify commands that get issued to the device. A pre-created device profile for the random number device is provided in this documentation. Download random-generator-device.yaml and save the file to the ./res folder. Open the random-generator-device.yaml file in a text editor. In this device profile, the device described has a deviceResource: randomnumber . Note how the association of a type to the deviceResource. In this case, the device profile informs EdgeX that randomnumber will be a INT32. In real world IoT situations, this deviceResource list could be extensive and filled with many deviceResources all different types of data. Note also how the device profile describes a REST command (GET Random) to call to get the random number from the device service.","title":"Creating your Device Profile"},{"location":"getting-started/Ch-GettingStartedSDK-C/#configuring-your-device-service","text":"Now update the configuration for the new device service. This documentation provides a new configuration.toml file. This configuration file: - changes the port the service operates on so as not to conflict with other device services - alters the the auto event frequency, which determines when the device service collects data from the simulated device (every 10 seconds) - sets up the initial provisioning of the random number generating device when the service starts Download configuration.toml and save the file to the ./res folder.","title":"Configuring your Device Service"},{"location":"getting-started/Ch-GettingStartedSDK-C/#rebuild-your-device-service","text":"Now you have your new device service, modified to return a random number, a device profile that will tell EdgeX how to read that random number, as well as a configuration file that will let your device service register itself and its device profile with EdgeX, and begin taking readings every 10 seconds. Rebuild your Device Service to reflect the changes that you have made: gcc -I $CSDK_DIR /include -L $CSDK_DIR /lib -o device-example-c template.c -lcsdk","title":"Rebuild your Device Service"},{"location":"getting-started/Ch-GettingStartedSDK-C/#run-your-device-service","text":"Allow your newly created Device Service, which was formed out of the Device Service C SDK, to create sensor mimicking data which it then sends to EdgeX. Follow the Getting Started with Docker guide to start all of EdgeX. From the folder containing the docker-compose file, start EdgeX with the following call: docker-compose up -d Back in your custom device service directory, tell your device service where to find the libcsdk.so : export LD_LIBRARY_PATH = $CSDK_DIR /lib Run your device service: ./device-example-c You should now see your device service having its /Random command called every 10 seconds. You can verify that it is sending data into EdgeX by watching the logs of the edgex-core-data service: docker logs -f edgex-core-data Which would print an event record every time your device service is called. You can manually generate an event using curl to query the device service directly: curl 0 :49992/api/v1/device/name/RandNum-Device01/randomnumber Using a browser, enter the following URL to see the event/reading data that the service is generating and sending to EdgeX: http://localhost:48080/api/v1/event/device/RandNum-Device01/100 This request asks core data to provide the last 100 events/readings associated to the RandNum-Device-01.","title":"Run your Device Service"},{"location":"getting-started/Ch-GettingStartedSDK-Go/","text":"Golang SDK In this guide, you create a simple device service that generates a random number as a means to simulate getting data from an actual device. In this way, you explore some the SDK framework and work necessary to complete a device service without actually having a device to talk to. Install dependencies See the Getting Started - Go Developers guide to install the necessary tools and infrastructure needed to develop a GoLang service. Get the EdgeX Device SDK for Go Follow these steps to create a folder on your file system, download the Device SDK , and get the GoLang device service SDK on your system. Create a collection of nested folders, ~/go/src/github.com/edgexfoundry on your file system. This folder will hold your new Device Service. In Linux, create a directory with a single mkdir command mkdir -p ~/go/src/github.com/edgexfoundry In a terminal window, change directories to the folder just created and pull down the SDK in Go with the commands as shown. cd ~/go/src/github.com/edgexfoundry git clone --depth 1 --branch v1.2.2 https://github.com/edgexfoundry/device-sdk-go.git Note The clone command above has you pull v1.2.2 of the Go SDK which is the version associated to Geneva. You may want to check for the latest released version by going to https://github.com/edgexfoundry/device-sdk-go and look for the lastest release tag. Create a folder that will hold the new device service. The name of the folder is also the name you want to give your new device service. Standard practice in EdgeX is to prefix the name of a device service with device- . In this example, the name 'device-simple` is used. mkdir ~/go/src/github.com/edgexfoundry/device-simple Copy the example code from device-sdk-go to device-simple : cd ~/go/src/github.com/edgexfoundry cp -rf ./device-sdk-go/example/* ./device-simple/ Copy Makefile to device-simple: cp ./device-sdk-go/Makefile ./device-simple Copy version.go to device-simple: cp ./device-sdk-go/version.go ./device-simple/ After completing these steps, your device-simple folder should look like the listing below. Start a new Device Service With the device service application structure in place, time now to program the service to act like a sensor data fetching service. Change folders to the device-simple directory. cd ~/go/src/github.com/edgexfoundry/device-simple Open main.go file in the cmd/device-simple folder with your favorite text editor. Modify the import statements. Replace github.com/edgexfoundry/device-sdk-go/example/driver with github.com/edgexfoundry/device-simple/driver in the import statements. Also replace github.com/edgexfoundry/device-sdk-go with github.com/edgexfoundry/device-simple . Save the file when you have finished editing. Open Makefile found in the base folder (~/go/src/github.com/edgexfoundry/device-simple) in your favorite text editor and make the following changes Replace: MICROSERVICES=example/cmd/device-simple/device-simple with: MICROSERVICES=cmd/device-simple/device-simple Change: GOFLAGS=-ldflags \"-X github.com/edgexfoundry/device-sdk-go.Version=$(VERSION)\" to refer to the new service with: GOFLAGS=-ldflags \"-X github.com/edgexfoundry/device-simple.Version=$(VERSION)\" Change: example/cmd/device-simple/device-simple: $(GO) build $(GOFLAGS) -o $@ ./example/cmd/device-simple to: cmd/device-simple/device-simple: $(GO) build $(GOFLAGS) -o $@ ./cmd/device-simple Save the file. Enter the following command to create the initial module definition and write it to the go.mod file: GO111MODULE=on go mod init Use an editor to open and edit the go.mod file created in ~/go/src/github.com/edgexfoundry/device-simple. Add the code highlighted below to the bottom of the file. This code indicates which version of the device service SDK and the associated EdgeX contracts module to use. require ( github . com / edgexfoundry / device - sdk - go v1 .2.2 github . com / edgexfoundry / go - mod - core - contracts v0 .1.58 ) Note You should always check the go.mod file in the latest released version SDK for the correct versions of the Go SDK and go-mod-contracts to use in your go.mod. Build your Device Service To ensure that the code you have moved and updated still works, build the device service. In a terminal window, make sure you are still in the device-simple folder (the folder containing the Makefile). Build the service by issuing the following command: make build If there are no errors, your service is ready for you to add custom code to generate data values as if there was a sensor attached. Customize your Device Service The device service you are creating isn't going to talk to a real device. Instead, it is going to generate a random number where the service would ordinarily make a call to get sensor data from the actual device. Locate the simpledriver.go file in the /driver folder and open it with your favorite editor. In the import() area at the top of the file, add \"math/rand\" under \"time\". Locate the HandleReadCommands() function in this same file (simpledriver.go). Find the following lines of code in this file (around line 87): if reqs [ 0 ]. DeviceResourceName == \"SwitchButton\" { cv , _ := dsModels . NewBoolValue ( reqs [ 0 ]. DeviceResourceName , now , s . switchButton ) res [ 0 ] = cv } Add the conditional (if-else) code in front of the above conditional: if reqs [ 0 ]. DeviceResourceName == \"randomnumber\" { cv , _ := dsModels . NewInt32Value ( reqs [ 0 ]. DeviceResourceName , now , int32 ( rand . Intn ( 100 ))) res [ 0 ] = cv } else The first line of code checks that the current request is for a resource called \"randomnumber\". The second line of code generates an integer (between 0 and 100) and uses that as the value the device service sends to EdgeX -- mimicking the collection of data from a real device. It is here that the device service would normally capture some sensor reading from a device and send the data to EdgeX. The HandleReadCommands is where you'd need to do some customization work to talk to the device, get the latest sensor values and send them into EdgeX. Save the simpledriver.go file Creating your Device Profile A device profile is a YAML file that describes a class of device to EdgeX. General characteristics about the type of device, the data these devices provide, and how to command the device are all in a device profile. The device profile tells the device service what data gets collected from the the device and how to get it. Follow these steps to create a device profile for the simple random number generating device service. Explore the files in the cmd/device-simple/res folder. Note the example Simple-Driver.yaml device profile that is already in this folder. Open the file with your favorite editor and explore its contents. Note how deviceResources in the file represent properties of a device (properties like SwitchButton, X, Y and Z rotation). Similarly, coreCommands specify commands that get issued to the device. A pre-created device profile for the random number device is provided in this documentation. Download random-generator-device.yaml and save the file to the ~/go/src/github.com/edgexfoundry/device-simple/cmd/device-simple/res folder. Open the random-generator-device.yaml file in a text editor. In this device profile, the device described has a deviceResource: randomnumber . Note how the association of a type to the deviceResource. In this case, the device profile informs EdgeX that randomnumber will be a INT32. In real world IoT situations, this deviceResource list could be extensive. Rather than a single deviceResource, you might find this section filled with many deviceResources and each deviceResource associated to a different type. Note also how the device profile describes a REST command (GET Random) to call to get the random number from the device service. Configuring your Device Service Now update the configuration for the new device service. This documentation provides a new configuration.toml file. This configuration file: changes the port the service operates on so as not to conflict with other device services alters the the auto event frequency, which determines when the device service collects data from the simulated device (every 10 seconds) sets up the initial provisioning of the random number generating device when the service starts Download configuration.toml and save the file to the ~/go/src/github.com/edgexfoundry/device-simple/cmd/device-simple/res folder (overwrite the existing configuration file). Change the host address of the device service to your system's IP address. Warning In the configuration.toml, change the host address (around line 7) to the IP address of the system host. This allows core metadata to callback to your new device service when a new device is created. Because the rest of EdgeX, to include core metadata, will be running in Docker, the IP address of the host system on the Docker network must be provided to allow metadata in Docker to call out from Docker to the new device service running on your host system. Rebuild your Device Service Just as you did in the Build your Device Service step above, build the device-simple service, which creates the executable program that is your device service. In a terminal window, make sure you are in the device-simple folder (the folder containing the Makefile). Build the service by issuing the following command: cd ~/go/src/github.com/edgexfoundry/device-simple make build If there are no errors, your service is created and put in the ~/go/src/github.com/edgexfoundry/device-simple/cmd/device-simple folder. Look for the device-simple executable in the folder. Run your Device Service Allow the newly created device service, which was formed out of the Device Service Go SDK, to create sensor-mimicking data that it then sends to EdgeX: Follow the Getting Started with Docker guide to start all of EdgeX. From the folder containing the docker-compose file, start EdgeX with the following call: docker-compose up -d In a terminal window, change directories to the device-simple's cmd/device-simple folder and run the new device-simple service. cd ~/go/src/github.com/edgexfoundry/device-simple/cmd/device-simple ./device-simple This starts the service and immediately displays log entries in the terminal. Using a browser, enter the following URL to see the event/reading data that the service is generating and sending to EdgeX: http://localhost:48080/api/v1/event/device/RandNum-Device01/100 This request asks core data to provide the last 100 events/readings associated to the RandNum-Device-01.","title":"Golang SDK"},{"location":"getting-started/Ch-GettingStartedSDK-Go/#golang-sdk","text":"In this guide, you create a simple device service that generates a random number as a means to simulate getting data from an actual device. In this way, you explore some the SDK framework and work necessary to complete a device service without actually having a device to talk to.","title":"Golang SDK"},{"location":"getting-started/Ch-GettingStartedSDK-Go/#install-dependencies","text":"See the Getting Started - Go Developers guide to install the necessary tools and infrastructure needed to develop a GoLang service.","title":"Install dependencies"},{"location":"getting-started/Ch-GettingStartedSDK-Go/#get-the-edgex-device-sdk-for-go","text":"Follow these steps to create a folder on your file system, download the Device SDK , and get the GoLang device service SDK on your system. Create a collection of nested folders, ~/go/src/github.com/edgexfoundry on your file system. This folder will hold your new Device Service. In Linux, create a directory with a single mkdir command mkdir -p ~/go/src/github.com/edgexfoundry In a terminal window, change directories to the folder just created and pull down the SDK in Go with the commands as shown. cd ~/go/src/github.com/edgexfoundry git clone --depth 1 --branch v1.2.2 https://github.com/edgexfoundry/device-sdk-go.git Note The clone command above has you pull v1.2.2 of the Go SDK which is the version associated to Geneva. You may want to check for the latest released version by going to https://github.com/edgexfoundry/device-sdk-go and look for the lastest release tag. Create a folder that will hold the new device service. The name of the folder is also the name you want to give your new device service. Standard practice in EdgeX is to prefix the name of a device service with device- . In this example, the name 'device-simple` is used. mkdir ~/go/src/github.com/edgexfoundry/device-simple Copy the example code from device-sdk-go to device-simple : cd ~/go/src/github.com/edgexfoundry cp -rf ./device-sdk-go/example/* ./device-simple/ Copy Makefile to device-simple: cp ./device-sdk-go/Makefile ./device-simple Copy version.go to device-simple: cp ./device-sdk-go/version.go ./device-simple/ After completing these steps, your device-simple folder should look like the listing below.","title":"Get the EdgeX Device SDK for Go"},{"location":"getting-started/Ch-GettingStartedSDK-Go/#start-a-new-device-service","text":"With the device service application structure in place, time now to program the service to act like a sensor data fetching service. Change folders to the device-simple directory. cd ~/go/src/github.com/edgexfoundry/device-simple Open main.go file in the cmd/device-simple folder with your favorite text editor. Modify the import statements. Replace github.com/edgexfoundry/device-sdk-go/example/driver with github.com/edgexfoundry/device-simple/driver in the import statements. Also replace github.com/edgexfoundry/device-sdk-go with github.com/edgexfoundry/device-simple . Save the file when you have finished editing. Open Makefile found in the base folder (~/go/src/github.com/edgexfoundry/device-simple) in your favorite text editor and make the following changes Replace: MICROSERVICES=example/cmd/device-simple/device-simple with: MICROSERVICES=cmd/device-simple/device-simple Change: GOFLAGS=-ldflags \"-X github.com/edgexfoundry/device-sdk-go.Version=$(VERSION)\" to refer to the new service with: GOFLAGS=-ldflags \"-X github.com/edgexfoundry/device-simple.Version=$(VERSION)\" Change: example/cmd/device-simple/device-simple: $(GO) build $(GOFLAGS) -o $@ ./example/cmd/device-simple to: cmd/device-simple/device-simple: $(GO) build $(GOFLAGS) -o $@ ./cmd/device-simple Save the file. Enter the following command to create the initial module definition and write it to the go.mod file: GO111MODULE=on go mod init Use an editor to open and edit the go.mod file created in ~/go/src/github.com/edgexfoundry/device-simple. Add the code highlighted below to the bottom of the file. This code indicates which version of the device service SDK and the associated EdgeX contracts module to use. require ( github . com / edgexfoundry / device - sdk - go v1 .2.2 github . com / edgexfoundry / go - mod - core - contracts v0 .1.58 ) Note You should always check the go.mod file in the latest released version SDK for the correct versions of the Go SDK and go-mod-contracts to use in your go.mod.","title":"Start a new Device Service"},{"location":"getting-started/Ch-GettingStartedSDK-Go/#build-your-device-service","text":"To ensure that the code you have moved and updated still works, build the device service. In a terminal window, make sure you are still in the device-simple folder (the folder containing the Makefile). Build the service by issuing the following command: make build If there are no errors, your service is ready for you to add custom code to generate data values as if there was a sensor attached.","title":"Build your Device Service"},{"location":"getting-started/Ch-GettingStartedSDK-Go/#customize-your-device-service","text":"The device service you are creating isn't going to talk to a real device. Instead, it is going to generate a random number where the service would ordinarily make a call to get sensor data from the actual device. Locate the simpledriver.go file in the /driver folder and open it with your favorite editor. In the import() area at the top of the file, add \"math/rand\" under \"time\". Locate the HandleReadCommands() function in this same file (simpledriver.go). Find the following lines of code in this file (around line 87): if reqs [ 0 ]. DeviceResourceName == \"SwitchButton\" { cv , _ := dsModels . NewBoolValue ( reqs [ 0 ]. DeviceResourceName , now , s . switchButton ) res [ 0 ] = cv } Add the conditional (if-else) code in front of the above conditional: if reqs [ 0 ]. DeviceResourceName == \"randomnumber\" { cv , _ := dsModels . NewInt32Value ( reqs [ 0 ]. DeviceResourceName , now , int32 ( rand . Intn ( 100 ))) res [ 0 ] = cv } else The first line of code checks that the current request is for a resource called \"randomnumber\". The second line of code generates an integer (between 0 and 100) and uses that as the value the device service sends to EdgeX -- mimicking the collection of data from a real device. It is here that the device service would normally capture some sensor reading from a device and send the data to EdgeX. The HandleReadCommands is where you'd need to do some customization work to talk to the device, get the latest sensor values and send them into EdgeX. Save the simpledriver.go file","title":"Customize your Device Service"},{"location":"getting-started/Ch-GettingStartedSDK-Go/#creating-your-device-profile","text":"A device profile is a YAML file that describes a class of device to EdgeX. General characteristics about the type of device, the data these devices provide, and how to command the device are all in a device profile. The device profile tells the device service what data gets collected from the the device and how to get it. Follow these steps to create a device profile for the simple random number generating device service. Explore the files in the cmd/device-simple/res folder. Note the example Simple-Driver.yaml device profile that is already in this folder. Open the file with your favorite editor and explore its contents. Note how deviceResources in the file represent properties of a device (properties like SwitchButton, X, Y and Z rotation). Similarly, coreCommands specify commands that get issued to the device. A pre-created device profile for the random number device is provided in this documentation. Download random-generator-device.yaml and save the file to the ~/go/src/github.com/edgexfoundry/device-simple/cmd/device-simple/res folder. Open the random-generator-device.yaml file in a text editor. In this device profile, the device described has a deviceResource: randomnumber . Note how the association of a type to the deviceResource. In this case, the device profile informs EdgeX that randomnumber will be a INT32. In real world IoT situations, this deviceResource list could be extensive. Rather than a single deviceResource, you might find this section filled with many deviceResources and each deviceResource associated to a different type. Note also how the device profile describes a REST command (GET Random) to call to get the random number from the device service.","title":"Creating your Device Profile"},{"location":"getting-started/Ch-GettingStartedSDK-Go/#configuring-your-device-service","text":"Now update the configuration for the new device service. This documentation provides a new configuration.toml file. This configuration file: changes the port the service operates on so as not to conflict with other device services alters the the auto event frequency, which determines when the device service collects data from the simulated device (every 10 seconds) sets up the initial provisioning of the random number generating device when the service starts Download configuration.toml and save the file to the ~/go/src/github.com/edgexfoundry/device-simple/cmd/device-simple/res folder (overwrite the existing configuration file). Change the host address of the device service to your system's IP address. Warning In the configuration.toml, change the host address (around line 7) to the IP address of the system host. This allows core metadata to callback to your new device service when a new device is created. Because the rest of EdgeX, to include core metadata, will be running in Docker, the IP address of the host system on the Docker network must be provided to allow metadata in Docker to call out from Docker to the new device service running on your host system.","title":"Configuring your Device Service"},{"location":"getting-started/Ch-GettingStartedSDK-Go/#rebuild-your-device-service","text":"Just as you did in the Build your Device Service step above, build the device-simple service, which creates the executable program that is your device service. In a terminal window, make sure you are in the device-simple folder (the folder containing the Makefile). Build the service by issuing the following command: cd ~/go/src/github.com/edgexfoundry/device-simple make build If there are no errors, your service is created and put in the ~/go/src/github.com/edgexfoundry/device-simple/cmd/device-simple folder. Look for the device-simple executable in the folder.","title":"Rebuild your Device Service"},{"location":"getting-started/Ch-GettingStartedSDK-Go/#run-your-device-service","text":"Allow the newly created device service, which was formed out of the Device Service Go SDK, to create sensor-mimicking data that it then sends to EdgeX: Follow the Getting Started with Docker guide to start all of EdgeX. From the folder containing the docker-compose file, start EdgeX with the following call: docker-compose up -d In a terminal window, change directories to the device-simple's cmd/device-simple folder and run the new device-simple service. cd ~/go/src/github.com/edgexfoundry/device-simple/cmd/device-simple ./device-simple This starts the service and immediately displays log entries in the terminal. Using a browser, enter the following URL to see the event/reading data that the service is generating and sending to EdgeX: http://localhost:48080/api/v1/event/device/RandNum-Device01/100 This request asks core data to provide the last 100 events/readings associated to the RandNum-Device-01.","title":"Run your Device Service"},{"location":"getting-started/Ch-GettingStartedSDK/","text":"Device Service SDK The EdgeX device service software development kits (SDKs) help developers create new device connectors for EdgeX. An SDK provides the common scaffolding that each device service needs. This allows developers to create new device/sensor connectors more quickly. The EdgeX community already provides many device services. However, there is no way the community can provide for every protocol and every sensor. Even if the EdgeX community provided a device service for every protocol, your use case, sensor, or security infrastructure might require customization. Thus, the device service SDKs provide the means to extend or customize EdgeX\u2019s device connectivity. EdgeX provides two SDKs to help developers create new device services. Most of EdgeX is written in Go and C. Thus, there's a device service SDK written in both Go and C to support the more popular languages used in EdgeX today. In the future, the community may offer alternate language SDKs. The SDKs are libraries that get incorporated into a new micro services. They make writing a new device service much easier. By importing the SDK library into your new device service project, developers are left to focus on the code that is specific to the communications with the device via the protocol of the device. The code in the SDK handles the other details, such as: - initialization of the device service - getting the service configured - sending sensor data to core data - managing communications with core metadata - and much more. The code in the SDK also helps to ensure your device service adheres to rules and standards of EdgeX. For example, it makes sure the service registers with the EdgeX registry service when it starts. Use the GoLang SDK Use the C SDK","title":"Device Service SDK"},{"location":"getting-started/Ch-GettingStartedSDK/#device-service-sdk","text":"The EdgeX device service software development kits (SDKs) help developers create new device connectors for EdgeX. An SDK provides the common scaffolding that each device service needs. This allows developers to create new device/sensor connectors more quickly. The EdgeX community already provides many device services. However, there is no way the community can provide for every protocol and every sensor. Even if the EdgeX community provided a device service for every protocol, your use case, sensor, or security infrastructure might require customization. Thus, the device service SDKs provide the means to extend or customize EdgeX\u2019s device connectivity. EdgeX provides two SDKs to help developers create new device services. Most of EdgeX is written in Go and C. Thus, there's a device service SDK written in both Go and C to support the more popular languages used in EdgeX today. In the future, the community may offer alternate language SDKs. The SDKs are libraries that get incorporated into a new micro services. They make writing a new device service much easier. By importing the SDK library into your new device service project, developers are left to focus on the code that is specific to the communications with the device via the protocol of the device. The code in the SDK handles the other details, such as: - initialization of the device service - getting the service configured - sending sensor data to core data - managing communications with core metadata - and much more. The code in the SDK also helps to ensure your device service adheres to rules and standards of EdgeX. For example, it makes sure the service registers with the EdgeX registry service when it starts. Use the GoLang SDK Use the C SDK","title":"Device Service SDK"},{"location":"getting-started/Ch-GettingStartedSnapUsers/","text":"Getting Started with Snap Introduction Just like Docker containers, the EdgeX project creates and publishes a snap for each release to the snap store . The snap currently supports running on both amd64 and arm64 platforms. See snap documents for help on using or installing snap. Installing EdgeX Foundry as a snap The snap is published in the snap store at https://snapcraft.io/edgexfoundry. You can see the current revisions available for your machine's architecture by running the command: $ snap info edgexfoundry The snap can be installed using snap install. To install the snap from the edge channel: $ sudo snap install edgexfoundry --edge You can install a specific release using the --channel option. For example to install the Fuji release of the snap: $ sudo snap install edgexfoundry --channel=fuji Lastly, on a system supporting it, the snap may be installed using GNOME (or Ubuntu) Software Center by searching for edgexfoundry. Note The snap has only been tested on Ubuntu Desktop/Server versions 18.04 and 16.04, as well as Ubuntu Core versions 16 and 18. Warning Running the EdgeX snap on a machine setup for EdgeX development can create conflicts and result in the platform errors/issues. Using the EdgeX snap Upon installation, the following EdgeX services are automatically and immediately started: - consul - redis - core-data - core-command - core-metadata - security-services (see note below) The following services are disabled by default: - app-service-configurable (required for Kuiper and support-rulesengine) - device-virtual - kuiper - support-logging - support-notifications - support-rulesengine (deprecated) - support-scheduler - sys-mgmt-agent Any disabled services can be enabled and started up using snap set: $ sudo snap set edgexfoundry support-notifications=on To turn a service off (thereby disabling and immediately stopping it) set the service to off: $ sudo snap set edgexfoundry support-notifications=off All services which are installed on the system as systemd units, which if enabled will automatically start running when the system boots or reboots. Configuring individual services All default configuration files are shipped with the snap inside $SNAP/config, however because $SNAP isn't writable, all of the config files are copied during snap installation (specifically during the install hook, see snap/hooks/install in this repository) to $SNAP_DATA/config. $ sudo snap restart edgexfoundry Viewing logs Currently, all log files for the snap's can be found inside $SNAP_COMMON, which is usually /var/snap/edgexfoundry/common. Once all the services are supported as daemons, you can also use sudo snap logs edgexfoundry to view logs. Additionally, logs can be viewed using the system journal or snap logs. To view the logs for all services in the edgexfoundry snap use: $ sudo snap logs edgexfoundry Individual service logs may be viewed by specifying the service name: $ sudo snap logs edgexfoundry.consul Or by using the systemd unit name and journalctl: $ journalctl -u snap.edgexfoundry.consul Security services Currently, the security services are enabled by default. The security services consitute the following components: - Kong - PostgreSQL - Vault - security-secrets-setup - security-secretstore-setup - security-proxy-setup Vault is used for secret management, and Kong is used as an HTTPS proxy for all the services. Kong can be disabled by using the following command: $ sudo snap set edgexfoundry security-proxy=off Vault can be also be disabled, but doing so will also disable Kong, as it depends on Vault. Thus the following command will disable both: Note Kong is currently not supported in the snap when installed on an arm64-based device, so it will be disabled on install.","title":"Getting Started with Snap"},{"location":"getting-started/Ch-GettingStartedSnapUsers/#getting-started-with-snap","text":"","title":"Getting Started with Snap"},{"location":"getting-started/Ch-GettingStartedSnapUsers/#introduction","text":"Just like Docker containers, the EdgeX project creates and publishes a snap for each release to the snap store . The snap currently supports running on both amd64 and arm64 platforms. See snap documents for help on using or installing snap.","title":"Introduction"},{"location":"getting-started/Ch-GettingStartedSnapUsers/#installing-edgex-foundry-as-a-snap","text":"The snap is published in the snap store at https://snapcraft.io/edgexfoundry. You can see the current revisions available for your machine's architecture by running the command: $ snap info edgexfoundry The snap can be installed using snap install. To install the snap from the edge channel: $ sudo snap install edgexfoundry --edge You can install a specific release using the --channel option. For example to install the Fuji release of the snap: $ sudo snap install edgexfoundry --channel=fuji Lastly, on a system supporting it, the snap may be installed using GNOME (or Ubuntu) Software Center by searching for edgexfoundry. Note The snap has only been tested on Ubuntu Desktop/Server versions 18.04 and 16.04, as well as Ubuntu Core versions 16 and 18. Warning Running the EdgeX snap on a machine setup for EdgeX development can create conflicts and result in the platform errors/issues.","title":"Installing EdgeX Foundry as a snap"},{"location":"getting-started/Ch-GettingStartedSnapUsers/#using-the-edgex-snap","text":"Upon installation, the following EdgeX services are automatically and immediately started: - consul - redis - core-data - core-command - core-metadata - security-services (see note below) The following services are disabled by default: - app-service-configurable (required for Kuiper and support-rulesengine) - device-virtual - kuiper - support-logging - support-notifications - support-rulesengine (deprecated) - support-scheduler - sys-mgmt-agent Any disabled services can be enabled and started up using snap set: $ sudo snap set edgexfoundry support-notifications=on To turn a service off (thereby disabling and immediately stopping it) set the service to off: $ sudo snap set edgexfoundry support-notifications=off All services which are installed on the system as systemd units, which if enabled will automatically start running when the system boots or reboots.","title":"Using the EdgeX snap"},{"location":"getting-started/Ch-GettingStartedSnapUsers/#configuring-individual-services","text":"All default configuration files are shipped with the snap inside $SNAP/config, however because $SNAP isn't writable, all of the config files are copied during snap installation (specifically during the install hook, see snap/hooks/install in this repository) to $SNAP_DATA/config. $ sudo snap restart edgexfoundry","title":"Configuring individual services"},{"location":"getting-started/Ch-GettingStartedSnapUsers/#viewing-logs","text":"Currently, all log files for the snap's can be found inside $SNAP_COMMON, which is usually /var/snap/edgexfoundry/common. Once all the services are supported as daemons, you can also use sudo snap logs edgexfoundry to view logs. Additionally, logs can be viewed using the system journal or snap logs. To view the logs for all services in the edgexfoundry snap use: $ sudo snap logs edgexfoundry Individual service logs may be viewed by specifying the service name: $ sudo snap logs edgexfoundry.consul Or by using the systemd unit name and journalctl: $ journalctl -u snap.edgexfoundry.consul","title":"Viewing logs"},{"location":"getting-started/Ch-GettingStartedSnapUsers/#security-services","text":"Currently, the security services are enabled by default. The security services consitute the following components: - Kong - PostgreSQL - Vault - security-secrets-setup - security-secretstore-setup - security-proxy-setup Vault is used for secret management, and Kong is used as an HTTPS proxy for all the services. Kong can be disabled by using the following command: $ sudo snap set edgexfoundry security-proxy=off Vault can be also be disabled, but doing so will also disable Kong, as it depends on Vault. Thus the following command will disable both: Note Kong is currently not supported in the snap when installed on an arm64-based device, so it will be disabled on install.","title":"Security services"},{"location":"getting-started/Ch-GettingStartedUsers/","text":"Getting Started with Docker Introduction These instructions are for Users to get and run EdgeX Foundry. (Developers should read: Getting Started Developers ) EdgeX is a collection of more than a dozen micro services that are deployed to provide a minimal edge platform capability. You can download EdgeX micro service source code and build your own micro services. However, if you do not have a need to change or add to EdgeX, then you do not need to download source code. Instead, Users run EdgeX micro service Docker containers. The EdgeX community builds and creates Docker container images with each release. Get & Run EdgeX Foundry Install Docker & Docker Compose To run Dockerized EdgeX, you need to install Docker. See https://docs.docker.com/install/ to learn how to install Docker. If you are new to Docker, the same web site provides you educational information. The following short video is also very informative https://www.youtube.com/watch?time_continue=3&v=VhabrYF1nms Use Docker Compose to orchestrate the fetch (or pull), install, and start the EdgeX micro service containers. Also use Docker Compose to stop the micro service containers. See: https://docs.docker.com/compose/ to learn more about Docker Compose. You do not need to be an expert with Docker (or Docker Compose) to get and run EdgeX. This guide provides the steps to get EdgeX running in your environment. Some knowledge of Docker and Docker Compose are nice to have, but not required. Basic Docker and Docker Compose commands provided here enable you to run, update, and diagnose issues within EdgeX. Select a EdgeX Foundry Compose File After installing Docker and Docker Compose, you need a EdgeX Docker Compose file. EdgeX Foundry has over a dozen micro services, each deployed in its own Docker container. This file is a manifest of all the EdgeX Foundry micro services to run. The Docker Compose file provides details about how to run each of the services. Specifically, a Docker Compose file is a manifest file, which lists: The Docker container images that should be downloaded, The order in which the containers should be started, The parameters (such as ports) under which the containers should be run The EdgeX development team provides Docker Compose files for each release. Visit the project GitHub and locate the EdgeX Docker Compose file for the version of EdgeX you want to run. The EdgeX Developer Scripts repository contains a folder for each release. In the folder, find the Docker Compose files for each release. Note At the GitHub location specified above there is a folder for each EdgeX release. The nightly-build folder contains Docker Compose files that use artifacts created from the latest code submitted by contributors. Most end users should avoid using these Docker Compose files. They are work-in-progress. Users should use the Docker Compose files for the latest version of EdgeX. In each folder, you will find several Docker Compose files (all with a .yml extension). The name of the file will suggest the type of EdgeX instance the Compose file will help setup. The table below provides a list of the Docker Compose filenames for the latest release (Geneva). Find the Docker Compose file that matches: your hardware (x86 or ARM) the database you want to use (Mongo or Redis) your desire to have security services on or off filename Docker Compose contents docker-compose-geneva-mongo-arm64.yml Specifies ARM 64 containers, uses Mongo database for persistence, and includes security services docker-compose-geneva-mongo-no-secty-arm64.yml Specifies x86 containers, uses Mongo database for persistence, but does not include security services docker-compose-geneva-mongo-no-secty.yml Specifies x86 containers, uses Mongo database for persistence, but does not include security services docker-compose-geneva-mongo.yml Specifies x86 containers, uses Mongo database for persistence, and includes security services docker-compose-geneva-redis-arm64.yml Specifies x86 containers, uses Redis database for persistence, and includes security services docker-compose-geneva-redis-no-secty-arm64.yml Specifies ARM 64 containers, uses Redis database for persistence, but does not include security services docker-compose-geneva-redis-no-secty.yml Specifies x86 containers, uses Redis database for persistence, but does not include security services docker-compose-geneva-redis.yml Specifies x86 containers, uses Redis database for persistence, and includes security services docker-compose-geneva-ui-arm64. Specifies the EdgeX user interface extension to be used with the ARM 64 EdgeX platform docker-compose-geneva-ui.yml Specifies the EdgeX user interface extension to be used with the x86 EdgeX platform docker-compose-portainer.yml Specifies the Portainer user interface extension (to be used with the x86 or ARM EdgeX platform) Info Unsure which Docker Compose file to use? The EdgeX community recommends you use the Reds, no security Docker Compose file for your architecture to start. As you learn about EdgeX, you can incorporate security elements. The Mongo database is being archived with the next release. Download a EdgeX Foundry Compose File Once you have selected the EdgeX Compose file you want to use, download it using your favorite tool. The examples below uses wget to fetch Docker Compose for the Geneva release, no security, Redis database. x86 wget https://raw.githubusercontent.com/edgexfoundry/developer-scripts/master/releases/geneva/compose-files/docker-compose-geneva-redis-no-secty.yml -O docker-compose.yml ARM wget https://raw.githubusercontent.com/edgexfoundry/developer-scripts/master/releases/geneva/compose-files/docker-compose-geneva-mongo-no-secty-arm64.yml -O docker-compose.yml Note The commands above fetch the Docker Compose to a file named 'docker-compose.yml' in the current directory. Docker Compose commands look for a file named 'docker-compose.yml' by default. You can use an alternate file name but then must specify that file name when issuing Docker Compose commands. See Compose reference documentation for help. Run EdgeX Foundry Now that you have the EdgeX Docker Compose file, you are ready to run EdgeX. Follow these steps to get the container images and start EdgeX! In a command terminal, change directories to the location of your docker-compose.yml. Run the following command in the terminal to pull (fetch) and then start the EdgeX containers. docker-compose up -d Info If you wish, you can fetch the images first and then run them. This allows you to make sure the EdgeX images you need are all available before trying to run. docker-compose pull docker-compose up -d Note The -d option indicates you want the Docker Compose to run the EdgeX containers in detached mode - that is to run the containers in the background. Without -d, the containers will all start in the terminal and to use the terminal further you have to stop the containers. Verify EdgeX Foundry Running In the same terminal, run the process status command shown below to confirm that all the containers downloaded and started. docker-compose ps If all EdgeX containers pulled and started correctly and without error, you should see a process status (ps) that looks similar to the image above. Checking the Status of EdgeX Foundry In addition to the process status of the EdgeX containers, there are a number of other tools to check on the healt and status of your EdgeX instance. EdgeX Foundry Container Logs Use the command below to see log of any service. # see the logs of a service docker-compose logs -f [ compose-service-name ] # example - core data docker-compose logs -f data See EdgeX Container Names for a list of the EdgeX Docker Compose service names. A check of an EdgeX service log usually indicates if the service is running normally or has errors. When you are done reviewing the content of the log, select Control-c to stop the output to your terminal. Ping Check Each EdgeX micro service has a built-in respond to a \"ping\" HTTP request. In networking environments, use a ping request to check the reach-ability of a network resource. EdgeX uses the same concept to check the availability or reach-ability of a micro service. After the EdgeX micro service containers are running, you can \"ping\" any one of the micro services to check that it is running. Open a browser or HTTP REST client tool and use the service's ping address (outlined below) to check that is available. http://localhost:[port]/api/v1/ping See EdgeX Device Service Ports for a list of the EdgeX default service ports. \"Pinging\" an EdgeX micro service allows you to check on its availability. If the service does not respond to ping, the service is down or having issues. Consul Registry Check EdgeX uses the open source Consul project as its registry service. All EdgeX micro services are expected to register with Consul as they start. Going to Consul's dashboard UI enables you to see which services are up. Find the Consul UI at http://localhost:8500/ui .","title":"Getting Started with Docker"},{"location":"getting-started/Ch-GettingStartedUsers/#getting-started-with-docker","text":"","title":"Getting Started with Docker"},{"location":"getting-started/Ch-GettingStartedUsers/#introduction","text":"These instructions are for Users to get and run EdgeX Foundry. (Developers should read: Getting Started Developers ) EdgeX is a collection of more than a dozen micro services that are deployed to provide a minimal edge platform capability. You can download EdgeX micro service source code and build your own micro services. However, if you do not have a need to change or add to EdgeX, then you do not need to download source code. Instead, Users run EdgeX micro service Docker containers. The EdgeX community builds and creates Docker container images with each release.","title":"Introduction"},{"location":"getting-started/Ch-GettingStartedUsers/#get-run-edgex-foundry","text":"","title":"Get &amp; Run EdgeX Foundry"},{"location":"getting-started/Ch-GettingStartedUsers/#install-docker-docker-compose","text":"To run Dockerized EdgeX, you need to install Docker. See https://docs.docker.com/install/ to learn how to install Docker. If you are new to Docker, the same web site provides you educational information. The following short video is also very informative https://www.youtube.com/watch?time_continue=3&v=VhabrYF1nms Use Docker Compose to orchestrate the fetch (or pull), install, and start the EdgeX micro service containers. Also use Docker Compose to stop the micro service containers. See: https://docs.docker.com/compose/ to learn more about Docker Compose. You do not need to be an expert with Docker (or Docker Compose) to get and run EdgeX. This guide provides the steps to get EdgeX running in your environment. Some knowledge of Docker and Docker Compose are nice to have, but not required. Basic Docker and Docker Compose commands provided here enable you to run, update, and diagnose issues within EdgeX.","title":"Install Docker &amp; Docker Compose"},{"location":"getting-started/Ch-GettingStartedUsers/#select-a-edgex-foundry-compose-file","text":"After installing Docker and Docker Compose, you need a EdgeX Docker Compose file. EdgeX Foundry has over a dozen micro services, each deployed in its own Docker container. This file is a manifest of all the EdgeX Foundry micro services to run. The Docker Compose file provides details about how to run each of the services. Specifically, a Docker Compose file is a manifest file, which lists: The Docker container images that should be downloaded, The order in which the containers should be started, The parameters (such as ports) under which the containers should be run The EdgeX development team provides Docker Compose files for each release. Visit the project GitHub and locate the EdgeX Docker Compose file for the version of EdgeX you want to run. The EdgeX Developer Scripts repository contains a folder for each release. In the folder, find the Docker Compose files for each release. Note At the GitHub location specified above there is a folder for each EdgeX release. The nightly-build folder contains Docker Compose files that use artifacts created from the latest code submitted by contributors. Most end users should avoid using these Docker Compose files. They are work-in-progress. Users should use the Docker Compose files for the latest version of EdgeX. In each folder, you will find several Docker Compose files (all with a .yml extension). The name of the file will suggest the type of EdgeX instance the Compose file will help setup. The table below provides a list of the Docker Compose filenames for the latest release (Geneva). Find the Docker Compose file that matches: your hardware (x86 or ARM) the database you want to use (Mongo or Redis) your desire to have security services on or off filename Docker Compose contents docker-compose-geneva-mongo-arm64.yml Specifies ARM 64 containers, uses Mongo database for persistence, and includes security services docker-compose-geneva-mongo-no-secty-arm64.yml Specifies x86 containers, uses Mongo database for persistence, but does not include security services docker-compose-geneva-mongo-no-secty.yml Specifies x86 containers, uses Mongo database for persistence, but does not include security services docker-compose-geneva-mongo.yml Specifies x86 containers, uses Mongo database for persistence, and includes security services docker-compose-geneva-redis-arm64.yml Specifies x86 containers, uses Redis database for persistence, and includes security services docker-compose-geneva-redis-no-secty-arm64.yml Specifies ARM 64 containers, uses Redis database for persistence, but does not include security services docker-compose-geneva-redis-no-secty.yml Specifies x86 containers, uses Redis database for persistence, but does not include security services docker-compose-geneva-redis.yml Specifies x86 containers, uses Redis database for persistence, and includes security services docker-compose-geneva-ui-arm64. Specifies the EdgeX user interface extension to be used with the ARM 64 EdgeX platform docker-compose-geneva-ui.yml Specifies the EdgeX user interface extension to be used with the x86 EdgeX platform docker-compose-portainer.yml Specifies the Portainer user interface extension (to be used with the x86 or ARM EdgeX platform) Info Unsure which Docker Compose file to use? The EdgeX community recommends you use the Reds, no security Docker Compose file for your architecture to start. As you learn about EdgeX, you can incorporate security elements. The Mongo database is being archived with the next release.","title":"Select a EdgeX Foundry Compose File"},{"location":"getting-started/Ch-GettingStartedUsers/#download-a-edgex-foundry-compose-file","text":"Once you have selected the EdgeX Compose file you want to use, download it using your favorite tool. The examples below uses wget to fetch Docker Compose for the Geneva release, no security, Redis database. x86 wget https://raw.githubusercontent.com/edgexfoundry/developer-scripts/master/releases/geneva/compose-files/docker-compose-geneva-redis-no-secty.yml -O docker-compose.yml ARM wget https://raw.githubusercontent.com/edgexfoundry/developer-scripts/master/releases/geneva/compose-files/docker-compose-geneva-mongo-no-secty-arm64.yml -O docker-compose.yml Note The commands above fetch the Docker Compose to a file named 'docker-compose.yml' in the current directory. Docker Compose commands look for a file named 'docker-compose.yml' by default. You can use an alternate file name but then must specify that file name when issuing Docker Compose commands. See Compose reference documentation for help.","title":"Download a EdgeX Foundry Compose File"},{"location":"getting-started/Ch-GettingStartedUsers/#run-edgex-foundry","text":"Now that you have the EdgeX Docker Compose file, you are ready to run EdgeX. Follow these steps to get the container images and start EdgeX! In a command terminal, change directories to the location of your docker-compose.yml. Run the following command in the terminal to pull (fetch) and then start the EdgeX containers. docker-compose up -d Info If you wish, you can fetch the images first and then run them. This allows you to make sure the EdgeX images you need are all available before trying to run. docker-compose pull docker-compose up -d Note The -d option indicates you want the Docker Compose to run the EdgeX containers in detached mode - that is to run the containers in the background. Without -d, the containers will all start in the terminal and to use the terminal further you have to stop the containers.","title":"Run EdgeX Foundry"},{"location":"getting-started/Ch-GettingStartedUsers/#verify-edgex-foundry-running","text":"In the same terminal, run the process status command shown below to confirm that all the containers downloaded and started. docker-compose ps If all EdgeX containers pulled and started correctly and without error, you should see a process status (ps) that looks similar to the image above.","title":"Verify EdgeX Foundry Running"},{"location":"getting-started/Ch-GettingStartedUsers/#checking-the-status-of-edgex-foundry","text":"In addition to the process status of the EdgeX containers, there are a number of other tools to check on the healt and status of your EdgeX instance.","title":"Checking the Status of EdgeX Foundry"},{"location":"getting-started/Ch-GettingStartedUsers/#edgex-foundry-container-logs","text":"Use the command below to see log of any service. # see the logs of a service docker-compose logs -f [ compose-service-name ] # example - core data docker-compose logs -f data See EdgeX Container Names for a list of the EdgeX Docker Compose service names. A check of an EdgeX service log usually indicates if the service is running normally or has errors. When you are done reviewing the content of the log, select Control-c to stop the output to your terminal.","title":"EdgeX Foundry Container Logs"},{"location":"getting-started/Ch-GettingStartedUsers/#ping-check","text":"Each EdgeX micro service has a built-in respond to a \"ping\" HTTP request. In networking environments, use a ping request to check the reach-ability of a network resource. EdgeX uses the same concept to check the availability or reach-ability of a micro service. After the EdgeX micro service containers are running, you can \"ping\" any one of the micro services to check that it is running. Open a browser or HTTP REST client tool and use the service's ping address (outlined below) to check that is available. http://localhost:[port]/api/v1/ping See EdgeX Device Service Ports for a list of the EdgeX default service ports. \"Pinging\" an EdgeX micro service allows you to check on its availability. If the service does not respond to ping, the service is down or having issues.","title":"Ping Check"},{"location":"getting-started/Ch-GettingStartedUsers/#consul-registry-check","text":"EdgeX uses the open source Consul project as its registry service. All EdgeX micro services are expected to register with Consul as they start. Going to Consul's dashboard UI enables you to see which services are up. Find the Consul UI at http://localhost:8500/ui .","title":"Consul Registry Check"},{"location":"getting-started/Ch-GettingStartedUsersNexus/","text":"Getting Docker Images from EdgeX Nexus Repository Released EdgeX Docker container images are available from Docker Hub . In some cases, it may be necessary to get your EdgeX container images from the Nexus repository. The Linux Foundation manages the Nexus repository for the project. Nexus contains the EdgeX project staging and development container images. In other words, Nexus contains work-in-progress or pre-release images. These, pre-release/work-in-progress Docker images are built nightly and made available at the following Nexus location: nexus3.edgexfoundry.org:10004 Rationale To Use Nexus Images Reasons you might want to use container images from Nexus include: The container is not available from Docker Hub (or Docker Hub is down temporarily) You need the latest development container image (the work in progress) You are working in a Windows or non-Linux environment and you are unable to build a container without some issues. A set of Docker Compose files have been created to allow you to get and use the latest EdgeX service images from Nexus. Find these Nexus \"Nightly Build\" Compose files in GitHub. The EdgeX development team provides these Docker Compose files. As with the EdgeX release Compose files, you will find several different Docker Compose files that allow you to get the type of EdgeX instance setup based on: your hardware (x86 or ARM) the database you want to use (Mongo or Redis) your desire to have security services on or off Warning The \"Nightly Build\" images are provided as is and may not always function properly or with other EdgeX services. Use with caution and typically only if you are a developer/contributor to EdgeX. These images represent the latest development work and may not have been thoroughly tested or integrated. Using Nexus Images The operations to pull the images and run the Nexus Repository is the same as when using EdgeX images from Docker Hub (see Getting Started with Docker ). To get containers from the Nexus Repository, in a command terminal, change directories to the location of your downloaded Nexus Docker Compose yaml. Rename the file to docker-compose.yml. Then run the following command in the terminal to pull (fetch) and then start the EdgeX Nexus-image containers. docker-compose up -d Using a Single Nexus Image In some cases, you may only need to use a single image from Nexus while other EdgeX services are created from the Docker Hub images. In this case, you can simply replace the image location for the selected image in your original Docker Compose file. The address of Nexus is nexus3.edgexfoundry.org at port 10004 . So, if you wished to use the EdgeX core data image from Nexus, you would replace the name and location of the core data image \"edgexfoundry/docker-core-data-go:1.2.1\" with \"nexus3.edgexfoundry.org:10004/docker-core-data-go:master\" in the Compose file. Note The example above replaces the Geneva core data service from Docker Hub with the latest core data image in Nexus.","title":"Getting Docker Images from EdgeX Nexus Repository"},{"location":"getting-started/Ch-GettingStartedUsersNexus/#getting-docker-images-from-edgex-nexus-repository","text":"Released EdgeX Docker container images are available from Docker Hub . In some cases, it may be necessary to get your EdgeX container images from the Nexus repository. The Linux Foundation manages the Nexus repository for the project. Nexus contains the EdgeX project staging and development container images. In other words, Nexus contains work-in-progress or pre-release images. These, pre-release/work-in-progress Docker images are built nightly and made available at the following Nexus location: nexus3.edgexfoundry.org:10004","title":"Getting Docker Images from EdgeX Nexus Repository"},{"location":"getting-started/Ch-GettingStartedUsersNexus/#rationale-to-use-nexus-images","text":"Reasons you might want to use container images from Nexus include: The container is not available from Docker Hub (or Docker Hub is down temporarily) You need the latest development container image (the work in progress) You are working in a Windows or non-Linux environment and you are unable to build a container without some issues. A set of Docker Compose files have been created to allow you to get and use the latest EdgeX service images from Nexus. Find these Nexus \"Nightly Build\" Compose files in GitHub. The EdgeX development team provides these Docker Compose files. As with the EdgeX release Compose files, you will find several different Docker Compose files that allow you to get the type of EdgeX instance setup based on: your hardware (x86 or ARM) the database you want to use (Mongo or Redis) your desire to have security services on or off Warning The \"Nightly Build\" images are provided as is and may not always function properly or with other EdgeX services. Use with caution and typically only if you are a developer/contributor to EdgeX. These images represent the latest development work and may not have been thoroughly tested or integrated.","title":"Rationale To Use Nexus Images"},{"location":"getting-started/Ch-GettingStartedUsersNexus/#using-nexus-images","text":"The operations to pull the images and run the Nexus Repository is the same as when using EdgeX images from Docker Hub (see Getting Started with Docker ). To get containers from the Nexus Repository, in a command terminal, change directories to the location of your downloaded Nexus Docker Compose yaml. Rename the file to docker-compose.yml. Then run the following command in the terminal to pull (fetch) and then start the EdgeX Nexus-image containers. docker-compose up -d","title":"Using Nexus Images"},{"location":"getting-started/Ch-GettingStartedUsersNexus/#using-a-single-nexus-image","text":"In some cases, you may only need to use a single image from Nexus while other EdgeX services are created from the Docker Hub images. In this case, you can simply replace the image location for the selected image in your original Docker Compose file. The address of Nexus is nexus3.edgexfoundry.org at port 10004 . So, if you wished to use the EdgeX core data image from Nexus, you would replace the name and location of the core data image \"edgexfoundry/docker-core-data-go:1.2.1\" with \"nexus3.edgexfoundry.org:10004/docker-core-data-go:master\" in the Compose file. Note The example above replaces the Geneva core data service from Docker Hub with the latest core data image in Nexus.","title":"Using a Single Nexus Image"},{"location":"getting-started/quick-start/","text":"Quick Start This guide will get EdgeX up and running on your machine in as little as 5 minutes. We will skip over lengthy descriptions for now. The goal here is to get you a working IoT Edge stack, from device to cloud, as simply as possible. When you need more detailed instructions or a breakdown of some of the commands you see in this quick start, see either the Getting Started- Users or Getting Started - Developers guides. Setup The fastest way to start running EdgeX is by using our pre-built Docker images. To use them you'll need to install the following: Docker https://docs.docker.com/install/ Docker Compose https://docs.docker.com/compose/install/ Running EdgeX Once you have Docker and Docker Compose installed, you need to: download / save the latest docker-compose file issue command to download and run the EdgeX Foundry Docker images from Docker Hub This can be accomplished with a single command as shown below (please note the tabs for x86 vs ARM architectures). x86 curl https://raw.githubusercontent.com/edgexfoundry/developer-scripts/master/releases/geneva/compose-files/docker-compose-geneva-redis-no-secty.yml -o docker-compose.yml; docker-compose up ARM curl https://raw.githubusercontent.com/edgexfoundry/developer-scripts/master/releases/geneva/compose-files/docker-compose-geneva-redis-no-secty-arm64.yml -o docker-compose.yml; docker-compose up Verify that the EdgeX containers have started: docker-compose ps If all EdgeX containers pulled and started correctly and without error, you should see a process status (ps) that looks similar to the image above. Connecting a Device EdgeX Foundry provides a Random Number device service which is useful to testing, it returns a random number within a configurable range. Configuration for running this service is in the docker-compose.yml file you downloaded at the start of this guide, but it is disabled by default. To enable it, uncomment the following lines in your docker-compose.yml : device-random : image : edgexfoundry/docker-device-random-go:1.2.1 ports : - \"127.0.0.1:49988:49988\" container_name : edgex-device-random hostname : edgex-device-random networks : - edgex-network environment : << : *common-variables Service_Host : edgex-device-random depends_on : - data - command Then you can start the Random device service with: docker-compose up -d device-random The device service will register a device named Random-Integer-Generator01 , which will start sending its random number readings into EdgeX. You can verify that those readings are being sent by querying the EdgeX core data service for the last 10 event records sent for Random-Integer-Generator01: curl http://localhost:48080/api/v1/event/device/Random-Integer-Generator01/10 Verify the random device service is operating correctly by requesting the last 10 event records received by core data for the Random-Integer-Generator device. Controlling the Device Reading data from devices is only part of what EdgeX is capable of. You can also use it to control your devices - this is termed 'actuating' the device. When a device registers with the EdgeX services, it provides a Device Profile that describes both the data readings available from that device, and also the commands that control it. When our Random Number device service registered the device Random-Integer-Generator01 , it used a profile which defines commands for changing the minimum and maximum values for the random numbers it will generate. Note The URLs won't be exactly the same for you, as the generated unique IDs for both the Device and the Command will be different. So be sure to use your values for the following steps. Warning Notice that localhost replaces edgex-core-command here. That's because the EdgeX Foundry services are running in Docker. Docker recognizes the internal hostname edgex-core-command , but when calling the service from outside of Docker, you have to use localhost to reach it. This command will return a JSON result that looks like this: { \"device\" : \"Random-Integer-Generator01\" , \"origin\" : 1592231895237359000 , \"readings\" : [ { \"origin\" : 1592231895237098000 , \"device\" : \"Random-Integer-Generator01\" , \"name\" : \"RandomValue_Int8\" , \"value\" : \"-45\" , \"valueType\" : \"Int8\" } ], \"EncodedEvent\" : null } A call to GET of the Random-Integer-Generator01 device's GenerateRandomValue_Int8 operation through the command service results in the next random value produced by the device in JSON format. Warning Again, also notice that localhost replaces edgex-core-command . There is no visible result of calling PUT if the call is successful. A call to the device's PUT command through the command service will return no results. Now every time we call GET on this command, the returned value will be between 0 and 100. Exporting Data EdgeX provides exporters (called application services) for a variety of cloud services and applications. To keep this guide simple, we're going to use the community provided 'application service configurable' to send the EdgeX data to a public MQTT broker hosted by HiveMQ. You can then watch for the EdgeX event data via HiveMQ provided MQTT browser client. First add the following application service to your docker-compose.yml file right after the 'rulesengine' service (around line 255). Spacing is important in YAML, so make sure to copy and paste it correctly. app-service-mqtt : image : edgexfoundry/docker-app-service-configurable:1.1.0 ports : - \"127.0.0.1:48101:48101\" container_name : edgex-app-service-configurable-mqtt hostname : edgex-app-service-configurable-mqtt networks : - edgex-network environment : << : *common-variables edgex_profile : mqtt-export Service_Host : edgex-app-service-configurable-mqtt Service_Port : 48101 MessageBus_SubscribeHost_Host : edgex-core-data Binding_PublishTopic : events Writable_Pipeline_Functions_MQTTSend_Addressable_Address : broker.mqttdashboard.com Writable_Pipeline_Functions_MQTTSend_Addressable_Port : 1883 Writable_Pipeline_Functions_MQTTSend_Addressable_Protocol : tcp Writable_Pipeline_Functions_MQTTSend_Addressable_Publisher : edgex Writable_Pipeline_Functions_MQTTSend_Addressable_Topic : EdgeXEvents depends_on : - consul - data Note This adds the application service configurable to your EdgeX system. The application service configurable allows you to configure (versus program) new exports - in this case exporting the EdgeX sensor data to the HiveMQ broker at broker.mqttdashboard.com port 1883. You will be publishing to EdgeXEvents topic. Save the compose file and then execute another compose up command to have Docker Compose pull and start the configurable application service. docker-compose up -d You can connect to this broker with any MQTT client to watch the sent data. HiveMQ provides a web-based client that you can use. Use a browser to go to the client's URL. Once there, hit the Connect button to connect to the HiveMQ public broker. Using the HiveMQ provided client tool, connect to the same public HiveMQ broker your configurable application service is sending EdgeX data to. Then, use the Subscriptions area to subscribe to the \"EdgeXEvents\" topic. You must subscribe to the same topic - EdgeXEvents - to see the EdgeX data sent by the configurable application service. You will begin seeing your random number readings appear in the Messages area on the screen. Once subscribed, the EdgeX event data will begin to appear in the Messages area on the browser screen. Next Steps Congratulations! You now have a full EdgeX deployment reading data from a (virtual) device and publishing it to an MQTT broker in the cloud, and you were able to control your device through commands into EdgeX. It's time to continue your journey by reading the Introduction to EdgeX Foundry, what it is and how it's built. From there you can take the Walkthrough to learn how the microservices work together to control devices and read data from them as you just did.","title":"Quick Start"},{"location":"getting-started/quick-start/#quick-start","text":"This guide will get EdgeX up and running on your machine in as little as 5 minutes. We will skip over lengthy descriptions for now. The goal here is to get you a working IoT Edge stack, from device to cloud, as simply as possible. When you need more detailed instructions or a breakdown of some of the commands you see in this quick start, see either the Getting Started- Users or Getting Started - Developers guides.","title":"Quick Start"},{"location":"getting-started/quick-start/#setup","text":"The fastest way to start running EdgeX is by using our pre-built Docker images. To use them you'll need to install the following: Docker https://docs.docker.com/install/ Docker Compose https://docs.docker.com/compose/install/","title":"Setup"},{"location":"getting-started/quick-start/#running-edgex","text":"Once you have Docker and Docker Compose installed, you need to: download / save the latest docker-compose file issue command to download and run the EdgeX Foundry Docker images from Docker Hub This can be accomplished with a single command as shown below (please note the tabs for x86 vs ARM architectures). x86 curl https://raw.githubusercontent.com/edgexfoundry/developer-scripts/master/releases/geneva/compose-files/docker-compose-geneva-redis-no-secty.yml -o docker-compose.yml; docker-compose up ARM curl https://raw.githubusercontent.com/edgexfoundry/developer-scripts/master/releases/geneva/compose-files/docker-compose-geneva-redis-no-secty-arm64.yml -o docker-compose.yml; docker-compose up Verify that the EdgeX containers have started: docker-compose ps If all EdgeX containers pulled and started correctly and without error, you should see a process status (ps) that looks similar to the image above.","title":"Running EdgeX"},{"location":"getting-started/quick-start/#connecting-a-device","text":"EdgeX Foundry provides a Random Number device service which is useful to testing, it returns a random number within a configurable range. Configuration for running this service is in the docker-compose.yml file you downloaded at the start of this guide, but it is disabled by default. To enable it, uncomment the following lines in your docker-compose.yml : device-random : image : edgexfoundry/docker-device-random-go:1.2.1 ports : - \"127.0.0.1:49988:49988\" container_name : edgex-device-random hostname : edgex-device-random networks : - edgex-network environment : << : *common-variables Service_Host : edgex-device-random depends_on : - data - command Then you can start the Random device service with: docker-compose up -d device-random The device service will register a device named Random-Integer-Generator01 , which will start sending its random number readings into EdgeX. You can verify that those readings are being sent by querying the EdgeX core data service for the last 10 event records sent for Random-Integer-Generator01: curl http://localhost:48080/api/v1/event/device/Random-Integer-Generator01/10 Verify the random device service is operating correctly by requesting the last 10 event records received by core data for the Random-Integer-Generator device.","title":"Connecting a Device"},{"location":"getting-started/quick-start/#controlling-the-device","text":"Reading data from devices is only part of what EdgeX is capable of. You can also use it to control your devices - this is termed 'actuating' the device. When a device registers with the EdgeX services, it provides a Device Profile that describes both the data readings available from that device, and also the commands that control it. When our Random Number device service registered the device Random-Integer-Generator01 , it used a profile which defines commands for changing the minimum and maximum values for the random numbers it will generate. Note The URLs won't be exactly the same for you, as the generated unique IDs for both the Device and the Command will be different. So be sure to use your values for the following steps. Warning Notice that localhost replaces edgex-core-command here. That's because the EdgeX Foundry services are running in Docker. Docker recognizes the internal hostname edgex-core-command , but when calling the service from outside of Docker, you have to use localhost to reach it. This command will return a JSON result that looks like this: { \"device\" : \"Random-Integer-Generator01\" , \"origin\" : 1592231895237359000 , \"readings\" : [ { \"origin\" : 1592231895237098000 , \"device\" : \"Random-Integer-Generator01\" , \"name\" : \"RandomValue_Int8\" , \"value\" : \"-45\" , \"valueType\" : \"Int8\" } ], \"EncodedEvent\" : null } A call to GET of the Random-Integer-Generator01 device's GenerateRandomValue_Int8 operation through the command service results in the next random value produced by the device in JSON format. Warning Again, also notice that localhost replaces edgex-core-command . There is no visible result of calling PUT if the call is successful. A call to the device's PUT command through the command service will return no results. Now every time we call GET on this command, the returned value will be between 0 and 100.","title":"Controlling the Device"},{"location":"getting-started/quick-start/#exporting-data","text":"EdgeX provides exporters (called application services) for a variety of cloud services and applications. To keep this guide simple, we're going to use the community provided 'application service configurable' to send the EdgeX data to a public MQTT broker hosted by HiveMQ. You can then watch for the EdgeX event data via HiveMQ provided MQTT browser client. First add the following application service to your docker-compose.yml file right after the 'rulesengine' service (around line 255). Spacing is important in YAML, so make sure to copy and paste it correctly. app-service-mqtt : image : edgexfoundry/docker-app-service-configurable:1.1.0 ports : - \"127.0.0.1:48101:48101\" container_name : edgex-app-service-configurable-mqtt hostname : edgex-app-service-configurable-mqtt networks : - edgex-network environment : << : *common-variables edgex_profile : mqtt-export Service_Host : edgex-app-service-configurable-mqtt Service_Port : 48101 MessageBus_SubscribeHost_Host : edgex-core-data Binding_PublishTopic : events Writable_Pipeline_Functions_MQTTSend_Addressable_Address : broker.mqttdashboard.com Writable_Pipeline_Functions_MQTTSend_Addressable_Port : 1883 Writable_Pipeline_Functions_MQTTSend_Addressable_Protocol : tcp Writable_Pipeline_Functions_MQTTSend_Addressable_Publisher : edgex Writable_Pipeline_Functions_MQTTSend_Addressable_Topic : EdgeXEvents depends_on : - consul - data Note This adds the application service configurable to your EdgeX system. The application service configurable allows you to configure (versus program) new exports - in this case exporting the EdgeX sensor data to the HiveMQ broker at broker.mqttdashboard.com port 1883. You will be publishing to EdgeXEvents topic. Save the compose file and then execute another compose up command to have Docker Compose pull and start the configurable application service. docker-compose up -d You can connect to this broker with any MQTT client to watch the sent data. HiveMQ provides a web-based client that you can use. Use a browser to go to the client's URL. Once there, hit the Connect button to connect to the HiveMQ public broker. Using the HiveMQ provided client tool, connect to the same public HiveMQ broker your configurable application service is sending EdgeX data to. Then, use the Subscriptions area to subscribe to the \"EdgeXEvents\" topic. You must subscribe to the same topic - EdgeXEvents - to see the EdgeX data sent by the configurable application service. You will begin seeing your random number readings appear in the Messages area on the screen. Once subscribed, the EdgeX event data will begin to appear in the Messages area on the browser screen.","title":"Exporting Data"},{"location":"getting-started/quick-start/#next-steps","text":"Congratulations! You now have a full EdgeX deployment reading data from a (virtual) device and publishing it to an MQTT broker in the cloud, and you were able to control your device through commands into EdgeX. It's time to continue your journey by reading the Introduction to EdgeX Foundry, what it is and how it's built. From there you can take the Walkthrough to learn how the microservices work together to control devices and read data from them as you just did.","title":"Next Steps"},{"location":"microservices/application/AdvancedTopics/","text":"Advanced Topics The following items discuss topics that are a bit beyond the basic use cases of the Application Functions SDK when interacting with EdgeX. Configurable Functions Pipeline This SDK provides the capability to define the functions pipeline via configuration rather than code by using the app-service-configurable application service. See the App Service Configurable section for more details. Using The Webserver It is not uncommon to require your own API endpoints when building an app service. Rather than spin up your own webserver inside of your app (alongside the already existing running webserver), we've exposed a method that allows you add your own routes to the existing webserver. A few routes are reserved and cannot be used: /api/version /api/v1/ping /api/v1/metrics /api/v1/config /api/v1/trigger /api/v1/secrets To add your own route, use the AddRoute(route string, handler func(nethttp.ResponseWriter, *nethttp.Request), methods ...string) error function provided on the SDK. Here's an example: edgexSdk . AddRoute ( \"/myroute\" , func ( writer http . ResponseWriter , req * http . Request ) { context := req . Context (). Value ( appsdk . SDKKey ).( * appsdk . AppFunctionsSDK ) context . LoggingClient . Info ( \"TEST\" ) // alternative to edgexSdk.LoggingClient.Info(\"TEST\") writer . Header (). Set ( \"Content-Type\" , \"text/plain\" ) writer . Write ([] byte ( \"hello\" )) writer . WriteHeader ( 200 ) }, \"GET\" ) Under the hood, this simply adds the provided route, handler, and method to the gorilla mux.Router we use in the SDK. For more information on gorilla mux you can check out the github repo here . You can access the resources such as the logging client by accessing the context as shown above -- this is useful for when your routes might not be defined in your main.go where you have access to the edgexSdk instance. Target Type The target type is the object type of the incoming data that is sent to the first function in the function pipeline. By default this is an EdgeX Event since typical usage is receiving events from Core Data via Message Bus. For other usages where the data is not events coming from Core Data, the TargetType of the accepted incoming data can be set when the SDK instance is created. There are scenarios where the incoming data is not an EdgeX Event . One example scenario is 2 application services are chained via the Message Bus. The output of the first service back to the Message Bus is inference data from analyzing the original input Event data. The second service needs to be able to let the SDK know the target type of the input data it is expecting. For usages where the incoming data is not events , the TargetType of the excepted incoming data can be set when the SDK instance is created. Example: type Person struct { FirstName string `json:\"first_name\"` LastName string `json:\"last_name\"` } edgexSdk := & appsdk . AppFunctionsSDK { ServiceKey : serviceKey , TargetType : & Person {}, } TargetType must be set to a pointer to an instance of your target type such as &Person{} . The first function in your function pipeline will be passed an instance of your target type, not a pointer to it. In the example above, the first function in the pipeline would start something like: func MyPersonFunction ( edgexcontext * appcontext . Context , params ... interface {}) ( bool , interface {}) { edgexcontext . LoggingClient . Debug ( \"MyPersonFunction\" ) if len ( params ) < 1 { // We didn't receive a result return false , nil } person , ok := params [ 0 ].( Person ) if ! ok { return false , errors . New ( \"type received is not a Person\" ) } // .... The SDK supports un-marshaling JSON or CBOR encoded data into an instance of the target type. If your incoming data is not JSON or CBOR encoded, you then need to set the TargetType to &[]byte . If the target type is set to &[]byte the incoming data will not be un-marshaled. The content type, if set, will be passed as the second parameter to the first function in your pipeline. Your first function will be responsible for decoding the data or not. Command Line Options The following command line options are available -c=<path> --confdir=<path> Specify an alternate configuration directory. -p=<profile> --profile=<profile> Specify a profile other than default. -f, --file <name> Indicates name of the local configuration file. Defaults to configuration.toml -cp=<url> --configProvider=<url> Indicates to use Configuration Provider service at specified URL. URL Format: {type}.{protocol}://{host}:{port} ex: consul.http://localhost:8500 No url, i.e. -cp, defaults to consul.http://localhost:8500 -o -overwrite Force overwrite configuration in the Configuration Provider with local values. -r --registry Indicates the service should use the service Registry. -s -skipVersionCheck Indicates the service should skip the Core Service's version compatibility check. -sk --serviceKey Overrides the service key used with Registry and/or Configuration Providers. If the name provided contains the text `<profile>`, this text will be replaced with the name of the profile used. Examples: simple-filter-xml -c = ./res -p = http-export or simple-filter-xml --confdir = ./res -p = http-export -cp = consul.http://localhost:8500 --registry Environment Variable Overrides All the configuration settings from the configuration.toml file can be overridden by environment variables. The environment variable names have the following format: < TOML KEY > < TOML SECTION > _ < TOML KEY > < TOML SECTION > _ < TOML SUB-SECTION > _ < TOML KEY > Note With the Geneva release CamelCase environment variable names are deprecated. Instead use all uppercase environment variable names as in the example below. Examples: TOML : FailLimit = 30 ENVVAR : FAILLIMIT = 100 TOML : [Logging] EnableRemote = false ENVVAR : LOGGING_ENABLEREMOTE = true TOML : [Clients] [Clients.CoreData] Host = 'localhost' ENVVAR : CLIENTS_COREDATA_HOST = edgex-core-data EDGEX_SERVICE_KEY This environment variable overrides the service key used with the Configuration and/or Registry providers. Default is set by the application service. Also overrides any value set with the -sk/--serviceKey command-line option. Note If the name provided contains the text <profile> , this text will be replaced with the name of the profile used. Example EDGEX_SERVICE_KEY: AppService-<profile>-mycloud and if profile: http-export then service key will be \"AppService-http-export-mycloud\" EDGEX_CONFIGURATION_PROVIDER This environment variable overrides the Configuration Provider connection information. The value is in the format of a URL. EDGEX_CONFIGURATION_PROVIDER=consul.http://edgex-core-consul:8500 This sets the Configration Provider information fields as follows: Type: consul Host: edgex-core-consul Port: 8500 edgex_registry (DEPRECATED) This environment variable overrides the Registry connection information and occurs every time the application service starts. The value is in the format of a URL. Note This environment variable override has been deprecated in the Geneva Release. Instead, use configuration overrides of REGISTRY_PROTOCOL and/or REGISTRY_HOST and/or REGISTRY_PORT EDGEX_REGISTRY=consul://edgex-core-consul:8500 This sets the Registry information fields as follows: Type: consul Host: edgex-core-consul Port: 8500 edgex_service (DEPRECATED) This environment variable overrides the Service connection information. The value is in the format of a URL. Note This environment variable override has been deprecated in the Geneva Release. Instead, use configuration overrides of SERVICE_PROTOCOL and/or SERVICE_HOST and/or SERVICE_PORT EDGEX_SERVICE=http://192.168.1.2:4903 This sets the Service information fields as follows: Protocol: http Host: 192.168.1.2 Port: 4903 EDGEX_PROFILE This environment variable overrides the command line profile argument. It will set the profile or replace the value passed via the -p or --profile , if one exists. This is useful when running the service via docker-compose. Note The lower case version has been deprecated in the Geneva release. Instead use upper case version EDGEX_PROFILE Using docker-compose: app-service-configurable-rules: image: edgexfoundry/docker-app-service-configurable:1.1.0 environment: - EDGEX_PROFILE : \"rules-engine\" ports: - \"48095:48095\" container_name: edgex-app-service-configurable hostname: edgex-app-service-configurable networks: edgex-network: aliases: - edgex-app-service-configurable depends_on: - data - command This sets the profile so that the application service uses the rules-engine configuration profile which resides at /res/rules-engine/configuration.toml Note EdgeX services no longer use docker profiles. They use Environment Overrides in the docker compose file to make the necessary changes to the configuration for running in Docker. See the Environment Variable Overrides For Docker * section in the App Service Configurable section for more details and an example. EDGEX_STARTUP_DURATION This environment variable overrides the default duration, 30 seconds, for a service to complete the start-up, aka bootstrap, phase of execution EDGEX_STARTUP_INTERVAL This environment variable overrides the retry interval or sleep time before a failure is retried during the start-up, aka bootstrap, phase of execution. EDGEX_CONF_DIR This environment variable overrides the configuration directory where the configuration file resides. Default is ./res and also overrides any value set with the -c/--confdir command-line option. EDGEX_CONFIG_FILE This environment variable overrides the configuration file name. Default is configutation.toml and also overrides any value set with the -f/--file command-line option. Store and Forward The Store and Forward capability allows for export functions to persist data on failure and for the export of the data to be retried at a later time. Note The order the data exported via this retry mechanism is not guaranteed to be the same order in which the data was initial received from Core Data Configuration Two sections of configuration have been added for Store and Forward. Writable.StoreAndForward allows enabling, setting the interval between retries and the max number of retries. If running with Configuration Provider, these setting can be changed on the fly without having to restart the service. [Writable.StoreAndForward] Enabled = false RetryInterval = '5m' MaxRetryCount = 10 Note RetryInterval should be at least 1 second (eg. '1s') or greater. If a value less than 1 second is specified, 1 second will be used. Endless retries will occur when MaxRetryCount is set to 0. If MaxRetryCount is set to less than 0, a default of 1 retry will be used. Database describes which database type to use, mongodb (DEPRECATED) or redisdb , and the information required to connect to the database. This section is required if Store and Forward is enabled, otherwise it is currently optional. [Database] Type = \"redisdb\" Host = \"localhost\" Port = 6379 Timeout = '30s' Username = \"\" Password = \"\" How it works When an export function encounters an error sending data it can call SetRetryData(payload []byte) on the Context. This will store the data for later retry. If the application service is stopped and then restarted while stored data hasn't been successfully exported, the export retry will resume once the service is up and running again. Note It is important that export functions return an error and stop pipeline execution after the call to SetRetryData . See HTTPPost function in SDK as an example When the RetryInterval expires, the function pipeline will be re-executed starting with the export function that saved the data. The saved data will be passed to the export function which can then attempt to resend the data. Note The export function will receive the data as it was stored, so it is important that any transformation of the data occur in functions prior to the export function. The export function should only export the data that it receives. One of three out comes can occur after the export retried has completed. Export retry was successful In this case, the stored data is removed from the database and the execution of the pipeline functions after the export function, if any, continues. Export retry fails and retry count has not been exceeded In this case, the stored data is updated in the database with the incremented retry count Export retry fails and retry count has been exceeded In this case, the stored data is removed from the database and never retried again. Note Changing Writable.Pipeline.ExecutionOrder will invalidate all currently stored data and result in it all being removed from the database on the next retry. This is because the position of the export function can no longer be guaranteed and no way to ensure it is properly executed on the retry. Secrets Configuration All instances of App Services share the same database and database credentials. However, there are secrets for each App Service that are exclusive to the instance running. As a result, two separate configurations for secret store clients are used to manage shared and exclusive application service secrets. The GetSecrets() and StoreSecrets() calls use the exclusive secret store client to manage application secrets. An example of configuration settings for each secret store client is below: # Shared Secret Store [SecretStore] Host = 'localhost' Port = 8200 Path = '/v1/secret/edgex/appservice/' Protocol = 'https' RootCaCertPath = '/tmp/edgex/secrets/ca/ca.pem' ServerName = 'edgex-vault' TokenFile = '/tmp/edgex/secrets/edgex-appservice/secrets-token.json' # Number of attempts to retry retrieving secrets before failing to start the service. AdditionalRetryAttempts = 10 # Amount of time to wait before attempting another retry RetryWaitPeriod = \"1s\" [SecretStore.Authentication] AuthType = 'X-Vault-Token' # Exclusive Secret Store [SecretStoreExclusive] Host = 'localhost' Port = 8200 Path = '/v1/secret/edgex/<app service key>/' Protocol = 'https' ServerName = 'edgex-vault' TokenFile = '/tmp/edgex/secrets/<app service key>/secrets-token.json' # Number of attempts to retry retrieving secrets before failing to start the service. AdditionalRetryAttempts = 10 # Amount of time to wait before attempting another retry RetryWaitPeriod = \"1s\" [SecretStoreExclusive.Authentication] AuthType = 'X-Vault-Token' Storing Secrets Secure Mode When running an application service in secure mode, secrets can be stored in the secret store (Vault) by making an HTTP POST call to the secrets API route in the application service, http://[host]:[port]/api/v1/secrets . The secrets are stored and retrieved from the secret store based on values in the SecretStoreExclusive section of the configuration file. Once a secret is stored, only the service that added the secret will be able to retrieve it. For secret retrieval see Getting Secrets . An example of the JSON message body is below. { \"path\" : \"MyPath\" , \"secrets\" : [ { \"key\" : \"MySecretKey\" , \"value\" : \"MySecretValue\" } ] } Note Path specifies the type or location of the secrets to store. It is appended to the base path from the SecretStoreExclusive configuration. An empty path is a valid configuration for a secret's location. Insecure Mode When running in insecure mode, the secrets are stored and retrieved from the Writable.InsecureSecrets section of the service's configuration toml file. Insecure secrets and their paths can be configured as below. [ Writable . InsecureSecrets ] [Writable.InsecureSecrets.AWS] Path = 'aws' [Writable.InsecureSecrets.AWS.Secrets] username = 'aws-user' password = 'aws-pw' [Writable.InsecureSecrets.DB] Path = 'redisdb' [Writable.InsecureSecrets.DB.Secrets] username = '' password = '' Note An empty path is a valid configuration for a secret's location Getting Secrets Application Services can retrieve their secrets from the underlying secret store using the GetSecrets() API in the SDK. If in secure mode, the secrets are retrieved from the secret store based on the SecretStoreExclusive configuration values. If running in insecure mode, the secrets are retrieved from the Writable.InsecureSecrets configuration.","title":"Advanced Topics"},{"location":"microservices/application/AdvancedTopics/#advanced-topics","text":"The following items discuss topics that are a bit beyond the basic use cases of the Application Functions SDK when interacting with EdgeX.","title":"Advanced Topics"},{"location":"microservices/application/AdvancedTopics/#configurable-functions-pipeline","text":"This SDK provides the capability to define the functions pipeline via configuration rather than code by using the app-service-configurable application service. See the App Service Configurable section for more details.","title":"Configurable Functions Pipeline"},{"location":"microservices/application/AdvancedTopics/#using-the-webserver","text":"It is not uncommon to require your own API endpoints when building an app service. Rather than spin up your own webserver inside of your app (alongside the already existing running webserver), we've exposed a method that allows you add your own routes to the existing webserver. A few routes are reserved and cannot be used: /api/version /api/v1/ping /api/v1/metrics /api/v1/config /api/v1/trigger /api/v1/secrets To add your own route, use the AddRoute(route string, handler func(nethttp.ResponseWriter, *nethttp.Request), methods ...string) error function provided on the SDK. Here's an example: edgexSdk . AddRoute ( \"/myroute\" , func ( writer http . ResponseWriter , req * http . Request ) { context := req . Context (). Value ( appsdk . SDKKey ).( * appsdk . AppFunctionsSDK ) context . LoggingClient . Info ( \"TEST\" ) // alternative to edgexSdk.LoggingClient.Info(\"TEST\") writer . Header (). Set ( \"Content-Type\" , \"text/plain\" ) writer . Write ([] byte ( \"hello\" )) writer . WriteHeader ( 200 ) }, \"GET\" ) Under the hood, this simply adds the provided route, handler, and method to the gorilla mux.Router we use in the SDK. For more information on gorilla mux you can check out the github repo here . You can access the resources such as the logging client by accessing the context as shown above -- this is useful for when your routes might not be defined in your main.go where you have access to the edgexSdk instance.","title":"Using The Webserver"},{"location":"microservices/application/AdvancedTopics/#target-type","text":"The target type is the object type of the incoming data that is sent to the first function in the function pipeline. By default this is an EdgeX Event since typical usage is receiving events from Core Data via Message Bus. For other usages where the data is not events coming from Core Data, the TargetType of the accepted incoming data can be set when the SDK instance is created. There are scenarios where the incoming data is not an EdgeX Event . One example scenario is 2 application services are chained via the Message Bus. The output of the first service back to the Message Bus is inference data from analyzing the original input Event data. The second service needs to be able to let the SDK know the target type of the input data it is expecting. For usages where the incoming data is not events , the TargetType of the excepted incoming data can be set when the SDK instance is created. Example: type Person struct { FirstName string `json:\"first_name\"` LastName string `json:\"last_name\"` } edgexSdk := & appsdk . AppFunctionsSDK { ServiceKey : serviceKey , TargetType : & Person {}, } TargetType must be set to a pointer to an instance of your target type such as &Person{} . The first function in your function pipeline will be passed an instance of your target type, not a pointer to it. In the example above, the first function in the pipeline would start something like: func MyPersonFunction ( edgexcontext * appcontext . Context , params ... interface {}) ( bool , interface {}) { edgexcontext . LoggingClient . Debug ( \"MyPersonFunction\" ) if len ( params ) < 1 { // We didn't receive a result return false , nil } person , ok := params [ 0 ].( Person ) if ! ok { return false , errors . New ( \"type received is not a Person\" ) } // .... The SDK supports un-marshaling JSON or CBOR encoded data into an instance of the target type. If your incoming data is not JSON or CBOR encoded, you then need to set the TargetType to &[]byte . If the target type is set to &[]byte the incoming data will not be un-marshaled. The content type, if set, will be passed as the second parameter to the first function in your pipeline. Your first function will be responsible for decoding the data or not.","title":"Target Type"},{"location":"microservices/application/AdvancedTopics/#command-line-options","text":"The following command line options are available -c=<path> --confdir=<path> Specify an alternate configuration directory. -p=<profile> --profile=<profile> Specify a profile other than default. -f, --file <name> Indicates name of the local configuration file. Defaults to configuration.toml -cp=<url> --configProvider=<url> Indicates to use Configuration Provider service at specified URL. URL Format: {type}.{protocol}://{host}:{port} ex: consul.http://localhost:8500 No url, i.e. -cp, defaults to consul.http://localhost:8500 -o -overwrite Force overwrite configuration in the Configuration Provider with local values. -r --registry Indicates the service should use the service Registry. -s -skipVersionCheck Indicates the service should skip the Core Service's version compatibility check. -sk --serviceKey Overrides the service key used with Registry and/or Configuration Providers. If the name provided contains the text `<profile>`, this text will be replaced with the name of the profile used. Examples: simple-filter-xml -c = ./res -p = http-export or simple-filter-xml --confdir = ./res -p = http-export -cp = consul.http://localhost:8500 --registry","title":"Command Line Options"},{"location":"microservices/application/AdvancedTopics/#environment-variable-overrides","text":"All the configuration settings from the configuration.toml file can be overridden by environment variables. The environment variable names have the following format: < TOML KEY > < TOML SECTION > _ < TOML KEY > < TOML SECTION > _ < TOML SUB-SECTION > _ < TOML KEY > Note With the Geneva release CamelCase environment variable names are deprecated. Instead use all uppercase environment variable names as in the example below. Examples: TOML : FailLimit = 30 ENVVAR : FAILLIMIT = 100 TOML : [Logging] EnableRemote = false ENVVAR : LOGGING_ENABLEREMOTE = true TOML : [Clients] [Clients.CoreData] Host = 'localhost' ENVVAR : CLIENTS_COREDATA_HOST = edgex-core-data","title":"Environment Variable Overrides"},{"location":"microservices/application/AdvancedTopics/#edgex_service_key","text":"This environment variable overrides the service key used with the Configuration and/or Registry providers. Default is set by the application service. Also overrides any value set with the -sk/--serviceKey command-line option. Note If the name provided contains the text <profile> , this text will be replaced with the name of the profile used. Example EDGEX_SERVICE_KEY: AppService-<profile>-mycloud and if profile: http-export then service key will be \"AppService-http-export-mycloud\"","title":"EDGEX_SERVICE_KEY"},{"location":"microservices/application/AdvancedTopics/#edgex_configuration_provider","text":"This environment variable overrides the Configuration Provider connection information. The value is in the format of a URL. EDGEX_CONFIGURATION_PROVIDER=consul.http://edgex-core-consul:8500 This sets the Configration Provider information fields as follows: Type: consul Host: edgex-core-consul Port: 8500","title":"EDGEX_CONFIGURATION_PROVIDER"},{"location":"microservices/application/AdvancedTopics/#edgex_registry-deprecated","text":"This environment variable overrides the Registry connection information and occurs every time the application service starts. The value is in the format of a URL. Note This environment variable override has been deprecated in the Geneva Release. Instead, use configuration overrides of REGISTRY_PROTOCOL and/or REGISTRY_HOST and/or REGISTRY_PORT EDGEX_REGISTRY=consul://edgex-core-consul:8500 This sets the Registry information fields as follows: Type: consul Host: edgex-core-consul Port: 8500","title":"edgex_registry (DEPRECATED)"},{"location":"microservices/application/AdvancedTopics/#edgex_service-deprecated","text":"This environment variable overrides the Service connection information. The value is in the format of a URL. Note This environment variable override has been deprecated in the Geneva Release. Instead, use configuration overrides of SERVICE_PROTOCOL and/or SERVICE_HOST and/or SERVICE_PORT EDGEX_SERVICE=http://192.168.1.2:4903 This sets the Service information fields as follows: Protocol: http Host: 192.168.1.2 Port: 4903","title":"edgex_service (DEPRECATED)"},{"location":"microservices/application/AdvancedTopics/#edgex_profile","text":"This environment variable overrides the command line profile argument. It will set the profile or replace the value passed via the -p or --profile , if one exists. This is useful when running the service via docker-compose. Note The lower case version has been deprecated in the Geneva release. Instead use upper case version EDGEX_PROFILE Using docker-compose: app-service-configurable-rules: image: edgexfoundry/docker-app-service-configurable:1.1.0 environment: - EDGEX_PROFILE : \"rules-engine\" ports: - \"48095:48095\" container_name: edgex-app-service-configurable hostname: edgex-app-service-configurable networks: edgex-network: aliases: - edgex-app-service-configurable depends_on: - data - command This sets the profile so that the application service uses the rules-engine configuration profile which resides at /res/rules-engine/configuration.toml Note EdgeX services no longer use docker profiles. They use Environment Overrides in the docker compose file to make the necessary changes to the configuration for running in Docker. See the Environment Variable Overrides For Docker * section in the App Service Configurable section for more details and an example.","title":"EDGEX_PROFILE"},{"location":"microservices/application/AdvancedTopics/#edgex_startup_duration","text":"This environment variable overrides the default duration, 30 seconds, for a service to complete the start-up, aka bootstrap, phase of execution","title":"EDGEX_STARTUP_DURATION"},{"location":"microservices/application/AdvancedTopics/#edgex_startup_interval","text":"This environment variable overrides the retry interval or sleep time before a failure is retried during the start-up, aka bootstrap, phase of execution.","title":"EDGEX_STARTUP_INTERVAL"},{"location":"microservices/application/AdvancedTopics/#edgex_conf_dir","text":"This environment variable overrides the configuration directory where the configuration file resides. Default is ./res and also overrides any value set with the -c/--confdir command-line option.","title":"EDGEX_CONF_DIR"},{"location":"microservices/application/AdvancedTopics/#edgex_config_file","text":"This environment variable overrides the configuration file name. Default is configutation.toml and also overrides any value set with the -f/--file command-line option.","title":"EDGEX_CONFIG_FILE"},{"location":"microservices/application/AdvancedTopics/#store-and-forward","text":"The Store and Forward capability allows for export functions to persist data on failure and for the export of the data to be retried at a later time. Note The order the data exported via this retry mechanism is not guaranteed to be the same order in which the data was initial received from Core Data","title":"Store and Forward"},{"location":"microservices/application/AdvancedTopics/#configuration","text":"Two sections of configuration have been added for Store and Forward. Writable.StoreAndForward allows enabling, setting the interval between retries and the max number of retries. If running with Configuration Provider, these setting can be changed on the fly without having to restart the service. [Writable.StoreAndForward] Enabled = false RetryInterval = '5m' MaxRetryCount = 10 Note RetryInterval should be at least 1 second (eg. '1s') or greater. If a value less than 1 second is specified, 1 second will be used. Endless retries will occur when MaxRetryCount is set to 0. If MaxRetryCount is set to less than 0, a default of 1 retry will be used. Database describes which database type to use, mongodb (DEPRECATED) or redisdb , and the information required to connect to the database. This section is required if Store and Forward is enabled, otherwise it is currently optional. [Database] Type = \"redisdb\" Host = \"localhost\" Port = 6379 Timeout = '30s' Username = \"\" Password = \"\"","title":"Configuration"},{"location":"microservices/application/AdvancedTopics/#how-it-works","text":"When an export function encounters an error sending data it can call SetRetryData(payload []byte) on the Context. This will store the data for later retry. If the application service is stopped and then restarted while stored data hasn't been successfully exported, the export retry will resume once the service is up and running again. Note It is important that export functions return an error and stop pipeline execution after the call to SetRetryData . See HTTPPost function in SDK as an example When the RetryInterval expires, the function pipeline will be re-executed starting with the export function that saved the data. The saved data will be passed to the export function which can then attempt to resend the data. Note The export function will receive the data as it was stored, so it is important that any transformation of the data occur in functions prior to the export function. The export function should only export the data that it receives. One of three out comes can occur after the export retried has completed. Export retry was successful In this case, the stored data is removed from the database and the execution of the pipeline functions after the export function, if any, continues. Export retry fails and retry count has not been exceeded In this case, the stored data is updated in the database with the incremented retry count Export retry fails and retry count has been exceeded In this case, the stored data is removed from the database and never retried again. Note Changing Writable.Pipeline.ExecutionOrder will invalidate all currently stored data and result in it all being removed from the database on the next retry. This is because the position of the export function can no longer be guaranteed and no way to ensure it is properly executed on the retry.","title":"How it works"},{"location":"microservices/application/AdvancedTopics/#secrets","text":"","title":"Secrets"},{"location":"microservices/application/AdvancedTopics/#configuration_1","text":"All instances of App Services share the same database and database credentials. However, there are secrets for each App Service that are exclusive to the instance running. As a result, two separate configurations for secret store clients are used to manage shared and exclusive application service secrets. The GetSecrets() and StoreSecrets() calls use the exclusive secret store client to manage application secrets. An example of configuration settings for each secret store client is below: # Shared Secret Store [SecretStore] Host = 'localhost' Port = 8200 Path = '/v1/secret/edgex/appservice/' Protocol = 'https' RootCaCertPath = '/tmp/edgex/secrets/ca/ca.pem' ServerName = 'edgex-vault' TokenFile = '/tmp/edgex/secrets/edgex-appservice/secrets-token.json' # Number of attempts to retry retrieving secrets before failing to start the service. AdditionalRetryAttempts = 10 # Amount of time to wait before attempting another retry RetryWaitPeriod = \"1s\" [SecretStore.Authentication] AuthType = 'X-Vault-Token' # Exclusive Secret Store [SecretStoreExclusive] Host = 'localhost' Port = 8200 Path = '/v1/secret/edgex/<app service key>/' Protocol = 'https' ServerName = 'edgex-vault' TokenFile = '/tmp/edgex/secrets/<app service key>/secrets-token.json' # Number of attempts to retry retrieving secrets before failing to start the service. AdditionalRetryAttempts = 10 # Amount of time to wait before attempting another retry RetryWaitPeriod = \"1s\" [SecretStoreExclusive.Authentication] AuthType = 'X-Vault-Token'","title":"Configuration"},{"location":"microservices/application/AdvancedTopics/#storing-secrets","text":"","title":"Storing Secrets"},{"location":"microservices/application/AdvancedTopics/#secure-mode","text":"When running an application service in secure mode, secrets can be stored in the secret store (Vault) by making an HTTP POST call to the secrets API route in the application service, http://[host]:[port]/api/v1/secrets . The secrets are stored and retrieved from the secret store based on values in the SecretStoreExclusive section of the configuration file. Once a secret is stored, only the service that added the secret will be able to retrieve it. For secret retrieval see Getting Secrets . An example of the JSON message body is below. { \"path\" : \"MyPath\" , \"secrets\" : [ { \"key\" : \"MySecretKey\" , \"value\" : \"MySecretValue\" } ] } Note Path specifies the type or location of the secrets to store. It is appended to the base path from the SecretStoreExclusive configuration. An empty path is a valid configuration for a secret's location.","title":"Secure Mode"},{"location":"microservices/application/AdvancedTopics/#insecure-mode","text":"When running in insecure mode, the secrets are stored and retrieved from the Writable.InsecureSecrets section of the service's configuration toml file. Insecure secrets and their paths can be configured as below. [ Writable . InsecureSecrets ] [Writable.InsecureSecrets.AWS] Path = 'aws' [Writable.InsecureSecrets.AWS.Secrets] username = 'aws-user' password = 'aws-pw' [Writable.InsecureSecrets.DB] Path = 'redisdb' [Writable.InsecureSecrets.DB.Secrets] username = '' password = '' Note An empty path is a valid configuration for a secret's location","title":"Insecure Mode"},{"location":"microservices/application/AdvancedTopics/#getting-secrets","text":"Application Services can retrieve their secrets from the underlying secret store using the GetSecrets() API in the SDK. If in secure mode, the secrets are retrieved from the secret store based on the SecretStoreExclusive configuration values. If running in insecure mode, the secrets are retrieved from the Writable.InsecureSecrets configuration.","title":"Getting Secrets"},{"location":"microservices/application/AppServiceConfigurable/","text":"App Service Configurable Getting Started App-Service-Configurable is provided as an easy way to get started with processing data flowing through EdgeX. This service leverages the App Functions SDK and provides a way for developers to use configuration instead of having to compile standalone services to utilize built in functions in the SDK. Please refer to Available Configurable Pipeline Functions section below for full list of built in functions that can be used in the configurable pipeline. To get started with the App-Service-Configurable, you'll want to start by determining which functions are required in your pipeline. Using a simple example, let's assume you wish to use the following functions from the SDK: FilterByDeviceName - to filter events for a specific device. TransformToXML - to transform the data to XML HTTPPost - to send the data to an HTTP endpoint that takes our XML data MarkAsPushed - to call Core Data API to mark the event as having been pushed Once the functions have been identified, we'll go ahead and build out the configuration in the configuration.toml file under the [Writable.Pipeline] section: [Writable] LogLevel = 'DEBUG' [Writable.Pipeline] ExecutionOrder = \"FilterByDeviceName, TransformToXML, HTTPPost, MarkAsPushed\" [Writable.Pipeline.Functions.FilterByDeviceName] [Writable.Pipeline.Functions.FilterByDeviceName.Parameters] FilterValues = \"Random-Float-Device, Random-Integer-Device\" [Writable.Pipeline.Functions.TransformToXML] [Writable.Pipeline.Functions.MarkAsPushed] [Writable.Pipeline.Functions.HTTPPost] [Writable.Pipeline.Functions.HTTPPost.Parameters] url = \"http://my.api.net/edgexdata\" mimeType = \"\" #OPTIONAL - default application/json The first line of note is ExecutionOrder = \"FilterByDeviceName, TransformToXML, HTTPPost,MarkAsPushed\" . This specifies the order in which to execute your functions. Each function specified here must also be placed in the [Writeable.Pipeline.Functions] section. Next, each function and its required information is listed. Each function typically has associated Parameters that must be configured to properly execute the function as designated by [Writable.Pipeline.Functions.{FunctionName}.Parameters] . Knowing which parameters are required for each function, can be referenced by taking a look at the Available Configurable Pipeline Functions section below. In a few cases, such as TransformToXML , TransformToJSON , SetOutputData`, etc. there are no parameters required. Note By default, the configuration provided is set to use MessageBus as a trigger from CoreData. This means you must have EdgeX Running with devices sending data in order to trigger the pipeline. You can also change the trigger to be HTTP. For more on triggers, view the Triggers documentation located in the Triggers section. That's it! Now we can run/deploy this service and the functions pipeline will process the data with functions we've defined. Environment Variable Overrides For Docker EdgeX services no longer have docker specific profiles. They now rely on environment variable overrides in the docker compose files for the docker specific differences. The following environment settings are required in the compose files when using App Service Configurable. EDGEX_PROFILE : [ target profile ] SERVICE_HOST : [ service name ] SERVICE_PORT : [ service port ] MESSAGEBUS_SUBSCRIBEHOST_HOST : edgex-core-data CLIENTS_COREDATA_HOST : edgex-core-data The following is an example docker compose entry for App Service Configurable : app-service-configurable-rules : image : edgexfoundry/docker-app-service-configurable:1.1.0 environment : EDGEX_PROFILE : rules-engine SERVICE_HOST : edgex-app-service-configurable-rules SERVICE_PORT : 48096 MESSAGEBUS_SUBSCRIBEHOST_HOST : edgex-core-data CLIENTS_COREDATA_HOST : edgex-core-data ports : - \"48096:48096\" container_name : edgex-app-service-configurable-rules hostname : edgex-app-service-configurable-rules networks : - edgex-network depends_on : - data Note App Service Configurable is designed to be run multiple times each with different profiles. This is why in the above example the name edgex-app-service-configurable-rules is used for the instance running the rules-engine profile. Deploying Multiple Instances using profiles App Service Configurable was designed to be deployed as multiple instances with different purposes. Since the function pipeline is specified in the configuration.toml file, we can use this as a way to run each instance with a different function pipeline. App Service Configurable does not have the standard default configuration at /res/configuration.toml . This default configuration has been moved to the sample profile. This forces you to specify the profile for the configuration you would like to run. The profile is specified using the -p/--profile=[profilename] command line option or the EDGEX_PROFILE=[profilename] environment variable override. The profile name selected is used in the service key ( AppService-[profile name] ) to make each instance unique, e.g. AppService-sample when specifying sample as the profile. Note If you need to run multiple instances with the same profile, e.g. http-export , but configured differently, you will need to override the service key with a custom name for one or more of the services. This is done with the -sk/-serviceKey command-line option or the EDGEX_SERVICE_KEY environment variable. See the Command-line Options and Environment Overrides sections for more detail. The following profiles and their purposes are provided with App Service Configurable. blackbox-tests - Profile used for black box testing http-export - Starter profile used for exporting data via HTTP. Requires further configuration which can easily be accomplished using environment variable overrides Required: WRITABLE_PIPELINE_FUNCTIONS_HTTPPOSTJSON_PARAMETERS_URL: [Your URL] Optional: environment : - WRITABLE_PIPELINE_FUNCTIONS_HTTPPOSTJSON_PARAMETERS_PERSISTONERROR : [ \"true\" /\"false\" ] - WRITABLE_PIPELINE_FUNCTIONS_FILTERBYDEVICENAME_PARAMETERS_DEVICENAMES : \"[comma separated list]\" - WRITABLE_PIPELINE_FUNCTIONS_FILTERBYVALUEDESCRIPTOR_PARAMETERS_VALUEDESCRIPTORS : \"[comma separated list]\" - WRITABLE_PIPELINE_FUNCTIONS_FILTERBYVALUEDESCRIPTOR_PARAMETERS_FILTEROUT : [ \"true\" /\"false\" ] mqtt-export - Starter profile used for exporting data via MQTT. Requires further configuration which can easily be accomplished using environment variable overrides Required: WRITABLE_PIPELINE_FUNCTIONS_MQTTSEND_ADDRESSABLE_ADDRESS: [Your Address] Optional: environment : - WRITABLE_PIPELINE_FUNCTIONS_MQTTSEND_ADDRESSABLE_PORT : [ \"your port\" ] - WRITABLE_PIPELINE_FUNCTIONS_MQTTSEND_ADDRESSABLE_PROTOCOL : [ tcp or tcps ] - WRITABLE_PIPELINE_FUNCTIONS_MQTTSEND_ADDRESSABLE_PUBLISHER : [ your name ] - WRITABLE_PIPELINE_FUNCTIONS_MQTTSEND_ADDRESSABLE_USER : [ your username ] - WRITABLE_PIPELINE_FUNCTIONS_MQTTSEND_ADDRESSABLE_PASSWORD : [ your password ] - WRITABLE_PIPELINE_FUNCTIONS_MQTTSEND_ADDRESSABLE_TOPIC : [ your topic ] - WRITABLE_PIPELINE_FUNCTIONS_MQTTSEND_PARAMETERS_QOS : [ \"your quality or service\" ] - WRITABLE_PIPELINE_FUNCTIONS_MQTTSEND_PARAMETERS_KEY : [ your Key ] - WRITABLE_PIPELINE_FUNCTIONS_MQTTSEND_PARAMETERS_CERT : [ your Certificate ] - WRITABLE_PIPELINE_FUNCTIONS_MQTTSEND_PARAMETERS_AUTORECONNECT : [ \"true\" or \"false\" ] - WRITABLE_PIPELINE_FUNCTIONS_MQTTSEND_PARAMETERS_RETAIN : [ \"true\" or \"false\" ] - WRITABLE_PIPELINE_FUNCTIONS_MQTTSEND_PARAMETERS_PERSISTONERROR : [ \"true\" or \"false\" ] rules-engine - Profile used to push Event messages to the Rules Engine via ZMQ Message Bus. rules-engine-mqtt - Profile used to push Event messages to the Rules Engine via MQTT Message Bus. rules-engine-redis Profile used to push Event messages to the Rules Engine via RedisStreams Message Bus. sample - Sample profile with all available functions declared and a sample pipeline. Provided as a sample that can be copied and modified to create new custom profiles. Note Functions can be declared in a profile but not used in the pipeline ExecutionOrder allowing them to be added to the pipeline ExecutionOrder later at runtime if needed. What if my input data isn't an EdgeX Event ? The default TargetType for data flowing into the functions pipeline is an EdgeX event. There are cases when this incoming data might not be an EdgeX event. In these cases the Pipeline can be configured using UseTargetTypeOfByteArray=true to set the TargetType to be a byte array, i.e. byte[] . The first function in the pipeline must then be one that can handle the byte[] data. The compression , encryption and export functions are examples of pipeline functions that will take input data that is byte[] . Here is an example of how to configure the functions pipeline to compress , encrypt and then export the byte[] data via HTTP. [Writable] LogLevel = 'DEBUG' [Writable.Pipeline] UseTargetTypeOfByteArray = true ExecutionOrder = \"CompressWithGZIP, EncryptWithAES, HTTPPost\" [Writable.Pipeline.Functions.CompressWithGZIP] [Writable.Pipeline.Functions.EncryptWithAES] [Writable.Pipeline.Functions.EncryptWithAES.Parameters] Key = \"aquqweoruqwpeoruqwpoeruqwpoierupqoweiurpoqwiuerpqowieurqpowieurpoqiweuroipwqure\" InitVector = \"123456789012345678901234567890\" [Writable.Pipeline.Functions.HTTPPost] [Writable.Pipeline.Functions.HTTPPost.Parameters] url = \"http://my.api.net/edgexdata\" If along with this pipeline configuration, you also configured the Binding to be http trigger, you could then send any data to the app-service-configurable' s /api/v1/trigger endpoint and have it compressed, encrypted and sent to your configured URL above. [Binding] Type = \"http\" Available Configurable Pipeline Functions Below are the functions that are available to use in the configurable functions pipeline ( [Writable.Pipeline] ) section of the configuration. The function names below can be added to the Writable.Pipeline.ExecutionOrder setting (comma separated list) and must also be present or added to the [Writable.Pipeline.Functions] section as [Writable.Pipeline.Functions.{FunctionName}] . Certain functions will also have the [Writable.Pipeline.Functions.{FunctionName}.Parameters] section where the function's parameters are configured. Please refer to the Getting Started section above for an example. Note The Parameters section for each function is a key/value map of string values. So even tough the parameter is referred to as an Integer or Boolean, it has to be specified as a string, e.g. \"20\" or \"true\". Please refer to the function's detailed documentation by clicking the function name below. BatchByCount Parameters BatchThreshold - Number of items to batch before sending batched items to the next function in the pipeline. Example [Writable.Pipeline.Functions.BatchByCount] [Writable.Pipeline.Functions.BatchByCount.Parameters] BatchThreshold = \"30\" BatchByTime Parameters TimeInterval - Time duration to batch before sending batched items to the next function in the pipeline. Example [Writable.Pipeline.Functions.BatchByTime] [Writable.Pipeline.Functions.BatchByTime.Parameters] TimeInterval = \"60s\" BatchByTimeAndCount Parameters BatchThreshold - The number of items to batch before sending batched items to the next function in the pipeline. TimeInterval - Time duration to batch before sending batched items to the next function in the pipeline. Example [Writable.Pipeline.Functions.BatchByTimeAndCount] [Writable.Pipeline.Functions.BatchByTimeAndCount.Parameters] BatchThreshold = \"30\" TimeInterval = \"60s\" CompressWithGZIP Parameters none Example [Writable.Pipeline.Functions.CompressWithGZIP] CompressWithZLIB Parameters none Example [Writable.Pipeline.Functions.CompressWithZLIB] EncryptWithAES Parameters Key - Encryption key used for the AES encryption. InitVector - Initialization vector used for the AES encryption. Example [Writable.Pipeline.Functions.EncryptWithAES] [Writable.Pipeline.Functions.EncryptWithAES.Parameters] Key = \"aquqweoruqwpeoruqwpoeruqwpoierupqoweiurpoqwiuerpqowieurqpowieurpoqiweuroipwqure\" InitVector = \"123456789012345678901234567890\" FilterByDeviceName Parameters DeviceNames - Comma separated list of device names for filtering FilterOut - Boolean indicating if the data matching the device names should be filtered out or filtered for. Example [Writable.Pipeline.Functions.FilterByDeviceName] [Writable.Pipeline.Functions.FilterByDeviceName.Parameters] DeviceNames = \"Random-Float-Device,Random-Integer-Device\" FilterOut = \"false\" FilterByValueDescriptor Parameters ValueDescriptors - Comma separated list of value descriptor (reading) names for filtering FilterOut - Boolean indicating if the data matching the value descriptor (reading) names should be filtered out or filtered for. Example [Writable.Pipeline.Functions.FilterByValueDescriptor] [Writable.Pipeline.Functions.FilterByValueDescriptor.Parameters] ValueDescriptors = \"RandomValue_Int8, RandomValue_Int64\" FilterOut = \"true\" HTTPPost Parameters Url - HTTP endpoint to POST the data. MimeType - Optional mime type for the data. Defaults to application/json. PersistOnError - Indicates to persist the data if the POST fails. Store and Forward must also be enabled if this is set to \"true\". SecretHeaderName - Optional HTTP header name used when POSTing with authorization token. If specified, the Secret Store (Vault or InsecureSecrets ) must contain the <name> secret at the specified SecretPath . SecretPath - Optional path in the secret store where to token is stored. Example [Writable.Pipeline.Functions.HTTPPost] [Writable.Pipeline.Functions.HTTPPost.Parameters] Url = \"http://my.api.net/edgexdata\" MimeType = \"\" #OPTIONAL - default application/json PersistOnError = \"false\" SecretHeaderName = \"\" # This is the name used in the HTTP header and also used as the secret key SecretPath = \"\" HTTPPostJSON Parameters Url - HTTP endpoint to POST the data. PersistOnError - Indicates to persist the data if the POST fails. Store and Forward must also be enabled if this is set to \"true\". SecretHeaderName - Optional HTTP header name used when POSTing with authorization token. If specified, the Secret Store (Vault or InsecureSecrets ) must contain the <name> secret at the specified SecretPath . SecretPath - Optional path in the secret store where to token is stored. Example [Writable.Pipeline.Functions.HTTPPostJSON] [Writable.Pipeline.Functions.HTTPPostJSON.Parameters] Url = \"https://my.api.net/edgexdata\" PersistOnError = \"true\" SecretHeaderName = \"Authorization\" # This is the name used in the HTTP header and also used as the secret key SecretPath = \"http\" HTTPPostXML Parameters Url - HTTP endpoint to POST the data. PersistOnError - Indicates to persist the data if the POST fails. Store and Forward must also be enabled if this is set to \"true\". SecretHeaderName - Optional HTTP header name used when POSTing with authorization token. If specified, the Secret Store (Vault or InsecureSecrets ) must contain the <name> secret at the specified SecretPath . SecretPath - Optional path in the secret store where to token is stored. Example [Writable.Pipeline.Functions.HTTPPostXML] [Writable.Pipeline.Functions.HTTPPostXML.Parameters] Url = \"http://my.api.net/edgexdata\" PersistOnError = \"false\" SecretHeaderName = \"\" # This is the name used in the HTTP header and also used as the secret key SecretPath = \"\" JSONLogic Parameters Rule - The JSON formatted rule that with be executed on the data by JSONLogic Example [Writable.Pipeline.Functions.JSONLogic] [Writable.Pipeline.Functions.JSONLogic.Parameters] Rule = \"{ \\\"and\\\" : [{\\\"<\\\" : [{ \\\"var\\\" : \\\"temp\\\" }, 110 ]}, {\\\"==\\\" : [{ \\\"var\\\" : \\\"sensor.type\\\" }, \\\"temperature\\\" ]} ] }\" MarkAsPushed Parameters none Example [Writable.Pipeline.Functions.MarkAsPushed] MQTTSecretSend Parameters BrokerAddress - URL specify the address of the MQTT Broker Topic - Topic to publish the data ClientId - Id to use when connection to the MQTT Broker Qos - MQTT Quality of Service setting to use (0, 1 or 2). Please refer here for more details on QOS values AutoReconnect - Boolean specifying if reconnect should be automatic if connection to MQTT broker is lost Retain - Boolean specifying if the MQTT Broker should save the last message published as the \u201cLast Good Message\u201d on that topic. SkipVerify - Boolean indicating if the certificate verification should be skipped. PersistOnError - Indicates to persist the data if the POST fails. Store and Forward must also be enabled if this is set to \"true\". AuthMode - Mode of authentication to use when connecting to the MQTT Broker none - No authentication required usernamepassword - Use username and password authentication. The Secret Store (Vault or InsecureSecrets ) must contain the username and password secrets. clientcert - Use Client Certificate authentication. The Secret Store (Vault or InsecureSecrets ) must contain the clientkey and clientcert secrets. cacert - Use CA Certificate authentication. The Secret Store (Vault or InsecureSecrets ) must contain the cacert secret. SecretPath - Path in the secret store where to authorization secrets are stored. Examples [Writable.Pipeline.Functions.MQTTSecretSend] [Writable.Pipeline.Functions.MQTTSecretSend.Parameters] BrokerAddress = \"tcps://localhost:8883\" Topic = \"mytopic\" ClientId = \"myclientid\" Qos = \"0\" AutoReconnect = \"false\" Retain = \"false\" SkipVerify = \"false\" PersistOnError = \"false\" AuthMode = \"\" SecretPath = \"\" [Writable.Pipeline.Functions.MQTTSecretSend] [Writable.Pipeline.Functions.MQTTSecretSend.Parameters] BrokerAddress = \"tcps://my-broker-host.com:8883\" Topic = \"mytopic\" ClientId = \"myclientid\" Qos = \"2\" AutoReconnect = \"true\" Retain = \"true\" SkipVerify = \"false\" PersistOnError = \"true\" AuthMode = \"usernamepassword\" SecretPath = \"mqtt\" MQTTSend MQTTSend has been deprecated. Please use MQTTSecretSend . PushToCore Parameters none Example [Writable.Pipeline.Functions.PushToCore] SetOutputData Parameters none Example [Writable.Pipeline.Functions.SetOutputData] TransformToJSON Parameters none Example [Writable.Pipeline.Functions.TransformToJSON] TransformToXML Parameters none Example [Writable.Pipeline.Functions.TransformToXML]","title":"App Service Configurable"},{"location":"microservices/application/AppServiceConfigurable/#app-service-configurable","text":"","title":"App Service Configurable"},{"location":"microservices/application/AppServiceConfigurable/#getting-started","text":"App-Service-Configurable is provided as an easy way to get started with processing data flowing through EdgeX. This service leverages the App Functions SDK and provides a way for developers to use configuration instead of having to compile standalone services to utilize built in functions in the SDK. Please refer to Available Configurable Pipeline Functions section below for full list of built in functions that can be used in the configurable pipeline. To get started with the App-Service-Configurable, you'll want to start by determining which functions are required in your pipeline. Using a simple example, let's assume you wish to use the following functions from the SDK: FilterByDeviceName - to filter events for a specific device. TransformToXML - to transform the data to XML HTTPPost - to send the data to an HTTP endpoint that takes our XML data MarkAsPushed - to call Core Data API to mark the event as having been pushed Once the functions have been identified, we'll go ahead and build out the configuration in the configuration.toml file under the [Writable.Pipeline] section: [Writable] LogLevel = 'DEBUG' [Writable.Pipeline] ExecutionOrder = \"FilterByDeviceName, TransformToXML, HTTPPost, MarkAsPushed\" [Writable.Pipeline.Functions.FilterByDeviceName] [Writable.Pipeline.Functions.FilterByDeviceName.Parameters] FilterValues = \"Random-Float-Device, Random-Integer-Device\" [Writable.Pipeline.Functions.TransformToXML] [Writable.Pipeline.Functions.MarkAsPushed] [Writable.Pipeline.Functions.HTTPPost] [Writable.Pipeline.Functions.HTTPPost.Parameters] url = \"http://my.api.net/edgexdata\" mimeType = \"\" #OPTIONAL - default application/json The first line of note is ExecutionOrder = \"FilterByDeviceName, TransformToXML, HTTPPost,MarkAsPushed\" . This specifies the order in which to execute your functions. Each function specified here must also be placed in the [Writeable.Pipeline.Functions] section. Next, each function and its required information is listed. Each function typically has associated Parameters that must be configured to properly execute the function as designated by [Writable.Pipeline.Functions.{FunctionName}.Parameters] . Knowing which parameters are required for each function, can be referenced by taking a look at the Available Configurable Pipeline Functions section below. In a few cases, such as TransformToXML , TransformToJSON , SetOutputData`, etc. there are no parameters required. Note By default, the configuration provided is set to use MessageBus as a trigger from CoreData. This means you must have EdgeX Running with devices sending data in order to trigger the pipeline. You can also change the trigger to be HTTP. For more on triggers, view the Triggers documentation located in the Triggers section. That's it! Now we can run/deploy this service and the functions pipeline will process the data with functions we've defined.","title":"Getting Started"},{"location":"microservices/application/AppServiceConfigurable/#environment-variable-overrides-for-docker","text":"EdgeX services no longer have docker specific profiles. They now rely on environment variable overrides in the docker compose files for the docker specific differences. The following environment settings are required in the compose files when using App Service Configurable. EDGEX_PROFILE : [ target profile ] SERVICE_HOST : [ service name ] SERVICE_PORT : [ service port ] MESSAGEBUS_SUBSCRIBEHOST_HOST : edgex-core-data CLIENTS_COREDATA_HOST : edgex-core-data The following is an example docker compose entry for App Service Configurable : app-service-configurable-rules : image : edgexfoundry/docker-app-service-configurable:1.1.0 environment : EDGEX_PROFILE : rules-engine SERVICE_HOST : edgex-app-service-configurable-rules SERVICE_PORT : 48096 MESSAGEBUS_SUBSCRIBEHOST_HOST : edgex-core-data CLIENTS_COREDATA_HOST : edgex-core-data ports : - \"48096:48096\" container_name : edgex-app-service-configurable-rules hostname : edgex-app-service-configurable-rules networks : - edgex-network depends_on : - data Note App Service Configurable is designed to be run multiple times each with different profiles. This is why in the above example the name edgex-app-service-configurable-rules is used for the instance running the rules-engine profile.","title":"Environment Variable Overrides For Docker"},{"location":"microservices/application/AppServiceConfigurable/#deploying-multiple-instances-using-profiles","text":"App Service Configurable was designed to be deployed as multiple instances with different purposes. Since the function pipeline is specified in the configuration.toml file, we can use this as a way to run each instance with a different function pipeline. App Service Configurable does not have the standard default configuration at /res/configuration.toml . This default configuration has been moved to the sample profile. This forces you to specify the profile for the configuration you would like to run. The profile is specified using the -p/--profile=[profilename] command line option or the EDGEX_PROFILE=[profilename] environment variable override. The profile name selected is used in the service key ( AppService-[profile name] ) to make each instance unique, e.g. AppService-sample when specifying sample as the profile. Note If you need to run multiple instances with the same profile, e.g. http-export , but configured differently, you will need to override the service key with a custom name for one or more of the services. This is done with the -sk/-serviceKey command-line option or the EDGEX_SERVICE_KEY environment variable. See the Command-line Options and Environment Overrides sections for more detail. The following profiles and their purposes are provided with App Service Configurable. blackbox-tests - Profile used for black box testing http-export - Starter profile used for exporting data via HTTP. Requires further configuration which can easily be accomplished using environment variable overrides Required: WRITABLE_PIPELINE_FUNCTIONS_HTTPPOSTJSON_PARAMETERS_URL: [Your URL] Optional: environment : - WRITABLE_PIPELINE_FUNCTIONS_HTTPPOSTJSON_PARAMETERS_PERSISTONERROR : [ \"true\" /\"false\" ] - WRITABLE_PIPELINE_FUNCTIONS_FILTERBYDEVICENAME_PARAMETERS_DEVICENAMES : \"[comma separated list]\" - WRITABLE_PIPELINE_FUNCTIONS_FILTERBYVALUEDESCRIPTOR_PARAMETERS_VALUEDESCRIPTORS : \"[comma separated list]\" - WRITABLE_PIPELINE_FUNCTIONS_FILTERBYVALUEDESCRIPTOR_PARAMETERS_FILTEROUT : [ \"true\" /\"false\" ] mqtt-export - Starter profile used for exporting data via MQTT. Requires further configuration which can easily be accomplished using environment variable overrides Required: WRITABLE_PIPELINE_FUNCTIONS_MQTTSEND_ADDRESSABLE_ADDRESS: [Your Address] Optional: environment : - WRITABLE_PIPELINE_FUNCTIONS_MQTTSEND_ADDRESSABLE_PORT : [ \"your port\" ] - WRITABLE_PIPELINE_FUNCTIONS_MQTTSEND_ADDRESSABLE_PROTOCOL : [ tcp or tcps ] - WRITABLE_PIPELINE_FUNCTIONS_MQTTSEND_ADDRESSABLE_PUBLISHER : [ your name ] - WRITABLE_PIPELINE_FUNCTIONS_MQTTSEND_ADDRESSABLE_USER : [ your username ] - WRITABLE_PIPELINE_FUNCTIONS_MQTTSEND_ADDRESSABLE_PASSWORD : [ your password ] - WRITABLE_PIPELINE_FUNCTIONS_MQTTSEND_ADDRESSABLE_TOPIC : [ your topic ] - WRITABLE_PIPELINE_FUNCTIONS_MQTTSEND_PARAMETERS_QOS : [ \"your quality or service\" ] - WRITABLE_PIPELINE_FUNCTIONS_MQTTSEND_PARAMETERS_KEY : [ your Key ] - WRITABLE_PIPELINE_FUNCTIONS_MQTTSEND_PARAMETERS_CERT : [ your Certificate ] - WRITABLE_PIPELINE_FUNCTIONS_MQTTSEND_PARAMETERS_AUTORECONNECT : [ \"true\" or \"false\" ] - WRITABLE_PIPELINE_FUNCTIONS_MQTTSEND_PARAMETERS_RETAIN : [ \"true\" or \"false\" ] - WRITABLE_PIPELINE_FUNCTIONS_MQTTSEND_PARAMETERS_PERSISTONERROR : [ \"true\" or \"false\" ] rules-engine - Profile used to push Event messages to the Rules Engine via ZMQ Message Bus. rules-engine-mqtt - Profile used to push Event messages to the Rules Engine via MQTT Message Bus. rules-engine-redis Profile used to push Event messages to the Rules Engine via RedisStreams Message Bus. sample - Sample profile with all available functions declared and a sample pipeline. Provided as a sample that can be copied and modified to create new custom profiles. Note Functions can be declared in a profile but not used in the pipeline ExecutionOrder allowing them to be added to the pipeline ExecutionOrder later at runtime if needed.","title":"Deploying Multiple Instances using profiles"},{"location":"microservices/application/AppServiceConfigurable/#what-if-my-input-data-isnt-an-edgex-event","text":"The default TargetType for data flowing into the functions pipeline is an EdgeX event. There are cases when this incoming data might not be an EdgeX event. In these cases the Pipeline can be configured using UseTargetTypeOfByteArray=true to set the TargetType to be a byte array, i.e. byte[] . The first function in the pipeline must then be one that can handle the byte[] data. The compression , encryption and export functions are examples of pipeline functions that will take input data that is byte[] . Here is an example of how to configure the functions pipeline to compress , encrypt and then export the byte[] data via HTTP. [Writable] LogLevel = 'DEBUG' [Writable.Pipeline] UseTargetTypeOfByteArray = true ExecutionOrder = \"CompressWithGZIP, EncryptWithAES, HTTPPost\" [Writable.Pipeline.Functions.CompressWithGZIP] [Writable.Pipeline.Functions.EncryptWithAES] [Writable.Pipeline.Functions.EncryptWithAES.Parameters] Key = \"aquqweoruqwpeoruqwpoeruqwpoierupqoweiurpoqwiuerpqowieurqpowieurpoqiweuroipwqure\" InitVector = \"123456789012345678901234567890\" [Writable.Pipeline.Functions.HTTPPost] [Writable.Pipeline.Functions.HTTPPost.Parameters] url = \"http://my.api.net/edgexdata\" If along with this pipeline configuration, you also configured the Binding to be http trigger, you could then send any data to the app-service-configurable' s /api/v1/trigger endpoint and have it compressed, encrypted and sent to your configured URL above. [Binding] Type = \"http\"","title":"What if my input data isn't an EdgeX Event ?"},{"location":"microservices/application/AppServiceConfigurable/#available-configurable-pipeline-functions","text":"Below are the functions that are available to use in the configurable functions pipeline ( [Writable.Pipeline] ) section of the configuration. The function names below can be added to the Writable.Pipeline.ExecutionOrder setting (comma separated list) and must also be present or added to the [Writable.Pipeline.Functions] section as [Writable.Pipeline.Functions.{FunctionName}] . Certain functions will also have the [Writable.Pipeline.Functions.{FunctionName}.Parameters] section where the function's parameters are configured. Please refer to the Getting Started section above for an example. Note The Parameters section for each function is a key/value map of string values. So even tough the parameter is referred to as an Integer or Boolean, it has to be specified as a string, e.g. \"20\" or \"true\". Please refer to the function's detailed documentation by clicking the function name below.","title":"Available Configurable Pipeline Functions"},{"location":"microservices/application/AppServiceConfigurable/#batchbycount","text":"Parameters BatchThreshold - Number of items to batch before sending batched items to the next function in the pipeline. Example [Writable.Pipeline.Functions.BatchByCount] [Writable.Pipeline.Functions.BatchByCount.Parameters] BatchThreshold = \"30\"","title":"BatchByCount"},{"location":"microservices/application/AppServiceConfigurable/#batchbytime","text":"Parameters TimeInterval - Time duration to batch before sending batched items to the next function in the pipeline. Example [Writable.Pipeline.Functions.BatchByTime] [Writable.Pipeline.Functions.BatchByTime.Parameters] TimeInterval = \"60s\"","title":"BatchByTime"},{"location":"microservices/application/AppServiceConfigurable/#batchbytimeandcount","text":"Parameters BatchThreshold - The number of items to batch before sending batched items to the next function in the pipeline. TimeInterval - Time duration to batch before sending batched items to the next function in the pipeline. Example [Writable.Pipeline.Functions.BatchByTimeAndCount] [Writable.Pipeline.Functions.BatchByTimeAndCount.Parameters] BatchThreshold = \"30\" TimeInterval = \"60s\"","title":"BatchByTimeAndCount"},{"location":"microservices/application/AppServiceConfigurable/#compresswithgzip","text":"Parameters none Example [Writable.Pipeline.Functions.CompressWithGZIP]","title":"CompressWithGZIP"},{"location":"microservices/application/AppServiceConfigurable/#compresswithzlib","text":"Parameters none Example [Writable.Pipeline.Functions.CompressWithZLIB]","title":"CompressWithZLIB"},{"location":"microservices/application/AppServiceConfigurable/#encryptwithaes","text":"Parameters Key - Encryption key used for the AES encryption. InitVector - Initialization vector used for the AES encryption. Example [Writable.Pipeline.Functions.EncryptWithAES] [Writable.Pipeline.Functions.EncryptWithAES.Parameters] Key = \"aquqweoruqwpeoruqwpoeruqwpoierupqoweiurpoqwiuerpqowieurqpowieurpoqiweuroipwqure\" InitVector = \"123456789012345678901234567890\"","title":"EncryptWithAES"},{"location":"microservices/application/AppServiceConfigurable/#filterbydevicename","text":"Parameters DeviceNames - Comma separated list of device names for filtering FilterOut - Boolean indicating if the data matching the device names should be filtered out or filtered for. Example [Writable.Pipeline.Functions.FilterByDeviceName] [Writable.Pipeline.Functions.FilterByDeviceName.Parameters] DeviceNames = \"Random-Float-Device,Random-Integer-Device\" FilterOut = \"false\"","title":"FilterByDeviceName"},{"location":"microservices/application/AppServiceConfigurable/#filterbyvaluedescriptor","text":"Parameters ValueDescriptors - Comma separated list of value descriptor (reading) names for filtering FilterOut - Boolean indicating if the data matching the value descriptor (reading) names should be filtered out or filtered for. Example [Writable.Pipeline.Functions.FilterByValueDescriptor] [Writable.Pipeline.Functions.FilterByValueDescriptor.Parameters] ValueDescriptors = \"RandomValue_Int8, RandomValue_Int64\" FilterOut = \"true\"","title":"FilterByValueDescriptor"},{"location":"microservices/application/AppServiceConfigurable/#httppost","text":"Parameters Url - HTTP endpoint to POST the data. MimeType - Optional mime type for the data. Defaults to application/json. PersistOnError - Indicates to persist the data if the POST fails. Store and Forward must also be enabled if this is set to \"true\". SecretHeaderName - Optional HTTP header name used when POSTing with authorization token. If specified, the Secret Store (Vault or InsecureSecrets ) must contain the <name> secret at the specified SecretPath . SecretPath - Optional path in the secret store where to token is stored. Example [Writable.Pipeline.Functions.HTTPPost] [Writable.Pipeline.Functions.HTTPPost.Parameters] Url = \"http://my.api.net/edgexdata\" MimeType = \"\" #OPTIONAL - default application/json PersistOnError = \"false\" SecretHeaderName = \"\" # This is the name used in the HTTP header and also used as the secret key SecretPath = \"\"","title":"HTTPPost"},{"location":"microservices/application/AppServiceConfigurable/#httppostjson","text":"Parameters Url - HTTP endpoint to POST the data. PersistOnError - Indicates to persist the data if the POST fails. Store and Forward must also be enabled if this is set to \"true\". SecretHeaderName - Optional HTTP header name used when POSTing with authorization token. If specified, the Secret Store (Vault or InsecureSecrets ) must contain the <name> secret at the specified SecretPath . SecretPath - Optional path in the secret store where to token is stored. Example [Writable.Pipeline.Functions.HTTPPostJSON] [Writable.Pipeline.Functions.HTTPPostJSON.Parameters] Url = \"https://my.api.net/edgexdata\" PersistOnError = \"true\" SecretHeaderName = \"Authorization\" # This is the name used in the HTTP header and also used as the secret key SecretPath = \"http\"","title":"HTTPPostJSON"},{"location":"microservices/application/AppServiceConfigurable/#httppostxml","text":"Parameters Url - HTTP endpoint to POST the data. PersistOnError - Indicates to persist the data if the POST fails. Store and Forward must also be enabled if this is set to \"true\". SecretHeaderName - Optional HTTP header name used when POSTing with authorization token. If specified, the Secret Store (Vault or InsecureSecrets ) must contain the <name> secret at the specified SecretPath . SecretPath - Optional path in the secret store where to token is stored. Example [Writable.Pipeline.Functions.HTTPPostXML] [Writable.Pipeline.Functions.HTTPPostXML.Parameters] Url = \"http://my.api.net/edgexdata\" PersistOnError = \"false\" SecretHeaderName = \"\" # This is the name used in the HTTP header and also used as the secret key SecretPath = \"\"","title":"HTTPPostXML"},{"location":"microservices/application/AppServiceConfigurable/#jsonlogic","text":"Parameters Rule - The JSON formatted rule that with be executed on the data by JSONLogic Example [Writable.Pipeline.Functions.JSONLogic] [Writable.Pipeline.Functions.JSONLogic.Parameters] Rule = \"{ \\\"and\\\" : [{\\\"<\\\" : [{ \\\"var\\\" : \\\"temp\\\" }, 110 ]}, {\\\"==\\\" : [{ \\\"var\\\" : \\\"sensor.type\\\" }, \\\"temperature\\\" ]} ] }\"","title":"JSONLogic"},{"location":"microservices/application/AppServiceConfigurable/#markaspushed","text":"Parameters none Example [Writable.Pipeline.Functions.MarkAsPushed]","title":"MarkAsPushed"},{"location":"microservices/application/AppServiceConfigurable/#mqttsecretsend","text":"Parameters BrokerAddress - URL specify the address of the MQTT Broker Topic - Topic to publish the data ClientId - Id to use when connection to the MQTT Broker Qos - MQTT Quality of Service setting to use (0, 1 or 2). Please refer here for more details on QOS values AutoReconnect - Boolean specifying if reconnect should be automatic if connection to MQTT broker is lost Retain - Boolean specifying if the MQTT Broker should save the last message published as the \u201cLast Good Message\u201d on that topic. SkipVerify - Boolean indicating if the certificate verification should be skipped. PersistOnError - Indicates to persist the data if the POST fails. Store and Forward must also be enabled if this is set to \"true\". AuthMode - Mode of authentication to use when connecting to the MQTT Broker none - No authentication required usernamepassword - Use username and password authentication. The Secret Store (Vault or InsecureSecrets ) must contain the username and password secrets. clientcert - Use Client Certificate authentication. The Secret Store (Vault or InsecureSecrets ) must contain the clientkey and clientcert secrets. cacert - Use CA Certificate authentication. The Secret Store (Vault or InsecureSecrets ) must contain the cacert secret. SecretPath - Path in the secret store where to authorization secrets are stored. Examples [Writable.Pipeline.Functions.MQTTSecretSend] [Writable.Pipeline.Functions.MQTTSecretSend.Parameters] BrokerAddress = \"tcps://localhost:8883\" Topic = \"mytopic\" ClientId = \"myclientid\" Qos = \"0\" AutoReconnect = \"false\" Retain = \"false\" SkipVerify = \"false\" PersistOnError = \"false\" AuthMode = \"\" SecretPath = \"\" [Writable.Pipeline.Functions.MQTTSecretSend] [Writable.Pipeline.Functions.MQTTSecretSend.Parameters] BrokerAddress = \"tcps://my-broker-host.com:8883\" Topic = \"mytopic\" ClientId = \"myclientid\" Qos = \"2\" AutoReconnect = \"true\" Retain = \"true\" SkipVerify = \"false\" PersistOnError = \"true\" AuthMode = \"usernamepassword\" SecretPath = \"mqtt\"","title":"MQTTSecretSend"},{"location":"microservices/application/AppServiceConfigurable/#mqttsend","text":"MQTTSend has been deprecated. Please use MQTTSecretSend .","title":"MQTTSend"},{"location":"microservices/application/AppServiceConfigurable/#pushtocore","text":"Parameters none Example [Writable.Pipeline.Functions.PushToCore]","title":"PushToCore"},{"location":"microservices/application/AppServiceConfigurable/#setoutputdata","text":"Parameters none Example [Writable.Pipeline.Functions.SetOutputData]","title":"SetOutputData"},{"location":"microservices/application/AppServiceConfigurable/#transformtojson","text":"Parameters none Example [Writable.Pipeline.Functions.TransformToJSON]","title":"TransformToJSON"},{"location":"microservices/application/AppServiceConfigurable/#transformtoxml","text":"Parameters none Example [Writable.Pipeline.Functions.TransformToXML]","title":"TransformToXML"},{"location":"microservices/application/ApplicationFunctionsSDK/","text":"App Functions SDK Welcome the App Functions SDK for EdgeX. This SDK is meant to provide all the plumbing necessary for developers to get started in processing/transforming/exporting data out of EdgeX. If you're new to the SDK - checkout the Getting Started guide. If you're already familiar - checkout the various sections about the SDK: Section Description Built In Transforms Provides a list of the available transforms in the SDK Context API Provides a list of all available functions on the context that is available inside of an app function Error Handling Describes how to properly handle pipeline execution failures Advanced Topics Learn about other ways to leverage the SDK beyond basic use cases","title":"App Functions SDK"},{"location":"microservices/application/ApplicationFunctionsSDK/#app-functions-sdk","text":"Welcome the App Functions SDK for EdgeX. This SDK is meant to provide all the plumbing necessary for developers to get started in processing/transforming/exporting data out of EdgeX. If you're new to the SDK - checkout the Getting Started guide. If you're already familiar - checkout the various sections about the SDK: Section Description Built In Transforms Provides a list of the available transforms in the SDK Context API Provides a list of all available functions on the context that is available inside of an app function Error Handling Describes how to properly handle pipeline execution failures Advanced Topics Learn about other ways to leverage the SDK beyond basic use cases","title":"App Functions SDK"},{"location":"microservices/application/ApplicationServices/","text":"Application Services Application Services are a means to get data from EdgeX Foundry to external systems and process (be it analytics package, enterprise or on-prem application, cloud systems like Azure IoT, AWS IoT, or Google IoT Core, etc.). Application Services provide the means for data to be prepared (transformed, enriched, filtered, etc.) and groomed (formatted, compressed, encrypted, etc.) before being sent to an endpoint of choice. Endpoints supported out of the box today include HTTP and MQTT endpoints, but will include additional offerings in the future and could include a custom endpoints. Note Application Services has replaced Export Services Application Services are based on the idea of a \"Functions Pipeline\". A functions pipeline is a collection of functions that process messages (in this case EdgeX event/reading messages) in the order that you've specified. The first function in a pipeline is a trigger. A trigger begins the functions pipeline execution. A trigger is something like a message landing in a watched message queue. An Applications Functions Software Development Kit (or App Functions SDK) is available to help create Application Services. Currently the only SDK supported language is Golang, with the intention that community developed and supported SDKs will come in the future for other languages. It is currently available as a Golang module to remain operating system (OS) agnostic and to comply with the latest EdgeX guidelines on dependency management. Any application built on top of the Application Functions SDK is considered an App Service. This SDK is provided to help build Application Services by assembling triggers, pre-existing functions and custom functions of your making into a pipeline. Application Service Improvements Providing an SDK that connects directly to a message bus by which Core Data events are published eliminates performance issues as well as allow the developers extra control on what happens with that data as soon as it is available. Furthermore, it emphasizes configuration over registration for consuming the data. The application services can be customized to a client's needs and thereby also removing the need for client registration. Standard Functions As mentioned, an Application Service is a function pipeline. The SDK provides some standard functions that can be used in a functions pipeline. In the future, additional functions will be provided \"standard\" or in other words provided with the SDK. Additionally, developers can implement their own custom functions and add those to their Application Service functions pipeline. One of the most common use cases for working with data that comes from Core Data is to filter data down to what is relevant for a given application and to format it. To help facilitate this, four primary functions ported over from the existing services today are included in the SDK. The first is the DeviceNameFilter function which will remove events that do not match the specified IDs and will cease execution of the pipeline if no event matches. The second is the ValueDescriptorFilter which exhibits the same behavior as DeviceNameFilter except filtering event readings on Value Descriptor instead of DeviceID. The third and fourth provided functions in the SDK transform the data received to either XML or JSON by calling XMLTransform or JSONTransform . Typically, after filtering and transforming the data as needed, exporting is the last step in a pipeline to ship the data where it needs to go. There are two primary functions included in the SDK to help facilitate this. The first is the HTTPPost function that will POST the provided data to a specified endpoint, and the second is an MQTTSecretSend() function that will publish the provided data to an MQTT Broker as specified in the configuration. There are two primary triggers that have been included in the SDK that initiate the start of the function pipeline. First is via a POST HTTP Endpoint /api/v1/trigger with the EdgeX event data as the body. Second is the MessageBus subscription with connection details as specified in the configuration. Finally, data may be sent back to the message bus or HTTP response by calling .complete() on the context. If the trigger is HTTP, then it will be an HTTP Response. If the trigger is MessageBus, then it will be published to the configured host and topic. Unsupported existing export service functions Valid Event Check --The first component in the pipe and filter, before the copier (described in the previous section) is a filter that can be optionally turned on or off by configuration. This filter is a general purpose data checking filter which assesses the device- or sensor-provided Event, with associated Readings, and ensures the data conforms to the ValueDescriptor associated with the Readings. For example, if the data from a sensor is described by its metadata profile as adhering to a \"Temperature\" value descriptor of floating number type, with the value between -100\u00b0 F and 200\u00b0 F, but the data seen in the Event and Readings is not a floating point number, for example if the data in the reading is a word such as \"cold,\" instead of a number, then the Event is rejected (no client receives the data) and no further processing is accomplished on the Event by the Export Distro service.","title":"Introduction"},{"location":"microservices/application/ApplicationServices/#application-services","text":"Application Services are a means to get data from EdgeX Foundry to external systems and process (be it analytics package, enterprise or on-prem application, cloud systems like Azure IoT, AWS IoT, or Google IoT Core, etc.). Application Services provide the means for data to be prepared (transformed, enriched, filtered, etc.) and groomed (formatted, compressed, encrypted, etc.) before being sent to an endpoint of choice. Endpoints supported out of the box today include HTTP and MQTT endpoints, but will include additional offerings in the future and could include a custom endpoints. Note Application Services has replaced Export Services Application Services are based on the idea of a \"Functions Pipeline\". A functions pipeline is a collection of functions that process messages (in this case EdgeX event/reading messages) in the order that you've specified. The first function in a pipeline is a trigger. A trigger begins the functions pipeline execution. A trigger is something like a message landing in a watched message queue. An Applications Functions Software Development Kit (or App Functions SDK) is available to help create Application Services. Currently the only SDK supported language is Golang, with the intention that community developed and supported SDKs will come in the future for other languages. It is currently available as a Golang module to remain operating system (OS) agnostic and to comply with the latest EdgeX guidelines on dependency management. Any application built on top of the Application Functions SDK is considered an App Service. This SDK is provided to help build Application Services by assembling triggers, pre-existing functions and custom functions of your making into a pipeline.","title":"Application Services"},{"location":"microservices/application/ApplicationServices/#application-service-improvements","text":"Providing an SDK that connects directly to a message bus by which Core Data events are published eliminates performance issues as well as allow the developers extra control on what happens with that data as soon as it is available. Furthermore, it emphasizes configuration over registration for consuming the data. The application services can be customized to a client's needs and thereby also removing the need for client registration.","title":"Application Service Improvements"},{"location":"microservices/application/ApplicationServices/#standard-functions","text":"As mentioned, an Application Service is a function pipeline. The SDK provides some standard functions that can be used in a functions pipeline. In the future, additional functions will be provided \"standard\" or in other words provided with the SDK. Additionally, developers can implement their own custom functions and add those to their Application Service functions pipeline. One of the most common use cases for working with data that comes from Core Data is to filter data down to what is relevant for a given application and to format it. To help facilitate this, four primary functions ported over from the existing services today are included in the SDK. The first is the DeviceNameFilter function which will remove events that do not match the specified IDs and will cease execution of the pipeline if no event matches. The second is the ValueDescriptorFilter which exhibits the same behavior as DeviceNameFilter except filtering event readings on Value Descriptor instead of DeviceID. The third and fourth provided functions in the SDK transform the data received to either XML or JSON by calling XMLTransform or JSONTransform . Typically, after filtering and transforming the data as needed, exporting is the last step in a pipeline to ship the data where it needs to go. There are two primary functions included in the SDK to help facilitate this. The first is the HTTPPost function that will POST the provided data to a specified endpoint, and the second is an MQTTSecretSend() function that will publish the provided data to an MQTT Broker as specified in the configuration. There are two primary triggers that have been included in the SDK that initiate the start of the function pipeline. First is via a POST HTTP Endpoint /api/v1/trigger with the EdgeX event data as the body. Second is the MessageBus subscription with connection details as specified in the configuration. Finally, data may be sent back to the message bus or HTTP response by calling .complete() on the context. If the trigger is HTTP, then it will be an HTTP Response. If the trigger is MessageBus, then it will be published to the configured host and topic.","title":"Standard Functions"},{"location":"microservices/application/ApplicationServices/#unsupported-existing-export-service-functions","text":"Valid Event Check --The first component in the pipe and filter, before the copier (described in the previous section) is a filter that can be optionally turned on or off by configuration. This filter is a general purpose data checking filter which assesses the device- or sensor-provided Event, with associated Readings, and ensures the data conforms to the ValueDescriptor associated with the Readings. For example, if the data from a sensor is described by its metadata profile as adhering to a \"Temperature\" value descriptor of floating number type, with the value between -100\u00b0 F and 200\u00b0 F, but the data seen in the Event and Readings is not a floating point number, for example if the data in the reading is a word such as \"cold,\" instead of a number, then the Event is rejected (no client receives the data) and no further processing is accomplished on the Event by the Export Distro service.","title":"Unsupported existing export service functions"},{"location":"microservices/application/BuiltIn/","text":"Built-In Transforms/Functions All transforms define a type and a New function which is used to initialize an instance of the type with the required parameters. These instances returned by these New functions give access to their appropriate pipeline function pointers when setting up the function pipeline. Example NewFilter ([] { \"Device1\" , \"Device2\" }). FilterByDeviceName Filtering There are two basic types of filtering included in the SDK to add to your pipeline. There is also an option to Filter Out specific items. These provided filter functions return a type of events.Model. If filtering results in no remaining data, the pipeline execution for that pass is terminated. If no values are provided for filtering, then data flows through unfiltered. Factory Method Description NewFilter([]string filterValues) This function returns a Filter instance initialized with the passed in filter values. This Filter instance is used to access the following filter functions that will operate using the specified filter values. type Filter struct { // Holds the values to be filtered FilterValues [] string // Determines if items in FilterValues should be filtered out. If set to true all items found in the filter will be removed. If set to false all items found in the filter will be returned. If FilterValues is empty then all items will be returned. FilterOut bool } By Device Name FilterByDeviceName - This function will filter the event data down to the specified device names and return the filtered data to the pipeline. NewFilter ([] { \"Device1\" , \"Device2\" }). FilterByDeviceName By Value Descriptor FilterByValueDescriptor - This function will filter the event data down to the specified device value descriptor and return the filtered data to the pipeline. NewFilter ([] { \"ValueDescriptor1\" , \"ValueDescriptor2\" }). FilterByValueDescriptor JSON Logic Factory Method Description NewJSONLogic(rule string) This function returns a JSONLogic instance initialized with the passed in JSON rule. The rule passed in should be a JSON string conforming to the specification here: http://jsonlogic.com/operations.html. Evaluate - This is the function that will be used in the pipeline to apply the JSON rule to data coming in on the pipeline. If the condition of your rule is met, then the pipeline will continue and the data will continue to flow to the next function in the pipeline. If the condition of your rule is NOT met, then pipeline execution stops. NewJSONLogic ( \"{ \\\"in\\\" : [{ \\\"var\\\" : \\\"device\\\" }, [\\\"Random-Integer-Device\\\",\\\"Random-Float-Device\\\"] ] }\" ). Evaluate Note Only operations that return true or false are supported. See http://jsonlogic.com/operations.html# for the complete list of operations paying attention to return values. Any operator that returns manipulated data is currently not supported. For more advanced scenarios checkout EMQ X Kuiper . Tip Leverage http://jsonlogic.com/play.html to get your rule right before implementing in code. JSON can be a bit tricky to get right in code with all the escaped double quotes. Encryption There is one encryption transform included in the SDK that can be added to your pipeline. Factory Method Description NewEncryption(key string, initializationVector string) This function returns a Encryption instance initialized with the passed in key and initialization vector. This Encryption instance is used to access the following encryption function that will use the specified key and initialization vector. AES EncryptWithAES - This function receives a either a string , []byte , or json.Marshaller type and encrypts it using AES encryption and returns a []byte to the pipeline. NewEncryption ( \"key\" , \"initializationVector\" ). EncryptWithAES Batch Included in the SDK is an in-memory batch function that will hold on to your data before continuing the pipeline. There are three functions provided for batching each with their own strategy. Factory Method Description NewBatchByTime(timeInterval string) This function returns a BatchConfig instance with time being the strategy that is used for determining when to release the batched data and continue the pipeline. timeInterval is the duration to wait (i.e. 10s ). The time begins after the first piece of data is received. If no data has been received no data will be sent forward. // Example: NewBatchByTime ( \"10s\" ). Batch NewBatchByCount(batchThreshold int) This function returns a BatchConfig instance with count being the strategy that is used for determining when to release the batched data and continue the pipeline. batchThreshold is how many events to hold on to (i.e. 25 ). The count begins after the first piece of data is received and once the threshold is met, the batched data will continue forward and the counter will be reset. // Example: NewBatchByCount ( 10 ). Batch NewBatchByTimeAndCount(timeInterval string, batchThreshold int) This function returns a BatchConfig instance with a combination of both time and count being the strategy that is used for determining when to release the batched data and continue the pipeline. Whichever occurs first will trigger the data to continue and be reset. // Example: NewBatchByTimeAndCount ( \"30s\" , 10 ). Batch Batch - This function will apply the selected strategy in your pipeline. Warning Keep memory usage in mind as you determine the thresholds for both time and count. The larger they are the more memory is required and could lead to performance issue. Conversion There are two conversions included in the SDK that can be added to your pipeline. These transforms return a string . Factory Method Description NewConversion() This function returns a Conversion instance that is used to access the conversion functions. XML TransformToXML - This function receives an events.Model type, converts it to XML format and returns the XML string to the pipeline. NewConversion (). TransformToXML JSON TransformToJSON - This function receives an events.Model type and converts it to JSON format and returns the JSON string to the pipeline. NewConversion (). TransformToJSON Compressions There are two compression types included in the SDK that can be added to your pipeline. These transforms return a []byte . Factory Method Description NewCompression() This function returns a Compression instance that is used to access the compression functions. GZIP CompressWithGZIP - This function receives either a string , []byte , or json.Marshaler type, GZIP compresses the data, converts result to base64 encoded string, which is returned as a []byte to the pipeline. NewCompression (). CompressWithGZIP ZLIB CompressWithZLIB - This function receives either a string , []byte , or json.Marshaler type, ZLIB compresses the data, converts result to base64 encoded string, which is returned as a []byte to the pipeline. NewCompression (). CompressWithZLIB CoreData Functions These are functions that enable interactions with the CoreData REST API. Factory Method Description NewCoreData() This function returns a CoreData instance. This CoreData instance is used to access core data functions. Mark As Pushed MarkAsPushed - This function provides the MarkAsPushed function from the context as a First-Class Transform that can be called in your pipeline. See Definition Above . The data passed into this function from the pipeline is passed along unmodified since all required information is provided on the context (EventId, CorrelationId,etc.. ) NewCoreData (). MarkAsPushed Push to Core PushToCore - This function provides the PushToCore function from the context as a First-Class Transform that can be called in your pipeline. See Definition Above . The data passed into this function from the pipeline is wrapped in an EdgeX event with the deviceName and readingName that were set upon the CoreData instance and then sent to Core Data service to be added as an event. Returns the new EdgeX event with ID populated. NewCoreData (). PushToCore Note If validation is turned on in Core Services then your deviceName and readingName must exist in the Core Metadata service and be properly registered in EdgeX. Export Functions There are a few export functions included in the SDK that can be added to your pipeline. HTTP HTTPPost - This function receives either a string , []byte , or json.Marshaler type from the previous function in the pipeline and posts it to the configured endpoint. If no previous function exists, then the event that triggered the pipeline, marshaled to json, will be used. If the post fails and persistOnError is true and Store and Forward is enabled, the data will be stored for later retry. See Store and Forward for more details. Factory Method Description NewHTTPSender(url string, mimeType string, persistOnError bool) This function returns a HTTPSender instance initialized with the passed in url, mime type and persistOnError values. NewHTTPSenderWithSecretHeader(url string, mimeType string, persistOnError bool, httpHeaderSecretName string, secretPath string) This function returns a HTTPSender instance similar to the above function however will set up the HTTPSender to add a header to the HTTP request using the httpHeaderSecretName as both the header key and the key to search for in the secret provider at secretPath leveraging secure storage of secrets. Example NewHTTPSender ( \"https://myendpoint.com\" , \"application/json\" , false ). HTTPPost //assumes TransformToJSON was used before this transform in the pipeline NewHTTPSenderWithSecretHeader ( \"https://myendpoint.com\" , \"application/json\" , false , \"Authentication\" , \"/jwt\" ). HTTPPost //assumes TransformToJSON was used before this transform in the pipeline and /jwt has been seeded into the secret provider with a key of Authentication MQTT Factory Method Description NewMQTTSecretSender(mqttConfig MQTTSecretConfig, persistOnError bool) This function returns a MQTTSecretSender instance initialized with the options specified in the MQTTSecretConfig . type MQTTSecretConfig struct { // BrokerAddress should be set to the complete broker address i.e. mqtts://mosquitto:8883/mybroker BrokerAddress string // ClientId to connect with the broker with. ClientId string // The name of the path in secret provider to retrieve your secrets SecretPath string // AutoReconnect indicated whether or not to retry connection if disconnected AutoReconnect bool // Topic that you wish to publish to Topic string // QoS for MQTT Connection QoS byte // Retain setting for MQTT Connection Retain bool // SkipCertVerify SkipCertVerify bool // AuthMode indicates what to use when connecting to the broker. // Options are \"none\", \"cacert\" , \"usernamepassword\", \"clientcert\". // If a CA Cert exists in the SecretPath then it will be used for // all modes except \"none\". AuthMode string } Secrets in the secret provider may be located at any path however they must have some or all the follow keys at the specified SecretPath . username - username to connect to the broker password - password used to connect to the broker clientkey - client private key in PEM format clientcert - client cert in PEM format cacert - ca cert in PEM format What AuthMode you choose depends on what values are used. For example, if \"none\" is specified as auth mode all keys will be ignored. Similarly, if AuthMode is set to \"clientcert\" username and password will be ignored. Factory Method Description DEPRECATED NewMQTTSender(logging logger.LoggingClient, addr models.Addressable, keyCertPair *KeyCertPair, mqttConfig MqttConfig, persistOnError bool) This function returns a MQTTSender instance initialized with the passed in MQTT configuration . This MQTTSender instance is used to access the following function that will use the specified MQTT configuration - `KeyCertPair` - This structure holds the Key and Certificate information for when using secure ** TLS ** connection to the broker . Can be `nil` if not using secure ** TLS ** connection . - `MqttConfig` - This structure holds addition MQTT configuration set tings . Qos byte Retain bool AutoReconnect bool SkipCertVerify bool User string Password string Note The GO complier will default these to 0 , false and \"\" , so you only need to set the fields that your usage requires that differ from the default. MQTTSend - This function receives either a string , []byte , or json.Marshaler type from the previous function in the pipeline and sends it to the specified MQTT broker. If no previous function exists, then the event that triggered the pipeline, marshaled to json, will be used. If the send fails and persistOnError is true and Store and Forward is enabled, the data will be stored for later retry. See Store and Forward for more details. Output Functions There is one output function included in the SDK that can be added to your pipeline. Factory Method Description NewOutput() This function returns a Output instance that is used to access the following output function SetOutput - This function receives either a string , []byte , or json.Marshaler type from the previous function in the pipeline and sets it as the output data for the pipeline to return to the configured trigger. If configured to use message bus, the data will be published to the message bus as determined by the MessageBus and Binding configuration. If configured to use HTTP trigger the data is returned as the HTTP response. Note Calling Complete() from the Context API in a custom function can be used in place of adding this function to your pipeline","title":"Built-In Transforms/Functions"},{"location":"microservices/application/BuiltIn/#built-in-transformsfunctions","text":"All transforms define a type and a New function which is used to initialize an instance of the type with the required parameters. These instances returned by these New functions give access to their appropriate pipeline function pointers when setting up the function pipeline. Example NewFilter ([] { \"Device1\" , \"Device2\" }). FilterByDeviceName","title":"Built-In Transforms/Functions"},{"location":"microservices/application/BuiltIn/#filtering","text":"There are two basic types of filtering included in the SDK to add to your pipeline. There is also an option to Filter Out specific items. These provided filter functions return a type of events.Model. If filtering results in no remaining data, the pipeline execution for that pass is terminated. If no values are provided for filtering, then data flows through unfiltered. Factory Method Description NewFilter([]string filterValues) This function returns a Filter instance initialized with the passed in filter values. This Filter instance is used to access the following filter functions that will operate using the specified filter values. type Filter struct { // Holds the values to be filtered FilterValues [] string // Determines if items in FilterValues should be filtered out. If set to true all items found in the filter will be removed. If set to false all items found in the filter will be returned. If FilterValues is empty then all items will be returned. FilterOut bool }","title":"Filtering"},{"location":"microservices/application/BuiltIn/#by-device-name","text":"FilterByDeviceName - This function will filter the event data down to the specified device names and return the filtered data to the pipeline. NewFilter ([] { \"Device1\" , \"Device2\" }). FilterByDeviceName","title":"By Device Name"},{"location":"microservices/application/BuiltIn/#by-value-descriptor","text":"FilterByValueDescriptor - This function will filter the event data down to the specified device value descriptor and return the filtered data to the pipeline. NewFilter ([] { \"ValueDescriptor1\" , \"ValueDescriptor2\" }). FilterByValueDescriptor","title":"By Value Descriptor"},{"location":"microservices/application/BuiltIn/#json-logic","text":"Factory Method Description NewJSONLogic(rule string) This function returns a JSONLogic instance initialized with the passed in JSON rule. The rule passed in should be a JSON string conforming to the specification here: http://jsonlogic.com/operations.html. Evaluate - This is the function that will be used in the pipeline to apply the JSON rule to data coming in on the pipeline. If the condition of your rule is met, then the pipeline will continue and the data will continue to flow to the next function in the pipeline. If the condition of your rule is NOT met, then pipeline execution stops. NewJSONLogic ( \"{ \\\"in\\\" : [{ \\\"var\\\" : \\\"device\\\" }, [\\\"Random-Integer-Device\\\",\\\"Random-Float-Device\\\"] ] }\" ). Evaluate Note Only operations that return true or false are supported. See http://jsonlogic.com/operations.html# for the complete list of operations paying attention to return values. Any operator that returns manipulated data is currently not supported. For more advanced scenarios checkout EMQ X Kuiper . Tip Leverage http://jsonlogic.com/play.html to get your rule right before implementing in code. JSON can be a bit tricky to get right in code with all the escaped double quotes.","title":"JSON Logic"},{"location":"microservices/application/BuiltIn/#encryption","text":"There is one encryption transform included in the SDK that can be added to your pipeline. Factory Method Description NewEncryption(key string, initializationVector string) This function returns a Encryption instance initialized with the passed in key and initialization vector. This Encryption instance is used to access the following encryption function that will use the specified key and initialization vector.","title":"Encryption"},{"location":"microservices/application/BuiltIn/#aes","text":"EncryptWithAES - This function receives a either a string , []byte , or json.Marshaller type and encrypts it using AES encryption and returns a []byte to the pipeline. NewEncryption ( \"key\" , \"initializationVector\" ). EncryptWithAES","title":"AES"},{"location":"microservices/application/BuiltIn/#batch","text":"Included in the SDK is an in-memory batch function that will hold on to your data before continuing the pipeline. There are three functions provided for batching each with their own strategy. Factory Method Description NewBatchByTime(timeInterval string) This function returns a BatchConfig instance with time being the strategy that is used for determining when to release the batched data and continue the pipeline. timeInterval is the duration to wait (i.e. 10s ). The time begins after the first piece of data is received. If no data has been received no data will be sent forward. // Example: NewBatchByTime ( \"10s\" ). Batch NewBatchByCount(batchThreshold int) This function returns a BatchConfig instance with count being the strategy that is used for determining when to release the batched data and continue the pipeline. batchThreshold is how many events to hold on to (i.e. 25 ). The count begins after the first piece of data is received and once the threshold is met, the batched data will continue forward and the counter will be reset. // Example: NewBatchByCount ( 10 ). Batch NewBatchByTimeAndCount(timeInterval string, batchThreshold int) This function returns a BatchConfig instance with a combination of both time and count being the strategy that is used for determining when to release the batched data and continue the pipeline. Whichever occurs first will trigger the data to continue and be reset. // Example: NewBatchByTimeAndCount ( \"30s\" , 10 ). Batch Batch - This function will apply the selected strategy in your pipeline. Warning Keep memory usage in mind as you determine the thresholds for both time and count. The larger they are the more memory is required and could lead to performance issue.","title":"Batch"},{"location":"microservices/application/BuiltIn/#conversion","text":"There are two conversions included in the SDK that can be added to your pipeline. These transforms return a string . Factory Method Description NewConversion() This function returns a Conversion instance that is used to access the conversion functions.","title":"Conversion"},{"location":"microservices/application/BuiltIn/#xml","text":"TransformToXML - This function receives an events.Model type, converts it to XML format and returns the XML string to the pipeline. NewConversion (). TransformToXML","title":"XML"},{"location":"microservices/application/BuiltIn/#json","text":"TransformToJSON - This function receives an events.Model type and converts it to JSON format and returns the JSON string to the pipeline. NewConversion (). TransformToJSON","title":"JSON"},{"location":"microservices/application/BuiltIn/#compressions","text":"There are two compression types included in the SDK that can be added to your pipeline. These transforms return a []byte . Factory Method Description NewCompression() This function returns a Compression instance that is used to access the compression functions.","title":"Compressions"},{"location":"microservices/application/BuiltIn/#gzip","text":"CompressWithGZIP - This function receives either a string , []byte , or json.Marshaler type, GZIP compresses the data, converts result to base64 encoded string, which is returned as a []byte to the pipeline. NewCompression (). CompressWithGZIP","title":"GZIP"},{"location":"microservices/application/BuiltIn/#zlib","text":"CompressWithZLIB - This function receives either a string , []byte , or json.Marshaler type, ZLIB compresses the data, converts result to base64 encoded string, which is returned as a []byte to the pipeline. NewCompression (). CompressWithZLIB","title":"ZLIB"},{"location":"microservices/application/BuiltIn/#coredata-functions","text":"These are functions that enable interactions with the CoreData REST API. Factory Method Description NewCoreData() This function returns a CoreData instance. This CoreData instance is used to access core data functions.","title":"CoreData Functions"},{"location":"microservices/application/BuiltIn/#mark-as-pushed","text":"MarkAsPushed - This function provides the MarkAsPushed function from the context as a First-Class Transform that can be called in your pipeline. See Definition Above . The data passed into this function from the pipeline is passed along unmodified since all required information is provided on the context (EventId, CorrelationId,etc.. ) NewCoreData (). MarkAsPushed","title":"Mark As Pushed"},{"location":"microservices/application/BuiltIn/#push-to-core","text":"PushToCore - This function provides the PushToCore function from the context as a First-Class Transform that can be called in your pipeline. See Definition Above . The data passed into this function from the pipeline is wrapped in an EdgeX event with the deviceName and readingName that were set upon the CoreData instance and then sent to Core Data service to be added as an event. Returns the new EdgeX event with ID populated. NewCoreData (). PushToCore Note If validation is turned on in Core Services then your deviceName and readingName must exist in the Core Metadata service and be properly registered in EdgeX.","title":"Push to Core"},{"location":"microservices/application/BuiltIn/#export-functions","text":"There are a few export functions included in the SDK that can be added to your pipeline.","title":"Export Functions"},{"location":"microservices/application/BuiltIn/#http","text":"HTTPPost - This function receives either a string , []byte , or json.Marshaler type from the previous function in the pipeline and posts it to the configured endpoint. If no previous function exists, then the event that triggered the pipeline, marshaled to json, will be used. If the post fails and persistOnError is true and Store and Forward is enabled, the data will be stored for later retry. See Store and Forward for more details. Factory Method Description NewHTTPSender(url string, mimeType string, persistOnError bool) This function returns a HTTPSender instance initialized with the passed in url, mime type and persistOnError values. NewHTTPSenderWithSecretHeader(url string, mimeType string, persistOnError bool, httpHeaderSecretName string, secretPath string) This function returns a HTTPSender instance similar to the above function however will set up the HTTPSender to add a header to the HTTP request using the httpHeaderSecretName as both the header key and the key to search for in the secret provider at secretPath leveraging secure storage of secrets. Example NewHTTPSender ( \"https://myendpoint.com\" , \"application/json\" , false ). HTTPPost //assumes TransformToJSON was used before this transform in the pipeline NewHTTPSenderWithSecretHeader ( \"https://myendpoint.com\" , \"application/json\" , false , \"Authentication\" , \"/jwt\" ). HTTPPost //assumes TransformToJSON was used before this transform in the pipeline and /jwt has been seeded into the secret provider with a key of Authentication","title":"HTTP"},{"location":"microservices/application/BuiltIn/#mqtt","text":"Factory Method Description NewMQTTSecretSender(mqttConfig MQTTSecretConfig, persistOnError bool) This function returns a MQTTSecretSender instance initialized with the options specified in the MQTTSecretConfig . type MQTTSecretConfig struct { // BrokerAddress should be set to the complete broker address i.e. mqtts://mosquitto:8883/mybroker BrokerAddress string // ClientId to connect with the broker with. ClientId string // The name of the path in secret provider to retrieve your secrets SecretPath string // AutoReconnect indicated whether or not to retry connection if disconnected AutoReconnect bool // Topic that you wish to publish to Topic string // QoS for MQTT Connection QoS byte // Retain setting for MQTT Connection Retain bool // SkipCertVerify SkipCertVerify bool // AuthMode indicates what to use when connecting to the broker. // Options are \"none\", \"cacert\" , \"usernamepassword\", \"clientcert\". // If a CA Cert exists in the SecretPath then it will be used for // all modes except \"none\". AuthMode string } Secrets in the secret provider may be located at any path however they must have some or all the follow keys at the specified SecretPath . username - username to connect to the broker password - password used to connect to the broker clientkey - client private key in PEM format clientcert - client cert in PEM format cacert - ca cert in PEM format What AuthMode you choose depends on what values are used. For example, if \"none\" is specified as auth mode all keys will be ignored. Similarly, if AuthMode is set to \"clientcert\" username and password will be ignored. Factory Method Description DEPRECATED NewMQTTSender(logging logger.LoggingClient, addr models.Addressable, keyCertPair *KeyCertPair, mqttConfig MqttConfig, persistOnError bool) This function returns a MQTTSender instance initialized with the passed in MQTT configuration . This MQTTSender instance is used to access the following function that will use the specified MQTT configuration - `KeyCertPair` - This structure holds the Key and Certificate information for when using secure ** TLS ** connection to the broker . Can be `nil` if not using secure ** TLS ** connection . - `MqttConfig` - This structure holds addition MQTT configuration set tings . Qos byte Retain bool AutoReconnect bool SkipCertVerify bool User string Password string Note The GO complier will default these to 0 , false and \"\" , so you only need to set the fields that your usage requires that differ from the default. MQTTSend - This function receives either a string , []byte , or json.Marshaler type from the previous function in the pipeline and sends it to the specified MQTT broker. If no previous function exists, then the event that triggered the pipeline, marshaled to json, will be used. If the send fails and persistOnError is true and Store and Forward is enabled, the data will be stored for later retry. See Store and Forward for more details.","title":"MQTT"},{"location":"microservices/application/BuiltIn/#output-functions","text":"There is one output function included in the SDK that can be added to your pipeline. Factory Method Description NewOutput() This function returns a Output instance that is used to access the following output function SetOutput - This function receives either a string , []byte , or json.Marshaler type from the previous function in the pipeline and sets it as the output data for the pipeline to return to the configured trigger. If configured to use message bus, the data will be published to the message bus as determined by the MessageBus and Binding configuration. If configured to use HTTP trigger the data is returned as the HTTP response. Note Calling Complete() from the Context API in a custom function can be used in place of adding this function to your pipeline","title":"Output Functions"},{"location":"microservices/application/ContextAPI/","text":"The context parameter passed to each function/transform provides operations and data associated with each execution of the pipeline. Let's take a look at a few of the properties that are available: type Context struct { // ID of the EdgeX Event (will be filled for a received JSON Event) EventID string // Checksum of the EdgeX Event (will be filled for a received CBOR Event) EventChecksum string // This is the ID used to track the EdgeX event through entire EdgeX framework. CorrelationID string // OutputData is used for specifying the data that is to be outputted. Leverage the .Complete() function to set. OutputData [] byte // This holds the configuration for your service. This is the preferred way to access your custom application settings that have been set in the configuration. Configuration common . ConfigurationStruct // LoggingClient is exposed to allow logging following the preferred logging strategy within EdgeX. LoggingClient logger . LoggingClient // EventClient exposes Core Data's EventClient API EventClient coredata . EventClient // ValueDescriptorClient exposes Core Data's ValueDescriptor API ValueDescriptorClient coredata . ValueDescriptorClient // CommandClient exposes Core Commands's Command API CommandClient command . CommandClient // NotificationsClient exposes Support Notification's Notifications API NotificationsClient notifications . NotificationsClient // RetryData holds the data to be stored for later retry when the pipeline function returns an error RetryData [] byte // SecretProvider exposes the support for getting and storing secrets SecretProvider * security . SecretProvider } Clients LoggingClient The LoggingClient exposed on the context is available to leverage logging libraries/service utilized throughout the EdgeX framework. The SDK has initialized everything so it can be used to log Trace , Debug , Warn , Info , and Error messages as appropriate. See simple-filter-xml/main.go for an example of how to use the LoggingClient . EventClient The EventClient exposed on the context is available to leverage Core Data's Event API. See interface definition for more details. This client is useful for querying events and is used by the MarkAsPushed convenience API described below. ValueDescriptorClient The ValueDescriptorClient exposed on the context is available to leverage Core Data's ValueDescriptor API. See interface definition for more details. Useful for looking up the value descriptor for a reading received. CommandClient The CommandClient exposed on the context is available to leverage Core Command's Command API. See interface definition for more details. Useful for sending commands to devices. NotificationsClient The NotificationsClient exposed on the context is available to leverage Support Notifications' Notifications API. See README for more details. Useful for sending notifications. Note about Clients Each of the clients above is only initialized if the Clients section of the configuration contains an entry for the service associated with the Client API. If it isn't in the configuration the client will be nil . Your code must check for nil to avoid panic in case it is missing from the configuration. Only add the clients to your configuration that your Application Service will actually be using. All application services need Core-Data for version compatibility check done on start-up. The following is an example Clients section of a configuration.toml with all supported clients specified: [Clients] [Clients.Logging] Protocol = \"http\" Host = \"localhost\" Port = 48061 [Clients.CoreData] Protocol = 'http' Host = 'localhost' Port = 48080 [Clients.Command] Protocol = 'http' Host = 'localhost' Port = 48082 [Clients.Notifications] Protocol = 'http' Host = 'localhost' Port = 48060 .MarkAsPushed() .MarkAsPushed() is used to indicate to EdgeX Core Data that an event has been \"pushed\" and is no longer required to be stored. The scheduler service will purge all events that have been marked as pushed based on the configured schedule. By default, it is once daily at midnight. If you leverage the built in export functions (i.e. HTTP Export, or MQTT Export), then simply adding the MaskedAsPush function to you pipeline after the export function will take care of calling this API. .PushToCore() .PushToCore(string deviceName, string readingName, byte[] value) is used to push data to EdgeX Core Data so that it can be shared with other applications that are subscribed to the message bus that core-data publishes to. deviceName can be set as you like along with the readingName which will be set on the EdgeX event sent to CoreData. This function will return the new EdgeX Event with the ID populated, however the CorrelationId will not be available. Note If validation is turned on in CoreServices then your deviceName and readingName must exist in the CoreMetadata and be properly registered in EdgeX. Warning Be aware that without a filter in your pipeline, it is possible to create an infinite loop when the Message Bus trigger is used. Choose your device-name and reading name appropriately. .Complete() .Complete([]byte outputData) can be used to return data back to the configured trigger. In the case of an HTTP trigger, this would be an HTTP Response to the caller. In the case of a message bus trigger, this is how data can be published to a new topic per the configuration. .SetRetryData() .SetRetryData(payload []byte) can be used to store data for later retry. This is useful when creating a custom export function that needs to retry on failure when sending the data. The payload data will be stored for later retry based on Store and Forward configuration. When the retry is triggered, the function pipeline will be re-executed starting with the function that called this API. That function will be passed the stored data, so it is important that all transformations occur in functions prior to the export function. The Context will also be restored to the state when the function called this API. See Store and Forward for more details. Note Store and Forward be must enabled when calling this API. .GetSecrets() .GetSecrets(path string, keys ...string) is used to retrieve secrets from the secret store. path specifies the type or location of the secrets to retrieve. If specified, it is appended to the base path from the exclusive secret store configuration. keys specifies the list of secrets to be retrieved. If no keys are provided then all the keys associated with the specified path will be returned.","title":"Context API"},{"location":"microservices/application/ContextAPI/#clients","text":"","title":"Clients"},{"location":"microservices/application/ContextAPI/#loggingclient","text":"The LoggingClient exposed on the context is available to leverage logging libraries/service utilized throughout the EdgeX framework. The SDK has initialized everything so it can be used to log Trace , Debug , Warn , Info , and Error messages as appropriate. See simple-filter-xml/main.go for an example of how to use the LoggingClient .","title":"LoggingClient"},{"location":"microservices/application/ContextAPI/#eventclient","text":"The EventClient exposed on the context is available to leverage Core Data's Event API. See interface definition for more details. This client is useful for querying events and is used by the MarkAsPushed convenience API described below.","title":"EventClient"},{"location":"microservices/application/ContextAPI/#valuedescriptorclient","text":"The ValueDescriptorClient exposed on the context is available to leverage Core Data's ValueDescriptor API. See interface definition for more details. Useful for looking up the value descriptor for a reading received.","title":"ValueDescriptorClient"},{"location":"microservices/application/ContextAPI/#commandclient","text":"The CommandClient exposed on the context is available to leverage Core Command's Command API. See interface definition for more details. Useful for sending commands to devices.","title":"CommandClient"},{"location":"microservices/application/ContextAPI/#notificationsclient","text":"The NotificationsClient exposed on the context is available to leverage Support Notifications' Notifications API. See README for more details. Useful for sending notifications.","title":"NotificationsClient"},{"location":"microservices/application/ContextAPI/#note-about-clients","text":"Each of the clients above is only initialized if the Clients section of the configuration contains an entry for the service associated with the Client API. If it isn't in the configuration the client will be nil . Your code must check for nil to avoid panic in case it is missing from the configuration. Only add the clients to your configuration that your Application Service will actually be using. All application services need Core-Data for version compatibility check done on start-up. The following is an example Clients section of a configuration.toml with all supported clients specified: [Clients] [Clients.Logging] Protocol = \"http\" Host = \"localhost\" Port = 48061 [Clients.CoreData] Protocol = 'http' Host = 'localhost' Port = 48080 [Clients.Command] Protocol = 'http' Host = 'localhost' Port = 48082 [Clients.Notifications] Protocol = 'http' Host = 'localhost' Port = 48060","title":"Note about Clients"},{"location":"microservices/application/ContextAPI/#markaspushed","text":".MarkAsPushed() is used to indicate to EdgeX Core Data that an event has been \"pushed\" and is no longer required to be stored. The scheduler service will purge all events that have been marked as pushed based on the configured schedule. By default, it is once daily at midnight. If you leverage the built in export functions (i.e. HTTP Export, or MQTT Export), then simply adding the MaskedAsPush function to you pipeline after the export function will take care of calling this API.","title":".MarkAsPushed()"},{"location":"microservices/application/ContextAPI/#pushtocore","text":".PushToCore(string deviceName, string readingName, byte[] value) is used to push data to EdgeX Core Data so that it can be shared with other applications that are subscribed to the message bus that core-data publishes to. deviceName can be set as you like along with the readingName which will be set on the EdgeX event sent to CoreData. This function will return the new EdgeX Event with the ID populated, however the CorrelationId will not be available. Note If validation is turned on in CoreServices then your deviceName and readingName must exist in the CoreMetadata and be properly registered in EdgeX. Warning Be aware that without a filter in your pipeline, it is possible to create an infinite loop when the Message Bus trigger is used. Choose your device-name and reading name appropriately.","title":".PushToCore()"},{"location":"microservices/application/ContextAPI/#complete","text":".Complete([]byte outputData) can be used to return data back to the configured trigger. In the case of an HTTP trigger, this would be an HTTP Response to the caller. In the case of a message bus trigger, this is how data can be published to a new topic per the configuration.","title":".Complete()"},{"location":"microservices/application/ContextAPI/#setretrydata","text":".SetRetryData(payload []byte) can be used to store data for later retry. This is useful when creating a custom export function that needs to retry on failure when sending the data. The payload data will be stored for later retry based on Store and Forward configuration. When the retry is triggered, the function pipeline will be re-executed starting with the function that called this API. That function will be passed the stored data, so it is important that all transformations occur in functions prior to the export function. The Context will also be restored to the state when the function called this API. See Store and Forward for more details. Note Store and Forward be must enabled when calling this API.","title":".SetRetryData()"},{"location":"microservices/application/ContextAPI/#getsecrets","text":".GetSecrets(path string, keys ...string) is used to retrieve secrets from the secret store. path specifies the type or location of the secrets to retrieve. If specified, it is appended to the base path from the exclusive secret store configuration. keys specifies the list of secrets to be retrieved. If no keys are provided then all the keys associated with the specified path will be returned.","title":".GetSecrets()"},{"location":"microservices/application/ErrorHandling/","text":"Error Handling Each transform returns a true or false as part of the return signature. This is called the continuePipeline flag and indicates whether the SDK should continue calling successive transforms in the pipeline. return false, nil will stop the pipeline and stop processing the event. This is useful, for example, when filtering on values and nothing matches the criteria you've filtered on. return false, error , will stop the pipeline as well and the SDK will log the error you have returned. return true, nil tells the SDK to continue, and will call the next function in the pipeline with your result. The SDK will return control back to main when receiving a SIGTERM/SIGINT event to allow for custom clean up.","title":"Error Handling"},{"location":"microservices/application/ErrorHandling/#error-handling","text":"Each transform returns a true or false as part of the return signature. This is called the continuePipeline flag and indicates whether the SDK should continue calling successive transforms in the pipeline. return false, nil will stop the pipeline and stop processing the event. This is useful, for example, when filtering on values and nothing matches the criteria you've filtered on. return false, error , will stop the pipeline as well and the SDK will log the error you have returned. return true, nil tells the SDK to continue, and will call the next function in the pipeline with your result. The SDK will return control back to main when receiving a SIGTERM/SIGINT event to allow for custom clean up.","title":"Error Handling"},{"location":"microservices/application/GeneralAppServiceConfig/","text":"General App Service Configuration Similar to other EdgeX services, configuration is first determined by the configuration.toml file in the /res folder. If -cp is passed to the application on startup, the SDK will leverage the specific configuration provider (i.e Consul) to push configuration from the file into the registry and monitor configuration from there. You will find the configuration under the edgex/appservices/1.0/ key. This section describes the configuration elements that are unique to Application Services Please refer to the general Configuration documentation for configuration properties common across all services. Note * indicates the configuration value can be changed on the fly if using a configuration provider (like Consul). ** indicates the configuration value can be changed but the service must be restarted. Writable The following are additional entries in the Writable section which are applicable to Application Services. Writable StoreAndForward The section configures the Store and Forward capability. Please refer to Store and Forward section for more details. Configuration Default Value Description Writable StoreAndForward Enabled false* Indicates whether the Store and Forward capability enabled or disabled Writable StoreAndForward RetryInterval \"5m\"* Indicates the duration of time to wait before retries, aka Forward Writable StoreAndForward MaxRetryCount 10* Indicates whether maximum number of retries of failed data. The failed data is removed after the maximum retries has been exceeded. A value of 0 indicates endless retries. Writable Pipeline The section configures the Configurable Function Pipeline which is used only by App Service Configurable. Please refer to App Service Configurable - Getting Started section for more details Writable InsecureSecrets This section defines Insecure Secrets that are used when running is non-secure mode, i.e. when Vault isn't available. This is a dynamic map of configuration, so can empty if no secrets are used or can have as many or few user define secrets. Below are a few that are need if using the indicated capabilities. Configuration Default Value Description Writable InsecureSecrets DB --- This section defines a block of insecure secrets for database connection when Store and Forward is enabled and running is non-secure mode. This section is not required if Store and Forward is not enabled. Writable InsecureSecrets DB path redisdb* Indicates the type of database the insecure secrets are for. redisdb id the DB type name used internally and used to look up the credentials. Writable InsecureSecrets DB Secrets --- This section contains the Secrets key value pair map of database credentials Writable InsecureSecrets DB Secrets username blank* Indicates the value for the username when connecting to the database. When running in non-secure mode it is blank . Writable InsecureSecrets DB Secrets password blank* Indicates the value for the password when connecting to the database. When running in non-secure mode it is blank . Writable InsecureSecrets http --- This section defines a block of insecure secrets for HTTP Export, i.e HTTPPost function Writable InsecureSecrets http path http* Indicates the secrets path for HTTP Export. Must match the secretpath name configured for the HTTPPost function. Writable InsecureSecrets http Secrets --- This section contains the Secrets key value pair map for the HTTPPost function Writable InsecureSecrets http Secrets [headername] undefined* This indicates the HTTP header name and the value to set it to. I.e. the key name you choose is the actual HTTP Header name. The key name must match the secretheadername configured for HTTPPost . The value is what you need the header set to. Writable InsecureSecrets MQTT --- This section defines a block of insecure secrets for MQTT export, i.e. MQTTSecretSend function. Writable InsecureSecrets MQTT path mqtt* Indicates the secrets path for MQTT Export. Must match the secretpath name configured for the MQTTSecretSend function. Writable InsecureSecrets MQTT Secrets --- This section contains the Secrets key value pair map for the MQTTSecretSend function Writable InsecureSecrets MQTT Secrets username blank* Indicates the value for the username when connecting to the MQTT broker using usernamepassword authentication mode. Must be configured to the value the MQTT broker is expecting. Writable InsecureSecrets MQTT Secrets password blank* Indicates the value for the password when connecting to the MQTT broker using usernamepassword authentication mode. Must be configured to the value the MQTT broker is expecting. Writable InsecureSecrets MQTT Secrets cacert blank* Indicates the value (contents) for the CA Certificate when connecting to the MQTT broker using cacert authentication mode. Must be configured to the value the MQTT broker is expecting. Writable InsecureSecrets MQTT Secrets clientcert blank* Indicates the value (contents) for the Client Certificate when connecting to the MQTT broker using clientcert authentication mode. Must be configured to the value the MQTT broker is expecting. Writable InsecureSecrets MQTT Secrets clientkey blank* Indicates the value (contents) for the Client Key when connecting to the MQTT broker using clientcert authentication mode. Must be configured to the value the MQTT broker is expecting. Not Writable The following are additional configuration which are applicable to Application Services that require the service to be restarted after value(s) are changed. Database This optional section contains the connection information. It is only required when the Store and Forward capability is enabled. Note that it has a slightly different format that the database section used in the core services configuration. Configuration Default Value Description Database Type redisdb** Indicates the type of database used. redisdb and mongodb are the only valid types. Database Host localhost** Indicates the hostname for the database Database Port 6379** Indicates the port number for the database Database Timeout \"30s\"** Indicates the connection timeout for the database SecretStoreExclusive This optional section defines the configuration for the Exclusive Secret Store (i.e. Vault) used to Put and Get secrets that are exclusive to the instance of the Application Service. Please refer to the Secrets section for more details. Configuration Default Value Description SecretStoreExclusive Host localhost** Indicates the hostname for the Secret Store SecretStoreExclusive Port 8200** Indicates the port number for the Secret Store SecretStoreExclusive Path Depends on profile used Indicates the base path for the secrets with in the SecretStoreExclusive Protocol https** Indicates the protocol used for the Secret Store SecretStoreExclusive RootCaCertPath /vault/config/pki/ EdgeXFoundryCA/ EdgeXFoundryCA.pem** Indicates the path to the root CA Certificate for Vault SecretStoreExclusive ServerName localhost** Indicates the server name for the Secret Store SecretStoreExclusive TokenFile /vault/config/ assets/ resp-init.json** Indicates the path to the exclusive token for the service to connect to the Secret Store SecretStoreExclusive AdditionalRetryAttempts 10** Indicates the maximum number of failed connection attempts allowed SecretStoreExclusive RetryWaitPeriod \"1s\"** Indicates the wait time between failed connection attempts SecretStoreExclusive Authentication --- The section defines the Secret Store Authentication SecretStoreExclusive Authentication AuthType X-Vault-Token** Indicates the authentication type used when connecting to the Secret Store Clients This section defines the clients connect information. Please refer to the Note about Clients section for more details. Binding This section defines the Trigger binding for incoming data. Configuration Default Value Description Binding Type messagebus** Indicates the Trigger binding type. valid values are messagebus and http Binding SubscribeTopic events** Only used for messagebus binding type Indicates the subscribe topic to use to receive data from the Message Bus Binding PublishTopic blank** Only used for messagebus binding type Indicates the publish topic to use when sending data to the Message Bus MessageBus This section defines the message bus connect information. Only used for messagebus binding type Configuration Default Value Description MessageBus Type zero** Indicates the type of message bus being used. Valid type are zero , mqtt or redisstreams MessageBus SubscribeHost ... This section defines the connection information for subscribing to the Message Bus MessageBus SubscribeHost Host localhost** Indicates the hostname for subscribing to the Message Bus MessageBus SubscribeHost Port 5563** Indicates the port number for subscribing to the Message Bus MessageBus SubscribeHost Protocol tcp** Indicates the protocol number for subscribing to the Message Bus MessageBus PublishHost ... This section defines the connection information for publishing to the Message Bus MessageBus PublishHost Host \" \" * Indicates the hostname for publishing to the Message Bus MessageBus SubscribeHost Port 5565** Indicates the port number for publishing to the Message Bus MessageBus SubscribeHost Protocol tcp** Indicates the protocol number for publishing to the Message Bus MessageBus Optional ... This section is used for optional configuration specific to the Message Bus type used. Please refer to go-mod-messaging for more details Application Settings [ApplicationSettings] - Is used for custom application settings and is accessed via the ApplicationSettings() API. The ApplicationSettings API returns a map[string] string containing the contents on the ApplicationSetting section of the configuration.toml file. [ApplicationSettings] ApplicationName = \"My Application Service\"","title":"General App Service Configuration"},{"location":"microservices/application/GeneralAppServiceConfig/#general-app-service-configuration","text":"Similar to other EdgeX services, configuration is first determined by the configuration.toml file in the /res folder. If -cp is passed to the application on startup, the SDK will leverage the specific configuration provider (i.e Consul) to push configuration from the file into the registry and monitor configuration from there. You will find the configuration under the edgex/appservices/1.0/ key. This section describes the configuration elements that are unique to Application Services Please refer to the general Configuration documentation for configuration properties common across all services. Note * indicates the configuration value can be changed on the fly if using a configuration provider (like Consul). ** indicates the configuration value can be changed but the service must be restarted.","title":"General App Service Configuration"},{"location":"microservices/application/GeneralAppServiceConfig/#writable","text":"The following are additional entries in the Writable section which are applicable to Application Services.","title":"Writable"},{"location":"microservices/application/GeneralAppServiceConfig/#writable-storeandforward","text":"The section configures the Store and Forward capability. Please refer to Store and Forward section for more details. Configuration Default Value Description Writable StoreAndForward Enabled false* Indicates whether the Store and Forward capability enabled or disabled Writable StoreAndForward RetryInterval \"5m\"* Indicates the duration of time to wait before retries, aka Forward Writable StoreAndForward MaxRetryCount 10* Indicates whether maximum number of retries of failed data. The failed data is removed after the maximum retries has been exceeded. A value of 0 indicates endless retries.","title":"Writable StoreAndForward"},{"location":"microservices/application/GeneralAppServiceConfig/#writable-pipeline","text":"The section configures the Configurable Function Pipeline which is used only by App Service Configurable. Please refer to App Service Configurable - Getting Started section for more details","title":"Writable Pipeline"},{"location":"microservices/application/GeneralAppServiceConfig/#writable-insecuresecrets","text":"This section defines Insecure Secrets that are used when running is non-secure mode, i.e. when Vault isn't available. This is a dynamic map of configuration, so can empty if no secrets are used or can have as many or few user define secrets. Below are a few that are need if using the indicated capabilities. Configuration Default Value Description Writable InsecureSecrets DB --- This section defines a block of insecure secrets for database connection when Store and Forward is enabled and running is non-secure mode. This section is not required if Store and Forward is not enabled. Writable InsecureSecrets DB path redisdb* Indicates the type of database the insecure secrets are for. redisdb id the DB type name used internally and used to look up the credentials. Writable InsecureSecrets DB Secrets --- This section contains the Secrets key value pair map of database credentials Writable InsecureSecrets DB Secrets username blank* Indicates the value for the username when connecting to the database. When running in non-secure mode it is blank . Writable InsecureSecrets DB Secrets password blank* Indicates the value for the password when connecting to the database. When running in non-secure mode it is blank . Writable InsecureSecrets http --- This section defines a block of insecure secrets for HTTP Export, i.e HTTPPost function Writable InsecureSecrets http path http* Indicates the secrets path for HTTP Export. Must match the secretpath name configured for the HTTPPost function. Writable InsecureSecrets http Secrets --- This section contains the Secrets key value pair map for the HTTPPost function Writable InsecureSecrets http Secrets [headername] undefined* This indicates the HTTP header name and the value to set it to. I.e. the key name you choose is the actual HTTP Header name. The key name must match the secretheadername configured for HTTPPost . The value is what you need the header set to. Writable InsecureSecrets MQTT --- This section defines a block of insecure secrets for MQTT export, i.e. MQTTSecretSend function. Writable InsecureSecrets MQTT path mqtt* Indicates the secrets path for MQTT Export. Must match the secretpath name configured for the MQTTSecretSend function. Writable InsecureSecrets MQTT Secrets --- This section contains the Secrets key value pair map for the MQTTSecretSend function Writable InsecureSecrets MQTT Secrets username blank* Indicates the value for the username when connecting to the MQTT broker using usernamepassword authentication mode. Must be configured to the value the MQTT broker is expecting. Writable InsecureSecrets MQTT Secrets password blank* Indicates the value for the password when connecting to the MQTT broker using usernamepassword authentication mode. Must be configured to the value the MQTT broker is expecting. Writable InsecureSecrets MQTT Secrets cacert blank* Indicates the value (contents) for the CA Certificate when connecting to the MQTT broker using cacert authentication mode. Must be configured to the value the MQTT broker is expecting. Writable InsecureSecrets MQTT Secrets clientcert blank* Indicates the value (contents) for the Client Certificate when connecting to the MQTT broker using clientcert authentication mode. Must be configured to the value the MQTT broker is expecting. Writable InsecureSecrets MQTT Secrets clientkey blank* Indicates the value (contents) for the Client Key when connecting to the MQTT broker using clientcert authentication mode. Must be configured to the value the MQTT broker is expecting.","title":"Writable InsecureSecrets"},{"location":"microservices/application/GeneralAppServiceConfig/#not-writable","text":"The following are additional configuration which are applicable to Application Services that require the service to be restarted after value(s) are changed.","title":"Not Writable"},{"location":"microservices/application/GeneralAppServiceConfig/#database","text":"This optional section contains the connection information. It is only required when the Store and Forward capability is enabled. Note that it has a slightly different format that the database section used in the core services configuration. Configuration Default Value Description Database Type redisdb** Indicates the type of database used. redisdb and mongodb are the only valid types. Database Host localhost** Indicates the hostname for the database Database Port 6379** Indicates the port number for the database Database Timeout \"30s\"** Indicates the connection timeout for the database","title":"Database"},{"location":"microservices/application/GeneralAppServiceConfig/#secretstoreexclusive","text":"This optional section defines the configuration for the Exclusive Secret Store (i.e. Vault) used to Put and Get secrets that are exclusive to the instance of the Application Service. Please refer to the Secrets section for more details. Configuration Default Value Description SecretStoreExclusive Host localhost** Indicates the hostname for the Secret Store SecretStoreExclusive Port 8200** Indicates the port number for the Secret Store SecretStoreExclusive Path Depends on profile used Indicates the base path for the secrets with in the SecretStoreExclusive Protocol https** Indicates the protocol used for the Secret Store SecretStoreExclusive RootCaCertPath /vault/config/pki/ EdgeXFoundryCA/ EdgeXFoundryCA.pem** Indicates the path to the root CA Certificate for Vault SecretStoreExclusive ServerName localhost** Indicates the server name for the Secret Store SecretStoreExclusive TokenFile /vault/config/ assets/ resp-init.json** Indicates the path to the exclusive token for the service to connect to the Secret Store SecretStoreExclusive AdditionalRetryAttempts 10** Indicates the maximum number of failed connection attempts allowed SecretStoreExclusive RetryWaitPeriod \"1s\"** Indicates the wait time between failed connection attempts SecretStoreExclusive Authentication --- The section defines the Secret Store Authentication SecretStoreExclusive Authentication AuthType X-Vault-Token** Indicates the authentication type used when connecting to the Secret Store","title":"SecretStoreExclusive"},{"location":"microservices/application/GeneralAppServiceConfig/#clients","text":"This section defines the clients connect information. Please refer to the Note about Clients section for more details.","title":"Clients"},{"location":"microservices/application/GeneralAppServiceConfig/#binding","text":"This section defines the Trigger binding for incoming data. Configuration Default Value Description Binding Type messagebus** Indicates the Trigger binding type. valid values are messagebus and http Binding SubscribeTopic events** Only used for messagebus binding type Indicates the subscribe topic to use to receive data from the Message Bus Binding PublishTopic blank** Only used for messagebus binding type Indicates the publish topic to use when sending data to the Message Bus","title":"Binding"},{"location":"microservices/application/GeneralAppServiceConfig/#messagebus","text":"This section defines the message bus connect information. Only used for messagebus binding type Configuration Default Value Description MessageBus Type zero** Indicates the type of message bus being used. Valid type are zero , mqtt or redisstreams MessageBus SubscribeHost ... This section defines the connection information for subscribing to the Message Bus MessageBus SubscribeHost Host localhost** Indicates the hostname for subscribing to the Message Bus MessageBus SubscribeHost Port 5563** Indicates the port number for subscribing to the Message Bus MessageBus SubscribeHost Protocol tcp** Indicates the protocol number for subscribing to the Message Bus MessageBus PublishHost ... This section defines the connection information for publishing to the Message Bus MessageBus PublishHost Host \" \" * Indicates the hostname for publishing to the Message Bus MessageBus SubscribeHost Port 5565** Indicates the port number for publishing to the Message Bus MessageBus SubscribeHost Protocol tcp** Indicates the protocol number for publishing to the Message Bus MessageBus Optional ... This section is used for optional configuration specific to the Message Bus type used. Please refer to go-mod-messaging for more details","title":"MessageBus"},{"location":"microservices/application/GeneralAppServiceConfig/#application-settings","text":"[ApplicationSettings] - Is used for custom application settings and is accessed via the ApplicationSettings() API. The ApplicationSettings API returns a map[string] string containing the contents on the ApplicationSetting section of the configuration.toml file. [ApplicationSettings] ApplicationName = \"My Application Service\"","title":"Application Settings"},{"location":"microservices/application/Triggers/","text":"Triggers determine how the app functions pipeline begins execution. The trigger is determined by the configuration.toml file located in the /res directory under a section called [Binding] . Check out the Configuration Section for more information about the toml file. Message Bus Trigger A message bus trigger will execute the pipeline every time data is received off of the configured topic. Type and Topic configuration Here's an example: Type = \"messagebus\" SubscribeTopic = \"events\" PublishTopic = \"\" The Type= is set to \"messagebus\". EdgeX Core Data is publishing data to the events topic. So to receive data from core data, you can set your SubscribeTopic= either to \"\" or \"events\" . You may also designate a PublishTopic= if you wish to publish data back to the message bus. edgexcontext.Complete([]byte outputData) - Will send data back to back to the message bus with the topic specified in the PublishTopic= property Message bus connection configuration The other piece of configuration required are the connection settings: [MessageBus] Type = 'zero' #specifies of message bus (i.e zero for ZMQ) [MessageBus.PublishHost] Host = '*' Port = 5564 Protocol = 'tcp' [MessageBus.SubscribeHost] Host = 'localhost' Port = 5563 Protocol = 'tcp' By default, EdgeX Core Data publishes data to the events topic using ZMQ on port 5563. The publish host is used if publishing data back to the message bus. Important When using ZMQ for the message bus, the Publish Host MUST be different for every topic you wish to publish to since the SDK will bind to the specific port. 5563 for example cannot be used to publish since EdgeX Core Data has bound to that port. Similarly, you cannot have two separate instances of the app functions SDK running publishing to the same port. HTTP Trigger Designating an HTTP trigger will allow the pipeline to be triggered by a RESTful POST call to http://[host]:[port]/api/v1/trigger/ . The body of the POST must be an EdgeX event. edgexcontext.Complete([]byte outputData) - Will send the specified data as the response to the request that originally triggered the HTTP Request.","title":"Triggers"},{"location":"microservices/application/Triggers/#message-bus-trigger","text":"A message bus trigger will execute the pipeline every time data is received off of the configured topic.","title":"Message Bus Trigger"},{"location":"microservices/application/Triggers/#type-and-topic-configuration","text":"Here's an example: Type = \"messagebus\" SubscribeTopic = \"events\" PublishTopic = \"\" The Type= is set to \"messagebus\". EdgeX Core Data is publishing data to the events topic. So to receive data from core data, you can set your SubscribeTopic= either to \"\" or \"events\" . You may also designate a PublishTopic= if you wish to publish data back to the message bus. edgexcontext.Complete([]byte outputData) - Will send data back to back to the message bus with the topic specified in the PublishTopic= property","title":"Type and Topic configuration"},{"location":"microservices/application/Triggers/#message-bus-connection-configuration","text":"The other piece of configuration required are the connection settings: [MessageBus] Type = 'zero' #specifies of message bus (i.e zero for ZMQ) [MessageBus.PublishHost] Host = '*' Port = 5564 Protocol = 'tcp' [MessageBus.SubscribeHost] Host = 'localhost' Port = 5563 Protocol = 'tcp' By default, EdgeX Core Data publishes data to the events topic using ZMQ on port 5563. The publish host is used if publishing data back to the message bus. Important When using ZMQ for the message bus, the Publish Host MUST be different for every topic you wish to publish to since the SDK will bind to the specific port. 5563 for example cannot be used to publish since EdgeX Core Data has bound to that port. Similarly, you cannot have two separate instances of the app functions SDK running publishing to the same port.","title":"Message bus connection configuration"},{"location":"microservices/application/Triggers/#http-trigger","text":"Designating an HTTP trigger will allow the pipeline to be triggered by a RESTful POST call to http://[host]:[port]/api/v1/trigger/ . The body of the POST must be an EdgeX event. edgexcontext.Complete([]byte outputData) - Will send the specified data as the response to the request that originally triggered the HTTP Request.","title":"HTTP Trigger"},{"location":"microservices/configuration/Ch-Configuration/","text":"Configuration and Registry Introduction The EdgeX registry and configuration service provides other EdgeX Foundry micro services with information about associated services within EdgeX Foundry (such as location and status) and configuration properties (i.e. - a repository of initialization and operating values). Today, EdgeX Foundry uses Consul by Hashicorp as its reference implementation configuration and registry service. However, abstractions are in place so that these functions could be provided by an alternate implementation. In fact, registration and configuration could be provided by different services under the covers. For more, see the Configuration Provider and Registry Provider sections in this page. Configuration Please refer to the EdgeX Foundry architectural decision record for details (and design decisions) behind the configuration in EdgeX. Local Configuration Because EdgeX Foundry may be deployed and run in several different ways, it is important to understand how configuration is loaded and from where it is sourced. Referring to the cmd directory within the edgex-go repository , each service has its own folder. Inside each service folder there is a res directory (short for \"resource\"). There you will find the configuration files in TOML format that defines each service's configuration. A service may support several different configuration profiles, such as a \"docker\" profile. In this case, the configuration file located directly in the res directory should be considered the default configuration profile. Sub-directories will contain configurations appropriate to the respective profile. As of the Geneva release, EdgeX recommends using environment variable overrides instead of creating profiles to override some subset of config values. You can see examples of this in the related docker-compose files . If you choose to use profiles as described above, the config profile can be indicated using one of the following command line flags: --profile / -p Taking the core-data service as an example: ./core-data starts the service using the default profile found locally ./core-data --profile=docker starts the service using the docker profile found locally Note Again, utilizing environment variables for configuration overrides is the recommended path. Config profiles have been deprecated and will be removed in a future release. Seeding Configuration When utilizing the registry to provide centralized configuration management for the EdgeX Foundry micro services, it is necessary to seed the required configuration before starting the services. Each service has the built-in capability to perform this seeding operation. A service will use its local configuration file to initialize the structure and relevant values, and then overlay any environment variable override values as specified. The end result will be seeded into the configuration provider if such is being used. In order for a service to now load the configuration from the configuration provider, use one of the following flags: --configProvider / -cp Again, taking the core-data service as an example: ./core-data -cp=consul.http://localhost:8500 will start the service using configuration values found in the provider Configuration Structure Configuration information is organized into a hierarchical structure allowing for a logical grouping of services, as well as versioning, beneath an \"edgex\" namespace at root level of the configuration tree. The root namespace separates EdgeX Foundry-related configuration information from other applications that may be using the same registry. Below the root, sub-nodes facilitate grouping of device services, EdgeX core services, security services, etc. As an example, the top-level nodes shown when one views the configuration registry might be as follows: edgex (root namespace) core (edgex core services) devices (device services) Versioning Incorporating versioning into the configuration hierarchy looks like this. edgex (root namespace) core (edgex core services) 1.0 edgex-core-command edgex-core-data edgex-core-metadata 2.0 devices (device services) 1.0 mqtt-c mqtt-go modbus-go 2.0 appservices (application services) 1.0 AppService-rules-engine 2.0 The versions shown correspond to major versions of the given services. For all minor/patch versions associated with a major version, the respective service keys live under the major version in configuration (such as 1.0). Changes to the configuration structure that may be required during the associated minor version development cycles can only be additive. That is, key names will not be removed or changed once set in a major version. Futhermore, sections of the configuration tree cannot be moved from one place to another. In this way, backward compatibility for the lifetime of the major version is maintained. An advantage of grouping all minor/patch versions under a major version involves end-user configuration changes that need to be persisted during an upgrade. A service on startup will not overwrite existing configuration when it runs unless explicitly told to do so via the --overwrite / -o command line flag. Therefore if a user leaves their configuration provider running during an EdgeX Foundry upgrade any customization will be left in place. Environment variable overrides such as those supplied in the docker-compose for a given release will always override existing content in the configuration provider. Configuration Properties The following tables document configuration properties that are common to all services in the EdgeX Foundry platform. Service-specific properties can be found on the respective documentation page for each service. Writable Property Default Value Description entries in the Writable section of the configuration can be changed on the fly while the service is running if the service is running with the -cp/--configProvider=consul.<url> flag LogLevel INFO log entry severity level . Log entries not of the default level or higher are ignored. Logging Property Default Value Description configuration governing logging behavior. With the default values below, all logging will be written to StdOut. EnableRemote false Facilitates delegation of logging via REST to the support-logging service File [empty string] File path to save logging entries. Empty by default. Databases/Databases.Primary Property Default Value Description configuration that govern database connectivity and the type of database to use. While not all services require DB connectivity, most do and so this has been included in the common configuration docs. Username [empty string] DB user name Password [empty string] DB password Host localhost DB host name Port 6379 DB port number Name coredata Database or document store name Timeout 5000 DB connection timeout Type redisdb DB type. Alternate is mongodb which is being deprecated Registry Property Default Value Description this configuration only takes effect when connecting to the registry for configuration info Host localhost Registry host name Port 8500 Registry port number Type consul Registry implementation type Clients/[Service name like Metadata] Property Default Value Description Protocol http The protocol to use when building a URI to local the service endpoint Host localhost The host name or IP address where the service is hosted Port 48081 The port exposed by the target service Startup Property Default Value Description Duration 30 The maximum amount of time (in seconds) the service is given to complete the bootstrap phase. Interval 1 The amount of time (in seconds) to sleep between retries on a failed dependency such as DB connection SecretStore Property Default Value Description these config values are used when security is enabled and Vault access is required for obtaining secrets, such as database credentials Host localhost The host name or IP address associated with Vault Port 8200 The configured port on which Vault is listening Path /v1/secret/edgex/coredata/ The service-specific path where the secrets are kept. This path will differ according to the given service Protocol https The protocol to be used when communicating with Vault RootCaCertPath /vault/config/pki/EdgeXFoundryCA/ EdgeXFoundryCA.pem The default location of the certificate used to communicate with Vault over a secure channel ServerName localhost The name of the server where Vault is located. TokenFile /vault/config/assets/resp-init.json Fully-qualified path to the location of the Vault root token. AdditionalRetryAttempts 10 Number of attemtps to retry retrieving secrets before failing to start the service RetryWaitPeriod 1s Amount of time to wait before attempting another connection to Vault Authentication AuthType X-Vault-Token A header used to indicate how the given service will authenticate with Vault Readable vs Writable Settings Within a given service's configuration, there are keys whose values can be edited and change the behavior of the service while it is running versus those that are effectively read-only. These writable settings are grouped under a given service key. For example, the top-level groupings for edgex-core-data are: /edgex/core/1.0/edgex-core-data/Clients /edgex/core/1.0/edgex-core-data/Databases /edgex/core/1.0/edgex-core-data/Logging /edgex/core/1.0/edgex-core-data/MessageQueue /edgex/core/1.0/edgex-core-data/Registry /edgex/core/1.0/edgex-core-data/SecretStore /edgex/core/1.0/edgex-core-data/Service /edgex/core/1.0/edgex-core-data/Writable Any configuration settings found in the Writable section shown above may be changed and affect a service's behavior without a restart. Any modifications to the other settings (read-only configuration) would require a restart. Note As of the Geneva release, the support-logging service is deprecated. In the Readable section of each service's configuration there is currently a Logging section shown below. The recommendation is that you not change the default values in this section unless you have a specific reason for doing so. # Remote and file logging disabled so only stdout logging is used [ Logging ] EnableRemote = false File = '' Configuration Provider You can supply and manage configuration in a centralized manner by utilizing the -cp/--configProvider=consul.<url> flag when starting a service. If the flag is provided and pointed to an application such as HashiCorp's Consul , the service will bootstrap its configuration into Consul if it doesn't exist. If configuration does already exist, it will load the content from the given location applying any environment variables overrides of which the service is aware. Integration with the configuration provider is handled through the go-mod-configuration module referenced by all services. Registry Provider The registry refers to any platform you may use for service discovery. For the EdgeX Foundry reference implementation, the default provider for this responsibility is Consul. Integration with the registry is handled through the go-mod-registry module referenced by all services. Introduction to Registry The objective of the registry is to enable micro services to find and to communicate with each other. When each micro service starts up, it registers itself with the registry, and the registry continues checking its availability periodically via a specified health check endpoint. When one micro service needs to connect to another one, it connects to the registry to retrieve the available host name and port number of the target micro service and then invokes the target micro service. The following figure shows the basic flow. Consul is the default registry implementation and provides native features for service registration, service discovery, and health checking. Please refer to the Consul official web site for more information: https://www.consul.io Physically, the \"registry\" and \"configuration\" management services are combined and running on the same Consul server node. Web User Interface A web user interface is also provided by Consul. Users can view the available service list and their health status through the web user interface. The web user interface is available at the /ui path on the same port as the HTTP API. By default this is http://localhost:8500/ui . For more detail, please see: https://www.consul.io/intro/getting-started/ui.html Running on Docker For ease of use to install and update, the micro services of EdgeX Foundry are published as Docker images onto Docker Hub, including Registry: https://hub.docker.com/r/edgexfoundry/docker-core-consul/ After the Docker engine is ready, users can download the latest Consul image by the docker pull command: docker pull edgexfoundry/docker-core-consul Then, startup Consul using Docker container by the Docker run command: docker run -p 8400 :8400 -p 8500 :8500 -p 8600 :8600 \\- -name edgex-core-consul \\- -hostname edgex-core-consul -d edgexfoundry/docker-core-consul These are the command steps to start up Consul and import the default configuration data: login to Docker Hub: docker login A Docker network is needed to enable one Docker container to communicate with another. This is preferred over use of --links that establishes a client-server relationship: docker network create edgex-network Create a Docker volume container for EdgeX Foundry: docker run -it --name edgex-files --net = edgex-network -v /data/db -v /edgex/logs -v /consul/config -v /consul/data -d edgexfoundry/docker-edgex-volume Create the Consul container: docker run -p 8400 :8400 -p 8500 :8500 -p 8600 :8600 --name edgex-core-consul --hostname edgex-core-consul --net = edgex-network --volumes-from edgex-files -d edgexfoundry/docker-core-consul Verify the result: http://localhost:8500/ui Running on Local Machine To run Consul on the local machine, following these steps: Download the binary from Consul official website: https://www.consul.io/downloads.html . Please choose the correct binary file according to the operation system. Set up the environment variable. Please refer to https://www.consul.io/intro/getting-started/install.html . Execute the following command: consul agent -data-dir \\$ { DATA_FOLDER } -ui -advertise 127 .0.0.1 -server -bootstrap-expect 1 # ${DATA_FOLDER} could be any folder to put the data files of Consul and it needs the read/write permission. Verify the result: http://localhost:8500/ui","title":"Configuration and Registry"},{"location":"microservices/configuration/Ch-Configuration/#configuration-and-registry","text":"","title":"Configuration and Registry"},{"location":"microservices/configuration/Ch-Configuration/#introduction","text":"The EdgeX registry and configuration service provides other EdgeX Foundry micro services with information about associated services within EdgeX Foundry (such as location and status) and configuration properties (i.e. - a repository of initialization and operating values). Today, EdgeX Foundry uses Consul by Hashicorp as its reference implementation configuration and registry service. However, abstractions are in place so that these functions could be provided by an alternate implementation. In fact, registration and configuration could be provided by different services under the covers. For more, see the Configuration Provider and Registry Provider sections in this page.","title":"Introduction"},{"location":"microservices/configuration/Ch-Configuration/#configuration","text":"Please refer to the EdgeX Foundry architectural decision record for details (and design decisions) behind the configuration in EdgeX.","title":"Configuration"},{"location":"microservices/configuration/Ch-Configuration/#local-configuration","text":"Because EdgeX Foundry may be deployed and run in several different ways, it is important to understand how configuration is loaded and from where it is sourced. Referring to the cmd directory within the edgex-go repository , each service has its own folder. Inside each service folder there is a res directory (short for \"resource\"). There you will find the configuration files in TOML format that defines each service's configuration. A service may support several different configuration profiles, such as a \"docker\" profile. In this case, the configuration file located directly in the res directory should be considered the default configuration profile. Sub-directories will contain configurations appropriate to the respective profile. As of the Geneva release, EdgeX recommends using environment variable overrides instead of creating profiles to override some subset of config values. You can see examples of this in the related docker-compose files . If you choose to use profiles as described above, the config profile can be indicated using one of the following command line flags: --profile / -p Taking the core-data service as an example: ./core-data starts the service using the default profile found locally ./core-data --profile=docker starts the service using the docker profile found locally Note Again, utilizing environment variables for configuration overrides is the recommended path. Config profiles have been deprecated and will be removed in a future release.","title":"Local Configuration"},{"location":"microservices/configuration/Ch-Configuration/#seeding-configuration","text":"When utilizing the registry to provide centralized configuration management for the EdgeX Foundry micro services, it is necessary to seed the required configuration before starting the services. Each service has the built-in capability to perform this seeding operation. A service will use its local configuration file to initialize the structure and relevant values, and then overlay any environment variable override values as specified. The end result will be seeded into the configuration provider if such is being used. In order for a service to now load the configuration from the configuration provider, use one of the following flags: --configProvider / -cp Again, taking the core-data service as an example: ./core-data -cp=consul.http://localhost:8500 will start the service using configuration values found in the provider","title":"Seeding Configuration"},{"location":"microservices/configuration/Ch-Configuration/#configuration-structure","text":"Configuration information is organized into a hierarchical structure allowing for a logical grouping of services, as well as versioning, beneath an \"edgex\" namespace at root level of the configuration tree. The root namespace separates EdgeX Foundry-related configuration information from other applications that may be using the same registry. Below the root, sub-nodes facilitate grouping of device services, EdgeX core services, security services, etc. As an example, the top-level nodes shown when one views the configuration registry might be as follows: edgex (root namespace) core (edgex core services) devices (device services)","title":"Configuration Structure"},{"location":"microservices/configuration/Ch-Configuration/#versioning","text":"Incorporating versioning into the configuration hierarchy looks like this. edgex (root namespace) core (edgex core services) 1.0 edgex-core-command edgex-core-data edgex-core-metadata 2.0 devices (device services) 1.0 mqtt-c mqtt-go modbus-go 2.0 appservices (application services) 1.0 AppService-rules-engine 2.0 The versions shown correspond to major versions of the given services. For all minor/patch versions associated with a major version, the respective service keys live under the major version in configuration (such as 1.0). Changes to the configuration structure that may be required during the associated minor version development cycles can only be additive. That is, key names will not be removed or changed once set in a major version. Futhermore, sections of the configuration tree cannot be moved from one place to another. In this way, backward compatibility for the lifetime of the major version is maintained. An advantage of grouping all minor/patch versions under a major version involves end-user configuration changes that need to be persisted during an upgrade. A service on startup will not overwrite existing configuration when it runs unless explicitly told to do so via the --overwrite / -o command line flag. Therefore if a user leaves their configuration provider running during an EdgeX Foundry upgrade any customization will be left in place. Environment variable overrides such as those supplied in the docker-compose for a given release will always override existing content in the configuration provider.","title":"Versioning"},{"location":"microservices/configuration/Ch-Configuration/#configuration-properties","text":"The following tables document configuration properties that are common to all services in the EdgeX Foundry platform. Service-specific properties can be found on the respective documentation page for each service. Writable Property Default Value Description entries in the Writable section of the configuration can be changed on the fly while the service is running if the service is running with the -cp/--configProvider=consul.<url> flag LogLevel INFO log entry severity level . Log entries not of the default level or higher are ignored. Logging Property Default Value Description configuration governing logging behavior. With the default values below, all logging will be written to StdOut. EnableRemote false Facilitates delegation of logging via REST to the support-logging service File [empty string] File path to save logging entries. Empty by default. Databases/Databases.Primary Property Default Value Description configuration that govern database connectivity and the type of database to use. While not all services require DB connectivity, most do and so this has been included in the common configuration docs. Username [empty string] DB user name Password [empty string] DB password Host localhost DB host name Port 6379 DB port number Name coredata Database or document store name Timeout 5000 DB connection timeout Type redisdb DB type. Alternate is mongodb which is being deprecated Registry Property Default Value Description this configuration only takes effect when connecting to the registry for configuration info Host localhost Registry host name Port 8500 Registry port number Type consul Registry implementation type Clients/[Service name like Metadata] Property Default Value Description Protocol http The protocol to use when building a URI to local the service endpoint Host localhost The host name or IP address where the service is hosted Port 48081 The port exposed by the target service Startup Property Default Value Description Duration 30 The maximum amount of time (in seconds) the service is given to complete the bootstrap phase. Interval 1 The amount of time (in seconds) to sleep between retries on a failed dependency such as DB connection SecretStore Property Default Value Description these config values are used when security is enabled and Vault access is required for obtaining secrets, such as database credentials Host localhost The host name or IP address associated with Vault Port 8200 The configured port on which Vault is listening Path /v1/secret/edgex/coredata/ The service-specific path where the secrets are kept. This path will differ according to the given service Protocol https The protocol to be used when communicating with Vault RootCaCertPath /vault/config/pki/EdgeXFoundryCA/ EdgeXFoundryCA.pem The default location of the certificate used to communicate with Vault over a secure channel ServerName localhost The name of the server where Vault is located. TokenFile /vault/config/assets/resp-init.json Fully-qualified path to the location of the Vault root token. AdditionalRetryAttempts 10 Number of attemtps to retry retrieving secrets before failing to start the service RetryWaitPeriod 1s Amount of time to wait before attempting another connection to Vault Authentication AuthType X-Vault-Token A header used to indicate how the given service will authenticate with Vault","title":"Configuration Properties"},{"location":"microservices/configuration/Ch-Configuration/#readable-vs-writable-settings","text":"Within a given service's configuration, there are keys whose values can be edited and change the behavior of the service while it is running versus those that are effectively read-only. These writable settings are grouped under a given service key. For example, the top-level groupings for edgex-core-data are: /edgex/core/1.0/edgex-core-data/Clients /edgex/core/1.0/edgex-core-data/Databases /edgex/core/1.0/edgex-core-data/Logging /edgex/core/1.0/edgex-core-data/MessageQueue /edgex/core/1.0/edgex-core-data/Registry /edgex/core/1.0/edgex-core-data/SecretStore /edgex/core/1.0/edgex-core-data/Service /edgex/core/1.0/edgex-core-data/Writable Any configuration settings found in the Writable section shown above may be changed and affect a service's behavior without a restart. Any modifications to the other settings (read-only configuration) would require a restart. Note As of the Geneva release, the support-logging service is deprecated. In the Readable section of each service's configuration there is currently a Logging section shown below. The recommendation is that you not change the default values in this section unless you have a specific reason for doing so. # Remote and file logging disabled so only stdout logging is used [ Logging ] EnableRemote = false File = ''","title":"Readable vs Writable Settings"},{"location":"microservices/configuration/Ch-Configuration/#configuration-provider","text":"You can supply and manage configuration in a centralized manner by utilizing the -cp/--configProvider=consul.<url> flag when starting a service. If the flag is provided and pointed to an application such as HashiCorp's Consul , the service will bootstrap its configuration into Consul if it doesn't exist. If configuration does already exist, it will load the content from the given location applying any environment variables overrides of which the service is aware. Integration with the configuration provider is handled through the go-mod-configuration module referenced by all services.","title":"Configuration Provider"},{"location":"microservices/configuration/Ch-Configuration/#registry-provider","text":"The registry refers to any platform you may use for service discovery. For the EdgeX Foundry reference implementation, the default provider for this responsibility is Consul. Integration with the registry is handled through the go-mod-registry module referenced by all services.","title":"Registry Provider"},{"location":"microservices/configuration/Ch-Configuration/#introduction-to-registry","text":"The objective of the registry is to enable micro services to find and to communicate with each other. When each micro service starts up, it registers itself with the registry, and the registry continues checking its availability periodically via a specified health check endpoint. When one micro service needs to connect to another one, it connects to the registry to retrieve the available host name and port number of the target micro service and then invokes the target micro service. The following figure shows the basic flow. Consul is the default registry implementation and provides native features for service registration, service discovery, and health checking. Please refer to the Consul official web site for more information: https://www.consul.io Physically, the \"registry\" and \"configuration\" management services are combined and running on the same Consul server node.","title":"Introduction to Registry"},{"location":"microservices/configuration/Ch-Configuration/#web-user-interface","text":"A web user interface is also provided by Consul. Users can view the available service list and their health status through the web user interface. The web user interface is available at the /ui path on the same port as the HTTP API. By default this is http://localhost:8500/ui . For more detail, please see: https://www.consul.io/intro/getting-started/ui.html","title":"Web User Interface"},{"location":"microservices/configuration/Ch-Configuration/#running-on-docker","text":"For ease of use to install and update, the micro services of EdgeX Foundry are published as Docker images onto Docker Hub, including Registry: https://hub.docker.com/r/edgexfoundry/docker-core-consul/ After the Docker engine is ready, users can download the latest Consul image by the docker pull command: docker pull edgexfoundry/docker-core-consul Then, startup Consul using Docker container by the Docker run command: docker run -p 8400 :8400 -p 8500 :8500 -p 8600 :8600 \\- -name edgex-core-consul \\- -hostname edgex-core-consul -d edgexfoundry/docker-core-consul These are the command steps to start up Consul and import the default configuration data: login to Docker Hub: docker login A Docker network is needed to enable one Docker container to communicate with another. This is preferred over use of --links that establishes a client-server relationship: docker network create edgex-network Create a Docker volume container for EdgeX Foundry: docker run -it --name edgex-files --net = edgex-network -v /data/db -v /edgex/logs -v /consul/config -v /consul/data -d edgexfoundry/docker-edgex-volume Create the Consul container: docker run -p 8400 :8400 -p 8500 :8500 -p 8600 :8600 --name edgex-core-consul --hostname edgex-core-consul --net = edgex-network --volumes-from edgex-files -d edgexfoundry/docker-core-consul Verify the result: http://localhost:8500/ui","title":"Running on Docker"},{"location":"microservices/configuration/Ch-Configuration/#running-on-local-machine","text":"To run Consul on the local machine, following these steps: Download the binary from Consul official website: https://www.consul.io/downloads.html . Please choose the correct binary file according to the operation system. Set up the environment variable. Please refer to https://www.consul.io/intro/getting-started/install.html . Execute the following command: consul agent -data-dir \\$ { DATA_FOLDER } -ui -advertise 127 .0.0.1 -server -bootstrap-expect 1 # ${DATA_FOLDER} could be any folder to put the data files of Consul and it needs the read/write permission. Verify the result: http://localhost:8500/ui","title":"Running on Local Machine"},{"location":"microservices/core/Ch-CoreServices/","text":"Core Services Core services provide the intermediary between the north and south sides of EdgeX. As the name of these services implies, they are \u201ccore\u201d to EdgeX functionality. Core services is where the innate knowledge of \u201cthings\u201d connected, sensor data collected, and EdgeX configuration resides. Core consists of the following micro services: Core data : a persistence repository and associated management service for data collected from south side objects. Command : a service that facilitates and controls actuation requests from the north side to the south side. Metadata : a repository and associated management service of metadata about the objects that are connected to EdgeX Foundry. Metadata provides the capability to provision new devices and pair them with their owning device services. Registry and Configuration : provides other EdgeX Foundry micro services with information about associated services within the system and micro services configuration properties (i.e. - a repository of initialization values).","title":"Core Services"},{"location":"microservices/core/Ch-CoreServices/#core-services","text":"Core services provide the intermediary between the north and south sides of EdgeX. As the name of these services implies, they are \u201ccore\u201d to EdgeX functionality. Core services is where the innate knowledge of \u201cthings\u201d connected, sensor data collected, and EdgeX configuration resides. Core consists of the following micro services: Core data : a persistence repository and associated management service for data collected from south side objects. Command : a service that facilitates and controls actuation requests from the north side to the south side. Metadata : a repository and associated management service of metadata about the objects that are connected to EdgeX Foundry. Metadata provides the capability to provision new devices and pair them with their owning device services. Registry and Configuration : provides other EdgeX Foundry micro services with information about associated services within the system and micro services configuration properties (i.e. - a repository of initialization values).","title":"Core Services"},{"location":"microservices/core/command/Ch-Command/","text":"Command Introduction The command micro service (often called the command and control micro service) enables the issuance of commands or actions to devices on behalf of: other micro services within EdgeX Foundry (for example, an edge analytics or rules engine micro service) other applications that may exist on the same system with EdgeX Foundry (for example, a management agent that needs to shutoff a sensor) To any external system that needs to command those devices (for example, a cloud-based application that determined the need to modify the settings on a collection of devices) The command micro service exposes the commands in a common, normalized way to simplify communications with the devices. There are two types of commands that can be sent to a device. a GET command requests data from the device. This is often used to request the latest sensor reading from the device. PUT commands request to take action or actuate the device or to set some configuration on the device. In most cases, GET commands are simple requests for the latest sensor reading from the device. Therefore, the request is often parameter-less (requiring no parameters or body in the request). As of the Geneva release, GET requests do allow query parameters to be added to the GET command requests (i.e. /api/v1/device/{deviceID}/command/{commandID}?param1=value&param2=value ). PUT commands often require a request body where the body provides a key/value pair array of values used as parameters in the request (i.e. {\"additionalProp1\": \"string\", \"additionalProp2\": \"string\"} ). The command micro service gets its knowledge about the devices from the metadata service. The command service always relays commands (GET or PUT) to the devices through the device service. The command service never communicates directly to a device. Therefore, the command micro service is a proxy service for command or action requests from the north side of EdgeX (such as analytic or application services) to the protocol-specific device service and associated device. While not current part of its duties, the command service could provide a layer of protection around device. Additional security could be added that would not allow unwarranted interaction with the devices (via device service). The command service could also regulate the number of requests on a device do not overwhelm the device - perhaps even caching responses so as to avoid waking a device unless necessary. Data Model Data Dictionary Action Property Description Action describes state related to the capabilities of a device Path Path used by service for action on a device or sensor Responses Responses from get or put requests to service URL Url for requests from command service Command Property Description defines a specific read/write operation targeting a device; the REST description of an interface. Id Unique identifier such as a UUID Name Unique name (on a profile) given to the Command Get Get or read Command Put Put or write Command Get Property Description a get command Action an action object Put Property Description a put command Action an action object ParameterNames Response Property Description A description of a possible REST response for a Command Code typically an HTTP response code Description ExpectedValues list of value descriptors for response type High Level Interaction Diagrams The two following High Level Diagrams show: Issue a PUT command Get a list of devices and the available commands Command PUT Request Request for Devices and Available Commands Configuration Properties Please refer to the general Configuration documentation for configuration properties common to all services. Service Property Default Value Description MaxResultCount 50000 Maximum number of objects (example: devices) that are to be returned on any query of command via its API Databases/Databases.Primary Property Default Value Description Properties used by the service to access the database Host 'localhost' Host running the metadata persistence database Name 'metadata' Document store or database name Password 'password' Password used to access the database Username 'core' Username used to access the database Port 6379 Port for accessing the database service - the Redis port by default Timeout 5000 Database connection timeout in milliseconds Type 'redisdb' Database to use - either redisdb or mongodb API Reference Core Command API Reference","title":"Command"},{"location":"microservices/core/command/Ch-Command/#command","text":"","title":"Command"},{"location":"microservices/core/command/Ch-Command/#introduction","text":"The command micro service (often called the command and control micro service) enables the issuance of commands or actions to devices on behalf of: other micro services within EdgeX Foundry (for example, an edge analytics or rules engine micro service) other applications that may exist on the same system with EdgeX Foundry (for example, a management agent that needs to shutoff a sensor) To any external system that needs to command those devices (for example, a cloud-based application that determined the need to modify the settings on a collection of devices) The command micro service exposes the commands in a common, normalized way to simplify communications with the devices. There are two types of commands that can be sent to a device. a GET command requests data from the device. This is often used to request the latest sensor reading from the device. PUT commands request to take action or actuate the device or to set some configuration on the device. In most cases, GET commands are simple requests for the latest sensor reading from the device. Therefore, the request is often parameter-less (requiring no parameters or body in the request). As of the Geneva release, GET requests do allow query parameters to be added to the GET command requests (i.e. /api/v1/device/{deviceID}/command/{commandID}?param1=value&param2=value ). PUT commands often require a request body where the body provides a key/value pair array of values used as parameters in the request (i.e. {\"additionalProp1\": \"string\", \"additionalProp2\": \"string\"} ). The command micro service gets its knowledge about the devices from the metadata service. The command service always relays commands (GET or PUT) to the devices through the device service. The command service never communicates directly to a device. Therefore, the command micro service is a proxy service for command or action requests from the north side of EdgeX (such as analytic or application services) to the protocol-specific device service and associated device. While not current part of its duties, the command service could provide a layer of protection around device. Additional security could be added that would not allow unwarranted interaction with the devices (via device service). The command service could also regulate the number of requests on a device do not overwhelm the device - perhaps even caching responses so as to avoid waking a device unless necessary.","title":"Introduction"},{"location":"microservices/core/command/Ch-Command/#data-model","text":"","title":"Data Model"},{"location":"microservices/core/command/Ch-Command/#data-dictionary","text":"Action Property Description Action describes state related to the capabilities of a device Path Path used by service for action on a device or sensor Responses Responses from get or put requests to service URL Url for requests from command service Command Property Description defines a specific read/write operation targeting a device; the REST description of an interface. Id Unique identifier such as a UUID Name Unique name (on a profile) given to the Command Get Get or read Command Put Put or write Command Get Property Description a get command Action an action object Put Property Description a put command Action an action object ParameterNames Response Property Description A description of a possible REST response for a Command Code typically an HTTP response code Description ExpectedValues list of value descriptors for response type","title":"Data Dictionary"},{"location":"microservices/core/command/Ch-Command/#high-level-interaction-diagrams","text":"The two following High Level Diagrams show: Issue a PUT command Get a list of devices and the available commands Command PUT Request Request for Devices and Available Commands","title":"High Level Interaction Diagrams"},{"location":"microservices/core/command/Ch-Command/#configuration-properties","text":"Please refer to the general Configuration documentation for configuration properties common to all services. Service Property Default Value Description MaxResultCount 50000 Maximum number of objects (example: devices) that are to be returned on any query of command via its API Databases/Databases.Primary Property Default Value Description Properties used by the service to access the database Host 'localhost' Host running the metadata persistence database Name 'metadata' Document store or database name Password 'password' Password used to access the database Username 'core' Username used to access the database Port 6379 Port for accessing the database service - the Redis port by default Timeout 5000 Database connection timeout in milliseconds Type 'redisdb' Database to use - either redisdb or mongodb","title":"Configuration Properties"},{"location":"microservices/core/command/Ch-Command/#api-reference","text":"Core Command API Reference","title":"API Reference"},{"location":"microservices/core/data/Ch-CoreData/","text":"Core Data Introduction The core data micro service provides centralized persistence for data collected by devices . Device services that collect sensor data call on the core data service to store the sensor data on the edge system (such as in a gateway ) until the data gets moved \"north\" and then exported to Enterprise and cloud systems. Core data persists the data in a local database. Redis is used by default, but a database abstraction layer allows for other databases to be used. Note EdgeX has used MongoDB in the past. Through the Geneva release, MongoDB is still supported but is considered deprecated. Alternate (both open source and commercial) implementations have also been provided in the past. Other services and systems, both within EdgeX Foundry and outside of EdgeX Foundry, access the sensor data only through the core data service. Core data could also provide a degree of security and protection of the data collected while the data is at the edge. Core data has a REST API for moving data into and out of the local storage. In the future, core data could be expandable to send or access sensor data via other protocols such as MQTT, AMQP, etc. Core data moves data to the application service (and edge analytcs ) via ZeroMQ by default. EdgeX provides a message bus abstraction that supports ZeroMQ (default) and MQTT. Use of MQTT requires the installation of a broker such as ActiveMQ. You can also add your own implementation of the message bus abstraction as needed. Core Data \"Streaming\" By default, core data persists all data collected by devices sent to it. However, when the data is too sensitive to keep at the edge, or there is no use for the data at the edge by other local services (e.g. by an analytics micro service), the data can be \"streamed\" through core data without persisting it. A configuration change to core data (PersistData=false) has core data send data to the application services without persisting the data. This option has the advantage of reducing latency through this layer and storage needs at the network edge. But the cost is having no historical data to use for analytics that need to look back in time to make a decision. Note When persistence is turned off via the PersistData flag, it is off for all devices. At this time, you cannot specify which device data is persisted and which device data is not. Application services do allow filtering of device data before it is exported or sent to another service like the rules engine, but this is not based on whether the data is persisted or not. Events and Readings Data collected from sensors is marshalled into EdgeX event and reading objects (delivered as JSON objects in service REST calls to core data). An event represents a collection of one or more sensor readings. Some sensors or devices are only providing a single value \u2013 a single reading - at a time. Other sensors spew multiple values whenever they are read. An event must have at least one reading. Events are associated to a sensor or device \u2013 the \u201cthing\u201d that sensed the environment and produced the readings. Readings represent a sensing on the part of a device or sensor. Readings only exist as part of (are owned by) an event. Readings are essentially a simple key/value pair of what was sensed (the key) and the value sensed (the value). A reading may include other bits of information to provide more context (for example data type information) for the users of that data. Consumers of the reading data could include things like user interfaces, data visualization systems and analytics tools. In the diagram below, an example event/reading collection is depicted. The event coming from the \u201cmotor123\u201d device has two readings (or sensed values). The first reading indicates that the motor123 device reported the pressure of the motor was 1300 (the unit of measure might be something like PSI). The value type property (shown as type above) on the reading lets the consumer of the information know that the value is an integer, base 64. The second reading indicates that the motor123 device also reported the temperature of the motor was 120 at the same time it reported the pressure (perhaps in degrees Fahrenheit). Data Model The following diagram shows the Data Model for core data. Device services send Event objects containing a collection or Readings to core data when a device captures a sensor reading. Data Dictionary Event Property Description Event represents a single measurable event read from a device. Event has a one-to-many relationship with Reading. ID Uniquely identifies an event, for example a UUID Pushed A timestamp indicating when the event was exported. If unexported, the value is zero. Device Device identifies the source of the event, can be a device name or id. Usually the device name. Created A timestamp indicating when the event was created in the database Modified A timestamp indicating when the event was last modified. Origin A timestamp indicating when the original event/reading took place. Most of the time, this indicates when the device service collected/created the event Readings A collection (one to many) of associated readings of a given event. Reading Property Description ID Uniquely identifies a reading, for example a UUID Pushed A timestamp indicating when the reading was exported. If unexported, the value is zero. Device Device identifies the source of the reading, can be a device name or id. Usually the device name. Created A timestamp indicating when the reading was created in the database Modified A timestamp indicating when the reading was last modified. Origin A timestamp indicating when the original event/reading took place. Most of the time, this indicates when the device service collected/created the event Name Name-Value provide the key/value pair of what was sensed by a device. Name specifies what was the value collected. Name should match a value descriptor name. Value The sensor data value ValueType The type of the sensor data - from a list of allowed value types that includes Bool, String, Uint8, Int8, ... FloatEncoding Floating point encoding format for float values BinaryValue Byte array of sensor data when the data captured is not structured; for example an image is captured. This information is not persisted in the Database and is expected to be empty when retrieving a Reading for the ValueType of Binary MediaType Indicating the type of binary data when collected ValueDescriptor Property Description Provide the context, unit of measure and more information about any sensed data value ID Uniquely identifies a value descriptor, for example a UUID Created A timestamp indicating when the value descriptor was created in the database Modified A timestamp indicating when the value descriptor was last modified. Origin A timestamp indicating when the original value descriptor was created. Most of the time, this indicates when the device service requested the value descriptor be created Descrption Describes what the value descriptor is used for (example: defines a thermostat temperature value) Name Name of the value descriptor and used as the name key in the reading Min Minimum allowed value Max Maximum allowed value DefaultValue Type Value data type UomLabel Unit of measure label Formatting Printf convention for display of the value Labels array of associated means to label or tag a value (examples: BACNet, temp, thermostat) FloatEncoding Floating point encoding format for float values MediaType Indicating the type of binary data when collected High Level Interaction Diagrams The two following High Level Interaction Diagrams show: How new sensor readings are collected by a device and added as event/readings to core data and the associated persistence store How a client (inside or outside of EdgeX) can query for events (in this case by device name) Core Data Add Sensor Readings Core Data Request Event / Reading for a Device Configuration Properties Please refer to the general Configuration documentation for configuration properties common to all services. Writable Property Default Value Description Writable properties can be set and will dynamically take effect without service restart DeviceUpdateLastConnected false When true, core data updates the last connected timestamp for the device in metadata with each event from a given device MetaDataCheck false When true, core data calls metadata to check that the event's referenced device is known to meta data PersistData true When true, core data persists all sensor data sent to it in its associated database ServiceUpdateLastConnected false When true, core data updates the last connected timestamp for the device service in metadata ValidateCheck false When true, core data checks that the name (the value descriptor) of a reading is known to metadata ChecksumAlgo 'xxHash' Identifies the algorithm to use when calculating an event's checksum. Service Property Default Value Description MaxResultCount 50000 Maximum number of objects (example: events) that are to be returned on any query of core data via its API Databases/Databases.Primary Property Default Value Description Properties used by the service to access the database Host 'localhost' Host running the core data persistence database Name 'coredata' Document store or database name Password 'password' Password used to access the database Username 'core' Username used to access the database Port 6379 Port for accessing the database service - the Redis port by default Timeout 5000 Database connection timeout in milliseconds Type 'redisdb' Database to use - either redisdb or mongodb MessageQueue Property Default Value Description Entries in the MessageQueue section of the configuration allow for publication of events to a message bus MessageQueue Protocol tcp Indicates the connectivity protocol to use to use the bus. MessageQueue Host * Indicates the host of the messaging broker, if applicable. MessageQueue Port 5563 Indicates the port to use when publishing a message. MessageQueue Type zero Indicates the type of messaging library to use. Currently this is ZeroMQ by default. Refer to the go-mod-messaging module for more information. MessageQueue Topic events Indicates the topic to which messages should be published. MessageQueue.Optional Property Default Value Description Configuration and connection parameters for use with MQTT message bus - in place of 0MQ Password 'password' Password used to access the message system Username 'core' Username used to access the message system ClientId 'core-data' Client ID used to put messages on the bus Qos '0' Quality of Sevice values are 0 (At most once), 1 (At least once) or 2 (Exactly once) KeepAlive '10' Period of time in seconds to keep the connection alive when there is no messages flowing (must be 2 or greater) Retained false Whether to retain messages AutoReconnect true Whether to reconnect to the message bus on connection loss ConnectTimeout 5 Message bus connection timeout in seconds SkipCertVerify false TLS configuration - Only used if Cert/Key file or Cert/Key PEMblock are specified API Reference Core Data API Reference","title":"Core Data"},{"location":"microservices/core/data/Ch-CoreData/#core-data","text":"","title":"Core Data"},{"location":"microservices/core/data/Ch-CoreData/#introduction","text":"The core data micro service provides centralized persistence for data collected by devices . Device services that collect sensor data call on the core data service to store the sensor data on the edge system (such as in a gateway ) until the data gets moved \"north\" and then exported to Enterprise and cloud systems. Core data persists the data in a local database. Redis is used by default, but a database abstraction layer allows for other databases to be used. Note EdgeX has used MongoDB in the past. Through the Geneva release, MongoDB is still supported but is considered deprecated. Alternate (both open source and commercial) implementations have also been provided in the past. Other services and systems, both within EdgeX Foundry and outside of EdgeX Foundry, access the sensor data only through the core data service. Core data could also provide a degree of security and protection of the data collected while the data is at the edge. Core data has a REST API for moving data into and out of the local storage. In the future, core data could be expandable to send or access sensor data via other protocols such as MQTT, AMQP, etc. Core data moves data to the application service (and edge analytcs ) via ZeroMQ by default. EdgeX provides a message bus abstraction that supports ZeroMQ (default) and MQTT. Use of MQTT requires the installation of a broker such as ActiveMQ. You can also add your own implementation of the message bus abstraction as needed.","title":"Introduction"},{"location":"microservices/core/data/Ch-CoreData/#core-data-streaming","text":"By default, core data persists all data collected by devices sent to it. However, when the data is too sensitive to keep at the edge, or there is no use for the data at the edge by other local services (e.g. by an analytics micro service), the data can be \"streamed\" through core data without persisting it. A configuration change to core data (PersistData=false) has core data send data to the application services without persisting the data. This option has the advantage of reducing latency through this layer and storage needs at the network edge. But the cost is having no historical data to use for analytics that need to look back in time to make a decision. Note When persistence is turned off via the PersistData flag, it is off for all devices. At this time, you cannot specify which device data is persisted and which device data is not. Application services do allow filtering of device data before it is exported or sent to another service like the rules engine, but this is not based on whether the data is persisted or not.","title":"Core Data \"Streaming\""},{"location":"microservices/core/data/Ch-CoreData/#events-and-readings","text":"Data collected from sensors is marshalled into EdgeX event and reading objects (delivered as JSON objects in service REST calls to core data). An event represents a collection of one or more sensor readings. Some sensors or devices are only providing a single value \u2013 a single reading - at a time. Other sensors spew multiple values whenever they are read. An event must have at least one reading. Events are associated to a sensor or device \u2013 the \u201cthing\u201d that sensed the environment and produced the readings. Readings represent a sensing on the part of a device or sensor. Readings only exist as part of (are owned by) an event. Readings are essentially a simple key/value pair of what was sensed (the key) and the value sensed (the value). A reading may include other bits of information to provide more context (for example data type information) for the users of that data. Consumers of the reading data could include things like user interfaces, data visualization systems and analytics tools. In the diagram below, an example event/reading collection is depicted. The event coming from the \u201cmotor123\u201d device has two readings (or sensed values). The first reading indicates that the motor123 device reported the pressure of the motor was 1300 (the unit of measure might be something like PSI). The value type property (shown as type above) on the reading lets the consumer of the information know that the value is an integer, base 64. The second reading indicates that the motor123 device also reported the temperature of the motor was 120 at the same time it reported the pressure (perhaps in degrees Fahrenheit).","title":"Events and Readings"},{"location":"microservices/core/data/Ch-CoreData/#data-model","text":"The following diagram shows the Data Model for core data. Device services send Event objects containing a collection or Readings to core data when a device captures a sensor reading.","title":"Data Model"},{"location":"microservices/core/data/Ch-CoreData/#data-dictionary","text":"Event Property Description Event represents a single measurable event read from a device. Event has a one-to-many relationship with Reading. ID Uniquely identifies an event, for example a UUID Pushed A timestamp indicating when the event was exported. If unexported, the value is zero. Device Device identifies the source of the event, can be a device name or id. Usually the device name. Created A timestamp indicating when the event was created in the database Modified A timestamp indicating when the event was last modified. Origin A timestamp indicating when the original event/reading took place. Most of the time, this indicates when the device service collected/created the event Readings A collection (one to many) of associated readings of a given event. Reading Property Description ID Uniquely identifies a reading, for example a UUID Pushed A timestamp indicating when the reading was exported. If unexported, the value is zero. Device Device identifies the source of the reading, can be a device name or id. Usually the device name. Created A timestamp indicating when the reading was created in the database Modified A timestamp indicating when the reading was last modified. Origin A timestamp indicating when the original event/reading took place. Most of the time, this indicates when the device service collected/created the event Name Name-Value provide the key/value pair of what was sensed by a device. Name specifies what was the value collected. Name should match a value descriptor name. Value The sensor data value ValueType The type of the sensor data - from a list of allowed value types that includes Bool, String, Uint8, Int8, ... FloatEncoding Floating point encoding format for float values BinaryValue Byte array of sensor data when the data captured is not structured; for example an image is captured. This information is not persisted in the Database and is expected to be empty when retrieving a Reading for the ValueType of Binary MediaType Indicating the type of binary data when collected ValueDescriptor Property Description Provide the context, unit of measure and more information about any sensed data value ID Uniquely identifies a value descriptor, for example a UUID Created A timestamp indicating when the value descriptor was created in the database Modified A timestamp indicating when the value descriptor was last modified. Origin A timestamp indicating when the original value descriptor was created. Most of the time, this indicates when the device service requested the value descriptor be created Descrption Describes what the value descriptor is used for (example: defines a thermostat temperature value) Name Name of the value descriptor and used as the name key in the reading Min Minimum allowed value Max Maximum allowed value DefaultValue Type Value data type UomLabel Unit of measure label Formatting Printf convention for display of the value Labels array of associated means to label or tag a value (examples: BACNet, temp, thermostat) FloatEncoding Floating point encoding format for float values MediaType Indicating the type of binary data when collected","title":"Data Dictionary"},{"location":"microservices/core/data/Ch-CoreData/#high-level-interaction-diagrams","text":"The two following High Level Interaction Diagrams show: How new sensor readings are collected by a device and added as event/readings to core data and the associated persistence store How a client (inside or outside of EdgeX) can query for events (in this case by device name) Core Data Add Sensor Readings Core Data Request Event / Reading for a Device","title":"High Level Interaction Diagrams"},{"location":"microservices/core/data/Ch-CoreData/#configuration-properties","text":"Please refer to the general Configuration documentation for configuration properties common to all services. Writable Property Default Value Description Writable properties can be set and will dynamically take effect without service restart DeviceUpdateLastConnected false When true, core data updates the last connected timestamp for the device in metadata with each event from a given device MetaDataCheck false When true, core data calls metadata to check that the event's referenced device is known to meta data PersistData true When true, core data persists all sensor data sent to it in its associated database ServiceUpdateLastConnected false When true, core data updates the last connected timestamp for the device service in metadata ValidateCheck false When true, core data checks that the name (the value descriptor) of a reading is known to metadata ChecksumAlgo 'xxHash' Identifies the algorithm to use when calculating an event's checksum. Service Property Default Value Description MaxResultCount 50000 Maximum number of objects (example: events) that are to be returned on any query of core data via its API Databases/Databases.Primary Property Default Value Description Properties used by the service to access the database Host 'localhost' Host running the core data persistence database Name 'coredata' Document store or database name Password 'password' Password used to access the database Username 'core' Username used to access the database Port 6379 Port for accessing the database service - the Redis port by default Timeout 5000 Database connection timeout in milliseconds Type 'redisdb' Database to use - either redisdb or mongodb MessageQueue Property Default Value Description Entries in the MessageQueue section of the configuration allow for publication of events to a message bus MessageQueue Protocol tcp Indicates the connectivity protocol to use to use the bus. MessageQueue Host * Indicates the host of the messaging broker, if applicable. MessageQueue Port 5563 Indicates the port to use when publishing a message. MessageQueue Type zero Indicates the type of messaging library to use. Currently this is ZeroMQ by default. Refer to the go-mod-messaging module for more information. MessageQueue Topic events Indicates the topic to which messages should be published. MessageQueue.Optional Property Default Value Description Configuration and connection parameters for use with MQTT message bus - in place of 0MQ Password 'password' Password used to access the message system Username 'core' Username used to access the message system ClientId 'core-data' Client ID used to put messages on the bus Qos '0' Quality of Sevice values are 0 (At most once), 1 (At least once) or 2 (Exactly once) KeepAlive '10' Period of time in seconds to keep the connection alive when there is no messages flowing (must be 2 or greater) Retained false Whether to retain messages AutoReconnect true Whether to reconnect to the message bus on connection loss ConnectTimeout 5 Message bus connection timeout in seconds SkipCertVerify false TLS configuration - Only used if Cert/Key file or Cert/Key PEMblock are specified","title":"Configuration Properties"},{"location":"microservices/core/data/Ch-CoreData/#api-reference","text":"Core Data API Reference","title":"API Reference"},{"location":"microservices/core/metadata/Ch-Metadata/","text":"Metadata Introduction The core metadata micro service has the knowledge about the devices and sensors and how to communicate with them used by the other services, such as core data, core command, and so forth. Specifically, metadata has the following abilities: Manages information about the devices connected to, and operated by, EdgeX Foundry Knows the type, and organization of data reported by the devices Knows how to command the devices Although metadata has the knowledge, it does not do the following activities: It is not responsible for actual data collection from devices, which is performed by device services and core data It is not responsible for issuing commands to the devices, which is performed by core command and device services Data Models To understand metadata, its important to understand the EdgeX data objects it manages. Metadata stores its knowledge in a local persistence database. Redis is used by default, but a database abstraction layer allows for other databases to be used. Note EdgeX has used MongoDB in the past. Through the Geneva release, MongoDB is still supported but is considered deprecated. Alternate (both open source and commercial) implementations have also been provided in the past. Device Profile Device profiles define general characteristics about devices, the data they provide, and how to command them. Think of a device profile as a template of a type or classification of device. For example, a device profile for BACnet thermostats provides general characteristics for the types of data a BACnet thermostat sends, such as current temperature and humidity level. It also defines which types of commands or actions EdgeX can send to the BACnet thermostat. Examples might include actions that set the cooling or heating point. Device profiles are typically specified in YAML file and uploaded to EdgeX. More details are provided below. Device Profile Details Metadata device profile object model General Properties A device profile has a number of high level properties to give the profile context and identification. Its name field is required and must be unique in an EdgeX deployment. Other fields are optional - they are not used by device services but may be populated for informational purposes: Description Manufacturer Model Labels Here is an example general information section for a sample KMC 9001 BACnet thermostat device profile provided with the BACnet device service (you can find the profile in Github) . Only the name is required in this section of the device profile. The name of the device profile must be unique in any EdgeX deployment. The manufacturer, model and labels are all optional bits of information that allow better queries of the device profiles in the system. name : \"BAC-9001\" manufacturer : \"KMC\" model : \"BAC-9001\" labels : - \"B-AAC\" description : \"KMC BAC-9001 BACnet thermostat\" Labels provided a way to tag, organize or categorize the various profiles. They serve no real purpose inside of EdgeX. Device Resources A device resource (deviceResource in the YAML file) specifies a sensor value within a device that may be read from or written to either individually or as part of a device command (see below). Think of a device resource as a specific value that can be obtained from the underlying device or a value that can be set to the underlying device. In a thermostat, a device resource may be a temperature or humidity (values sensed from the devices) or cooling point or heating point (values that can be set/actuated to allow the thermostat to determine when associated heat/cooling systems are turned on or off). A device resource has a name for identification and a description for informational purposes. Back to the BACnet example, here are two device resources. One will be used to get the temperature (read) the current temperature and the other to set (write or actuate) the active cooling set point. The device resource name must be provided and it must also be unique in any EdgeX deployment. name : Temperature description : \"Get the current temperature\" name : ActiveCoolingSetpoint description : \"The active cooling set point\" The device service allows access to the device resources via REST endpoint. Values specified in the device resources section of the device profile can be accessed through the following URL patterns: http:// : /api/v1/device/ / http:// : /api/v1/device/name/ / The is the physical identifier for the device, which is generated when the device is created in EdgeX. Attributes The attributes associated to a device resource are the specific parameters required by the device service to access the particular value. In other words, attributes are \u201cinward facing\u201d and are used by the device service to determine how to speak to the device to either get or set some of its values. Attributes are detailed protocol and/or device specific information that informs the device service how to communication with the device to get (or set) values of interest. Returning to the BACnet device profile example, below are the complete device resource sections for Temperature and ActiveCoolingSetPoint \u2013 inclusive of the attributes \u2013 for the example device. - name : Temperature description : \"Get the current temperature\" attributes : { type : \"analogValue\" , instance : \"1\" , property : \"presentValue\" , index : \"none\" } - name : ActiveCoolingSetpoint description : \"The active cooling set point\" attributes : { type : \"analogValue\" , instance : \"3\" , property : \"presentValue\" , index : \"none\" } Properties The properties of a device resource describe the value obtained or set on the device. The properties can optionally inform the device service of some simple processing to be performed on the value. Again, using the BACnet profile as an example, here are the properties associated to the thermostat's temperature device resource. name : Temperature description : \"Get the current temperature\" attributes : { type : \"analogValue\" , instance : \"1\" , property : \"presentValue\" , index : \"none\" } properties : value : { type : \"Float32\" , floatEncoding : \"eNotation\" , readWrite : \"R\" } units : { type : \"String\" , readWrite : \"R\" , defaultValue : \"Degrees Fahrenheit\" } The 'value' property of properties gives more detail about the value collected or set. In this case giving the details of the temperature value to be set. The value provides details such as the type of the data collected or set, whether the value can be read, written or both. The following fields are available in the value property: type - Required. The data type of the value. Supported types are bool, int8 - int64, uint8 - uint64, float32, float64, string, binary and arrays of the primitive types (ints, floats, bool). Arrays are specified as eg. float32array, boolarray etc. readWrite - R, RW, or W indicating whether the value is readable or writable. defaultValue - a value used for PUT requests which do not specify one. base - a value to be raised to the power of the raw reading before it is returned. scale - a factor by which to multiply a reading before it is returned. offset - a value to be added to a reading before it is returned. mask - a binary mask which will be applied to an integer reading. shift - a number of bits by which an integer reading will be shifted right. The processing defined by base, scale, offset, mask and shift is applied in that order. This is done within the SDK. A reverse transformation is applied by the SDK to incoming data on set operations (NB mask transforms on set are NYI) The 'units' property gives more detail about the unit of measure associated with the value. In this case, the temperature unit of measure is in degrees Fahrenheit. The unit of measure can also have a type (although it is most often just a String), a default value, whether the unit can be read, written or both (although it is most often set to read only). Device Commands Device commands (deviceCommand in YAML) define access to reads and writes for multiple simultaneous device resources. Device commands are optional. Each named device command should contain a number of get and/or set resource operations, describing the read or write respectively. Device commands may be useful when readings are logically related, for example with a 3-axis accelerometer it is helpful to read all axes (X, Y and Z) together. A resource operation consists of the following properties: index - a number, used to define an order in which the resource is processed. operation - get or set (mixing of get and set operations is not supported) deviceResource - the name of the device resource to access. parameter - optional, a value that will be used if a PUT request does not specify one. mappings - optional, allows readings of String type to be re-mapped. The device commands can also be accessed through a device service\u2019s REST API in a similar manner as described for device resources. http:// : /api/v1/device/ / http:// : /api/v1/device/name/ / If a device command and device resource have the same name, it will be the device command which is available. Core Commands Core commands (coreCommands in the YAML) are associated to either a device resource or a device command by name. Core commands are also optional. Core commands are available through the core command service\u2019s REST API for reading and writing to a device. In other words, core commands specify which of the device service\u2019s device resource or device commands are seen and available via the EdgeX core command service. Other services (such as the rules engine) or external clients of EdgeX, should make requests of device services through the core command service, and when they do, they are calling on the device service\u2019s core commands (which under the covers calls on the device resource or device commands of the device service). Direct access to the device commands or device resources of a device service is frowned upon. Core commands, made available through the EdgeX command service allows the EdgeX adopter to add additional security or controls on who/what/when things are triggered and called on an actual device. Core commands provide the command service with information about which device commands are accessible. Other services or external systems should access device services (and devices) through the core command service which call on core commands. Core commands support both get and/or put methods. For a get, the returned values are specified in the expectedValues field of the device profile. For a put, the parameters to be given are specified in the parameterNames field of the device profile. Both fields are arrays and specify the device resources to be read or written to. In either case, the different HTTP status codes that the device service generates are shown as response indicators. Metadata's command object model Device Data about actual devices is another type of information that the metadata micro service stores and manages. Each device managed by EdgeX Foundry registers with metadata (via its owning device service. Each device must have a unique ID associated to it. Metadata stores information about a device (such as its address) against the identifier in its database. Each device is also associated to a device profile. This association enables metadata to apply knowledge provided by the device profile to each device. For example, a thermostat profile would say that it reports temperature values in Celsius. Associating a particular thermostat (the thermostat in the lobby for example) to the thermostat profile allows metadata to know that the lobby thermostat reports temperature value in Celsius. Device Service Metadata also stores and manages information about the device services. Device services serve as EdgeX's interfaces to the actual devices and sensors. Device services are other micro services that communicate with devices via the protocol of that device. For example, a Modbus device service facilitates communications among all types of Modbus devices. Examples of Modbus devices include motor controllers, proximity sensors, thermostats, and power meters. Device services simplify communications with the device for the rest of EdgeX. When a device service starts, it registers itself with metadata. When EdgeX provisions a new devices the device gets associated to its owning device service. That association is also stored in metadata. Metadata Device, Device Service and Device Profile Model Metadata's Device Profile, Device and Device Service object model and the association between them Provision Watcher Device services may contain logic to automatically provision new devices. This can be done statically or dynamically. In static device configuration (also known as static provisioning) the device service connects to and establishes a new device that it manages in EdgeX (specifically metadata) from configuration the device service is provided. For example, a device service may be provided with the specific IP address and additional device details for a device (or devices) that it is to onboard at startup. In static provisioning, it is assumed that the device will be there and that it will be available at the address or place specified through configuration. The devices and the connection information for those devices is known at the point that the device service starts. In dynamic discovery (also known as automatic provisioning), a device service is given some general information about where to look and general parameters for a device (or devices). For example, the device service may be given a range of BLE address space and told to look for devices of a certain nature in this range. However, the device service does not know that the device is physically there \u2013 and the device may not be there at start up. It must continually scan during its operations (typically on some sort of schedule) for new devices within the guides of the location and device parameters provided by configuration. Not all device services support dynamic discovery. If it does support dynamic discovery, the configuration about what and where to look (in other words, where to scan) for new devices is specified by a provision watcher. A provision watcher, is specific configuration information provided to a device service (usually at startup) that gets stored in metadata. In addition to providing details about what devices to look for during a scan, a provision watcher may also contain \u201cblocking\u201d indicators, which define parameters about devices that are not to be automatically provisioned. This allows the scope of a device scan to be narrowed or allow specific devices to be avoided. Metadata's provision watcher object model Data Dictionary Action Property Description Action describes state related to the capabilities of a device Path Path used by service for action on a device or sensor Responses Responses from get or put requests to service URL Url for requests from command service Addressable Property Description The metadata required to make a request to an EdgeX Foundry target. For example, the Addressable could be HTTP and URL address Id Unique identifier for the Addressable, such as a UUID Name Unique name given to the Addressable Protocol Protocol for the address (HTTP/TCP) HTTPMethod Method for connecting (i.e. POST) Address Address of the addressable Port Port for the address Path Path for callbacks Publisher For message bus protocols User User id for authentication Password Password of the user for authentication for the addressable Topic Topic for message bus addressables AutoEvent Property Description AutoEvent supports auto-generated events sourced from a device service Frequency Frequency indicates how often the specific resource needs to be polled. OnChange indicates whether the device service will generate an event only Resource the name of the resource in the device profile which describes the event to generate CallBackAlert Property Description An action to take when a callback fires Id Unique identifier such as a UUID ActionType Frequency indicates how often the specific resource needs to be polled. Command Property Description defines a specific read/write operation targeting a device; the REST description of an interface. Id Unique identifier such as a UUID Name Unique name (on a profile) given to the Command Get Get or read Command Put Put or write Command CommandResponse Property Description Id Unique identifier such as a UUID Name name given to the CommandResponse AdminState Admin state (locked/unlocked) OperatingState Operating state (enabled/disabled) LastConnected Time (milliseconds) that the device last provided any feedback or responded to any request LastReported Labels Other labels applied to the device to help with searching Location Device service specific location (interface{} is an empty interface so it can be anything) Commands array of commands Device Property Description The object that contains information about the state, position, reachability, and methods of interfacing with a Device; represents a registered device participating within the EdgeX Foundry ecosystem Id uniquely identifies the device, a UUID for example Description Name Name for identifying a device AdminState Admin state (locked/unlocked) OperatingState Protocols A map of supported protocols for the given device LastConnected Time (milliseconds) that the device last provided any feedback or responded to any request LastReported Labels Other labels applied to the device to help with searching Location Device service specific location (interface{} is an empty interface so it can be anything) Service Associated Device Service - One per device Profile AutoEvents A list of auto-generated events coming from the device DeviceProfile Property Description represents the attributes and operational capabilities of a device. It is a template for which there can be multiple matching devices within a given system. Id uniquely identifies the device, a UUID for example Description Name Name for identifying a device Manufacturer Manufacturer of the device Model Model of the device Labels Labels used to search for groups of profiles DeviceResources deviceResource collection DeviceCommands collect of deviceCommand CoreCommands List of commands to Get/Put information for devices associated with this profile DeviceResource Property Description The atomic description of a particular protocol level interface for a class of Devices; represents a value on a device that can be read or written Description Name Tag Properties list of associated properties Attributes list of associated attributes DeviceService Property Description represents a service that is responsible for proxying connectivity between a set of devices and the EdgeX Foundry core services; the current state and reachability information for a registered device service Id uniquely identifies the device service, a UUID for example Name LastConnected LastReported ime (milliseconds) that the device service reported data to the core microservice OperatingState operational state - ether enabled or disabled Labels Addressable address (MQTT topic, HTTP address, serial bus, etc.) for reaching the service AdminState Get Property Description a get command Action an action object ProfileProperty Property Description The transformation, constraint, and unit properties for a class of Device data. PropertyValue value Units units of measure for the value ProfileResource Property Description The set of operations that is executed by a Service for a particular Command. Name Get list of get resource operations Set list of set resource operations ProfileValue Property Description The transformation and constraint properties for a class of data. Type ValueDescriptor Type of property after transformations ReadWrite Read/Write Permissions set for this property Minimum Minimum value that can be get/set from this property Maximum Maximum value that can be get/set from this property DefaultValue Default value set to this property if no argument is passed Size Size of this property in its type (i.e. bytes for numeric types, characters for string types) Mask Mask to be applied prior to get/set of property Shift Shift to be applied after masking, prior to get/set of property Scale Multiplicative factor to be applied after shifting, prior to get/set of property Offset Additive factor to be applied after multiplying, prior to get/set of property Base Base for property to be applied to, leave 0 for no power operation (i.e. base ^ property: 2 ^ 10) Assertion Required value of the property, set for checking error state. Failing an assertion condition will mark the device with an error state Precision FloatEncoding FloatEncoding indicates the representation of floating value of reading. It should be 'Base64' or 'eNotation' MediaType ProvisionWatcher Property Description The metadata used by a Service for automatically provisioning matching Devices. Id Name unique name and identifier of the provision watcher Identifiers set of key value pairs that identify property (MAC, HTTP,...) and value to watch for (00-05-1B-A1-99-99, 10.0.0.1,...) BlockingIdentifiers set of key-values pairs that identify devices which will not be added despite matching on Identifiers Profile device profile that should be applied to the devices available at the identifier addresses Service device service that new devices will be associated to AdminState administrative state for new devices - either unlocked or locked Put Property Description a put command Action an action object ParameterNames Response Property Description A description of a possible REST response for a Command Code typically an HTTP response code Description ExpectedValues list of value descriptors for response type Units Property Description The unit metadata about a class of Device data. Type ValueDescriptor Type of units after transformations - typically string ReadWrite Read/Write Permissions set for this units - typically read DefaultValue Default value set to this units if no argument is passed High Level Interaction Diagrams Sequence diagrams for some of the more critical or complex events regarding metadata. These High Level Interaction Diagrams show: Adding a new device profile (Step 1 to provisioning a new device) via metadata Adding a new device via metadata (Step 2 to provisioning a new device) EdgeX Foundry device service startup (and its interactions with metadata) Add a New Device Profile (Step 1 to provisioning a new device) Add a New Device (Step 2 to provisioning a new device) What happens on a device service startup? Configuration Properties Please refer to the general Configuration documentation for configuration properties common to all services. Writable Property Default Value Description Writable properties can be set and will dynamically take effect without service restart EnableValueDescriptorManagement false Service Property Default Value Description MaxResultCount 50000 Maximum number of objects (example: devices) that are to be returned on any query of metadata via its API Databases/Databases.Primary Property Default Value Description Properties used by the service to access the database Host 'localhost' Host running the metadata persistence database Name 'metadata' Document store or database name Password 'password' Password used to access the database Username 'core' Username used to access the database Port 6379 Port for accessing the database service - the Redis port by default Timeout 5000 Database connection timeout in milliseconds Type 'redisdb' Database to use - either redisdb or mongodb Notifications Property Default Value Description Configuration to post device changes through the notifiction service PostDeviceChanges true Whether to send out notification when a device has been added, changed, or removed Slug 'device-change-' Notification service slug to use in sending notification messages Content 'Device update: ' Start of the notification message when sending notification messages on device change Sender 'core-metadata' Sender of any notification messages sent on device change Description 'Metadata device notice' Message description of any notification messages sent on device change Label 'metadata' Label to put on messages for any notification messages sent on device change API Reference Core Metadata API Reference","title":"Metadata"},{"location":"microservices/core/metadata/Ch-Metadata/#metadata","text":"","title":"Metadata"},{"location":"microservices/core/metadata/Ch-Metadata/#introduction","text":"The core metadata micro service has the knowledge about the devices and sensors and how to communicate with them used by the other services, such as core data, core command, and so forth. Specifically, metadata has the following abilities: Manages information about the devices connected to, and operated by, EdgeX Foundry Knows the type, and organization of data reported by the devices Knows how to command the devices Although metadata has the knowledge, it does not do the following activities: It is not responsible for actual data collection from devices, which is performed by device services and core data It is not responsible for issuing commands to the devices, which is performed by core command and device services","title":"Introduction"},{"location":"microservices/core/metadata/Ch-Metadata/#data-models","text":"To understand metadata, its important to understand the EdgeX data objects it manages. Metadata stores its knowledge in a local persistence database. Redis is used by default, but a database abstraction layer allows for other databases to be used. Note EdgeX has used MongoDB in the past. Through the Geneva release, MongoDB is still supported but is considered deprecated. Alternate (both open source and commercial) implementations have also been provided in the past.","title":"Data Models"},{"location":"microservices/core/metadata/Ch-Metadata/#device-profile","text":"Device profiles define general characteristics about devices, the data they provide, and how to command them. Think of a device profile as a template of a type or classification of device. For example, a device profile for BACnet thermostats provides general characteristics for the types of data a BACnet thermostat sends, such as current temperature and humidity level. It also defines which types of commands or actions EdgeX can send to the BACnet thermostat. Examples might include actions that set the cooling or heating point. Device profiles are typically specified in YAML file and uploaded to EdgeX. More details are provided below.","title":"Device Profile"},{"location":"microservices/core/metadata/Ch-Metadata/#device-profile-details","text":"Metadata device profile object model General Properties A device profile has a number of high level properties to give the profile context and identification. Its name field is required and must be unique in an EdgeX deployment. Other fields are optional - they are not used by device services but may be populated for informational purposes: Description Manufacturer Model Labels Here is an example general information section for a sample KMC 9001 BACnet thermostat device profile provided with the BACnet device service (you can find the profile in Github) . Only the name is required in this section of the device profile. The name of the device profile must be unique in any EdgeX deployment. The manufacturer, model and labels are all optional bits of information that allow better queries of the device profiles in the system. name : \"BAC-9001\" manufacturer : \"KMC\" model : \"BAC-9001\" labels : - \"B-AAC\" description : \"KMC BAC-9001 BACnet thermostat\" Labels provided a way to tag, organize or categorize the various profiles. They serve no real purpose inside of EdgeX. Device Resources A device resource (deviceResource in the YAML file) specifies a sensor value within a device that may be read from or written to either individually or as part of a device command (see below). Think of a device resource as a specific value that can be obtained from the underlying device or a value that can be set to the underlying device. In a thermostat, a device resource may be a temperature or humidity (values sensed from the devices) or cooling point or heating point (values that can be set/actuated to allow the thermostat to determine when associated heat/cooling systems are turned on or off). A device resource has a name for identification and a description for informational purposes. Back to the BACnet example, here are two device resources. One will be used to get the temperature (read) the current temperature and the other to set (write or actuate) the active cooling set point. The device resource name must be provided and it must also be unique in any EdgeX deployment. name : Temperature description : \"Get the current temperature\" name : ActiveCoolingSetpoint description : \"The active cooling set point\" The device service allows access to the device resources via REST endpoint. Values specified in the device resources section of the device profile can be accessed through the following URL patterns: http:// : /api/v1/device/ / http:// : /api/v1/device/name/ / The is the physical identifier for the device, which is generated when the device is created in EdgeX. Attributes The attributes associated to a device resource are the specific parameters required by the device service to access the particular value. In other words, attributes are \u201cinward facing\u201d and are used by the device service to determine how to speak to the device to either get or set some of its values. Attributes are detailed protocol and/or device specific information that informs the device service how to communication with the device to get (or set) values of interest. Returning to the BACnet device profile example, below are the complete device resource sections for Temperature and ActiveCoolingSetPoint \u2013 inclusive of the attributes \u2013 for the example device. - name : Temperature description : \"Get the current temperature\" attributes : { type : \"analogValue\" , instance : \"1\" , property : \"presentValue\" , index : \"none\" } - name : ActiveCoolingSetpoint description : \"The active cooling set point\" attributes : { type : \"analogValue\" , instance : \"3\" , property : \"presentValue\" , index : \"none\" } Properties The properties of a device resource describe the value obtained or set on the device. The properties can optionally inform the device service of some simple processing to be performed on the value. Again, using the BACnet profile as an example, here are the properties associated to the thermostat's temperature device resource. name : Temperature description : \"Get the current temperature\" attributes : { type : \"analogValue\" , instance : \"1\" , property : \"presentValue\" , index : \"none\" } properties : value : { type : \"Float32\" , floatEncoding : \"eNotation\" , readWrite : \"R\" } units : { type : \"String\" , readWrite : \"R\" , defaultValue : \"Degrees Fahrenheit\" } The 'value' property of properties gives more detail about the value collected or set. In this case giving the details of the temperature value to be set. The value provides details such as the type of the data collected or set, whether the value can be read, written or both. The following fields are available in the value property: type - Required. The data type of the value. Supported types are bool, int8 - int64, uint8 - uint64, float32, float64, string, binary and arrays of the primitive types (ints, floats, bool). Arrays are specified as eg. float32array, boolarray etc. readWrite - R, RW, or W indicating whether the value is readable or writable. defaultValue - a value used for PUT requests which do not specify one. base - a value to be raised to the power of the raw reading before it is returned. scale - a factor by which to multiply a reading before it is returned. offset - a value to be added to a reading before it is returned. mask - a binary mask which will be applied to an integer reading. shift - a number of bits by which an integer reading will be shifted right. The processing defined by base, scale, offset, mask and shift is applied in that order. This is done within the SDK. A reverse transformation is applied by the SDK to incoming data on set operations (NB mask transforms on set are NYI) The 'units' property gives more detail about the unit of measure associated with the value. In this case, the temperature unit of measure is in degrees Fahrenheit. The unit of measure can also have a type (although it is most often just a String), a default value, whether the unit can be read, written or both (although it is most often set to read only). Device Commands Device commands (deviceCommand in YAML) define access to reads and writes for multiple simultaneous device resources. Device commands are optional. Each named device command should contain a number of get and/or set resource operations, describing the read or write respectively. Device commands may be useful when readings are logically related, for example with a 3-axis accelerometer it is helpful to read all axes (X, Y and Z) together. A resource operation consists of the following properties: index - a number, used to define an order in which the resource is processed. operation - get or set (mixing of get and set operations is not supported) deviceResource - the name of the device resource to access. parameter - optional, a value that will be used if a PUT request does not specify one. mappings - optional, allows readings of String type to be re-mapped. The device commands can also be accessed through a device service\u2019s REST API in a similar manner as described for device resources. http:// : /api/v1/device/ / http:// : /api/v1/device/name/ / If a device command and device resource have the same name, it will be the device command which is available. Core Commands Core commands (coreCommands in the YAML) are associated to either a device resource or a device command by name. Core commands are also optional. Core commands are available through the core command service\u2019s REST API for reading and writing to a device. In other words, core commands specify which of the device service\u2019s device resource or device commands are seen and available via the EdgeX core command service. Other services (such as the rules engine) or external clients of EdgeX, should make requests of device services through the core command service, and when they do, they are calling on the device service\u2019s core commands (which under the covers calls on the device resource or device commands of the device service). Direct access to the device commands or device resources of a device service is frowned upon. Core commands, made available through the EdgeX command service allows the EdgeX adopter to add additional security or controls on who/what/when things are triggered and called on an actual device. Core commands provide the command service with information about which device commands are accessible. Other services or external systems should access device services (and devices) through the core command service which call on core commands. Core commands support both get and/or put methods. For a get, the returned values are specified in the expectedValues field of the device profile. For a put, the parameters to be given are specified in the parameterNames field of the device profile. Both fields are arrays and specify the device resources to be read or written to. In either case, the different HTTP status codes that the device service generates are shown as response indicators. Metadata's command object model","title":"Device Profile Details"},{"location":"microservices/core/metadata/Ch-Metadata/#device","text":"Data about actual devices is another type of information that the metadata micro service stores and manages. Each device managed by EdgeX Foundry registers with metadata (via its owning device service. Each device must have a unique ID associated to it. Metadata stores information about a device (such as its address) against the identifier in its database. Each device is also associated to a device profile. This association enables metadata to apply knowledge provided by the device profile to each device. For example, a thermostat profile would say that it reports temperature values in Celsius. Associating a particular thermostat (the thermostat in the lobby for example) to the thermostat profile allows metadata to know that the lobby thermostat reports temperature value in Celsius.","title":"Device"},{"location":"microservices/core/metadata/Ch-Metadata/#device-service","text":"Metadata also stores and manages information about the device services. Device services serve as EdgeX's interfaces to the actual devices and sensors. Device services are other micro services that communicate with devices via the protocol of that device. For example, a Modbus device service facilitates communications among all types of Modbus devices. Examples of Modbus devices include motor controllers, proximity sensors, thermostats, and power meters. Device services simplify communications with the device for the rest of EdgeX. When a device service starts, it registers itself with metadata. When EdgeX provisions a new devices the device gets associated to its owning device service. That association is also stored in metadata. Metadata Device, Device Service and Device Profile Model Metadata's Device Profile, Device and Device Service object model and the association between them","title":"Device Service"},{"location":"microservices/core/metadata/Ch-Metadata/#provision-watcher","text":"Device services may contain logic to automatically provision new devices. This can be done statically or dynamically. In static device configuration (also known as static provisioning) the device service connects to and establishes a new device that it manages in EdgeX (specifically metadata) from configuration the device service is provided. For example, a device service may be provided with the specific IP address and additional device details for a device (or devices) that it is to onboard at startup. In static provisioning, it is assumed that the device will be there and that it will be available at the address or place specified through configuration. The devices and the connection information for those devices is known at the point that the device service starts. In dynamic discovery (also known as automatic provisioning), a device service is given some general information about where to look and general parameters for a device (or devices). For example, the device service may be given a range of BLE address space and told to look for devices of a certain nature in this range. However, the device service does not know that the device is physically there \u2013 and the device may not be there at start up. It must continually scan during its operations (typically on some sort of schedule) for new devices within the guides of the location and device parameters provided by configuration. Not all device services support dynamic discovery. If it does support dynamic discovery, the configuration about what and where to look (in other words, where to scan) for new devices is specified by a provision watcher. A provision watcher, is specific configuration information provided to a device service (usually at startup) that gets stored in metadata. In addition to providing details about what devices to look for during a scan, a provision watcher may also contain \u201cblocking\u201d indicators, which define parameters about devices that are not to be automatically provisioned. This allows the scope of a device scan to be narrowed or allow specific devices to be avoided. Metadata's provision watcher object model","title":"Provision Watcher"},{"location":"microservices/core/metadata/Ch-Metadata/#data-dictionary","text":"Action Property Description Action describes state related to the capabilities of a device Path Path used by service for action on a device or sensor Responses Responses from get or put requests to service URL Url for requests from command service Addressable Property Description The metadata required to make a request to an EdgeX Foundry target. For example, the Addressable could be HTTP and URL address Id Unique identifier for the Addressable, such as a UUID Name Unique name given to the Addressable Protocol Protocol for the address (HTTP/TCP) HTTPMethod Method for connecting (i.e. POST) Address Address of the addressable Port Port for the address Path Path for callbacks Publisher For message bus protocols User User id for authentication Password Password of the user for authentication for the addressable Topic Topic for message bus addressables AutoEvent Property Description AutoEvent supports auto-generated events sourced from a device service Frequency Frequency indicates how often the specific resource needs to be polled. OnChange indicates whether the device service will generate an event only Resource the name of the resource in the device profile which describes the event to generate CallBackAlert Property Description An action to take when a callback fires Id Unique identifier such as a UUID ActionType Frequency indicates how often the specific resource needs to be polled. Command Property Description defines a specific read/write operation targeting a device; the REST description of an interface. Id Unique identifier such as a UUID Name Unique name (on a profile) given to the Command Get Get or read Command Put Put or write Command CommandResponse Property Description Id Unique identifier such as a UUID Name name given to the CommandResponse AdminState Admin state (locked/unlocked) OperatingState Operating state (enabled/disabled) LastConnected Time (milliseconds) that the device last provided any feedback or responded to any request LastReported Labels Other labels applied to the device to help with searching Location Device service specific location (interface{} is an empty interface so it can be anything) Commands array of commands Device Property Description The object that contains information about the state, position, reachability, and methods of interfacing with a Device; represents a registered device participating within the EdgeX Foundry ecosystem Id uniquely identifies the device, a UUID for example Description Name Name for identifying a device AdminState Admin state (locked/unlocked) OperatingState Protocols A map of supported protocols for the given device LastConnected Time (milliseconds) that the device last provided any feedback or responded to any request LastReported Labels Other labels applied to the device to help with searching Location Device service specific location (interface{} is an empty interface so it can be anything) Service Associated Device Service - One per device Profile AutoEvents A list of auto-generated events coming from the device DeviceProfile Property Description represents the attributes and operational capabilities of a device. It is a template for which there can be multiple matching devices within a given system. Id uniquely identifies the device, a UUID for example Description Name Name for identifying a device Manufacturer Manufacturer of the device Model Model of the device Labels Labels used to search for groups of profiles DeviceResources deviceResource collection DeviceCommands collect of deviceCommand CoreCommands List of commands to Get/Put information for devices associated with this profile DeviceResource Property Description The atomic description of a particular protocol level interface for a class of Devices; represents a value on a device that can be read or written Description Name Tag Properties list of associated properties Attributes list of associated attributes DeviceService Property Description represents a service that is responsible for proxying connectivity between a set of devices and the EdgeX Foundry core services; the current state and reachability information for a registered device service Id uniquely identifies the device service, a UUID for example Name LastConnected LastReported ime (milliseconds) that the device service reported data to the core microservice OperatingState operational state - ether enabled or disabled Labels Addressable address (MQTT topic, HTTP address, serial bus, etc.) for reaching the service AdminState Get Property Description a get command Action an action object ProfileProperty Property Description The transformation, constraint, and unit properties for a class of Device data. PropertyValue value Units units of measure for the value ProfileResource Property Description The set of operations that is executed by a Service for a particular Command. Name Get list of get resource operations Set list of set resource operations ProfileValue Property Description The transformation and constraint properties for a class of data. Type ValueDescriptor Type of property after transformations ReadWrite Read/Write Permissions set for this property Minimum Minimum value that can be get/set from this property Maximum Maximum value that can be get/set from this property DefaultValue Default value set to this property if no argument is passed Size Size of this property in its type (i.e. bytes for numeric types, characters for string types) Mask Mask to be applied prior to get/set of property Shift Shift to be applied after masking, prior to get/set of property Scale Multiplicative factor to be applied after shifting, prior to get/set of property Offset Additive factor to be applied after multiplying, prior to get/set of property Base Base for property to be applied to, leave 0 for no power operation (i.e. base ^ property: 2 ^ 10) Assertion Required value of the property, set for checking error state. Failing an assertion condition will mark the device with an error state Precision FloatEncoding FloatEncoding indicates the representation of floating value of reading. It should be 'Base64' or 'eNotation' MediaType ProvisionWatcher Property Description The metadata used by a Service for automatically provisioning matching Devices. Id Name unique name and identifier of the provision watcher Identifiers set of key value pairs that identify property (MAC, HTTP,...) and value to watch for (00-05-1B-A1-99-99, 10.0.0.1,...) BlockingIdentifiers set of key-values pairs that identify devices which will not be added despite matching on Identifiers Profile device profile that should be applied to the devices available at the identifier addresses Service device service that new devices will be associated to AdminState administrative state for new devices - either unlocked or locked Put Property Description a put command Action an action object ParameterNames Response Property Description A description of a possible REST response for a Command Code typically an HTTP response code Description ExpectedValues list of value descriptors for response type Units Property Description The unit metadata about a class of Device data. Type ValueDescriptor Type of units after transformations - typically string ReadWrite Read/Write Permissions set for this units - typically read DefaultValue Default value set to this units if no argument is passed","title":"Data Dictionary"},{"location":"microservices/core/metadata/Ch-Metadata/#high-level-interaction-diagrams","text":"Sequence diagrams for some of the more critical or complex events regarding metadata. These High Level Interaction Diagrams show: Adding a new device profile (Step 1 to provisioning a new device) via metadata Adding a new device via metadata (Step 2 to provisioning a new device) EdgeX Foundry device service startup (and its interactions with metadata) Add a New Device Profile (Step 1 to provisioning a new device) Add a New Device (Step 2 to provisioning a new device) What happens on a device service startup?","title":"High Level Interaction Diagrams"},{"location":"microservices/core/metadata/Ch-Metadata/#configuration-properties","text":"Please refer to the general Configuration documentation for configuration properties common to all services. Writable Property Default Value Description Writable properties can be set and will dynamically take effect without service restart EnableValueDescriptorManagement false Service Property Default Value Description MaxResultCount 50000 Maximum number of objects (example: devices) that are to be returned on any query of metadata via its API Databases/Databases.Primary Property Default Value Description Properties used by the service to access the database Host 'localhost' Host running the metadata persistence database Name 'metadata' Document store or database name Password 'password' Password used to access the database Username 'core' Username used to access the database Port 6379 Port for accessing the database service - the Redis port by default Timeout 5000 Database connection timeout in milliseconds Type 'redisdb' Database to use - either redisdb or mongodb Notifications Property Default Value Description Configuration to post device changes through the notifiction service PostDeviceChanges true Whether to send out notification when a device has been added, changed, or removed Slug 'device-change-' Notification service slug to use in sending notification messages Content 'Device update: ' Start of the notification message when sending notification messages on device change Sender 'core-metadata' Sender of any notification messages sent on device change Description 'Metadata device notice' Message description of any notification messages sent on device change Label 'metadata' Label to put on messages for any notification messages sent on device change","title":"Configuration Properties"},{"location":"microservices/core/metadata/Ch-Metadata/#api-reference","text":"Core Metadata API Reference","title":"API Reference"},{"location":"microservices/device/Ch-DeviceServices/","text":"Device Services Microservices Introduction The Device Services Layer interacts with Device Services. Device services are the edge connectors interacting with the devices that include, but are not limited to: appliances in your home, alarm systems, HVAC equipment, lighting, machines in any industry, irrigation systems, drones, traffic signals, automated transportation, and so forth. EdgeX device services translate information coming from devices via hundreds of protocols and thousands of formats and bring them into EdgeX. In other terms, device services ingest sensor data provided by \u201cthings\u201d. When it ingests the sensor data, the device service converts the data produced and communicated by the \u201cthing\u201d into a common EdgeX Foundry data structure, and sends that converted data into the core services layer, and to other micro services in other layers of EdgeX Foundry. Device services also receive and handle any request for actuation back to the device. Device services take a general command from EdgeX to perform some sort of action and it translates that into a protocol specific request and forwards the request to the desired device. Device services serve as the main means EdgeX interacts with sensors/devices. So, in addition to getting sensor data and actuating devices, device services also: Get status updates from devices/sensors Transform data before sending sensor data to EdgeX Change configuration Discover devices Device services may service one or a number of devices at one time. A device that a device service manages, could be something other than a simple, single, physical device. The device could be an edge/IoT gateway (and all of that gateway's devices), a device manager, a sensor hub, a web service available over HTTP, or a software sensor that acts as a device, or collection of devices, to EdgeX Foundry. The device service communicates with the devices through protocols native to each device object. EdgeX comes with a number of device services speaking many common IoT protocols such as Modbus, BACnet, BLE, etc. EdgeX also provides the means to create new devices services through device service software development kits (SDKs) when you encounter a new protocol and need EdgeX to communicate with a new device. Device Service Abstraction A device service is really just a software abstraction around a device and any associated firmware, software and protocol stack. It allows the rest of EdgeX (and users of EdgeX) to talk to a device via the abstraction API so that all devices look the same from the perspective of how you communicate with them. Under the covers, the implementation of the device service has some common elements, but can also vary greatly depending on the underlying device, protocol, and associate software. A device service provides the abstraction between the rest of EdgeX and the physical device. In other terms, the device service \u201cwraps\u201d the protocol communication code, device driver/firmware and actual device. Each device service in EdgeX is an independent micro service. Devices services are typically created using a device service SDK . The SDK is really just a library that provides common scaffolding code and convenience methods that are needed by all device services. While not required, the EdgeX community use the SDKs as the basis for the all device services the community provides. The SDKs make it easier to create device service by allowing a developer to focus on device specific communications, features, etc. versus having to code a lot of EdgeX service boilerplate code. Using the SDKs also helps to ensure the device services adhere to rules required of the device services. Unless you need to create a new device service or modify an existing device service, you may not ever have to go under the covers, so to speak, to understand how a device service works. However, having some general understanding of what a device service does and how it does it can be helpful in customization, setting configuration and diagnosing problems. Device Service Functionality All device services must perform the following tasks: Register with core metadata \u2013 thereby letting all of EdgeX know that it is running and stands ready to manage devices. In the case of an existing device service, the device service will update its metadata registration and get any new information. Get its configuration settings from the EdgeX\u2019s configuration service (or local configuration file if the configuration service is not being used). Register itself an EdgeX running micro service with the EdgeX registry service (when running) \u2013 thereby allowing other EdgeX services to communicate with it. On-board and manage physical devices it knows how to communicate with. This process is called provisioning of the device(s). In some cases, the device service may have the means to automatically detect and provision the devices. For example, a BLE device service may automatically scan a BLE address space, detect a new BLE device in its range, and then provision that device to EdgeX and the associated BLE device service. Update and inform EdgeX on the operating state of the device (does it appear the device is still running and able to communicate). Monitor for configuration changes and apply new configuration where applicable. Note, in some cases configuration changes cannot be dynamically applied (example: change the operating port of the device service). Get sensor data (i.e. ingest sensor data) and pass that data to the core data micro service via REST. Receive and react to REST based actuation commands. As you can imagine, many of these tasks (like registering with core metadata) are generic and the same for all device services and thereby provided by the SDK. Other tasks (like getting sensor data from the underlying device) are quite specific to the underlying device. In these cases, the device service SDK provides empty functions for performing the work, but the developer would need to fill in the function code as it relates to the specific device, the communication protocol, device driver, etc. Device Service Functional Requirements Requirements for the device service are provided in the Edge Wiki. These requirements are being used to define what functionality needs to be offered via any Device Service SDK to produce the device service scaffolding code. They may also help the reader further understand the duties and role of a device service. Device Profile EdgeX comes with a number of existing device services for communicating with devices that speak many IoT protocols \u2013 such as Modbus, BACnet, BLE, etc. While these devices services know how to speak to devices that communicate by the associated protocol, the device service doesn\u2019t know the specifics of all devices that speak that protocol. For example, there are thousands of Modbus devices in the world. It is a common industrial protocol used in a variety of devices. Some Modbus devices measure temperature and humidity and provide thermostatic control over building HVAC systems, while other Modbus devices are used in automation control of flare gas meters in the oil and gas industry. This diversity of devices means that the Modbus device service could never know how to communicate with each Modbus device directly. The device service just knows the Modbus protocol generically and must be informed of how to communicate with each individual device based on what that device knows and communicates. Using an analogy, you may speak a language or two. Just because you speak English, doesn\u2019t mean you know everything about all English-speaking people. For example, just because someone spoke English, you would not know if they could solve a calculus problem for you or if they can sing your favorite song. Device profiles describe a specific device to a device service. Each device managed by a device service has an association device profile, which defines that device in terms of the data it reports and operations that it supports. General characteristics about the type of device, the data the device provides, and how to command the device is all provided in a device profile. A device profile is described in YAML which is a human-readable data serialization language (similar to a markup language like XML). See the page on device profiles to learn more about how they provide the detail EdgeX device services need to communicate with a device. Info Device profiles, while normally provided to EdgeX in a YAML file, can also be specified to EdgeX in JSON. See the metadata API for upload via JSON versus upload YAML file . Device Discovery and Provision Watchers Device Services may contain logic to automatically provision new devices. This can be done statically or dynamically . Static Provisioning In static device configuration (also known as static provisioning) the device service connects to and establishes a new device that it manages in EdgeX (specifically metadata) from configuration the device service is provided. For example, a device service may be provided with the specific IP address and additional device details for a device (or devices) that it is to onboard at startup. In static provisioning, it is assumed that the device will be there and that it will be available at the address or place specified through configuration. The devices and the connection information for those devices is known at the point that the device service starts. Dynamic Provisioning In dynamic discovery (also known as automatic provisioning), a device service is given some general information about where to look and general parameters for a device (or devices). For example, the device service may be given a range of BLE address space and told to look for devices of a certain nature in this range. However, the device service does not know that the device is physically there \u2013 and the device may not be there at start up. It must continually scan during its operations (typically on some sort of schedule) for new devices within the guides of the location and device parameters provided by configuration. Not all device services support dynamic discovery. If it does support dynamic discovery, the configuration about what and where to look (in other words, where to scan) for new devices is specified by a provision watcher. A provision watcher is created via a call to the core metadata provision watcher API (and is stored in the metadata database). In addition to providing details about what devices to look for during a scan, a provision watcher may also contain \u201cblocking\u201d indicators, which define parameters about devices that are not to be automatically provisioned. This allows the scope of a device scan to be narrowed or allow specific devices to be avoided. Operating State and Admin State There are two states which the device service uses to indicate the status or availability of a device. Both states are stored in metadata and associated to each device. Admin State The adminState is either LOCKED or UNLOCKED for each device. This is an administrative condition applied to the device. This state is periodically set by an administrator of the system \u2013 perhaps for system maintenance or upgrade of the sensor. When LOCKED , requests to the device via the device service are stopped and an indication that the device is locked (HTTP 423 status code) is returned to the caller. Operating State The operatingState is either ENABLED of DISABLED . This is an indication of the operations of the device. If the device appears to be unresponsive or not sending its sensor data as requested, the device service may choose to set the operatingState to DISABLED to indicate to the system and to users that the device is not operating according to expectations. Sensor Reading Schedule Data collected from devices by a device service is marshalled into EdgeX event and reading objects (delivered as JSON objects in service REST calls). This is one of the primary responsibilities of a device service. Typically, a configurable schedule - called an auto event schedule - determines when a device service sends data to core data via core data\u2019s REST API (future EdgeX implementations may afford alternate means to send the data to core data or to send sensor data to other services). Test and Demonstration Device Services Among the many available device services provided by EdgeX, there are two device services that are typically used for demonstration, education and testing purposes only. The random device service ( device-random-go ) is a very simple device service used to provide device service authors a bare bones example inclusive of a device profile. It can also be used to create random integer data (either 8, 16, or 32 bit signed or unsigned) to simulate integer readings when developing or testing other EdgeX micro services. It was created from the Go-based device service SDK. The virtual device service ( device-virtual-go ) is also used for demonstration, education and testing. It is a more complex simulator in that it allows any type of data to be generated on a scheduled basis and used an embedded SQL database (ql) to provide simulated data. Manipulating the data in the embedded database allows the service to mimic almost any type of sensing device. More information on the virtual device service is available in this documentation. Configuration Properties Please refer to the general Configuration documentation for configuration properties common to all services. Device Property Default Value Description properties that determine how the device service communicates with a device DataTransform true InitCmd '' InitCmdArgs '' MaxCmdOps 128 MaxCmdValueLen 256 RemoveCmd '' RemoveCmdArgs '' ProfilesDir './res' UpdateLastConnected false DeviceList Property Default Value Description properties used in defining the static provisioning for the device service Name '' name of the device Profile '' device profile that defines the resources and commands of the device Description '' description of the device Labels [''] labels array used for searching for devices DeviceList/DeviceList.AutoEvents Property Default Value Description properties used to define how often an event/reading is schedule for collection to send to core data from the device Frequency '10s' how often should collection occur OnChange false collect only when a change is detected Resource '' resource to collect API Reference Device Service - SDK- API Reference","title":"Device Services Microservices"},{"location":"microservices/device/Ch-DeviceServices/#device-services-microservices","text":"","title":"Device Services Microservices"},{"location":"microservices/device/Ch-DeviceServices/#introduction","text":"The Device Services Layer interacts with Device Services. Device services are the edge connectors interacting with the devices that include, but are not limited to: appliances in your home, alarm systems, HVAC equipment, lighting, machines in any industry, irrigation systems, drones, traffic signals, automated transportation, and so forth. EdgeX device services translate information coming from devices via hundreds of protocols and thousands of formats and bring them into EdgeX. In other terms, device services ingest sensor data provided by \u201cthings\u201d. When it ingests the sensor data, the device service converts the data produced and communicated by the \u201cthing\u201d into a common EdgeX Foundry data structure, and sends that converted data into the core services layer, and to other micro services in other layers of EdgeX Foundry. Device services also receive and handle any request for actuation back to the device. Device services take a general command from EdgeX to perform some sort of action and it translates that into a protocol specific request and forwards the request to the desired device. Device services serve as the main means EdgeX interacts with sensors/devices. So, in addition to getting sensor data and actuating devices, device services also: Get status updates from devices/sensors Transform data before sending sensor data to EdgeX Change configuration Discover devices Device services may service one or a number of devices at one time. A device that a device service manages, could be something other than a simple, single, physical device. The device could be an edge/IoT gateway (and all of that gateway's devices), a device manager, a sensor hub, a web service available over HTTP, or a software sensor that acts as a device, or collection of devices, to EdgeX Foundry. The device service communicates with the devices through protocols native to each device object. EdgeX comes with a number of device services speaking many common IoT protocols such as Modbus, BACnet, BLE, etc. EdgeX also provides the means to create new devices services through device service software development kits (SDKs) when you encounter a new protocol and need EdgeX to communicate with a new device.","title":"Introduction"},{"location":"microservices/device/Ch-DeviceServices/#device-service-abstraction","text":"A device service is really just a software abstraction around a device and any associated firmware, software and protocol stack. It allows the rest of EdgeX (and users of EdgeX) to talk to a device via the abstraction API so that all devices look the same from the perspective of how you communicate with them. Under the covers, the implementation of the device service has some common elements, but can also vary greatly depending on the underlying device, protocol, and associate software. A device service provides the abstraction between the rest of EdgeX and the physical device. In other terms, the device service \u201cwraps\u201d the protocol communication code, device driver/firmware and actual device. Each device service in EdgeX is an independent micro service. Devices services are typically created using a device service SDK . The SDK is really just a library that provides common scaffolding code and convenience methods that are needed by all device services. While not required, the EdgeX community use the SDKs as the basis for the all device services the community provides. The SDKs make it easier to create device service by allowing a developer to focus on device specific communications, features, etc. versus having to code a lot of EdgeX service boilerplate code. Using the SDKs also helps to ensure the device services adhere to rules required of the device services. Unless you need to create a new device service or modify an existing device service, you may not ever have to go under the covers, so to speak, to understand how a device service works. However, having some general understanding of what a device service does and how it does it can be helpful in customization, setting configuration and diagnosing problems.","title":"Device Service Abstraction"},{"location":"microservices/device/Ch-DeviceServices/#device-service-functionality","text":"All device services must perform the following tasks: Register with core metadata \u2013 thereby letting all of EdgeX know that it is running and stands ready to manage devices. In the case of an existing device service, the device service will update its metadata registration and get any new information. Get its configuration settings from the EdgeX\u2019s configuration service (or local configuration file if the configuration service is not being used). Register itself an EdgeX running micro service with the EdgeX registry service (when running) \u2013 thereby allowing other EdgeX services to communicate with it. On-board and manage physical devices it knows how to communicate with. This process is called provisioning of the device(s). In some cases, the device service may have the means to automatically detect and provision the devices. For example, a BLE device service may automatically scan a BLE address space, detect a new BLE device in its range, and then provision that device to EdgeX and the associated BLE device service. Update and inform EdgeX on the operating state of the device (does it appear the device is still running and able to communicate). Monitor for configuration changes and apply new configuration where applicable. Note, in some cases configuration changes cannot be dynamically applied (example: change the operating port of the device service). Get sensor data (i.e. ingest sensor data) and pass that data to the core data micro service via REST. Receive and react to REST based actuation commands. As you can imagine, many of these tasks (like registering with core metadata) are generic and the same for all device services and thereby provided by the SDK. Other tasks (like getting sensor data from the underlying device) are quite specific to the underlying device. In these cases, the device service SDK provides empty functions for performing the work, but the developer would need to fill in the function code as it relates to the specific device, the communication protocol, device driver, etc.","title":"Device Service Functionality"},{"location":"microservices/device/Ch-DeviceServices/#device-service-functional-requirements","text":"Requirements for the device service are provided in the Edge Wiki. These requirements are being used to define what functionality needs to be offered via any Device Service SDK to produce the device service scaffolding code. They may also help the reader further understand the duties and role of a device service.","title":"Device Service Functional Requirements"},{"location":"microservices/device/Ch-DeviceServices/#device-profile","text":"EdgeX comes with a number of existing device services for communicating with devices that speak many IoT protocols \u2013 such as Modbus, BACnet, BLE, etc. While these devices services know how to speak to devices that communicate by the associated protocol, the device service doesn\u2019t know the specifics of all devices that speak that protocol. For example, there are thousands of Modbus devices in the world. It is a common industrial protocol used in a variety of devices. Some Modbus devices measure temperature and humidity and provide thermostatic control over building HVAC systems, while other Modbus devices are used in automation control of flare gas meters in the oil and gas industry. This diversity of devices means that the Modbus device service could never know how to communicate with each Modbus device directly. The device service just knows the Modbus protocol generically and must be informed of how to communicate with each individual device based on what that device knows and communicates. Using an analogy, you may speak a language or two. Just because you speak English, doesn\u2019t mean you know everything about all English-speaking people. For example, just because someone spoke English, you would not know if they could solve a calculus problem for you or if they can sing your favorite song. Device profiles describe a specific device to a device service. Each device managed by a device service has an association device profile, which defines that device in terms of the data it reports and operations that it supports. General characteristics about the type of device, the data the device provides, and how to command the device is all provided in a device profile. A device profile is described in YAML which is a human-readable data serialization language (similar to a markup language like XML). See the page on device profiles to learn more about how they provide the detail EdgeX device services need to communicate with a device. Info Device profiles, while normally provided to EdgeX in a YAML file, can also be specified to EdgeX in JSON. See the metadata API for upload via JSON versus upload YAML file .","title":"Device Profile"},{"location":"microservices/device/Ch-DeviceServices/#device-discovery-and-provision-watchers","text":"Device Services may contain logic to automatically provision new devices. This can be done statically or dynamically .","title":"Device Discovery and Provision Watchers"},{"location":"microservices/device/Ch-DeviceServices/#static-provisioning","text":"In static device configuration (also known as static provisioning) the device service connects to and establishes a new device that it manages in EdgeX (specifically metadata) from configuration the device service is provided. For example, a device service may be provided with the specific IP address and additional device details for a device (or devices) that it is to onboard at startup. In static provisioning, it is assumed that the device will be there and that it will be available at the address or place specified through configuration. The devices and the connection information for those devices is known at the point that the device service starts.","title":"Static Provisioning"},{"location":"microservices/device/Ch-DeviceServices/#dynamic-provisioning","text":"In dynamic discovery (also known as automatic provisioning), a device service is given some general information about where to look and general parameters for a device (or devices). For example, the device service may be given a range of BLE address space and told to look for devices of a certain nature in this range. However, the device service does not know that the device is physically there \u2013 and the device may not be there at start up. It must continually scan during its operations (typically on some sort of schedule) for new devices within the guides of the location and device parameters provided by configuration. Not all device services support dynamic discovery. If it does support dynamic discovery, the configuration about what and where to look (in other words, where to scan) for new devices is specified by a provision watcher. A provision watcher is created via a call to the core metadata provision watcher API (and is stored in the metadata database). In addition to providing details about what devices to look for during a scan, a provision watcher may also contain \u201cblocking\u201d indicators, which define parameters about devices that are not to be automatically provisioned. This allows the scope of a device scan to be narrowed or allow specific devices to be avoided.","title":"Dynamic Provisioning"},{"location":"microservices/device/Ch-DeviceServices/#operating-state-and-admin-state","text":"There are two states which the device service uses to indicate the status or availability of a device. Both states are stored in metadata and associated to each device.","title":"Operating State and Admin State"},{"location":"microservices/device/Ch-DeviceServices/#admin-state","text":"The adminState is either LOCKED or UNLOCKED for each device. This is an administrative condition applied to the device. This state is periodically set by an administrator of the system \u2013 perhaps for system maintenance or upgrade of the sensor. When LOCKED , requests to the device via the device service are stopped and an indication that the device is locked (HTTP 423 status code) is returned to the caller.","title":"Admin State"},{"location":"microservices/device/Ch-DeviceServices/#operating-state","text":"The operatingState is either ENABLED of DISABLED . This is an indication of the operations of the device. If the device appears to be unresponsive or not sending its sensor data as requested, the device service may choose to set the operatingState to DISABLED to indicate to the system and to users that the device is not operating according to expectations.","title":"Operating State"},{"location":"microservices/device/Ch-DeviceServices/#sensor-reading-schedule","text":"Data collected from devices by a device service is marshalled into EdgeX event and reading objects (delivered as JSON objects in service REST calls). This is one of the primary responsibilities of a device service. Typically, a configurable schedule - called an auto event schedule - determines when a device service sends data to core data via core data\u2019s REST API (future EdgeX implementations may afford alternate means to send the data to core data or to send sensor data to other services).","title":"Sensor Reading Schedule"},{"location":"microservices/device/Ch-DeviceServices/#test-and-demonstration-device-services","text":"Among the many available device services provided by EdgeX, there are two device services that are typically used for demonstration, education and testing purposes only. The random device service ( device-random-go ) is a very simple device service used to provide device service authors a bare bones example inclusive of a device profile. It can also be used to create random integer data (either 8, 16, or 32 bit signed or unsigned) to simulate integer readings when developing or testing other EdgeX micro services. It was created from the Go-based device service SDK. The virtual device service ( device-virtual-go ) is also used for demonstration, education and testing. It is a more complex simulator in that it allows any type of data to be generated on a scheduled basis and used an embedded SQL database (ql) to provide simulated data. Manipulating the data in the embedded database allows the service to mimic almost any type of sensing device. More information on the virtual device service is available in this documentation.","title":"Test and Demonstration Device Services"},{"location":"microservices/device/Ch-DeviceServices/#configuration-properties","text":"Please refer to the general Configuration documentation for configuration properties common to all services. Device Property Default Value Description properties that determine how the device service communicates with a device DataTransform true InitCmd '' InitCmdArgs '' MaxCmdOps 128 MaxCmdValueLen 256 RemoveCmd '' RemoveCmdArgs '' ProfilesDir './res' UpdateLastConnected false DeviceList Property Default Value Description properties used in defining the static provisioning for the device service Name '' name of the device Profile '' device profile that defines the resources and commands of the device Description '' description of the device Labels [''] labels array used for searching for devices DeviceList/DeviceList.AutoEvents Property Default Value Description properties used to define how often an event/reading is schedule for collection to send to core data from the device Frequency '10s' how often should collection occur OnChange false collect only when a change is detected Resource '' resource to collect","title":"Configuration Properties"},{"location":"microservices/device/Ch-DeviceServices/#api-reference","text":"Device Service - SDK- API Reference","title":"API Reference"},{"location":"microservices/device/profile/Ch-DeviceProfile/","text":"Device Profile The device profile describes a type of device within the EdgeX system. Each device managed by a device service has an association with a device profile, which defines that device type in terms of the operations which it supports. For a full list of device profile fields and their required values see the device profile reference . For a detailed look at the device profile model and all its properties, see the metadata device profile data model . Identification The profile contains various identification fields. The Name field is required and must be unique in an EdgeX deployment. Other fields are optional - they are not used by device services but may be populated for informational purposes: Description Manufacturer Model Labels DeviceResources A deviceResource specifies a sensor value within a device that may be read from or written to either individually or as part of a deviceCommand. It has a name for identification and a description for informational purposes. The device service allows access to deviceResources via its device REST endpoint. The Attributes in a deviceResource are the device-service-specific parameters required to access the particular value. Each device service implementation will have its own set of named values that are required here, for example a BACnet device service may need an Object Identifier and a Property Identifier whereas a Bluetooth device service could use a UUID to identify a value. The Properties of a deviceResource describe the value and optionally request some simple processing to be performed on it. Each device resource is given two properties, value and units . The following fields are available in the value property: type - Required. The data type of the value. Supported types are bool , int8 - int64 , uint8 - uint64 , float32 , float64 , string , binary and arrays of the primitive types (ints, floats, bool). Arrays are specified as eg. float32array , boolarray etc. readWrite - R , RW , or W indicating whether the value is readable or writable. defaultValue - a value used for PUT requests which do not specify one. assertion - a string value to which a reading (after processing) is compared. If the reading is not the same as the assertion value, the device's operating state will be set to disbled. This can be useful for health checks. base - a value to be raised to the power of the raw reading before it is returned. scale - a factor by which to multiply a reading before it is returned. offset - a value to be added to a reading before it is returned. mask - a binary mask which will be applied to an integer reading. shift - a number of bits by which an integer reading will be shifted right. The processing defined by base, scale, offset, mask and shift is applied in that order. This is done within the SDK. A reverse transformation is applied by the SDK to incoming data on set operations (NB mask transforms on set are NYI) The units property is used to indicate the units of the value, eg Amperes, degrees C, etc. It should have a defaultValue that specifies the units. DeviceCommands DeviceCommands define access to reads and writes for multiple simultaneous device resources. Each named deviceCommand should contain a number of get and/or set resourceOperations , describing the read or write respectively. DeviceCommands may be useful when readings are logically related, for example with a 3-axis accelerometer it is helpful to read all axes together. A resourceOperation consists of the following properties: index - a number, used to define an order in which the resource is processed. and set operations is not supported. deviceResource - the name of the deviceResource to access. parameter - optional, a value that will be used if a PUT request does not specify one. mappings - optional, allows readings of String type to be re-mapped. The device service allows access to deviceCommands via the same device REST endpoint as is used to access deviceResources. If a deviceCommand and deviceResource have the same name, it will be the deviceCommand which is available. CoreCommands CoreCommands specify the commands which are available via the core-command micro service, for reading and writing to the device. Both deviceResources and deviceCommands may be represented by coreCommands (the name of the coreCommand refers to the name of the deviceCommand or deviceResource). Commands may allow get or put methods (or both). For a get type, the returned values are specified in the expectedValues field, for a put type, the parameters to be given are specified in parameterNames . In either case, the different http response codes that the service may generate are indicated. Core Commands may be thought of as defining the outward-facing API for the device. A typical setup would prevent external access to the device service itself, so use of the full range of device resources and device commands would only be available to other components within the EdgeX deployment. Only those that has corresponding coreCommands would be available externally (via core-command).","title":"Device Profile"},{"location":"microservices/device/profile/Ch-DeviceProfile/#device-profile","text":"The device profile describes a type of device within the EdgeX system. Each device managed by a device service has an association with a device profile, which defines that device type in terms of the operations which it supports. For a full list of device profile fields and their required values see the device profile reference . For a detailed look at the device profile model and all its properties, see the metadata device profile data model .","title":"Device Profile"},{"location":"microservices/device/profile/Ch-DeviceProfile/#identification","text":"The profile contains various identification fields. The Name field is required and must be unique in an EdgeX deployment. Other fields are optional - they are not used by device services but may be populated for informational purposes: Description Manufacturer Model Labels","title":"Identification"},{"location":"microservices/device/profile/Ch-DeviceProfile/#deviceresources","text":"A deviceResource specifies a sensor value within a device that may be read from or written to either individually or as part of a deviceCommand. It has a name for identification and a description for informational purposes. The device service allows access to deviceResources via its device REST endpoint. The Attributes in a deviceResource are the device-service-specific parameters required to access the particular value. Each device service implementation will have its own set of named values that are required here, for example a BACnet device service may need an Object Identifier and a Property Identifier whereas a Bluetooth device service could use a UUID to identify a value. The Properties of a deviceResource describe the value and optionally request some simple processing to be performed on it. Each device resource is given two properties, value and units . The following fields are available in the value property: type - Required. The data type of the value. Supported types are bool , int8 - int64 , uint8 - uint64 , float32 , float64 , string , binary and arrays of the primitive types (ints, floats, bool). Arrays are specified as eg. float32array , boolarray etc. readWrite - R , RW , or W indicating whether the value is readable or writable. defaultValue - a value used for PUT requests which do not specify one. assertion - a string value to which a reading (after processing) is compared. If the reading is not the same as the assertion value, the device's operating state will be set to disbled. This can be useful for health checks. base - a value to be raised to the power of the raw reading before it is returned. scale - a factor by which to multiply a reading before it is returned. offset - a value to be added to a reading before it is returned. mask - a binary mask which will be applied to an integer reading. shift - a number of bits by which an integer reading will be shifted right. The processing defined by base, scale, offset, mask and shift is applied in that order. This is done within the SDK. A reverse transformation is applied by the SDK to incoming data on set operations (NB mask transforms on set are NYI) The units property is used to indicate the units of the value, eg Amperes, degrees C, etc. It should have a defaultValue that specifies the units.","title":"DeviceResources"},{"location":"microservices/device/profile/Ch-DeviceProfile/#devicecommands","text":"DeviceCommands define access to reads and writes for multiple simultaneous device resources. Each named deviceCommand should contain a number of get and/or set resourceOperations , describing the read or write respectively. DeviceCommands may be useful when readings are logically related, for example with a 3-axis accelerometer it is helpful to read all axes together. A resourceOperation consists of the following properties: index - a number, used to define an order in which the resource is processed. and set operations is not supported. deviceResource - the name of the deviceResource to access. parameter - optional, a value that will be used if a PUT request does not specify one. mappings - optional, allows readings of String type to be re-mapped. The device service allows access to deviceCommands via the same device REST endpoint as is used to access deviceResources. If a deviceCommand and deviceResource have the same name, it will be the deviceCommand which is available.","title":"DeviceCommands"},{"location":"microservices/device/profile/Ch-DeviceProfile/#corecommands","text":"CoreCommands specify the commands which are available via the core-command micro service, for reading and writing to the device. Both deviceResources and deviceCommands may be represented by coreCommands (the name of the coreCommand refers to the name of the deviceCommand or deviceResource). Commands may allow get or put methods (or both). For a get type, the returned values are specified in the expectedValues field, for a put type, the parameters to be given are specified in parameterNames . In either case, the different http response codes that the service may generate are indicated. Core Commands may be thought of as defining the outward-facing API for the device. A typical setup would prevent external access to the device service itself, so use of the full range of device resources and device commands would only be available to other components within the EdgeX deployment. Only those that has corresponding coreCommands would be available externally (via core-command).","title":"CoreCommands"},{"location":"microservices/device/profile/Ch-DeviceProfileRef/","text":"Device Profile Reference This chapter details the structure of a Device Profile and allowable values for its fields. Device Profile Field Name Type Required? Notes Name String Y Must be unique in the EdgeX deployment Manufacturer String N Model String N Labels Array of String N DeviceResources Array of DeviceResource Y DeviceCommands Array of DeviceCommand N CoreCommands Array of CoreCommand N DeviceResource Field Name Type Required? Notes Name String Y Must be unique in the EdgeX deployment Description String N Tag String N Attributes String-String Map Y Each Device Service should define required and optional keys Properties ProfileProperty Y ProfileProperty Field Name Type Required? Notes Value PropertyValue Y Units Units N PropertyValue Field Name Type Required? Notes Type Enum Y uint8 , uint16 , uint32 , uint64 , int8 , int16 , int32 , int64 , float32 , float64 , bool , string , binary , uint8array , uint16array , uint32array , uint64array , int8array , int16array , int32array , int64array , float32array , float64array , boolarray ReadWrite Enum Y R , W , RW DefaultValue String N If present, should be compatible with the Type field Mask Unsigned Int N Only valid where Type is one of the integer types Shift Unsigned Int N Only valid where Type is one of the integer types Scale Int or Float N Only valid where Type is one of the integer or float types Offset Int or Float N Only valid where Type is one of the integer or float types Base Int or Float N Only valid where Type is one of the integer or float types Assertion String N FloatEncoding Enum N base64 , eNotation - Only valid where Type is one of the float types MediaType String N Only valid where Type is Binary Units Field Name Type Required? Notes DefaultValue String Y DeviceCommand (Note: represented in Go by ProfileResource ) Field Name Type Required? Notes Name String Y Must be unique in this profile. May have the same name as a DeviceResource but this will make the DeviceResource not accessible individually. Such a configuration is only recommended if Mappings are used: see below. Get Array of ResourceOperation N At least one of Get and Set must be present Set Array of ResourceOperation N At least one of Get and Set must be present ResourceOperation Field Name Type Required? Notes DeviceResource String Y Must name a DeviceResource in this profile Parameter String N If present, should be compatible with the Type field of the named DeviceResource Mappings String-String Map N Only valid where the Type of the named DeviceResource is String CoreCommand (Note: represented in Go by Command ) Field Name Type Required? Notes Name String Y Must name a DeviceCommand or a DeviceResource in this profile Get GetCommand See note At least one of Get and Put must be present Put PutCommand See note At least one of Get and Put must be present GetCommand Field Name Type Required? Notes Path String Y Must be /api/v1/device/{deviceId}/XXX where XXX is the name of the command Responses Array of Response Y PutCommand Field Name Type Required? Notes Path String Y Must be /api/v1/device/{deviceId}/XXX where XXX is the name of the command Responses Array of Response Y ParameterNames Array of String Y Should correspond to the DeviceResource names associated with this Command Response Field Name Type Required? Notes Code Unsigned Int Y Should be a valid HTTP response code Description String N ExpectedValues Array of String Y For Get commands with success (2xx) Code, should correspond to the DeviceResource names associated with this command. For failing Get commands and Put commands, should be an empty array.","title":"Device Profile Reference"},{"location":"microservices/device/profile/Ch-DeviceProfileRef/#device-profile-reference","text":"This chapter details the structure of a Device Profile and allowable values for its fields.","title":"Device Profile Reference"},{"location":"microservices/device/profile/Ch-DeviceProfileRef/#device-profile","text":"Field Name Type Required? Notes Name String Y Must be unique in the EdgeX deployment Manufacturer String N Model String N Labels Array of String N DeviceResources Array of DeviceResource Y DeviceCommands Array of DeviceCommand N CoreCommands Array of CoreCommand N","title":"Device Profile"},{"location":"microservices/device/profile/Ch-DeviceProfileRef/#deviceresource","text":"Field Name Type Required? Notes Name String Y Must be unique in the EdgeX deployment Description String N Tag String N Attributes String-String Map Y Each Device Service should define required and optional keys Properties ProfileProperty Y","title":"DeviceResource"},{"location":"microservices/device/profile/Ch-DeviceProfileRef/#profileproperty","text":"Field Name Type Required? Notes Value PropertyValue Y Units Units N","title":"ProfileProperty"},{"location":"microservices/device/profile/Ch-DeviceProfileRef/#propertyvalue","text":"Field Name Type Required? Notes Type Enum Y uint8 , uint16 , uint32 , uint64 , int8 , int16 , int32 , int64 , float32 , float64 , bool , string , binary , uint8array , uint16array , uint32array , uint64array , int8array , int16array , int32array , int64array , float32array , float64array , boolarray ReadWrite Enum Y R , W , RW DefaultValue String N If present, should be compatible with the Type field Mask Unsigned Int N Only valid where Type is one of the integer types Shift Unsigned Int N Only valid where Type is one of the integer types Scale Int or Float N Only valid where Type is one of the integer or float types Offset Int or Float N Only valid where Type is one of the integer or float types Base Int or Float N Only valid where Type is one of the integer or float types Assertion String N FloatEncoding Enum N base64 , eNotation - Only valid where Type is one of the float types MediaType String N Only valid where Type is Binary","title":"PropertyValue"},{"location":"microservices/device/profile/Ch-DeviceProfileRef/#units","text":"Field Name Type Required? Notes DefaultValue String Y","title":"Units"},{"location":"microservices/device/profile/Ch-DeviceProfileRef/#devicecommand","text":"(Note: represented in Go by ProfileResource ) Field Name Type Required? Notes Name String Y Must be unique in this profile. May have the same name as a DeviceResource but this will make the DeviceResource not accessible individually. Such a configuration is only recommended if Mappings are used: see below. Get Array of ResourceOperation N At least one of Get and Set must be present Set Array of ResourceOperation N At least one of Get and Set must be present","title":"DeviceCommand"},{"location":"microservices/device/profile/Ch-DeviceProfileRef/#resourceoperation","text":"Field Name Type Required? Notes DeviceResource String Y Must name a DeviceResource in this profile Parameter String N If present, should be compatible with the Type field of the named DeviceResource Mappings String-String Map N Only valid where the Type of the named DeviceResource is String","title":"ResourceOperation"},{"location":"microservices/device/profile/Ch-DeviceProfileRef/#corecommand","text":"(Note: represented in Go by Command ) Field Name Type Required? Notes Name String Y Must name a DeviceCommand or a DeviceResource in this profile Get GetCommand See note At least one of Get and Put must be present Put PutCommand See note At least one of Get and Put must be present","title":"CoreCommand"},{"location":"microservices/device/profile/Ch-DeviceProfileRef/#getcommand","text":"Field Name Type Required? Notes Path String Y Must be /api/v1/device/{deviceId}/XXX where XXX is the name of the command Responses Array of Response Y","title":"GetCommand"},{"location":"microservices/device/profile/Ch-DeviceProfileRef/#putcommand","text":"Field Name Type Required? Notes Path String Y Must be /api/v1/device/{deviceId}/XXX where XXX is the name of the command Responses Array of Response Y ParameterNames Array of String Y Should correspond to the DeviceResource names associated with this Command","title":"PutCommand"},{"location":"microservices/device/profile/Ch-DeviceProfileRef/#response","text":"Field Name Type Required? Notes Code Unsigned Int Y Should be a valid HTTP response code Description String N ExpectedValues Array of String Y For Get commands with success (2xx) Code, should correspond to the DeviceResource names associated with this command. For failing Get commands and Put commands, should be an empty array.","title":"Response"},{"location":"microservices/device/sdk/Ch-DeviceSDK/","text":"Device Services SDK Introduction to the SDKs EdgeX provides two software development kits (SDKs) to help developers create new device services. While the EdgeX community and the larger EdgeX ecosystem provide a number of open source and commercially available device services for use with EdgeX, there is no way that every protocol and every sensor can be accommodated and connected to EdgeX with a pre-existing device service. Even if all the device service connectivity were provided, your use case, sensor or security infrastructure may require customization. Therefore, the device service SDKs provide the means to extend or customize EdgeX\u2019s device connectivity. EdgeX is mostly written in Go and C. There is a device service SDK written in both Go and C to support the more popular languages used in EdgeX today. In the future, alternate language SDKs may be provided by the community or made available by the larger ecosystem. The SDKs are really libraries to be incorporated into a new micro service. They make writing a new device service much easier. By importing the SDK library of choice into your new device service project, you can focus on the details associated with getting and manipulating sensor data from your device via the specific protocol of your device. Other details, such as initialization of the device service, getting the service configured, sending sensor data to core data, managing communications with core metadata, and much more are handled by the code in the SDK library. The code in the SDK also helps to ensure your device service adheres to rules and standards of EdgeX \u2013 such as making sure the service registers with the EdgeX registry service when it starts up. The EdgeX Foundry Device Service Software Development Kit (SDK) takes the developer through the step-by-step process to create an EdgeX Foundry device service micro service. Then setup the SDK and execute the code to generate the device service scaffolding to get you started using EdgeX. The Device Service SDK supports: Synchronous read and write operations Asynchronous device data collection Initialization and deconstruction of Driver Interface Initialization and destruction of Device Connection Framework for automated Provisioning Mechanism Support for multiple classes of Devices with Profiles Support for sets of actions triggered by a command Cached responses to queries Writing a Device Service Writing a new Device Service in Go Writing a new Device Service in C","title":"Device Services SDK"},{"location":"microservices/device/sdk/Ch-DeviceSDK/#device-services-sdk","text":"","title":"Device Services SDK"},{"location":"microservices/device/sdk/Ch-DeviceSDK/#introduction-to-the-sdks","text":"EdgeX provides two software development kits (SDKs) to help developers create new device services. While the EdgeX community and the larger EdgeX ecosystem provide a number of open source and commercially available device services for use with EdgeX, there is no way that every protocol and every sensor can be accommodated and connected to EdgeX with a pre-existing device service. Even if all the device service connectivity were provided, your use case, sensor or security infrastructure may require customization. Therefore, the device service SDKs provide the means to extend or customize EdgeX\u2019s device connectivity. EdgeX is mostly written in Go and C. There is a device service SDK written in both Go and C to support the more popular languages used in EdgeX today. In the future, alternate language SDKs may be provided by the community or made available by the larger ecosystem. The SDKs are really libraries to be incorporated into a new micro service. They make writing a new device service much easier. By importing the SDK library of choice into your new device service project, you can focus on the details associated with getting and manipulating sensor data from your device via the specific protocol of your device. Other details, such as initialization of the device service, getting the service configured, sending sensor data to core data, managing communications with core metadata, and much more are handled by the code in the SDK library. The code in the SDK also helps to ensure your device service adheres to rules and standards of EdgeX \u2013 such as making sure the service registers with the EdgeX registry service when it starts up. The EdgeX Foundry Device Service Software Development Kit (SDK) takes the developer through the step-by-step process to create an EdgeX Foundry device service micro service. Then setup the SDK and execute the code to generate the device service scaffolding to get you started using EdgeX. The Device Service SDK supports: Synchronous read and write operations Asynchronous device data collection Initialization and deconstruction of Driver Interface Initialization and destruction of Device Connection Framework for automated Provisioning Mechanism Support for multiple classes of Devices with Profiles Support for sets of actions triggered by a command Cached responses to queries","title":"Introduction to the SDKs"},{"location":"microservices/device/sdk/Ch-DeviceSDK/#writing-a-device-service","text":"Writing a new Device Service in Go Writing a new Device Service in C","title":"Writing a Device Service"},{"location":"microservices/device/virtual/Ch-VirtualDevice/","text":"Virtual Device Introduction The virtual device service simulates different kinds of devices to generate events and readings to the core data micro service, and users send commands and get responses through the command and control micro service. These features of the virtual device services are useful when executing functional or performance tests without having any real devices. The virtual device service, built in Go and based on the device service Go SDK, can simulate sensors by generating data of the following data types: Bool Int8, Int16, Int32, Int64 Uint8, Uint16, Uint32, Uint64 Float32, Float64 Binary The virtual device services leverages ql(an embedded SQL database engine) to simulate virtual resources. By default, the virtual device service is included and configured to run with all EdgeX Docker Compose files. This allows users to have a complete EdgeX system up and running - with simulated data from the virtual device service - in minutes. Using the Virtual Device Service The virtual device service contains 4 pre-defined devices as random value generators: Random-Boolean-Device Random-Integer-Device Random-UnsignedInteger-Device Random-Float-Device Random-Binary-Device These devices are created by the virtual device service in core metadata when the service first initializes. These devices are defined by device profiles that ship with the virtual device service. Each virtual device causes the generation of one to many values of the type specified by the device name. For example, Random-Integer-Device generates integer values: Int8, Int16, Int32 and Int64. As with all devices, the deviceResources in the associated device profile of the device defind what values are produced by the device service. In the case of Random-Integer-Device, the Int8, Int16, Int32 and Int64 values are defined as deviceResources. - name : \"Int8\" description : \"Generate random int8 value\" properties : value : { type : \"Int8\" , readWrite : \"R\" , defaultValue : \"0\" } units : { type : \"String\" , readWrite : \"R\" , defaultValue : \"random int8 value\" } - name : \"Int16\" description : \"Generate random int16 value\" properties : value : { type : \"Int16\" , readWrite : \"R\" , defaultValue : \"0\" } units : { type : \"String\" , readWrite : \"R\" , defaultValue : \"random int16 value\" } - name : \"Int32\" description : \"Generate random int32 value\" properties : value : { type : \"Int32\" , readWrite : \"R\" , defaultValue : \"0\" } units : { type : \"String\" , readWrite : \"R\" , defaultValue : \"random int32 value\" } - name : \"Int64\" description : \"Generate random int64 value\" properties : value : { type : \"Int64\" , readWrite : \"R\" , defaultValue : \"0\" } units : { type : \"String\" , readWrite : \"R\" , defaultValue : \"random int64 value\" } Additionally, there is an accompanying deviceResource for each of the generated value deviceResource. Each deviceResources has an associated EnableRandomization_X deviceResource. In the case of the integer deviceResources above, there are the associated EnableRandomization_IntX deviceResources below. The EnableRandomization deviceResources are boolean values, and when set to true, the associated simulated sensor value is generated by the device service. When the EnableRandomization_IntX value is set to false, then the associated simulator sensor value is fixed. - name : \"EnableRandomization_Int8\" description : \"used to decide whether to re-generate a random value\" properties : value : { type : \"Bool\" , readWrite : \"W\" , defaultValue : \"true\" } units : { type : \"String\" , readWrite : \"R\" , defaultValue : \"Random\" } - name : \"EnableRandomization_Int16\" description : \"used to decide whether to re-generate a random value\" properties : value : { type : \"Bool\" , readWrite : \"W\" , defaultValue : \"true\" } units : { type : \"String\" , readWrite : \"R\" , defaultValue : \"Random\" } - name : \"EnableRandomization_Int32\" description : \"used to decide whether to re-generate a random value\" properties : value : { type : \"Bool\" , readWrite : \"W\" , defaultValue : \"true\" } units : { type : \"String\" , readWrite : \"R\" , defaultValue : \"Random\" } - name : \"EnableRandomization_Int64\" description : \"used to decide whether to re-generate a random value\" properties : value : { type : \"Bool\" , readWrite : \"W\" , defaultValue : \"true\" } units : { type : \"String\" , readWrite : \"R\" , defaultValue : \"Random\" } Info The Enable_Randomization attribute of resource is automatically set to false when you use a PUT command to set a specified generated value. Furtehr, the minimum and maximum values of generated value deviceResource can be specified in the device profile. Below, Int8 is set to be between -100 and 100. deviceResources : - name : \"Int8\" description : \"Generate random int8 value\" properties : value : { type : \"Int8\" , readWrite : \"R\" , minimum : \"-100\" , maximum : \"100\" , defaultValue : \"0\" } units : { type : \"String\" , readWrite : \"R\" , defaultValue : \"random int8 value\" } For the binary deviceResources, values are generated by the function rand.Read(p []byte) in Golang math package. The []byte size is fixed to MaxBinaryBytes/1000. Core Command and the Virtual Device Service Use the following core command service APIs to execute commands against the virtual device service for the specified devices. Both GET and PUT commands can be issued with these APIs. GET command request the next generated value while PUT commands will allow you to disable randomization (EnableRandomization) and set the fixed values to be returned by the device. http://[host]:48082/api/v1/device/name/Random-Boolean-Device http://[host]:48082/api/v1/device/name/Random-Integer-Device http://[host]:48082/api/v1/device/name/Random-UnsignedInteger-Device http://[host]:48082/api/v1/device/name/Random-Float-Device http://[host]:48082/api/v1/device/name/Random-Binary-Device Note Port 48082 is the default port for the core command service. Configuration Properties Please refer to the general Configuration documentation for configuration properties common to all services. DeviceList Property Example Value Description properties used in defining the static provisioning of each of the virtual devices Name 'Random-Integer-Device' name of the virtual device Profile 'Random-Integer-Device' device profile that defines the resources and commands of the virtual device Description 'Example of Device Virtual' description of the virtual device Labels ['device-virtual-example'] labels array used for searching for virtual devices DeviceList/DeviceList.Protocols/DeviceList.Protocols.other Property Example Value Description Address 'device-virtual-int-01' address for the virtual device Protocol '300' DeviceList/DeviceList.AutoEvents Property Default Value Description properties used to define how often an event/reading is schedule for collection to send to core data from the virtual device Frequency '15s' every 15 seconds OnChange false collect data regardless of change Resource 'Int8' deviceResource to collect - in this case the Int8 resource API Reference Device Service - SDK- API Reference","title":"Virtual Device"},{"location":"microservices/device/virtual/Ch-VirtualDevice/#virtual-device","text":"","title":"Virtual Device"},{"location":"microservices/device/virtual/Ch-VirtualDevice/#introduction","text":"The virtual device service simulates different kinds of devices to generate events and readings to the core data micro service, and users send commands and get responses through the command and control micro service. These features of the virtual device services are useful when executing functional or performance tests without having any real devices. The virtual device service, built in Go and based on the device service Go SDK, can simulate sensors by generating data of the following data types: Bool Int8, Int16, Int32, Int64 Uint8, Uint16, Uint32, Uint64 Float32, Float64 Binary The virtual device services leverages ql(an embedded SQL database engine) to simulate virtual resources. By default, the virtual device service is included and configured to run with all EdgeX Docker Compose files. This allows users to have a complete EdgeX system up and running - with simulated data from the virtual device service - in minutes.","title":"Introduction"},{"location":"microservices/device/virtual/Ch-VirtualDevice/#using-the-virtual-device-service","text":"The virtual device service contains 4 pre-defined devices as random value generators: Random-Boolean-Device Random-Integer-Device Random-UnsignedInteger-Device Random-Float-Device Random-Binary-Device These devices are created by the virtual device service in core metadata when the service first initializes. These devices are defined by device profiles that ship with the virtual device service. Each virtual device causes the generation of one to many values of the type specified by the device name. For example, Random-Integer-Device generates integer values: Int8, Int16, Int32 and Int64. As with all devices, the deviceResources in the associated device profile of the device defind what values are produced by the device service. In the case of Random-Integer-Device, the Int8, Int16, Int32 and Int64 values are defined as deviceResources. - name : \"Int8\" description : \"Generate random int8 value\" properties : value : { type : \"Int8\" , readWrite : \"R\" , defaultValue : \"0\" } units : { type : \"String\" , readWrite : \"R\" , defaultValue : \"random int8 value\" } - name : \"Int16\" description : \"Generate random int16 value\" properties : value : { type : \"Int16\" , readWrite : \"R\" , defaultValue : \"0\" } units : { type : \"String\" , readWrite : \"R\" , defaultValue : \"random int16 value\" } - name : \"Int32\" description : \"Generate random int32 value\" properties : value : { type : \"Int32\" , readWrite : \"R\" , defaultValue : \"0\" } units : { type : \"String\" , readWrite : \"R\" , defaultValue : \"random int32 value\" } - name : \"Int64\" description : \"Generate random int64 value\" properties : value : { type : \"Int64\" , readWrite : \"R\" , defaultValue : \"0\" } units : { type : \"String\" , readWrite : \"R\" , defaultValue : \"random int64 value\" } Additionally, there is an accompanying deviceResource for each of the generated value deviceResource. Each deviceResources has an associated EnableRandomization_X deviceResource. In the case of the integer deviceResources above, there are the associated EnableRandomization_IntX deviceResources below. The EnableRandomization deviceResources are boolean values, and when set to true, the associated simulated sensor value is generated by the device service. When the EnableRandomization_IntX value is set to false, then the associated simulator sensor value is fixed. - name : \"EnableRandomization_Int8\" description : \"used to decide whether to re-generate a random value\" properties : value : { type : \"Bool\" , readWrite : \"W\" , defaultValue : \"true\" } units : { type : \"String\" , readWrite : \"R\" , defaultValue : \"Random\" } - name : \"EnableRandomization_Int16\" description : \"used to decide whether to re-generate a random value\" properties : value : { type : \"Bool\" , readWrite : \"W\" , defaultValue : \"true\" } units : { type : \"String\" , readWrite : \"R\" , defaultValue : \"Random\" } - name : \"EnableRandomization_Int32\" description : \"used to decide whether to re-generate a random value\" properties : value : { type : \"Bool\" , readWrite : \"W\" , defaultValue : \"true\" } units : { type : \"String\" , readWrite : \"R\" , defaultValue : \"Random\" } - name : \"EnableRandomization_Int64\" description : \"used to decide whether to re-generate a random value\" properties : value : { type : \"Bool\" , readWrite : \"W\" , defaultValue : \"true\" } units : { type : \"String\" , readWrite : \"R\" , defaultValue : \"Random\" } Info The Enable_Randomization attribute of resource is automatically set to false when you use a PUT command to set a specified generated value. Furtehr, the minimum and maximum values of generated value deviceResource can be specified in the device profile. Below, Int8 is set to be between -100 and 100. deviceResources : - name : \"Int8\" description : \"Generate random int8 value\" properties : value : { type : \"Int8\" , readWrite : \"R\" , minimum : \"-100\" , maximum : \"100\" , defaultValue : \"0\" } units : { type : \"String\" , readWrite : \"R\" , defaultValue : \"random int8 value\" } For the binary deviceResources, values are generated by the function rand.Read(p []byte) in Golang math package. The []byte size is fixed to MaxBinaryBytes/1000.","title":"Using the Virtual Device Service"},{"location":"microservices/device/virtual/Ch-VirtualDevice/#core-command-and-the-virtual-device-service","text":"Use the following core command service APIs to execute commands against the virtual device service for the specified devices. Both GET and PUT commands can be issued with these APIs. GET command request the next generated value while PUT commands will allow you to disable randomization (EnableRandomization) and set the fixed values to be returned by the device. http://[host]:48082/api/v1/device/name/Random-Boolean-Device http://[host]:48082/api/v1/device/name/Random-Integer-Device http://[host]:48082/api/v1/device/name/Random-UnsignedInteger-Device http://[host]:48082/api/v1/device/name/Random-Float-Device http://[host]:48082/api/v1/device/name/Random-Binary-Device Note Port 48082 is the default port for the core command service.","title":"Core Command and the Virtual Device Service"},{"location":"microservices/device/virtual/Ch-VirtualDevice/#configuration-properties","text":"Please refer to the general Configuration documentation for configuration properties common to all services. DeviceList Property Example Value Description properties used in defining the static provisioning of each of the virtual devices Name 'Random-Integer-Device' name of the virtual device Profile 'Random-Integer-Device' device profile that defines the resources and commands of the virtual device Description 'Example of Device Virtual' description of the virtual device Labels ['device-virtual-example'] labels array used for searching for virtual devices DeviceList/DeviceList.Protocols/DeviceList.Protocols.other Property Example Value Description Address 'device-virtual-int-01' address for the virtual device Protocol '300' DeviceList/DeviceList.AutoEvents Property Default Value Description properties used to define how often an event/reading is schedule for collection to send to core data from the virtual device Frequency '15s' every 15 seconds OnChange false collect data regardless of change Resource 'Int8' deviceResource to collect - in this case the Int8 resource","title":"Configuration Properties"},{"location":"microservices/device/virtual/Ch-VirtualDevice/#api-reference","text":"Device Service - SDK- API Reference","title":"API Reference"},{"location":"microservices/security/Ch-APIGateway/","text":"API Gateway The security API gateway is the single point of entry for all EdgeX REST traffic. It is the barrier between external clients and the EdgeX microservices preventing unauthorized access to EdgeX REST APIs. The API gateway accepts client requests, verifies the identity of the clients, redirects the requests to correspondent microservice and relays the results back to the client. The API Gateway provides an HTTP REST interface for administration management. The administrative management offers the means to configure API routing, as well as client authentication and access control. This configuration is store in an embedded database. KONG ( https://konghq.com/ ) is the product underlying the API gateway. The EdgeX community has added code to initialize the KONG environment, set up service routes for EdgeX microservices, and add various authentication/authorization mechanisms including JWT authentication, OAuth2 authentication and ACL. Start the API Gateway Start the API gateway with Docker Compose and a Docker Compose manifest file (the Docker Compose file named docker-compose-nexus-{redis,mongo}.yml (or -arm64 variabnts) found at https://github.com/edgexfoundry/developer-scripts/tree/master/releases/geneva/compose-files )). This Compose file starts all of EdgeX including the security services. The command to start EdgeX inclusive of API gateway related services is: : docker-compose up -d For debugging purpose, the API gateway services can be started individually with these commands used in sequence after secret store starts successfully. Lines starts with # are comments to explain the purpose of the command. : docker - compose up - d kong - db # start up backend database for API gateway docker - compose up - d kong - migrations # initialize the backend database for API gateway docker - compose up - d kong # start up KONG the major component of API gateway docker - compose up - d edgex - proxy # initialize KONG, configure proxy routes, apply certificates to routes, and enable various authentication/ACL features. If the last command returns an error message for any reason (such as incorrect configuration file), the API gateway may be in an unstable status. The following command can be used to stop and remove the containers. : docker-compose down # stop and remove the containers After stopping and removing the containers, you can attempt to recreate and start them again. Alternatively you can use the command to reset the API gateway as shown below: : docker run \u2013network=edgex-network edgexfoundry/docker-edgex-proxy-go --reset=true After issuing the reset command, attempt to start and reinitialize with the command below. : docker run \u2013network=edgex-network edgexfoundry/docker-edgex-proxy-go --init=true You can learn more about these commands, to include some additional options by running: : docker run \u2013network=edgex-network edgexfoundry/docker-edgex-proxy-go \u2013h On successfully starting EdgeX with the API Gateway services, the list of running containers should close follow the listing shown below. Note key security service containers like kong, kong-db, edgex-vault are listed. Configuring API Gateway The API gateway supports two different forms of authentication: JSON Web Token (JWT) or OAuth2 Authentication. Only one authentication method can be enabled at a time. The API Gateway also supports an Access Control List (ACL) which can be enabled with one of the authentication methods mentioned earlier for fine control among the groups. The authentication and ACL need to be specified in the API gateway's configuration file. Setup of authentication and access control occurs automatically as part of API gateway initialization. The configuration file can be found at https://github.com/edgexfoundry/edgex-go/blob/master/cmd/security-proxy-setup/res/configuration.toml Configuration of JWT Authentication for API Gateway When using JWT Authentication, the [KongAuth] section needs to be specified in the configuration file as shown below. : [KongAuth] Name = \"jwt\" Configuration of OAuth2 Authentication for API Gateway When using OAuth2 Authentication, the [KongAuth] section needs to specify oauth2 in the configuration file as shown below. Note, today EdgeX only supports \"client credential\" authentication (specified in \"granttype\") currently for OAuth. [kongauth] name = \"oauth2\" scopes = \"email,phone,address\" mandatoryscope = \"true\" enableclientcredentials = \"true\" clientid = \"test\" clientsecret = \"test\" redirecturi = \"http://edgex.com\" granttype = \"client_credentials\" scopegranted = \"email\" resource = \"coredata\" Configuration of ACL for API Gateway Access control is also specified in the configuration file as shown below. Note, users that belong to the whitelist will have access to the resources of EdgeX, and users not belonging to the group listed here will be denied when trying to access resources through the API Gateway. : [kongacl] name = \"acl\" whitelist = \"admin,user\" Configuration of Adding Microservices Routes for API Gateway For the current pre-existing Kong routes, they are configured and initialized statically through configuration TOML file specified in security-proxy-setup application. This is not sufficient for some other new additional microservices like application services, for example. Thus, adding new proxy Kong routes are now possibly achieved via the environment variable, ADD_PROXY_ROUTE , of service edgex-proxy in the docker-compose file. Here is an example: edgex-proxy : ... environment : ... ADD_PROXY_ROUTE : \"myApp.http://my-app:56789\" ... ... my-app : ... container_name : myApp hostname : myApp ... The value of ADD_PROXY_ROUTE takes a comma-separated list of one or more (at least one) paired additional service name and URL for which to create proxy Kong routes. The paired specification is given as the following: \\<RoutePrefix>.\\<TargetRouteURL> where RoutePrefix is the name of service which requests to create proxy Kong route and it is case insensitive; it is the docker network hostname of the service that want to add the proxy Kong route in the docker-compose file if running from docker-compose, for example, myApp in this case. TargetRouteURL is the full qualified URL for the target service, like http://my-app:56789 So as an example, for a single service, the value of ADD_PROXY_ROUTE would be: \" myApp.http://my-app:56789 \". Once ADD_PROXY_ROUTE is configured and composed-up successfully, the proxy route then can be accessed the app's REST API via Kong as http://localhost:8000/myApp/api/v1/... in the same way you would access the edgex service in which you will also need an access token and it is using default access role if not specified in the TOML configuration file as well. Using API Gateway Resource Mapping between EdgeX Microservice and API gateway If the EdgeX API gateway is not in use, a client can access and use any REST API provided by the EdgeX microservices by sending an HTTP request to the service endpoint. E.g., a client can consume the ping endpoint of the Core Data microservice with curl command like this: : curl http://<core-data-microservice-ip>:48080/api/v1/ping Once the API gateway is started and initialized successfully, and all the common ports for EdgeX microservices are blocked by disabling the exposed external ports of the EdgeX microservices through updating the docker compose file, the EdgeX microservice will be behind the gateway. At this time both the microservice host/IP Address (\\<core-data-microservice-ip> in the example) as well as the service port (48080 in the example) are not available to external access. EdgeX uses the gateway as a single entry point for all the REST APIs. With the API gateway in place, the curl command to ping the endpoint of the same Core Data service, as shown above, needs to change to : : curl https://<api-gateway-host-ip>:8443/coredata/api/v1/ping Comparing these two curl commands you may notice several differences. \"Http\" is switched to \"https\" as we enable the SSL/TLS for secure communication. This applies to any client side request. The EdgeX microservice IP address where the request is sent changed to the host/IP address of API gateway service (recall the API gateway becomes the single entry point for all the EdgeX micro services). The API gateway will eventually lateral the request to the Core Data service if the client is authorized. The port of the request is switched from 48080 to 8443, which is the default SSL/TLS port for API gateway (versus the micro service port). This applies to any client side request. The \"/coredata/\" path in the URL is used to identify which EdgeX micro service the request is routed to. As each EdgeX micro service has a dedicated service port open that accepts incoming requests, there is a mapping table kept by the API gateway that maps paths to micro service ports. A partial listing of the map between ports and URL paths is shown in the table below. EdgeX microservice Name Port number Partial URL coredata 48080 coredata metadata 48081 metadata command 48082 command notifications 48060 notifications supportlogging 48061 supportlogging Creating Access Token for API Gateway Authentication If the EdgeX API gateway is not in use, a client can access and use any REST API provided by the EdgeX microservices by sending an HTTP request to the service endpoint. E.g., a client can consume the ping endpoint of the Core Data microservice with curl command like this: : curl http://<core-data-microservice-ip>:48080/api/v1/ping Again, the request doesn't include client identity information. Once the API gateway is started and initialized successfully, the EdgeX microservice REST APIs will be behind the gateway, an access token must be attached with any client-side HTTP request for identity verification and authentication done by the API gateway. This access token is different from the access token of secret store even though they have the same name. The purpose of the access token for the API gateway is to identity clients that send the requests to consume the REST API of EdgeX. The secret store will then use the token to verify the identity of clients that send the request to access the secrets of EdgeX that are stored in the secret store. To obtain an access token for a client, a user that is associated with the client as well as a group that the user belongs to needs to be added into the API gateway. The command to add a user and the group is: : docker-compose -f docker-compose-nexus-mongo.yml run --rm --entrypoint /edgex/security-proxy-setup edgex-proxy --init=false --useradd=<user> --group=<groupname> The command above will return an access token that can then be used by the client to access the EdgeX REST API resources. Depending on the choice of authentication method, the format of the access token will be something like this if JWT is enabled: : eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiI5M3V3cmZBc0xzS2Qwd1JnckVFdlRzQloxSmtYOTRRciIsImFjY291bnQiOiJhZG1pbmlzdHJhdG9yIn0.em8ffitqrd59_DeYKfQkTZGtUA1T99NikETwtedOgHQ Alternatively, the access token may look like what is shown below if the OAuth2 is enabled: : MNsBh6jDDSxaECzUtimW1nDSvI2v0xsZ If a client needs to be disabled and the client's token invalidated, use the command here to remove/delete the user: : docker run \u2013network=edgex-network edgexfoundry/docker-edgex-proxy-go \u2013-userdel=<user> Using API Gateway to Proxy Existing EdgeX Microservices Once the resource mapping and access token to API gateway are in place, a client can use the access token to use the protected EdgeX REST API resources behind the API gateway. Again, without the API Gateway in place, here is the sample request to hit the ping endpoint of the EdgeX Core Data microservice using curl: : curl http://<core-data-microservice-ip>:48080/api/v1/ping With the security service and JWT authentication is enabled, the command changes to: : curl \u2013H \u201chost: edgex\u201d https://<api-gateway-service-ip>:8443/coredata/api/v1/ping? -H \"Authorization: Bearer <access-token>\u201d In summary the difference between the two commands are listed below: --H \"host: edgex\" is used to indicate that the request is for EdgeX domain as the API gateway could be used to take requests for different domains. Use the https versus http protocol identifier for SSL/TLS secure communication. The service port 8443 is the default TLS service port of API gateway Use the URL path \"coredata\" to indicate which EdgeX microservice the request is routed to Use header of -H \"Authorization: Bearer \\<access-token>\" to specify the access token associated with the client that was generated when the client was added. The format for OAuth2 authentication is similar. For OAuth2 use the bearer token from OAuth2 authentication instead of the JWT token. Here is an example of the curl command using OAuth2: : curl \u2013H \"host: edgex\" https://<api-gateway-service-ip>:8443/coredata/api/v1/ping -H \"Authorization:bearer <access-token>\"","title":"API Gateway"},{"location":"microservices/security/Ch-APIGateway/#api-gateway","text":"The security API gateway is the single point of entry for all EdgeX REST traffic. It is the barrier between external clients and the EdgeX microservices preventing unauthorized access to EdgeX REST APIs. The API gateway accepts client requests, verifies the identity of the clients, redirects the requests to correspondent microservice and relays the results back to the client. The API Gateway provides an HTTP REST interface for administration management. The administrative management offers the means to configure API routing, as well as client authentication and access control. This configuration is store in an embedded database. KONG ( https://konghq.com/ ) is the product underlying the API gateway. The EdgeX community has added code to initialize the KONG environment, set up service routes for EdgeX microservices, and add various authentication/authorization mechanisms including JWT authentication, OAuth2 authentication and ACL.","title":"API Gateway"},{"location":"microservices/security/Ch-APIGateway/#start-the-api-gateway","text":"Start the API gateway with Docker Compose and a Docker Compose manifest file (the Docker Compose file named docker-compose-nexus-{redis,mongo}.yml (or -arm64 variabnts) found at https://github.com/edgexfoundry/developer-scripts/tree/master/releases/geneva/compose-files )). This Compose file starts all of EdgeX including the security services. The command to start EdgeX inclusive of API gateway related services is: : docker-compose up -d For debugging purpose, the API gateway services can be started individually with these commands used in sequence after secret store starts successfully. Lines starts with # are comments to explain the purpose of the command. : docker - compose up - d kong - db # start up backend database for API gateway docker - compose up - d kong - migrations # initialize the backend database for API gateway docker - compose up - d kong # start up KONG the major component of API gateway docker - compose up - d edgex - proxy # initialize KONG, configure proxy routes, apply certificates to routes, and enable various authentication/ACL features. If the last command returns an error message for any reason (such as incorrect configuration file), the API gateway may be in an unstable status. The following command can be used to stop and remove the containers. : docker-compose down # stop and remove the containers After stopping and removing the containers, you can attempt to recreate and start them again. Alternatively you can use the command to reset the API gateway as shown below: : docker run \u2013network=edgex-network edgexfoundry/docker-edgex-proxy-go --reset=true After issuing the reset command, attempt to start and reinitialize with the command below. : docker run \u2013network=edgex-network edgexfoundry/docker-edgex-proxy-go --init=true You can learn more about these commands, to include some additional options by running: : docker run \u2013network=edgex-network edgexfoundry/docker-edgex-proxy-go \u2013h On successfully starting EdgeX with the API Gateway services, the list of running containers should close follow the listing shown below. Note key security service containers like kong, kong-db, edgex-vault are listed.","title":"Start the API Gateway"},{"location":"microservices/security/Ch-APIGateway/#configuring-api-gateway","text":"The API gateway supports two different forms of authentication: JSON Web Token (JWT) or OAuth2 Authentication. Only one authentication method can be enabled at a time. The API Gateway also supports an Access Control List (ACL) which can be enabled with one of the authentication methods mentioned earlier for fine control among the groups. The authentication and ACL need to be specified in the API gateway's configuration file. Setup of authentication and access control occurs automatically as part of API gateway initialization. The configuration file can be found at https://github.com/edgexfoundry/edgex-go/blob/master/cmd/security-proxy-setup/res/configuration.toml Configuration of JWT Authentication for API Gateway When using JWT Authentication, the [KongAuth] section needs to be specified in the configuration file as shown below. : [KongAuth] Name = \"jwt\" Configuration of OAuth2 Authentication for API Gateway When using OAuth2 Authentication, the [KongAuth] section needs to specify oauth2 in the configuration file as shown below. Note, today EdgeX only supports \"client credential\" authentication (specified in \"granttype\") currently for OAuth. [kongauth] name = \"oauth2\" scopes = \"email,phone,address\" mandatoryscope = \"true\" enableclientcredentials = \"true\" clientid = \"test\" clientsecret = \"test\" redirecturi = \"http://edgex.com\" granttype = \"client_credentials\" scopegranted = \"email\" resource = \"coredata\" Configuration of ACL for API Gateway Access control is also specified in the configuration file as shown below. Note, users that belong to the whitelist will have access to the resources of EdgeX, and users not belonging to the group listed here will be denied when trying to access resources through the API Gateway. : [kongacl] name = \"acl\" whitelist = \"admin,user\" Configuration of Adding Microservices Routes for API Gateway For the current pre-existing Kong routes, they are configured and initialized statically through configuration TOML file specified in security-proxy-setup application. This is not sufficient for some other new additional microservices like application services, for example. Thus, adding new proxy Kong routes are now possibly achieved via the environment variable, ADD_PROXY_ROUTE , of service edgex-proxy in the docker-compose file. Here is an example: edgex-proxy : ... environment : ... ADD_PROXY_ROUTE : \"myApp.http://my-app:56789\" ... ... my-app : ... container_name : myApp hostname : myApp ... The value of ADD_PROXY_ROUTE takes a comma-separated list of one or more (at least one) paired additional service name and URL for which to create proxy Kong routes. The paired specification is given as the following: \\<RoutePrefix>.\\<TargetRouteURL> where RoutePrefix is the name of service which requests to create proxy Kong route and it is case insensitive; it is the docker network hostname of the service that want to add the proxy Kong route in the docker-compose file if running from docker-compose, for example, myApp in this case. TargetRouteURL is the full qualified URL for the target service, like http://my-app:56789 So as an example, for a single service, the value of ADD_PROXY_ROUTE would be: \" myApp.http://my-app:56789 \". Once ADD_PROXY_ROUTE is configured and composed-up successfully, the proxy route then can be accessed the app's REST API via Kong as http://localhost:8000/myApp/api/v1/... in the same way you would access the edgex service in which you will also need an access token and it is using default access role if not specified in the TOML configuration file as well.","title":"Configuring API Gateway"},{"location":"microservices/security/Ch-APIGateway/#using-api-gateway","text":"Resource Mapping between EdgeX Microservice and API gateway If the EdgeX API gateway is not in use, a client can access and use any REST API provided by the EdgeX microservices by sending an HTTP request to the service endpoint. E.g., a client can consume the ping endpoint of the Core Data microservice with curl command like this: : curl http://<core-data-microservice-ip>:48080/api/v1/ping Once the API gateway is started and initialized successfully, and all the common ports for EdgeX microservices are blocked by disabling the exposed external ports of the EdgeX microservices through updating the docker compose file, the EdgeX microservice will be behind the gateway. At this time both the microservice host/IP Address (\\<core-data-microservice-ip> in the example) as well as the service port (48080 in the example) are not available to external access. EdgeX uses the gateway as a single entry point for all the REST APIs. With the API gateway in place, the curl command to ping the endpoint of the same Core Data service, as shown above, needs to change to : : curl https://<api-gateway-host-ip>:8443/coredata/api/v1/ping Comparing these two curl commands you may notice several differences. \"Http\" is switched to \"https\" as we enable the SSL/TLS for secure communication. This applies to any client side request. The EdgeX microservice IP address where the request is sent changed to the host/IP address of API gateway service (recall the API gateway becomes the single entry point for all the EdgeX micro services). The API gateway will eventually lateral the request to the Core Data service if the client is authorized. The port of the request is switched from 48080 to 8443, which is the default SSL/TLS port for API gateway (versus the micro service port). This applies to any client side request. The \"/coredata/\" path in the URL is used to identify which EdgeX micro service the request is routed to. As each EdgeX micro service has a dedicated service port open that accepts incoming requests, there is a mapping table kept by the API gateway that maps paths to micro service ports. A partial listing of the map between ports and URL paths is shown in the table below. EdgeX microservice Name Port number Partial URL coredata 48080 coredata metadata 48081 metadata command 48082 command notifications 48060 notifications supportlogging 48061 supportlogging Creating Access Token for API Gateway Authentication If the EdgeX API gateway is not in use, a client can access and use any REST API provided by the EdgeX microservices by sending an HTTP request to the service endpoint. E.g., a client can consume the ping endpoint of the Core Data microservice with curl command like this: : curl http://<core-data-microservice-ip>:48080/api/v1/ping Again, the request doesn't include client identity information. Once the API gateway is started and initialized successfully, the EdgeX microservice REST APIs will be behind the gateway, an access token must be attached with any client-side HTTP request for identity verification and authentication done by the API gateway. This access token is different from the access token of secret store even though they have the same name. The purpose of the access token for the API gateway is to identity clients that send the requests to consume the REST API of EdgeX. The secret store will then use the token to verify the identity of clients that send the request to access the secrets of EdgeX that are stored in the secret store. To obtain an access token for a client, a user that is associated with the client as well as a group that the user belongs to needs to be added into the API gateway. The command to add a user and the group is: : docker-compose -f docker-compose-nexus-mongo.yml run --rm --entrypoint /edgex/security-proxy-setup edgex-proxy --init=false --useradd=<user> --group=<groupname> The command above will return an access token that can then be used by the client to access the EdgeX REST API resources. Depending on the choice of authentication method, the format of the access token will be something like this if JWT is enabled: : eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiI5M3V3cmZBc0xzS2Qwd1JnckVFdlRzQloxSmtYOTRRciIsImFjY291bnQiOiJhZG1pbmlzdHJhdG9yIn0.em8ffitqrd59_DeYKfQkTZGtUA1T99NikETwtedOgHQ Alternatively, the access token may look like what is shown below if the OAuth2 is enabled: : MNsBh6jDDSxaECzUtimW1nDSvI2v0xsZ If a client needs to be disabled and the client's token invalidated, use the command here to remove/delete the user: : docker run \u2013network=edgex-network edgexfoundry/docker-edgex-proxy-go \u2013-userdel=<user> Using API Gateway to Proxy Existing EdgeX Microservices Once the resource mapping and access token to API gateway are in place, a client can use the access token to use the protected EdgeX REST API resources behind the API gateway. Again, without the API Gateway in place, here is the sample request to hit the ping endpoint of the EdgeX Core Data microservice using curl: : curl http://<core-data-microservice-ip>:48080/api/v1/ping With the security service and JWT authentication is enabled, the command changes to: : curl \u2013H \u201chost: edgex\u201d https://<api-gateway-service-ip>:8443/coredata/api/v1/ping? -H \"Authorization: Bearer <access-token>\u201d In summary the difference between the two commands are listed below: --H \"host: edgex\" is used to indicate that the request is for EdgeX domain as the API gateway could be used to take requests for different domains. Use the https versus http protocol identifier for SSL/TLS secure communication. The service port 8443 is the default TLS service port of API gateway Use the URL path \"coredata\" to indicate which EdgeX microservice the request is routed to Use header of -H \"Authorization: Bearer \\<access-token>\" to specify the access token associated with the client that was generated when the client was added. The format for OAuth2 authentication is similar. For OAuth2 use the bearer token from OAuth2 authentication instead of the JWT token. Here is an example of the curl command using OAuth2: : curl \u2013H \"host: edgex\" https://<api-gateway-service-ip>:8443/coredata/api/v1/ping -H \"Authorization:bearer <access-token>\"","title":"Using API Gateway"},{"location":"microservices/security/Ch-AccessEdgeXRESTResources/","text":"Access EdgeX REST resources When the EdgeX API Gateway is used, access to the micro service APIs must go through the reverse proxy. Requestors of an EdgeX REST endpoints must therefore change the URL they use to access the services. Example below explain how to map the non-secured micro service URLs with reverse proxy protected URLS. To access the ping endpoint of an EdgeX micro service (using the command service as an example), the URL is http://edgex-command-service:48082/api/v1/ping With API gateway serving as the single access point for the EdgeX services, the ping URL is https://api-gateway-server:8443/command/api/v1/ping?jwt= \\<JWT-Token> Please notice that there are 4 major differences when comparing the URLs above Switch from http to https as the API Gateway server enables https The host address and port are switched from original micro service host address and port to a common api gateway service address and 8443 port as the api gateway server will serve as the single point for all the EdgeX services Use the name of the service (in this case \"command\") within the URL to indicate that the request is to be routed to the appropriate EdgeX service (command in this example) Add a JWT as part of the URL as all the REST resources are protected by either OAuth2 or JWT authentication. The JWT can be obtained when a user account is created with the security API Gateway.","title":"Access EdgeX REST resources"},{"location":"microservices/security/Ch-AccessEdgeXRESTResources/#access-edgex-rest-resources","text":"When the EdgeX API Gateway is used, access to the micro service APIs must go through the reverse proxy. Requestors of an EdgeX REST endpoints must therefore change the URL they use to access the services. Example below explain how to map the non-secured micro service URLs with reverse proxy protected URLS. To access the ping endpoint of an EdgeX micro service (using the command service as an example), the URL is http://edgex-command-service:48082/api/v1/ping With API gateway serving as the single access point for the EdgeX services, the ping URL is https://api-gateway-server:8443/command/api/v1/ping?jwt= \\<JWT-Token> Please notice that there are 4 major differences when comparing the URLs above Switch from http to https as the API Gateway server enables https The host address and port are switched from original micro service host address and port to a common api gateway service address and 8443 port as the api gateway server will serve as the single point for all the EdgeX services Use the name of the service (in this case \"command\") within the URL to indicate that the request is to be routed to the appropriate EdgeX service (command in this example) Add a JWT as part of the URL as all the REST resources are protected by either OAuth2 or JWT authentication. The JWT can be obtained when a user account is created with the security API Gateway.","title":"Access EdgeX REST resources"},{"location":"microservices/security/Ch-Docker-Swarm-SecuringDeviceServices/","text":"Security for EdgeX Stack This page shows how to secure communication between core EdgeX services and various device services by utilizing docker swarm to create an encrypted overlay network between two hosts. We are showcasing two interesting concepts here. 1) Securing the traffic between core and device services 2) Setting up an EdgeX Stack cross platform using docker swarm Docker Swarm Overlay Network Docker's overlay network driver is a software abstraction on top of physical networking hardware to link multiple nodes together in a distributed network. This allows nodes/containers running on the network to communicate securely, if encryption is in enabled. Overlay network encryption is not supported on Windows. We created two docker swarm nodes for this example a manager node and a worker node. The manager node is running all of the core EdgeX services and the worker node runs the device services. Using the docker daemon's overlay network abstraction and enabling security we can have secure communication between these nodes. Reference implementation example The reference implementation example can be found in this repository: Reference example device-service docker-swarm overlay network Setup remote running Virtual Machine In this example setup, similar to the the SSH example , vagrant is used on the top of Virtual Box to set up the secondary/remote VM. Download vagrant from Hashicorp website or if you're on Ubuntu via sudo apt install virtualbox and sudo apt install vagrant . We have a simple vagrant file used for this tutorial here This vagrant file sets the hostname for the new VM and installs docker. Getting the VM running Launch the worker node or VM if it is not yet running: This will create the VM select your network interface and let the prompt continue. Once the prompt finishes, ignore the VMs popup window, we will be login in via SSH in the next step. vagrant up ssh into the worker node via from your host's terminal: vagrant ssh This will give you a terminal prompt in the worker node where you will run the sudo docker swarm join command in a few steps. Connecting the swarm nodes With the VM up and running we need to connect the two nodes using docker swarm. The following command initializes a docker swarm and is to be ran on the host machine: sudo docker swarm init --advertise-addr <your host ip address> The previous command will output a token use this token in the following join command. This joins the worker node to the cluster, to be ran your vagrant VM (worker-node): sudo docker swarm join --token <token> <manager ip address>:2377 Next, I will walk-through the changes we made to the docker-stack.yml file to convert the edgex compose file into a docker swarm stack file. Setting up the docker-stack-edgex.yml file All of the following changes are already done in the examples repo. I will just outline the necessary changes to go from a compose file to stack file. First, remove 'restart' command from compose file; 'restart' is not a valid command in docker swarm. Next, we define constraints that the edgex core services must not run on the worker node add this section of yml to the 'docker-stack-edgex.yml'. We will do the inverse for the device-service to ensure it does run on the worker node thus ensuring it uses the overlay network to communicate with the other services. Note that this is already done in the example directory. deploy : placement : constraints : - node.hostname != worker-node Here is the inverse of the previous yml block. This gets added to the device services in the stack file. deploy : placement : constraints : - node.hostname == worker-node These work because we set the 'hostname = worker-node' in the Vagrantfile. Adding Host Mounted Volumes In docker swarm bind mount volumes need to be explicitly defined in the stack yml file. Below are the first three bind mount volume definitions these directories must be created on the host before the stack file can be ran. Note that this is only an example. In a production deployment you would want to use a network filesystem or create the shared volumes between containers. secrets-volume : driver : local driver_opts : o : bind type : none device : /tmp/edgex/secrets/ secrets-ca-volume : driver : local driver_opts : o : bind type : none device : /tmp/edgex/secrets/ca/ edgex-consul : driver : local driver_opts : o : bind type : none device : /tmp/edgex/secrets/edgex-consul/ ... The full docker-stack file is included here: docker-stack-edgex.yml file Other changes in docker-stack-edgex.yml file Another change we had to make in the docker-stack-edgex.yml file is to disable IPC_LOCK because the cap_add flag in vault's configuration is not supported in docker swarm. To do this we add SKIP_SETCAP=true and disable_mlock = \"true\" to vault in the stack file. vault : image : vault:1.3.1 hostname : edgex-vault networks : edgex-network : aliases : - edgex-vault ports : - target : 8200 published : 8200 protocol : tcp mode : host # cap_add not allowed in docker swarm, this is a security issue and I don't recommend disabling this in production # cap_add: # - \"IPC_LOCK\" tmpfs : - /vault/config entrypoint : [ \"/vault/init/start_vault.sh\" ] environment : - VAULT_ADDR=https://edgex-vault:8200 - VAULT_CONFIG_DIR=/vault/config - VAULT_UI=true - SKIP_SETCAP=true - | VAULT_LOCAL_CONFIG= listener \"tcp\" { address = \"edgex-vault:8200\" tls_disable = \"0\" cluster_address = \"edgex-vault:8201\" tls_min_version = \"tls12\" tls_client_ca_file =\"/tmp/edgex/secrets/edgex-vault/ca.pem\" tls_cert_file =\"/tmp/edgex/secrets/edgex-vault/server.crt\" tls_key_file = \"/tmp/edgex/secrets/edgex-vault/server.key\" tls_perfer_server_cipher_suites = \"true\" } backend \"consul\" { path = \"vault/\" address = \"edgex-core-consul:8500\" scheme = \"http\" redirect_addr = \"https://edgex-vault:8200\" cluster_addr = \"https://edgex-vault:8201\" } default_lease_ttl = \"168h\" max_lease_ttl = \"720h\" disable_mlock = \"true\" volumes : - vault-file:/vault/file:z - vault-logs:/vault/logs:z - vault-init:/vault/init:ro,z - edgex-vault:/tmp/edgex/secrets/edgex-vault:ro,z depends_on : - consul - security-secrets-setup deploy : endpoint_mode : dnsrr placement : constraints : - node.hostname != worker-node Another change we had to make is to set the restart policy for one-shot initialization containers like kong-migrations and edgex-proxy. Simply add this section of yaml to the services you'd like to only run once and they wont be restarted unless a failure condition happens. restart_policy: condition: on-failure The next and final change in the stack yml file is to ensure the EdgeX services are binding to the correct host. In Geneva we do this by adding a common variable Service_ServerBindAddr: \"0.0.0.0\" to ensure that the service will bind to any host and not be limited to the hostname. Running the docker stack file With all of these changes in place we are ready to run the stack file. We included a script to run the stack file and create the volumes needed in the stack file. This script simply creates the volumes directories and runs the docker stack deploy ... command. sudo ./run.sh Once the stack is up you can run the following command to view the running services: sudo docker stack services edgex-overlay Confirming results To ensure the device service is running on the worker node you can run the docker stack ps edgex-overlay command. Now check that you see the device service running on the worker-node while all of the other services are running on your host. We have encryption enabled but how to we confirm that the overlay network is encrypting our data? We can use tcpdum with a protocol filter for ESP (Encapsulating Security Payload) traffic on the worker node this allows us to sniff and ensure the traffic is coming over the expected encrypted protocol. Adding a -A flag would also highlight that the data is not in the HTTP protocol format. sudo tcpdump -p esp Tearing everything down To remove the stack run the command: sudo ./down.sh This will remove the volumes and the stack. To remove the swarm itself run: on the worker node docker swarm leave and on the host machine docker swarm leave --force . To remove the vagrant VM run vagrant destroy on the host.","title":"Security for EdgeX Stack"},{"location":"microservices/security/Ch-Docker-Swarm-SecuringDeviceServices/#security-for-edgex-stack","text":"This page shows how to secure communication between core EdgeX services and various device services by utilizing docker swarm to create an encrypted overlay network between two hosts. We are showcasing two interesting concepts here. 1) Securing the traffic between core and device services 2) Setting up an EdgeX Stack cross platform using docker swarm","title":"Security for EdgeX Stack"},{"location":"microservices/security/Ch-Docker-Swarm-SecuringDeviceServices/#docker-swarm-overlay-network","text":"Docker's overlay network driver is a software abstraction on top of physical networking hardware to link multiple nodes together in a distributed network. This allows nodes/containers running on the network to communicate securely, if encryption is in enabled. Overlay network encryption is not supported on Windows. We created two docker swarm nodes for this example a manager node and a worker node. The manager node is running all of the core EdgeX services and the worker node runs the device services. Using the docker daemon's overlay network abstraction and enabling security we can have secure communication between these nodes.","title":"Docker Swarm Overlay Network"},{"location":"microservices/security/Ch-Docker-Swarm-SecuringDeviceServices/#reference-implementation-example","text":"The reference implementation example can be found in this repository: Reference example device-service docker-swarm overlay network","title":"Reference implementation example"},{"location":"microservices/security/Ch-Docker-Swarm-SecuringDeviceServices/#setup-remote-running-virtual-machine","text":"In this example setup, similar to the the SSH example , vagrant is used on the top of Virtual Box to set up the secondary/remote VM. Download vagrant from Hashicorp website or if you're on Ubuntu via sudo apt install virtualbox and sudo apt install vagrant . We have a simple vagrant file used for this tutorial here This vagrant file sets the hostname for the new VM and installs docker.","title":"Setup remote running Virtual Machine"},{"location":"microservices/security/Ch-Docker-Swarm-SecuringDeviceServices/#getting-the-vm-running","text":"Launch the worker node or VM if it is not yet running: This will create the VM select your network interface and let the prompt continue. Once the prompt finishes, ignore the VMs popup window, we will be login in via SSH in the next step. vagrant up ssh into the worker node via from your host's terminal: vagrant ssh This will give you a terminal prompt in the worker node where you will run the sudo docker swarm join command in a few steps.","title":"Getting the VM running"},{"location":"microservices/security/Ch-Docker-Swarm-SecuringDeviceServices/#connecting-the-swarm-nodes","text":"With the VM up and running we need to connect the two nodes using docker swarm. The following command initializes a docker swarm and is to be ran on the host machine: sudo docker swarm init --advertise-addr <your host ip address> The previous command will output a token use this token in the following join command. This joins the worker node to the cluster, to be ran your vagrant VM (worker-node): sudo docker swarm join --token <token> <manager ip address>:2377 Next, I will walk-through the changes we made to the docker-stack.yml file to convert the edgex compose file into a docker swarm stack file.","title":"Connecting the swarm nodes"},{"location":"microservices/security/Ch-Docker-Swarm-SecuringDeviceServices/#setting-up-the-docker-stack-edgexyml-file","text":"All of the following changes are already done in the examples repo. I will just outline the necessary changes to go from a compose file to stack file. First, remove 'restart' command from compose file; 'restart' is not a valid command in docker swarm. Next, we define constraints that the edgex core services must not run on the worker node add this section of yml to the 'docker-stack-edgex.yml'. We will do the inverse for the device-service to ensure it does run on the worker node thus ensuring it uses the overlay network to communicate with the other services. Note that this is already done in the example directory. deploy : placement : constraints : - node.hostname != worker-node Here is the inverse of the previous yml block. This gets added to the device services in the stack file. deploy : placement : constraints : - node.hostname == worker-node These work because we set the 'hostname = worker-node' in the Vagrantfile.","title":"Setting up the docker-stack-edgex.yml file"},{"location":"microservices/security/Ch-Docker-Swarm-SecuringDeviceServices/#adding-host-mounted-volumes","text":"In docker swarm bind mount volumes need to be explicitly defined in the stack yml file. Below are the first three bind mount volume definitions these directories must be created on the host before the stack file can be ran. Note that this is only an example. In a production deployment you would want to use a network filesystem or create the shared volumes between containers. secrets-volume : driver : local driver_opts : o : bind type : none device : /tmp/edgex/secrets/ secrets-ca-volume : driver : local driver_opts : o : bind type : none device : /tmp/edgex/secrets/ca/ edgex-consul : driver : local driver_opts : o : bind type : none device : /tmp/edgex/secrets/edgex-consul/ ... The full docker-stack file is included here: docker-stack-edgex.yml file","title":"Adding Host Mounted Volumes"},{"location":"microservices/security/Ch-Docker-Swarm-SecuringDeviceServices/#other-changes-in-docker-stack-edgexyml-file","text":"Another change we had to make in the docker-stack-edgex.yml file is to disable IPC_LOCK because the cap_add flag in vault's configuration is not supported in docker swarm. To do this we add SKIP_SETCAP=true and disable_mlock = \"true\" to vault in the stack file. vault : image : vault:1.3.1 hostname : edgex-vault networks : edgex-network : aliases : - edgex-vault ports : - target : 8200 published : 8200 protocol : tcp mode : host # cap_add not allowed in docker swarm, this is a security issue and I don't recommend disabling this in production # cap_add: # - \"IPC_LOCK\" tmpfs : - /vault/config entrypoint : [ \"/vault/init/start_vault.sh\" ] environment : - VAULT_ADDR=https://edgex-vault:8200 - VAULT_CONFIG_DIR=/vault/config - VAULT_UI=true - SKIP_SETCAP=true - | VAULT_LOCAL_CONFIG= listener \"tcp\" { address = \"edgex-vault:8200\" tls_disable = \"0\" cluster_address = \"edgex-vault:8201\" tls_min_version = \"tls12\" tls_client_ca_file =\"/tmp/edgex/secrets/edgex-vault/ca.pem\" tls_cert_file =\"/tmp/edgex/secrets/edgex-vault/server.crt\" tls_key_file = \"/tmp/edgex/secrets/edgex-vault/server.key\" tls_perfer_server_cipher_suites = \"true\" } backend \"consul\" { path = \"vault/\" address = \"edgex-core-consul:8500\" scheme = \"http\" redirect_addr = \"https://edgex-vault:8200\" cluster_addr = \"https://edgex-vault:8201\" } default_lease_ttl = \"168h\" max_lease_ttl = \"720h\" disable_mlock = \"true\" volumes : - vault-file:/vault/file:z - vault-logs:/vault/logs:z - vault-init:/vault/init:ro,z - edgex-vault:/tmp/edgex/secrets/edgex-vault:ro,z depends_on : - consul - security-secrets-setup deploy : endpoint_mode : dnsrr placement : constraints : - node.hostname != worker-node Another change we had to make is to set the restart policy for one-shot initialization containers like kong-migrations and edgex-proxy. Simply add this section of yaml to the services you'd like to only run once and they wont be restarted unless a failure condition happens. restart_policy: condition: on-failure The next and final change in the stack yml file is to ensure the EdgeX services are binding to the correct host. In Geneva we do this by adding a common variable Service_ServerBindAddr: \"0.0.0.0\" to ensure that the service will bind to any host and not be limited to the hostname.","title":"Other changes in docker-stack-edgex.yml file"},{"location":"microservices/security/Ch-Docker-Swarm-SecuringDeviceServices/#running-the-docker-stack-file","text":"With all of these changes in place we are ready to run the stack file. We included a script to run the stack file and create the volumes needed in the stack file. This script simply creates the volumes directories and runs the docker stack deploy ... command. sudo ./run.sh Once the stack is up you can run the following command to view the running services: sudo docker stack services edgex-overlay","title":"Running the docker stack file"},{"location":"microservices/security/Ch-Docker-Swarm-SecuringDeviceServices/#confirming-results","text":"To ensure the device service is running on the worker node you can run the docker stack ps edgex-overlay command. Now check that you see the device service running on the worker-node while all of the other services are running on your host. We have encryption enabled but how to we confirm that the overlay network is encrypting our data? We can use tcpdum with a protocol filter for ESP (Encapsulating Security Payload) traffic on the worker node this allows us to sniff and ensure the traffic is coming over the expected encrypted protocol. Adding a -A flag would also highlight that the data is not in the HTTP protocol format. sudo tcpdump -p esp","title":"Confirming results"},{"location":"microservices/security/Ch-Docker-Swarm-SecuringDeviceServices/#tearing-everything-down","text":"To remove the stack run the command: sudo ./down.sh This will remove the volumes and the stack. To remove the swarm itself run: on the worker node docker swarm leave and on the host machine docker swarm leave --force . To remove the vagrant VM run vagrant destroy on the host.","title":"Tearing everything down"},{"location":"microservices/security/Ch-SSH-Tunneling-HowToSecureDeviceServices/","text":"Security for EdgeX Stack This page describes one of many options to secure the EdgeX software stack with running remote device services like device-virtual, device-rest, device-mqtt, and so on, via secure two-way SSH-tunnelings. Basic SSH-Tunneling In this option to secure the EdgeX software stack, SSH tunneling is utilized. The basic idea is to create a secure SSH connection between a local machine and a remote machine in which some micro-services or applications can be relayed. In this particular example, the local machine as the primary host is running the whole EdgeX core services including core services and security services but without any device service. The device services are running in the remote machine. The communication is secure because SSH port forwarding connection is encrypted by default. The SSH communication is established by introducing some extra SSH-related services: 1) device-ssh-proxy : this is the service with ssh client opening up the SSH communication between the local machine and the remote one 2) device-ssh-remote : this is actually the SSH server or daemon service together with device services running on the remote machine The high-level diagram is shown as follows: \"Top level diagram for SSH tunneling for device services\" In the local machine, the SSH tunneling handshake is initiated by device-ssh-proxy service to the remote running device services. The dependencies that remote device services needed are reversely tunneling back from the local machine. Reference implementation example The whole reference implementation example can be found in this repository: Reference example in holding repo for device service SSH tunneling Setup remote running Virtual Machine In the example setup, vagrant is used on the top of Virtual Box to set up as the secondary/remote VM. The network port for ssh standard port 22 is mapped into 2222 for vagrant ssh itself and the forwarded port is also mapped on the VM network for port 2223 to the host machine port 2223. This port 2223 is used for the ssh daemon Docker container that will be introduced later on below. Once you have downloaded the vagrant from Hashicorp website, typical vagrant setup for the first time can be done via command ./vagrant init and it will generate the Vagrant configuration file. Here is the Vagrant file used to create the remote machine: remote VM Vagrant file with docker and docker-compose installed SSH Tunneling: Setup the SSH server on the remote machine For an example of how to run a SSH server in Docker, checkout https://docs.docker.com/engine/examples/running_ssh_service/ for detailed instructions. Note that this one is the ssh server and it is set up using password authentication by default. In order to authenticate to this ssh server without password prompt, we injected the generated public SSH key from the local machine via simple login into the ssh server machine first and then created the authorized_keys under ~/.ssh directory. In general, the following command example shows how this is accomplished: root@sshd-remote: mkdir -p ~/.ssh root@sshd-remote: chmod 700 ~/.ssh root@sshd-remote: echo \"ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDKvsFf5HocBOBWXdVJKfQzkhf0K8lSLjZn9PX84VdhHyP8n1mzfpZywA4vsz8+A3OsGHAr2xpkyzOS0YkwD7nrI3q1x0A0+ANhQNOaKbnfQRe... root\" >> ~/.ssh/authorized_keys The ssh key pairs can be generated using ssh-keygen command from the local machine and the contents of ssh public key usually is stored as ~/.ssh/id_rsa.pub file like this: ssh-keygen -q -t rsa -C root -N '' -f ~/.ssh/id_rsa 2 >/dev/null An example of a build script to inject the SSH public key into the sshd server can be found as the following here . SSH Tunneling: Local Port Forwarding This step is to show how to connect from the local machine to the remote machine. The -L flag of ssh command is important here. ssh -vv -o StrictHostKeyChecking = no \\ -o UserKnownHostsFile = /dev/null \\ -N $TUNNEL_HOST \\ -L *: $SERVICE_PORT : $SERVICE_HOST : $SERVICE_PORT \\ -p $TUNNEL_SSH_PROT where environment variables are: TUNNEL_HOST is the remote host name or IP address that SSH daemon or server is running on; TUNNEL_SSH_PROT is the port number to be used on the SSH tunnel communication between the local machine and the remote machine SERVICE_PORT is the port number from the local or the primary to be forwared to the remote machine; without lose of generality, the port number on the remote machine is the same as the local one SERVICE_HOST is the service host name or IP address of the Docker containers that are running on the remote machine; SSH Reverse Tunneling: Remote Port Forwarding This step is to show the reverse direction of SSH tunneling: from the remote back to the local machine. The reverse SSH tunneling is also needed because the device services depends on the core services like coreData , metaData , and coreConsul . These core services are running on the local machine and should be reverse tunneling back to the device services on the remote side through the SSH remote port forwarding connection. This can be achieved by using -R flag of ssh command. ssh -vv -o StrictHostKeyChecking = no \\ -o UserKnownHostsFile = /dev/null \\ -N $TUNNEL_HOST \\ -R 0 .0.0.0:48080:edgex-core-data:48080 \\ -R 0 .0.0.0:5563:edgex-core-data:5563 \\ -R 0 .0.0.0:48081:edgex-core-metadata:48081 \\ -R 0 .0.0.0:8500:edgex-core-consul:8500 \\ -p $TUNNEL_SSH_PROT where environment variables are: TUNNEL_HOST is the remote host name or IP address that SSH daemon or server is running on; In the reverse tunneling, the service host names of dependent services are used like edgex-core-data , for example. Put it all together Launch the remote machine or VM if it is not yet: ~/vm/vagrant up and ssh into the remote machine via ~/vm/vagrant ssh In the local machine, generate ssh key pairs using ssh-keygen : ssh-keygen -q -t rsa -C root -N '' -f ~/.ssh/id_rsa 2 >/dev/null This produces two files under directory ~/.ssh: one for private key (id_rsa) and one for public key (id_rsa.pub) Make docker build with ssh-device-proxy Dockerfile and entrypoint.sh : local device service proxy Dockerfile Docker entrypoint shell script for local device service proxy and build it with the following command: docker build -f Dockerfile-primary-ds-proxy --build-arg SSH_PORT = 2223 -t device-ssh-proxy:test . Make docker build the remote sshd server / daemon image with Dockerfile: remote sshd Dockerfile to build: docker build -t eg_sshd . Run the remote EdgeX device services with the following docker-compose file: docker-compose file for remote device services with SSH server/daemon Note that the following ssh server service is added in the docker-compose file: ################################################################ # SSH Daemon ################################################################ sshd-remote : image : eg_sshd ports : - \"2223:22\" container_name : edgex-sshd-remote hostname : edgex-sshd-remote networks : edgex-network : aliases : - edgex-core-consul - edgex-core-data - edgex-core-metadata In the local machine, include device-ssh-proxy:test ssh proxy docker image together with EdgeX core services in the docker-compose file like this: ########################################################## # ssh tunneling proxy service for device-virtual ########################################################## device-ssh-proxy : image : device-ssh-proxy:test container_name : edgex-device-ssh-proxy hostname : edgex-device-ssh-proxy volumes : - $HOME/.ssh:/root/ssh:ro ports : - \"49990:49990\" networks : edgex-network : aliases : - edgex-device-virtual environment : TUNNEL_HOST : 192.168.1.190 TUNNEL_SSH_PORT : 2223 SERVICE_HOST : edgex-device-virtual SERVICE_PORT : 49990 The full docker-compose file is included here: docker-compose file for the local core services and ssh tunneling proxy service without any device services Note that: The values of environment variables depend on your environment settings of the local machine and the remote machine. In this particular case, we are ssh tunneling to the remote device-virtual service. The docker-compose file in the local machine does not include any device services at all. This is to ensure that we are actually using the device services in the remote machine. Test with the device-virtual APIs mainly run curl or postman directly from the local machine to the device-virtual APIs to verify the remote device virtual service can be accessible from the local host machine via two-way SSH tunneling. This can be checked from the console of the local machine: the ping response of calling edgex-device-virtual's ping action: jim@jim-NUC7i5DNHE:~/go/src/github.com/edgexfoundry/developer-scripts/releases/geneva/compose-files$ curl http://localhost:49990/api/v1/ping 1 .2.0-dev.13j or see the configuration of it via curl command: jim@jim-NUC7i5DNHE:~/go/src/github.com/edgexfoundry/developer-scripts/releases/geneva/compose-files$ curl http://localhost:49990/api/v1/config { \"Writable\" :{ \"LogLevel\" : \"INFO\" }, \"Clients\" :{ \"Data\" :{ \"Host\" : \"localhost\" , \"Port\" : 48080 , \"Protocol\" : \"http\" }, \"Logging\" :{ \"Host\" : \"localhost\" , \"Port\" : 48061 , \"Protocol\" : \"http\" }, \"Metadata\" :{ \"Host\" : \"edgex-core-metadata\" , \"Port\" : 48081 , \"Protocol\" : \"http\" }}, \"Logging\" :{ \"EnableRemote\" : false , \"File\" : \"\" }, \"Registry\" :{ \"Host\" : \"edgex-core-consul\" , \"Port\" : 8500 , \"Type\" : \"consul\" }, \"Service\" :{ \"BootTimeout\" : 30000 , \"CheckInterval\" : \"10s\" , \"ClientMonitor\" : 15000 , \"Host\" : \"edgex-device-virtual\" , \"Port\" : 49990 , \"Protocol\" : \"http\" , \"StartupMsg\" : \"device virtual started\" , \"MaxResultCount\" : 0 , \"Timeout\" : 5000 , \"ConnectRetries\" : 10 , \"Labels\" :[], \"EnableAsyncReadings\" : true , \"AsyncBufferSize\" : 16 }, \"Device\" :{ \"DataTransform\" : true , \"InitCmd\" : \"\" , \"InitCmdArgs\" : \"\" , \"MaxCmdOps\" : 128 , \"MaxCmdValueLen\" : 256 , \"RemoveCmd\" : \"\" , \"RemoveCmdArgs\" : \"\" , \"ProfilesDir\" : \"./res\" , \"UpdateLastConnected\" : false , \"Discovery\" :{ \"Enabled\" : false , \"Interval\" : \"\" }}, \"DeviceList\" :[{ \"Name\" : \"Random-Boolean-Device\" , \"Profile\" : \"Random-Boolean-Device\" , \"Description\" : \"Example of Device Virtual\" , \"Labels\" :[ \"device-virtual-example\" ], \"Protocols\" :{ \"other\" :{ \"Address\" : \"device-virtual-bool-01\" , \"Port\" : \"300\" }}, \"AutoEvents\" :[{ \"frequency\" : \"10s\" , \"resource\" : \"Bool\" }]},{ \"Name\" : \"Random-Integer-Device\" , \"Profile\" : \"Random-Integer-Device\" , \"Description\" : \"Example of Device Virtual\" , \"Labels\" :[ \"device-virtual-example\" ], \"Protocols\" :{ \"other\" :{ \"Address\" : \"device-virtual-int-01\" , \"Protocol\" : \"300\" }}, \"AutoEvents\" :[{ \"frequency\" : \"15s\" , \"resource\" : \"Int8\" },{ \"frequency\" : \"15s\" , \"resource\" : \"Int16\" },{ \"frequency\" : \"15s\" , \"resource\" : \"Int32\" },{ \"frequency\" : \"15s\" , \"resource\" : \"Int64\" }]},{ \"Name\" : \"Random-UnsignedInteger-Device\" , \"Profile\" : \"Random-UnsignedInteger-Device\" , \"Description\" : \"Example of Device Virtual\" , \"Labels\" :[ \"device-virtual-example\" ], \"Protocols\" :{ \"other\" :{ \"Address\" : \"device-virtual-uint-01\" , \"Protocol\" : \"300\" }}, \"AutoEvents\" :[{ \"frequency\" : \"20s\" , \"resource\" : \"Uint8\" },{ \"frequency\" : \"20s\" , \"resource\" : \"Uint16\" },{ \"frequency\" : \"20s\" , \"resource\" : \"Uint32\" },{ \"frequency\" : \"20s\" , \"resource\" : \"Uint64\" }]},{ \"Name\" : \"Random-Float-Device\" , \"Profile\" : \"Random-Float-Device\" , \"Description\" : \"Example of Device Virtual\" , \"Labels\" :[ \"device-virtual-example\" ], \"Protocols\" :{ \"other\" :{ \"Address\" : \"device-virtual-float-01\" , \"Protocol\" : \"300\" }}, \"AutoEvents\" :[{ \"frequency\" : \"30s\" , \"resource\" : \"Float32\" },{ \"frequency\" : \"30s\" , \"resource\" : \"Float64\" }]},{ \"Name\" : \"Random-Binary-Device\" , \"Profile\" : \"Random-Binary-Device\" , \"Description\" : \"Example of Device Virtual\" , \"Labels\" :[ \"device-virtual-example\" ], \"Protocols\" :{ \"other\" :{ \"Address\" : \"device-virtual-bool-01\" , \"Port\" : \"300\" }}, \"AutoEvents\" : null }], \"Driver\" :{}} one can also monitor the docker log messages of core-data on the local machine too see if it publishes the events to the bus: $ docker logs -f edgex-core-data level = INFO ts = 2020 -06-10T00:49:26.579819548Z app = edgex-core-data source = event.go:284 msg = \"Putting event on message queue\" level = INFO ts = 2020 -06-10T00:49:26.579909649Z app = edgex-core-data source = event.go:302 msg = \"Event Published on message queue. Topic: events, Correlation-id: 4dc57d03-178e-49f5-a799-67813db9d85b \" level = INFO ts = 2020 -06-10T00:49:27.107028244Z app = edgex-core-data source = event.go:284 msg = \"Putting event on message queue\" level = INFO ts = 2020 -06-10T00:49:27.107128916Z app = edgex-core-data source = event.go:302 msg = \"Event Published on message queue. Topic: events, Correlation-id: 2a0fd8fa-bb16-4d1a-ba1b-c5e70e1a1cec \" level = INFO ts = 2020 -06-10T00:49:27.376915392Z app = edgex-core-data source = event.go:284 msg = \"Putting event on message queue\" level = INFO ts = 2020 -06-10T00:49:27.377084206Z app = edgex-core-data source = event.go:302 msg = \"Event Published on message queue. Topic: events, Correlation-id: 76d288e2-a2e8-4ed4-9265-986661b71bbe \" level = INFO ts = 2020 -06-10T00:49:27.718042678Z app = edgex-core-data source = event.go:284 msg = \"Putting event on message queue\" level = INFO ts = 2020 -06-10T00:49:27.718125128Z app = edgex-core-data source = event.go:302 msg = \"Event Published on message queue. Topic: events, Correlation-id: f5412a38-0346-4bd3-b9da-69498e4edb9a \" level = INFO ts = 2020 -06-10T00:49:30.49407257Z app = edgex-core-data source = event.go:284 msg = \"Putting event on message queue\" level = INFO ts = 2020 -06-10T00:49:30.494162219Z app = edgex-core-data source = event.go:302 msg = \"Event Published on message queue. Topic: events, Correlation-id: da54fcc9-4771-4e0f-9eff-e0d2067eac7e \" level = INFO ts = 2020 -06-10T00:49:31.204976003Z app = edgex-core-data source = event.go:284 msg = \"Putting event on message queue\" level = INFO ts = 2020 -06-10T00:49:31.205211102Z app = edgex-core-data source = event.go:302 msg = \"Event Published on message queue. Topic: events, Correlation-id: 08574f61-6ea3-49cf-a776-028876de7957 \" level = INFO ts = 2020 -06-10T00:49:31.778242016Z app = edgex-core-data source = event.go:284 msg = \"Putting event on message queue\" level = INFO ts = 2020 -06-10T00:49:31.778342992Z app = edgex-core-data source = event.go:302 msg = \"Event Published on message queue. Topic: events, Correlation-id: f1630f13-6fa7-45a6-b6f6-6bbde159b414 \" level = INFO ts = 2020 -06-10T00:49:34.747901983Z app = edgex-core-data source = event.go:284 msg = \"Putting event on message queue\" level = INFO ts = 2020 -06-10T00:49:34.748045382Z app = edgex-core-data source = event.go:302 msg = \"Event Published on message queue. Topic: events, Correlation-id: cf14c573-60b9-43cd-b95b-2c6ffe26ba20 \" level = INFO ts = 2020 -06-10T00:49:34.944758331Z app = edgex-core-data source = event.go:284 msg = \"Putting event on message queue\" level = INFO ts = 2020 -06-10T00:49:34.9449585Z app = edgex-core-data source = event.go:302 msg = \"Event Published on message queue. Topic: events, Correlation-id: 292b9ca7-a640-4ac8-8650-866b7c4a6d15 \" level = INFO ts = 2020 -06-10T00:49:37.421202715Z app = edgex-core-data source = event.go:284 msg = \"Putting event on message queue\" level = INFO ts = 2020 -06-10T00:49:37.421367863Z app = edgex-core-data source = event.go:302 msg = \"Event Published on message queue. Topic: events, Correlation-id: bb7a34b1-c65f-4820-91a3-162903ac1e7a \" level = INFO ts = 2020 -06-10T00:49:42.290660694Z app = edgex-core-data source = event.go:284 msg = \"Putting event on message queue\" level = INFO ts = 2020 -06-10T00:49:42.290756356Z app = edgex-core-data source = event.go:302 msg = \"Event Published on message queue. Topic: events, Correlation-id: 8fff92c0-ef69-4758-bf8a-3492fb48cef2 \" level = INFO ts = 2020 -06-10T00:49:42.559019764Z app = edgex-core-data source = event.go:284 msg = \"Putting event on message queue\" level = INFO ts = 2020 -06-10T00:49:42.559105855Z app = edgex-core-data source = event.go:302 msg = \"Event Published on message queue. Topic: events, Correlation-id: 12947a42-4669-4bff-8720-d0e9fbeef343 \" level = INFO ts = 2020 -06-10T00:49:44.922764379Z app = edgex-core-data source = event.go:284 msg = \"Putting event on message queue\" level = INFO ts = 2020 -06-10T00:49:44.922848184Z app = edgex-core-data source = event.go:302 msg = \"Event Published on message queue. Topic: events, Correlation-id: 3c07ce76-203a-4bf5-ab89-b99a1fbbb266 \" and also do the docker log messages of device-virtual container on the remote: vagrant@ubuntu-bionic:~/geneva$ docker logs -f edgex-device-virtual level = INFO ts = 2020 -06-10T00:51:52.602154238Z app = device-virtual source = utils.go:94 Content-Type = application/json correlation-id = 3d86a699-c089-412d-94f3-af6cd9093f28 msg = \"SendEvent: Pushed event to core data\" level = INFO ts = 2020 -06-10T00:51:53.358352349Z app = device-virtual source = utils.go:94 Content-Type = application/json correlation-id = 9612b186-98cb-4dc5-887a-195ce7300978 msg = \"SendEvent: Pushed event to core data\" level = INFO ts = 2020 -06-10T00:51:57.649085447Z app = device-virtual source = utils.go:94 Content-Type = application/json correlation-id = da682ffb-9120-4286-9f33-aa0a9f2c0489 msg = \"SendEvent: Pushed event to core data\" level = INFO ts = 2020 -06-10T00:51:57.86899148Z app = device-virtual source = utils.go:94 Content-Type = application/json correlation-id = afc1fccf-de8a-46ce-9849-82c5e4e5837e msg = \"SendEvent: Pushed event to core data\" level = INFO ts = 2020 -06-10T00:51:59.543754189Z app = device-virtual source = utils.go:94 Content-Type = application/json correlation-id = 80ac32a0-3a9a-4b07-bf3f-b26ec159dc40 msg = \"SendEvent: Pushed event to core data\" level = INFO ts = 2020 -06-10T00:51:59.688746606Z app = device-virtual source = utils.go:94 Content-Type = application/json correlation-id = 21501030 -c07c-4ac4-a2d2-1243782cb4b8 msg = \"SendEvent: Pushed event to core data\" level = INFO ts = 2020 -06-10T00:51:59.853069376Z app = device-virtual source = utils.go:94 Content-Type = application/json correlation-id = 3b2927db-e689-4fad-8d53-af6fe20239f8 msg = \"SendEvent: Pushed event to core data\" level = INFO ts = 2020 -06-10T00:52:00.055657757Z app = device-virtual source = utils.go:94 Content-Type = application/json correlation-id = a7698f2d-a115-4b46-af5f-3b8bf77e6ea4 msg = \"SendEvent: Pushed event to core data\" level = INFO ts = 2020 -06-10T00:52:04.460557145Z app = device-virtual source = utils.go:94 Content-Type = application/json correlation-id = 602efd03-8e9d-441b-9a7d-45dbcb6b416f msg = \"SendEvent: Pushed event to core data\" level = INFO ts = 2020 -06-10T00:52:07.696983268Z app = device-virtual source = utils.go:94 Content-Type = application/json correlation-id = 88190186 -6f93-4c6a-a1f6-d6a20a6e79e4 msg = \"SendEvent: Pushed event to core data\" level = INFO ts = 2020 -06-10T00:52:08.040474761Z app = device-virtual source = utils.go:94 Content-Type = application/json correlation-id = 73c60159-f50c-480b-90da-ebe310fa2f6e msg = \"SendEvent: Pushed event to core data\" level = INFO ts = 2020 -06-10T00:52:08.2091048Z app = device-virtual source = utils.go:94 Content-Type = application/json correlation-id = 2d799509-dc1d-4075-b193-1e5da24cfa77 msg = \"SendEvent: Pushed event to core data\" level = INFO ts = 2020 -06-10T00:52:12.751717832Z app = device-virtual source = utils.go:94 Content-Type = application/json correlation-id = 7611a188-23f4-44d0-bd12-f6574535be8d msg = \"SendEvent: Pushed event to core data\" level = INFO ts = 2020 -06-10T00:52:13.553351482Z app = device-virtual source = utils.go:94 Content-Type = application/json correlation-id = a32067c8-adae-4778-b72d-0d8d7d11220f msg = \"SendEvent: Pushed event to core data\" level = INFO ts = 2020 -06-10T00:52:15.20395683Z app = device-virtual source = utils.go:94 Content-Type = application/json correlation-id = 41df0427-5998-4d1e-9c26-1f727912638b msg = \"SendEvent: Pushed event to core data\" level = INFO ts = 2020 -06-10T00:52:15.686970839Z app = device-virtual source = utils.go:94 Content-Type = application/json correlation-id = c6a8bb2d-22ab-4932-bdd0-138f12f843b6 msg = \"SendEvent: Pushed event to core data\" level = INFO ts = 2020 -06-10T00:52:18.177810023Z app = device-virtual source = utils.go:94 Content-Type = application/json correlation-id = a49d663b-1676-4ecf-ba52-76e9ad7c501d msg = \"SendEvent: Pushed event to core data\" level = INFO ts = 2020 -06-10T00:52:19.600220653Z app = device-virtual source = utils.go:94 Content-Type = application/json correlation-id = b6d2c2d1-5d5c-4f7a-9dd2-2067e732f018 msg = \"SendEvent: Pushed event to core data\" level = INFO ts = 2020 -06-10T00:52:19.990751025Z app = device-virtual source = utils.go:94 Content-Type = application/json correlation-id = 1db5dde3-bb6b-4600-abbb-d01b3042c329 msg = \"SendEvent: Pushed event to core data\" test to get random integer value of the remote device-virtual random integer device from the local machine using curl command like this: jim@jim-NUC7i5DNHE:~/go/src/github.com/edgexfoundry/device-virtual-go$ curl -k http://localhost:49990/api/v1/device/name/Random-Integer-Device/Int8 { \"device\" : \"Random-Integer-Device\" , \"origin\" :1592432603445490720, \"readings\" : [{ \"origin\" :1592432603404127336, \"device\" : \"Random-Integer-Device\" , \"name\" : \"Int8\" , \"value\" : \"11\" , \"valueType\" : \"Int8\" }] , \"EncodedEvent\" :null }","title":"Security for EdgeX Stack"},{"location":"microservices/security/Ch-SSH-Tunneling-HowToSecureDeviceServices/#security-for-edgex-stack","text":"This page describes one of many options to secure the EdgeX software stack with running remote device services like device-virtual, device-rest, device-mqtt, and so on, via secure two-way SSH-tunnelings.","title":"Security for EdgeX Stack"},{"location":"microservices/security/Ch-SSH-Tunneling-HowToSecureDeviceServices/#basic-ssh-tunneling","text":"In this option to secure the EdgeX software stack, SSH tunneling is utilized. The basic idea is to create a secure SSH connection between a local machine and a remote machine in which some micro-services or applications can be relayed. In this particular example, the local machine as the primary host is running the whole EdgeX core services including core services and security services but without any device service. The device services are running in the remote machine. The communication is secure because SSH port forwarding connection is encrypted by default. The SSH communication is established by introducing some extra SSH-related services: 1) device-ssh-proxy : this is the service with ssh client opening up the SSH communication between the local machine and the remote one 2) device-ssh-remote : this is actually the SSH server or daemon service together with device services running on the remote machine The high-level diagram is shown as follows: \"Top level diagram for SSH tunneling for device services\" In the local machine, the SSH tunneling handshake is initiated by device-ssh-proxy service to the remote running device services. The dependencies that remote device services needed are reversely tunneling back from the local machine.","title":"Basic SSH-Tunneling"},{"location":"microservices/security/Ch-SSH-Tunneling-HowToSecureDeviceServices/#reference-implementation-example","text":"The whole reference implementation example can be found in this repository: Reference example in holding repo for device service SSH tunneling","title":"Reference implementation example"},{"location":"microservices/security/Ch-SSH-Tunneling-HowToSecureDeviceServices/#setup-remote-running-virtual-machine","text":"In the example setup, vagrant is used on the top of Virtual Box to set up as the secondary/remote VM. The network port for ssh standard port 22 is mapped into 2222 for vagrant ssh itself and the forwarded port is also mapped on the VM network for port 2223 to the host machine port 2223. This port 2223 is used for the ssh daemon Docker container that will be introduced later on below. Once you have downloaded the vagrant from Hashicorp website, typical vagrant setup for the first time can be done via command ./vagrant init and it will generate the Vagrant configuration file. Here is the Vagrant file used to create the remote machine: remote VM Vagrant file with docker and docker-compose installed","title":"Setup remote running Virtual Machine"},{"location":"microservices/security/Ch-SSH-Tunneling-HowToSecureDeviceServices/#ssh-tunneling-setup-the-ssh-server-on-the-remote-machine","text":"For an example of how to run a SSH server in Docker, checkout https://docs.docker.com/engine/examples/running_ssh_service/ for detailed instructions. Note that this one is the ssh server and it is set up using password authentication by default. In order to authenticate to this ssh server without password prompt, we injected the generated public SSH key from the local machine via simple login into the ssh server machine first and then created the authorized_keys under ~/.ssh directory. In general, the following command example shows how this is accomplished: root@sshd-remote: mkdir -p ~/.ssh root@sshd-remote: chmod 700 ~/.ssh root@sshd-remote: echo \"ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDKvsFf5HocBOBWXdVJKfQzkhf0K8lSLjZn9PX84VdhHyP8n1mzfpZywA4vsz8+A3OsGHAr2xpkyzOS0YkwD7nrI3q1x0A0+ANhQNOaKbnfQRe... root\" >> ~/.ssh/authorized_keys The ssh key pairs can be generated using ssh-keygen command from the local machine and the contents of ssh public key usually is stored as ~/.ssh/id_rsa.pub file like this: ssh-keygen -q -t rsa -C root -N '' -f ~/.ssh/id_rsa 2 >/dev/null An example of a build script to inject the SSH public key into the sshd server can be found as the following here .","title":"SSH Tunneling: Setup the SSH server on the remote machine"},{"location":"microservices/security/Ch-SSH-Tunneling-HowToSecureDeviceServices/#ssh-tunneling-local-port-forwarding","text":"This step is to show how to connect from the local machine to the remote machine. The -L flag of ssh command is important here. ssh -vv -o StrictHostKeyChecking = no \\ -o UserKnownHostsFile = /dev/null \\ -N $TUNNEL_HOST \\ -L *: $SERVICE_PORT : $SERVICE_HOST : $SERVICE_PORT \\ -p $TUNNEL_SSH_PROT where environment variables are: TUNNEL_HOST is the remote host name or IP address that SSH daemon or server is running on; TUNNEL_SSH_PROT is the port number to be used on the SSH tunnel communication between the local machine and the remote machine SERVICE_PORT is the port number from the local or the primary to be forwared to the remote machine; without lose of generality, the port number on the remote machine is the same as the local one SERVICE_HOST is the service host name or IP address of the Docker containers that are running on the remote machine;","title":"SSH Tunneling: Local Port Forwarding"},{"location":"microservices/security/Ch-SSH-Tunneling-HowToSecureDeviceServices/#ssh-reverse-tunneling-remote-port-forwarding","text":"This step is to show the reverse direction of SSH tunneling: from the remote back to the local machine. The reverse SSH tunneling is also needed because the device services depends on the core services like coreData , metaData , and coreConsul . These core services are running on the local machine and should be reverse tunneling back to the device services on the remote side through the SSH remote port forwarding connection. This can be achieved by using -R flag of ssh command. ssh -vv -o StrictHostKeyChecking = no \\ -o UserKnownHostsFile = /dev/null \\ -N $TUNNEL_HOST \\ -R 0 .0.0.0:48080:edgex-core-data:48080 \\ -R 0 .0.0.0:5563:edgex-core-data:5563 \\ -R 0 .0.0.0:48081:edgex-core-metadata:48081 \\ -R 0 .0.0.0:8500:edgex-core-consul:8500 \\ -p $TUNNEL_SSH_PROT where environment variables are: TUNNEL_HOST is the remote host name or IP address that SSH daemon or server is running on; In the reverse tunneling, the service host names of dependent services are used like edgex-core-data , for example.","title":"SSH Reverse Tunneling: Remote Port Forwarding"},{"location":"microservices/security/Ch-SSH-Tunneling-HowToSecureDeviceServices/#put-it-all-together","text":"Launch the remote machine or VM if it is not yet: ~/vm/vagrant up and ssh into the remote machine via ~/vm/vagrant ssh In the local machine, generate ssh key pairs using ssh-keygen : ssh-keygen -q -t rsa -C root -N '' -f ~/.ssh/id_rsa 2 >/dev/null This produces two files under directory ~/.ssh: one for private key (id_rsa) and one for public key (id_rsa.pub) Make docker build with ssh-device-proxy Dockerfile and entrypoint.sh : local device service proxy Dockerfile Docker entrypoint shell script for local device service proxy and build it with the following command: docker build -f Dockerfile-primary-ds-proxy --build-arg SSH_PORT = 2223 -t device-ssh-proxy:test . Make docker build the remote sshd server / daemon image with Dockerfile: remote sshd Dockerfile to build: docker build -t eg_sshd . Run the remote EdgeX device services with the following docker-compose file: docker-compose file for remote device services with SSH server/daemon Note that the following ssh server service is added in the docker-compose file: ################################################################ # SSH Daemon ################################################################ sshd-remote : image : eg_sshd ports : - \"2223:22\" container_name : edgex-sshd-remote hostname : edgex-sshd-remote networks : edgex-network : aliases : - edgex-core-consul - edgex-core-data - edgex-core-metadata In the local machine, include device-ssh-proxy:test ssh proxy docker image together with EdgeX core services in the docker-compose file like this: ########################################################## # ssh tunneling proxy service for device-virtual ########################################################## device-ssh-proxy : image : device-ssh-proxy:test container_name : edgex-device-ssh-proxy hostname : edgex-device-ssh-proxy volumes : - $HOME/.ssh:/root/ssh:ro ports : - \"49990:49990\" networks : edgex-network : aliases : - edgex-device-virtual environment : TUNNEL_HOST : 192.168.1.190 TUNNEL_SSH_PORT : 2223 SERVICE_HOST : edgex-device-virtual SERVICE_PORT : 49990 The full docker-compose file is included here: docker-compose file for the local core services and ssh tunneling proxy service without any device services Note that: The values of environment variables depend on your environment settings of the local machine and the remote machine. In this particular case, we are ssh tunneling to the remote device-virtual service. The docker-compose file in the local machine does not include any device services at all. This is to ensure that we are actually using the device services in the remote machine.","title":"Put it all together"},{"location":"microservices/security/Ch-SSH-Tunneling-HowToSecureDeviceServices/#test-with-the-device-virtual-apis","text":"mainly run curl or postman directly from the local machine to the device-virtual APIs to verify the remote device virtual service can be accessible from the local host machine via two-way SSH tunneling. This can be checked from the console of the local machine: the ping response of calling edgex-device-virtual's ping action: jim@jim-NUC7i5DNHE:~/go/src/github.com/edgexfoundry/developer-scripts/releases/geneva/compose-files$ curl http://localhost:49990/api/v1/ping 1 .2.0-dev.13j or see the configuration of it via curl command: jim@jim-NUC7i5DNHE:~/go/src/github.com/edgexfoundry/developer-scripts/releases/geneva/compose-files$ curl http://localhost:49990/api/v1/config { \"Writable\" :{ \"LogLevel\" : \"INFO\" }, \"Clients\" :{ \"Data\" :{ \"Host\" : \"localhost\" , \"Port\" : 48080 , \"Protocol\" : \"http\" }, \"Logging\" :{ \"Host\" : \"localhost\" , \"Port\" : 48061 , \"Protocol\" : \"http\" }, \"Metadata\" :{ \"Host\" : \"edgex-core-metadata\" , \"Port\" : 48081 , \"Protocol\" : \"http\" }}, \"Logging\" :{ \"EnableRemote\" : false , \"File\" : \"\" }, \"Registry\" :{ \"Host\" : \"edgex-core-consul\" , \"Port\" : 8500 , \"Type\" : \"consul\" }, \"Service\" :{ \"BootTimeout\" : 30000 , \"CheckInterval\" : \"10s\" , \"ClientMonitor\" : 15000 , \"Host\" : \"edgex-device-virtual\" , \"Port\" : 49990 , \"Protocol\" : \"http\" , \"StartupMsg\" : \"device virtual started\" , \"MaxResultCount\" : 0 , \"Timeout\" : 5000 , \"ConnectRetries\" : 10 , \"Labels\" :[], \"EnableAsyncReadings\" : true , \"AsyncBufferSize\" : 16 }, \"Device\" :{ \"DataTransform\" : true , \"InitCmd\" : \"\" , \"InitCmdArgs\" : \"\" , \"MaxCmdOps\" : 128 , \"MaxCmdValueLen\" : 256 , \"RemoveCmd\" : \"\" , \"RemoveCmdArgs\" : \"\" , \"ProfilesDir\" : \"./res\" , \"UpdateLastConnected\" : false , \"Discovery\" :{ \"Enabled\" : false , \"Interval\" : \"\" }}, \"DeviceList\" :[{ \"Name\" : \"Random-Boolean-Device\" , \"Profile\" : \"Random-Boolean-Device\" , \"Description\" : \"Example of Device Virtual\" , \"Labels\" :[ \"device-virtual-example\" ], \"Protocols\" :{ \"other\" :{ \"Address\" : \"device-virtual-bool-01\" , \"Port\" : \"300\" }}, \"AutoEvents\" :[{ \"frequency\" : \"10s\" , \"resource\" : \"Bool\" }]},{ \"Name\" : \"Random-Integer-Device\" , \"Profile\" : \"Random-Integer-Device\" , \"Description\" : \"Example of Device Virtual\" , \"Labels\" :[ \"device-virtual-example\" ], \"Protocols\" :{ \"other\" :{ \"Address\" : \"device-virtual-int-01\" , \"Protocol\" : \"300\" }}, \"AutoEvents\" :[{ \"frequency\" : \"15s\" , \"resource\" : \"Int8\" },{ \"frequency\" : \"15s\" , \"resource\" : \"Int16\" },{ \"frequency\" : \"15s\" , \"resource\" : \"Int32\" },{ \"frequency\" : \"15s\" , \"resource\" : \"Int64\" }]},{ \"Name\" : \"Random-UnsignedInteger-Device\" , \"Profile\" : \"Random-UnsignedInteger-Device\" , \"Description\" : \"Example of Device Virtual\" , \"Labels\" :[ \"device-virtual-example\" ], \"Protocols\" :{ \"other\" :{ \"Address\" : \"device-virtual-uint-01\" , \"Protocol\" : \"300\" }}, \"AutoEvents\" :[{ \"frequency\" : \"20s\" , \"resource\" : \"Uint8\" },{ \"frequency\" : \"20s\" , \"resource\" : \"Uint16\" },{ \"frequency\" : \"20s\" , \"resource\" : \"Uint32\" },{ \"frequency\" : \"20s\" , \"resource\" : \"Uint64\" }]},{ \"Name\" : \"Random-Float-Device\" , \"Profile\" : \"Random-Float-Device\" , \"Description\" : \"Example of Device Virtual\" , \"Labels\" :[ \"device-virtual-example\" ], \"Protocols\" :{ \"other\" :{ \"Address\" : \"device-virtual-float-01\" , \"Protocol\" : \"300\" }}, \"AutoEvents\" :[{ \"frequency\" : \"30s\" , \"resource\" : \"Float32\" },{ \"frequency\" : \"30s\" , \"resource\" : \"Float64\" }]},{ \"Name\" : \"Random-Binary-Device\" , \"Profile\" : \"Random-Binary-Device\" , \"Description\" : \"Example of Device Virtual\" , \"Labels\" :[ \"device-virtual-example\" ], \"Protocols\" :{ \"other\" :{ \"Address\" : \"device-virtual-bool-01\" , \"Port\" : \"300\" }}, \"AutoEvents\" : null }], \"Driver\" :{}} one can also monitor the docker log messages of core-data on the local machine too see if it publishes the events to the bus: $ docker logs -f edgex-core-data level = INFO ts = 2020 -06-10T00:49:26.579819548Z app = edgex-core-data source = event.go:284 msg = \"Putting event on message queue\" level = INFO ts = 2020 -06-10T00:49:26.579909649Z app = edgex-core-data source = event.go:302 msg = \"Event Published on message queue. Topic: events, Correlation-id: 4dc57d03-178e-49f5-a799-67813db9d85b \" level = INFO ts = 2020 -06-10T00:49:27.107028244Z app = edgex-core-data source = event.go:284 msg = \"Putting event on message queue\" level = INFO ts = 2020 -06-10T00:49:27.107128916Z app = edgex-core-data source = event.go:302 msg = \"Event Published on message queue. Topic: events, Correlation-id: 2a0fd8fa-bb16-4d1a-ba1b-c5e70e1a1cec \" level = INFO ts = 2020 -06-10T00:49:27.376915392Z app = edgex-core-data source = event.go:284 msg = \"Putting event on message queue\" level = INFO ts = 2020 -06-10T00:49:27.377084206Z app = edgex-core-data source = event.go:302 msg = \"Event Published on message queue. Topic: events, Correlation-id: 76d288e2-a2e8-4ed4-9265-986661b71bbe \" level = INFO ts = 2020 -06-10T00:49:27.718042678Z app = edgex-core-data source = event.go:284 msg = \"Putting event on message queue\" level = INFO ts = 2020 -06-10T00:49:27.718125128Z app = edgex-core-data source = event.go:302 msg = \"Event Published on message queue. Topic: events, Correlation-id: f5412a38-0346-4bd3-b9da-69498e4edb9a \" level = INFO ts = 2020 -06-10T00:49:30.49407257Z app = edgex-core-data source = event.go:284 msg = \"Putting event on message queue\" level = INFO ts = 2020 -06-10T00:49:30.494162219Z app = edgex-core-data source = event.go:302 msg = \"Event Published on message queue. Topic: events, Correlation-id: da54fcc9-4771-4e0f-9eff-e0d2067eac7e \" level = INFO ts = 2020 -06-10T00:49:31.204976003Z app = edgex-core-data source = event.go:284 msg = \"Putting event on message queue\" level = INFO ts = 2020 -06-10T00:49:31.205211102Z app = edgex-core-data source = event.go:302 msg = \"Event Published on message queue. Topic: events, Correlation-id: 08574f61-6ea3-49cf-a776-028876de7957 \" level = INFO ts = 2020 -06-10T00:49:31.778242016Z app = edgex-core-data source = event.go:284 msg = \"Putting event on message queue\" level = INFO ts = 2020 -06-10T00:49:31.778342992Z app = edgex-core-data source = event.go:302 msg = \"Event Published on message queue. Topic: events, Correlation-id: f1630f13-6fa7-45a6-b6f6-6bbde159b414 \" level = INFO ts = 2020 -06-10T00:49:34.747901983Z app = edgex-core-data source = event.go:284 msg = \"Putting event on message queue\" level = INFO ts = 2020 -06-10T00:49:34.748045382Z app = edgex-core-data source = event.go:302 msg = \"Event Published on message queue. Topic: events, Correlation-id: cf14c573-60b9-43cd-b95b-2c6ffe26ba20 \" level = INFO ts = 2020 -06-10T00:49:34.944758331Z app = edgex-core-data source = event.go:284 msg = \"Putting event on message queue\" level = INFO ts = 2020 -06-10T00:49:34.9449585Z app = edgex-core-data source = event.go:302 msg = \"Event Published on message queue. Topic: events, Correlation-id: 292b9ca7-a640-4ac8-8650-866b7c4a6d15 \" level = INFO ts = 2020 -06-10T00:49:37.421202715Z app = edgex-core-data source = event.go:284 msg = \"Putting event on message queue\" level = INFO ts = 2020 -06-10T00:49:37.421367863Z app = edgex-core-data source = event.go:302 msg = \"Event Published on message queue. Topic: events, Correlation-id: bb7a34b1-c65f-4820-91a3-162903ac1e7a \" level = INFO ts = 2020 -06-10T00:49:42.290660694Z app = edgex-core-data source = event.go:284 msg = \"Putting event on message queue\" level = INFO ts = 2020 -06-10T00:49:42.290756356Z app = edgex-core-data source = event.go:302 msg = \"Event Published on message queue. Topic: events, Correlation-id: 8fff92c0-ef69-4758-bf8a-3492fb48cef2 \" level = INFO ts = 2020 -06-10T00:49:42.559019764Z app = edgex-core-data source = event.go:284 msg = \"Putting event on message queue\" level = INFO ts = 2020 -06-10T00:49:42.559105855Z app = edgex-core-data source = event.go:302 msg = \"Event Published on message queue. Topic: events, Correlation-id: 12947a42-4669-4bff-8720-d0e9fbeef343 \" level = INFO ts = 2020 -06-10T00:49:44.922764379Z app = edgex-core-data source = event.go:284 msg = \"Putting event on message queue\" level = INFO ts = 2020 -06-10T00:49:44.922848184Z app = edgex-core-data source = event.go:302 msg = \"Event Published on message queue. Topic: events, Correlation-id: 3c07ce76-203a-4bf5-ab89-b99a1fbbb266 \" and also do the docker log messages of device-virtual container on the remote: vagrant@ubuntu-bionic:~/geneva$ docker logs -f edgex-device-virtual level = INFO ts = 2020 -06-10T00:51:52.602154238Z app = device-virtual source = utils.go:94 Content-Type = application/json correlation-id = 3d86a699-c089-412d-94f3-af6cd9093f28 msg = \"SendEvent: Pushed event to core data\" level = INFO ts = 2020 -06-10T00:51:53.358352349Z app = device-virtual source = utils.go:94 Content-Type = application/json correlation-id = 9612b186-98cb-4dc5-887a-195ce7300978 msg = \"SendEvent: Pushed event to core data\" level = INFO ts = 2020 -06-10T00:51:57.649085447Z app = device-virtual source = utils.go:94 Content-Type = application/json correlation-id = da682ffb-9120-4286-9f33-aa0a9f2c0489 msg = \"SendEvent: Pushed event to core data\" level = INFO ts = 2020 -06-10T00:51:57.86899148Z app = device-virtual source = utils.go:94 Content-Type = application/json correlation-id = afc1fccf-de8a-46ce-9849-82c5e4e5837e msg = \"SendEvent: Pushed event to core data\" level = INFO ts = 2020 -06-10T00:51:59.543754189Z app = device-virtual source = utils.go:94 Content-Type = application/json correlation-id = 80ac32a0-3a9a-4b07-bf3f-b26ec159dc40 msg = \"SendEvent: Pushed event to core data\" level = INFO ts = 2020 -06-10T00:51:59.688746606Z app = device-virtual source = utils.go:94 Content-Type = application/json correlation-id = 21501030 -c07c-4ac4-a2d2-1243782cb4b8 msg = \"SendEvent: Pushed event to core data\" level = INFO ts = 2020 -06-10T00:51:59.853069376Z app = device-virtual source = utils.go:94 Content-Type = application/json correlation-id = 3b2927db-e689-4fad-8d53-af6fe20239f8 msg = \"SendEvent: Pushed event to core data\" level = INFO ts = 2020 -06-10T00:52:00.055657757Z app = device-virtual source = utils.go:94 Content-Type = application/json correlation-id = a7698f2d-a115-4b46-af5f-3b8bf77e6ea4 msg = \"SendEvent: Pushed event to core data\" level = INFO ts = 2020 -06-10T00:52:04.460557145Z app = device-virtual source = utils.go:94 Content-Type = application/json correlation-id = 602efd03-8e9d-441b-9a7d-45dbcb6b416f msg = \"SendEvent: Pushed event to core data\" level = INFO ts = 2020 -06-10T00:52:07.696983268Z app = device-virtual source = utils.go:94 Content-Type = application/json correlation-id = 88190186 -6f93-4c6a-a1f6-d6a20a6e79e4 msg = \"SendEvent: Pushed event to core data\" level = INFO ts = 2020 -06-10T00:52:08.040474761Z app = device-virtual source = utils.go:94 Content-Type = application/json correlation-id = 73c60159-f50c-480b-90da-ebe310fa2f6e msg = \"SendEvent: Pushed event to core data\" level = INFO ts = 2020 -06-10T00:52:08.2091048Z app = device-virtual source = utils.go:94 Content-Type = application/json correlation-id = 2d799509-dc1d-4075-b193-1e5da24cfa77 msg = \"SendEvent: Pushed event to core data\" level = INFO ts = 2020 -06-10T00:52:12.751717832Z app = device-virtual source = utils.go:94 Content-Type = application/json correlation-id = 7611a188-23f4-44d0-bd12-f6574535be8d msg = \"SendEvent: Pushed event to core data\" level = INFO ts = 2020 -06-10T00:52:13.553351482Z app = device-virtual source = utils.go:94 Content-Type = application/json correlation-id = a32067c8-adae-4778-b72d-0d8d7d11220f msg = \"SendEvent: Pushed event to core data\" level = INFO ts = 2020 -06-10T00:52:15.20395683Z app = device-virtual source = utils.go:94 Content-Type = application/json correlation-id = 41df0427-5998-4d1e-9c26-1f727912638b msg = \"SendEvent: Pushed event to core data\" level = INFO ts = 2020 -06-10T00:52:15.686970839Z app = device-virtual source = utils.go:94 Content-Type = application/json correlation-id = c6a8bb2d-22ab-4932-bdd0-138f12f843b6 msg = \"SendEvent: Pushed event to core data\" level = INFO ts = 2020 -06-10T00:52:18.177810023Z app = device-virtual source = utils.go:94 Content-Type = application/json correlation-id = a49d663b-1676-4ecf-ba52-76e9ad7c501d msg = \"SendEvent: Pushed event to core data\" level = INFO ts = 2020 -06-10T00:52:19.600220653Z app = device-virtual source = utils.go:94 Content-Type = application/json correlation-id = b6d2c2d1-5d5c-4f7a-9dd2-2067e732f018 msg = \"SendEvent: Pushed event to core data\" level = INFO ts = 2020 -06-10T00:52:19.990751025Z app = device-virtual source = utils.go:94 Content-Type = application/json correlation-id = 1db5dde3-bb6b-4600-abbb-d01b3042c329 msg = \"SendEvent: Pushed event to core data\" test to get random integer value of the remote device-virtual random integer device from the local machine using curl command like this: jim@jim-NUC7i5DNHE:~/go/src/github.com/edgexfoundry/device-virtual-go$ curl -k http://localhost:49990/api/v1/device/name/Random-Integer-Device/Int8 { \"device\" : \"Random-Integer-Device\" , \"origin\" :1592432603445490720, \"readings\" : [{ \"origin\" :1592432603404127336, \"device\" : \"Random-Integer-Device\" , \"name\" : \"Int8\" , \"value\" : \"11\" , \"valueType\" : \"Int8\" }] , \"EncodedEvent\" :null }","title":"Test with the device-virtual APIs"},{"location":"microservices/security/Ch-SecretStore/","text":"Secret Store There are all kinds of secrets used within EdgeX Foundry micro services, such as tokens, passwords, certificates etc. The secret store serves as the central repository to keep these secrets. The developers of other EdgeX Foundry micro services utilize the secret store to create, store and retrieve secrets relevant to their corresponding micro service. The communications the between secret store and other micro services are secured by TLS. Currently the EdgeX Foundry secret store is implemented with Vault , a HashiCorp open source software product. Vault is a tool for securely accessing secrets. A secret is anything that you want to tightly control access to, such as API keys, passwords, database credentials, service credentials, or certificates. Vault provides a unified interface to any secret, while providing tight access control and multiple authentication mechanisms (token, LDAP, etc.). Vault adds on key rolling, revocation rules, time-to-live access tokens, secure storage, Shamir Secret Sharing based unlocking mechanism, high availability and detailed auditing. Vault can use several backend systems (filesystem, databases, Consul, Etcd, S3, Azure, etc.) to securely store every sensitive asset. The current EdgeX Foundry implementation of Vault is using Consul , another HashiCorp open source software product. Consul is a distributed service mesh to connect, secure, and configure services across any runtime platform and public or private cloud. Consul uses a consensus protocol to provide Consistency as defined by CAP . The consensus protocol is based on \"Raft: In search of an Understandable Consensus Algorithm\" . For a visual explanation of Raft, see The Secret Lives of Data . The seamless integration of Vault and Consul provides a strong yet simple infrastructure to setup a reliable high availability architecture (Vault failover nodes, Consul Clustering) for the EdgeX Foundry Security services in production. The key features of Vault are: Secure Secret Storage: Arbitrary key/value secrets can be stored in Vault. Vault encrypts these secrets prior to writing them to persistent storage, so gaining access to the raw storage isn't enough to access your secrets. Authentication mechanisms (internal and/or external) and authorizations based upon policies provide access management. Dynamic Secrets: Vault can generate secrets on-demand for some systems, automatically revoking them after the lease is up. Data Encryption: Vault can encrypt and decrypt data without storing it. Leasing and Renewal: All secrets in Vault have a lease associated with them (automatic revocation). However, clients can renew leases via built-in renew APIs. Revocation: Vault has built-in support for secret revocation. Single secrets, but also a tree of secrets. Revocation assists in key rolling as well as locking down systems in the case of an intrusion. Start the Secret Store Start the Secret Store with Docker Compose and a Docker Compose manifest file. The whole set of Docker Compose files for Geneva release can be found here: https://github.com/edgexfoundry/developer-scripts/blob/master/releases/geneva/compose-files The Compose file starts the entire EdgeX Foundry platform with Redis including the security services. The command to start EdgeX Foundry platform including the Secret Store and API gateway related services is: sh> docker-compose up -d For a pristine run, it is strongly recommended to thoroughly clean up any Docker artifacts remaining from the current run. sh> docker-compose down -v The \"down\" operation will remove containers, network and adding the -v option it will also remove persistent volumes: Stopping edgex-vault ... done Stopping edgex-core-consul ... done Stopping edgex-files ... done Removing edgex-vault-worker ... done Removing edgex-vault ... done Removing edgex-config-seed ... done Removing edgex-core-consul ... done Removing edgex-files ... done Removing network security-secret-store_edgex-network Removing volume security-secret-store_db-data Removing volume security-secret-store_log-data Removing volume security-secret-store_consul-config Removing volume security-secret-store_consul-data Removing volume security-secret-store_vault-config Removing volume security-secret-store_vault-file Removing volume security-secret-store_vault-logs Troubleshooting steps For debugging purpose, the Secret Store services can be started individually with these commands. A pre-requisite being to carefully follow the invocation sequence in order to avoid any dependency failure. Lines starting with # (hashtag) are contextual comments to explicit the purpose of the above corresponding command: Clean-up sh> cd <path-to-EdgeX-Foundry-Secret-Store> # <...>/security-secret-store/ sh> docker-compose down -v sh> docker-compose ps # Check no previous container is running sh> docker volume ls # Check and remove any previous persistent and/or unused volumes sh> docker volume prune sh> docker volume rm <volume-name> sh> docker network ls # Check and remove the previous EdgeX Foundry Docker network sh> docker network rm edgex-network Start the first service: volume (platform volume initializations) sh> docker-compose up -d volume Sample output: Creating network \"security-secret-store_edgex-network\" with driver \"bridge\" Creating volume \"security-secret-store_db-data\" with default driver Creating volume \"security-secret-store_log-data\" with default driver Creating volume \"security-secret-store_consul-config\" with default driver Creating volume \"security-secret-store_consul-data\" with default driver Creating volume \"security-secret-store_vault-config\" with default driver Creating volume \"security-secret-store_vault-file\" with default driver Creating volume \"security-secret-store_vault-logs\" with default driver Creating edgex-files ... done Start the second service: consul (Consul is Vault store backend) sh> docker-compose up -d consul Sample output: edgex-files is up-to-date Creating edgex-core-consul ... done Display and inspect consul service logs: important lines are highlighted sh> docker-compose logs consul Sample output: Attaching to edgex-core-consul edgex-core-consul | ==> Starting Consul agent... edgex-core-consul | ==> Consul agent running! edgex-core-consul | Version: 'v1.1.0' edgex-core-consul | Node ID: '371cbce6-02a8-65f6-ddea-6df5c40a4c50' edgex-core-consul | Node name: 'edgex-core-consul' edgex-core-consul | Datacenter: 'dc1' (Segment: '<all>') edgex-core-consul | Server: true (Bootstrap: false) edgex-core-consul | Client Addr: [0.0.0.0] (HTTP: 8500, HTTPS: -1, DNS: 8600) edgex-core-consul | Cluster Addr: 127.0.0.1 (LAN: 8301, WAN: 8302) edgex-core-consul | Encrypt: Gossip: false, TLS-Outgoing: false, TLS-Incoming: false edgex-core-consul | edgex-core-consul | ==> Log data will now stream in as it occurs: edgex-core-consul | edgex-core-consul | 2019/01/13 13:25:06 [DEBUG] agent: Using random ID \"371cbce6-02a8-65f6-ddea-6df5c40a4c50\" as node ID edgex-core-consul | 2019/01/13 13:25:06 [INFO] raft: Initial configuration (index=1): [{Suffrage:Voter ID:371cbce6-02a8-65f6-ddea-6df5c40a4c50 Address:127.0.0.1:8300}] edgex-core-consul | 2019/01/13 13:25:06 [INFO] raft: Node at 127.0.0.1:8300 [Follower] entering Follower state (Leader: \"\") edgex-core-consul | 2019/01/13 13:25:06 [INFO] serf: EventMemberJoin: edgex-core-consul.dc1 127.0.0.1 edgex-core-consul | 2019/01/13 13:25:06 [INFO] serf: EventMemberJoin: edgex-core-consul 127.0.0.1 edgex-core-consul | 2019/01/13 13:25:06 [INFO] consul: Adding LAN server edgex-core-consul (Addr: tcp/127.0.0.1:8300) (DC: dc1) edgex-core-consul | 2019/01/13 13:25:06 [INFO] consul: Handled member-join event for server \"edgex-core-consul.dc1\" in area \"wan\" edgex-core-consul | 2019/01/13 13:25:06 [INFO] agent: Started DNS server 0.0.0.0:8600 (tcp) edgex-core-consul | 2019/01/13 13:25:06 [INFO] agent: Started DNS server 0.0.0.0:8600 (udp) edgex-core-consul | 2019/01/13 13:25:06 [INFO] agent: Started HTTP server on [::]:8500 (tcp) edgex-core-consul | 2019/01/13 13:25:06 [INFO] agent: started state syncer edgex-core-consul | 2019/01/13 13:25:06 [WARN] raft: Heartbeat timeout from \"\" reached, starting election edgex-core-consul | 2019/01/13 13:25:06 [INFO] raft: Node at 127.0.0.1:8300 [Candidate] entering Candidate state in term 2 edgex-core-consul | 2019/01/13 13:25:06 [DEBUG] raft: Votes needed: 1 edgex-core-consul | 2019/01/13 13:25:06 [DEBUG] raft: Vote granted from 371cbce6-02a8-65f6-ddea-6df5c40a4c50 in term 2. Tally: 1 edgex-core-consul | 2019/01/13 13:25:06 [INFO] raft: Election won. Tally: 1 edgex-core-consul | 2019/01/13 13:25:06 [INFO] raft: Node at 127.0.0.1:8300 [Leader] entering Leader state edgex-core-consul | 2019/01/13 13:25:06 [INFO] consul: cluster leadership acquired Start the third service: config-seed (platform configuration initializations) sh> docker-compose up -d config-seed Sample output: edgex-files is up-to-date edgex-core-consul is up-to-date Creating edgex-config-seed ... done Display and inspect the created container states: important lines are highlighted sh> docker-compose ps Sample output: Name Command State Ports ---------------------------------------------------------------------------------------------------------------------------------------edgex-config-seed /bin/sh -c /edgex/cmd/conf ... Exit 0 edgex-core-consul docker-entrypoint.sh agent ... Up 8300/tcp, 8301/tcp, 8301/udp, 8302/tcp, 8302/udp, 0.0.0.0:8400->8400/tcp, 0.0.0.0:8500->8500/tcp, 0.0.0.0:8600->8600/tcp, 8600/udp edgex-files /bin/sh -c /usr/bin/tail - ... Up Note Line 3: edgex-config-seed service has exited after successful processing (exit code 0) Start the fourth service: vault (Vault tool) Note Vault will be uninitialized and unsealed upon success. The vault-worker service will process the initialization and unsealing tasks. sh> docker-compose up -d vault Sample output: edgex-files is up-to-date edgex-core-consul is up-to-date Creating edgex-vault ... done Display and inspect \"vault\" service logs: important lines are highlighted sh> docker-compose logs vault Sample output: Attaching to edgex-vault edgex-vault | ==> Vault server configuration: edgex-vault | edgex-vault | Api Address: https://edgex-vault:8200 edgex-vault | Cgo: disabled edgex-vault | Cluster Address: https://edgex-vault:8201 edgex-vault | Listener 1: tcp (addr: \"edgex-vault:8200\", cluster address: \"edgex-vault:8201\", tls: \"enabled\") edgex-vault | Log Level: info edgex-vault | Mlock: supported: true, enabled: true edgex-vault | Storage: consul (HA available) edgex-vault | Version: Vault v0.10.2 edgex-vault | Version Sha: 3ee0802ed08cb7f4046c2151ec4671a076b76166 edgex-vault | edgex-vault | ==> Vault server started! Log data will stream in below: edgex-vault | Note Line 4 & 7: Vault API endpoint on port 8200 (lines 4 and 7). Line 7: Vault has TLS enabled. Line 10: Vault backend storage is Consul . Start the fifth service: vault-worker (Vault init/unseal process and setups) sh> docker-compose up -d vault-worker Sample output: edgex-files is up-to-date edgex-core-consul is up-to-date edgex-vault is up-to-date Creating edgex-vault-worker ... done Display and inspect \"vault-worker\" service logs: important lines are highlighted sh> docker-compose logs vault-worker Sample output: Attaching to edgex-vault-worker edgex-vault-worker | INFO: 2019/01/13 13:35:42 successful loading the rootCA cert. edgex-vault-worker | INFO: 2019/01/13 13:35:43 {\"keys\":[\"564b9444eebe28b393c21a4dca1e32835b7dc27f5da03b73d22b666cb20224a9\"],\"keys_base64\":[\"VkuURO6+KLOTwhpNyh4yg1t9wn9doDtz0itmbLICJKk=\"],\"recovery_keys\":null,\"recovery_keys_base64\":null,\"root_token\":\"01dbbae4-353a-8cdf-8189-4d50e5535a6f\"} edgex-vault-worker | INFO: 2019/01/13 13:35:43 Vault has been initialized successfully. edgex-vault-worker | INFO: 2019/01/13 13:35:43 Vault has been unsealed successfully. edgex-vault-worker | INFO: 2019/01/13 13:35:48 Vault Health Check HTTP Status: 200 OK (StatusCode: 200) edgex-vault-worker | INFO: 2019/01/13 13:35:48 Verifying Admin policy file hash (SHA256). edgex-vault-worker | INFO: 2019/01/13 13:35:48 Vault policy file checksum (SHA256): 5ce8d58cf7d931735f6532742f677c109a91a263bcefe9aef73ab2a69f4b43d3 edgex-vault-worker | INFO: 2019/01/13 13:35:48 Reading Admin policy file. edgex-vault-worker | INFO: 2019/01/13 13:35:48 Importing Vault Admin policy. edgex-vault-worker | INFO: 2019/01/13 13:35:48 Import Policy Successfull. edgex-vault-worker | INFO: 2019/01/13 13:35:48 Reading Kong policy file. edgex-vault-worker | INFO: 2019/01/13 13:35:48 Importing Vault Kong policy. edgex-vault-worker | INFO: 2019/01/13 13:35:48 Import Policy Successfull. edgex-vault-worker | INFO: 2019/01/13 13:35:48 Creating Vault Admin token. edgex-vault-worker | INFO: 2019/01/13 13:35:48 Create Token Successfull. edgex-vault-worker | INFO: 2019/01/13 13:35:48 Creating Vault Kong token. edgex-vault-worker | INFO: 2019/01/13 13:35:48 Create Token Successfull. edgex-vault-worker | INFO: 2019/01/13 13:35:48 Successful on reading certificate from v1/secret/edgex/pki/tls/edgex-kong. edgex-vault-worker | INFO: 2019/01/13 13:35:48 Cert&key are not in the secret store yet, will need to upload them. edgex-vault-worker | INFO: 2019/01/13 13:35:48 Load cert&key pair from volume successfully, now will upload to secret store. edgex-vault-worker | INFO: 2019/01/13 13:35:48 Trying to upload cert&key to secret store. edgex-vault-worker | INFO: 2019/01/13 13:35:48 Successful to add certificate to the secret store. Display and inspect \"vault\" service logs: important lines are highlighted sh> docker-compose logs vault Sample output: Attaching to edgex-vault edgex-vault | ==> Vault server configuration: edgex-vault | edgex-vault | Api Address: https://edgex-vault:8200 edgex-vault | Cgo: disabled edgex-vault | Cluster Address: https://edgex-vault:8201 edgex-vault | Listener 1: tcp (addr: \"edgex-vault:8200\", cluster address: \"edgex-vault:8201\", tls: enabled\") edgex-vault | Log Level: info edgex-vault | Mlock: supported: true, enabled: true edgex-vault | Storage: consul (HA available) edgex-vault | Version: Vault v0.10.2 edgex-vault | Version Sha: 3ee0802ed08cb7f4046c2151ec4671a076b76166 edgex-vault | edgex-vault | ==> Vault server started! Log data will stream in below: edgex-vault | edgex-vault | 2019-01-13T13:35:42.549Z [INFO ] core: security barrier not initialized edgex-vault | 2019-01-13T13:35:42.551Z [INFO ] core: security barrier not initialized edgex-vault | 2019-01-13T13:35:42.554Z [INFO ] core: security barrier initialized: shares=1 threshold=1 edgex-vault | 2019-01-13T13:35:42.575Z [INFO ] core: post-unseal setup starting edgex-vault | 2019-01-13T13:35:42.583Z [INFO ] core: loaded wrapping token key edgex-vault | 2019-01-13T13:35:42.583Z [INFO ] core: successfully setup plugin catalog: plugin-directory= edgex-vault | 2019-01-13T13:35:42.584Z [INFO ] core: no mounts; adding default mount table edgex-vault | 2019-01-13T13:35:42.585Z [INFO ] core: successfully mounted backend: type=kv path=secret/ edgex-vault | 2019-01-13T13:35:42.586Z [INFO ] core: successfully mounted backend: type=cubbyhole path=cubbyhole/ edgex-vault | 2019-01-13T13:35:42.586Z [INFO ] core: successfully mounted backend: type=system path=sys/ edgex-vault | 2019-01-13T13:35:42.586Z [INFO ] core: successfully mounted backend: type=identity path=identity/ edgex-vault | 2019-01-13T13:35:42.593Z [INFO ] core: restoring leases edgex-vault | 2019-01-13T13:35:42.593Z [INFO ] rollback: starting rollback manager edgex-vault | 2019-01-13T13:35:42.594Z [INFO ] expiration: lease restore complete edgex-vault | 2019-01-13T13:35:42.596Z [INFO ] identity: entities restored edgex-vault | 2019-01-13T13:35:42.597Z [INFO ] identity: groups restored edgex-vault | 2019-01-13T13:35:42.597Z [INFO ] core: post-unseal setup complete edgex-vault | 2019-01-13T13:35:42.597Z [INFO ] core: core/startClusterListener: starting listener: listener_address=172.19.0.4:8201 edgex-vault | 2019-01-13T13:35:42.597Z [INFO ] core: core/startClusterListener: serving cluster requests: cluster_listen_address=172.19.0.4:8201 edgex-vault | 2019-01-13T13:35:42.600Z [INFO ] core: root token generated edgex-vault | 2019-01-13T13:35:42.600Z [INFO ] core: pre-seal teardown starting edgex-vault | 2019-01-13T13:35:42.600Z [INFO ] core: stopping cluster listeners edgex-vault | 2019-01-13T13:35:42.600Z [INFO ] core: shutting down forwarding rpc listeners edgex-vault | 2019-01-13T13:35:42.600Z [INFO ] core: forwarding rpc listeners stopped edgex-vault | 2019-01-13T13:35:43.099Z [INFO ] core: rpc listeners successfully shut down edgex-vault | 2019-01-13T13:35:43.099Z [INFO ] core: cluster listeners successfully shut down edgex-vault | 2019-01-13T13:35:43.100Z [INFO ] rollback: stopping rollback manager edgex-vault | 2019-01-13T13:35:43.100Z [INFO ] core: pre-seal teardown complete edgex-vault | 2019-01-13T13:35:43.105Z [INFO ] core: vault is unsealed edgex-vault | 2019-01-13T13:35:43.105Z [INFO ] core: entering standby mode edgex-vault | 2019-01-13T13:35:43.109Z [INFO ] core: acquired lock, enabling active operation edgex-vault | 2019-01-13T13:35:43.134Z [INFO ] core: post-unseal setup starting edgex-vault | 2019-01-13T13:35:43.135Z [INFO ] core: loaded wrapping token key edgex-vault | 2019-01-13T13:35:43.135Z [INFO ] core: successfully setup plugin catalog: plugin-directory= edgex-vault | 2019-01-13T13:35:43.137Z [INFO ] core: successfully mounted backend: type=kv path=secret/ edgex-vault | 2019-01-13T13:35:43.137Z [INFO ] core: successfully mounted backend: type=system path=sys/ edgex-vault | 2019-01-13T13:35:43.137Z [INFO ] core: successfully mounted backend: type=identity path=identity/ edgex-vault | 2019-01-13T13:35:43.137Z [INFO ] core: successfully mounted backend: type=cubbyhole path=cubbyhole/ edgex-vault | 2019-01-13T13:35:43.141Z [INFO ] core: restoring leases edgex-vault | 2019-01-13T13:35:43.142Z [INFO ] rollback: starting rollback manager edgex-vault | 2019-01-13T13:35:43.142Z [INFO ] expiration: lease restore complete edgex-vault | 2019-01-13T13:35:43.143Z [INFO ] identity: entities restored edgex-vault | 2019-01-13T13:35:43.143Z [INFO ] identity: groups restored edgex-vault | 2019-01-13T13:35:43.144Z [INFO ] core: post-unseal setup complete edgex-vault | 2019-01-13T13:35:43.144Z [INFO ] core: core/startClusterListener: starting listener: listener_address=172.19.0.4:8201 edgex-vault | 2019-01-13T13:35:43.144Z [INFO ] core: core/startClusterListener: serving cluster requests: cluster_listen_address=172.19.0.4:8201 Note Line 18: Vault initialization successful. Line 35: Vault root token generated. Line 44: Vault unsealing successful. Line 50: Vault key/value store secret successfully mounted . Line 60 & 61: Vault successfully started . Display and inspect the created container states: important lines are highlighted sh> docker-compose ps Sample output: Name Command State Ports ---------------------------------------------------------------------------------------------------------------------------------------edgex-config-seed /bin/sh -c /edgex/cmd/conf ... Exit 0 edgex-core-consul docker-entrypoint.sh agent ... Up 8300/tcp, 8301/tcp, 8301/udp, 8302/tcp, 8302/udp, 0.0.0.0:8400->8400/tcp, 0.0.0.0:8500->8500/tcp, 0.0.0.0:8600->8600/tcp, 8600/udp edgex-files /bin/sh -c /usr/bin/tail - ... Up edgex-vault docker-entrypoint.sh serve ... Up 0.0.0.0:8200->8200/tcp edgex-vault-worker ./edgex-vault-worker --ini ... Exit 0 Note Line 9: edgex-vault-worker service has exited after successful processing (exit code 0) Display and inspect the created container volumes: important lines are highlighted sh> docker volume ls DRIVER VOLUME NAME local security-secret-store_consul-config local security-secret-store_consul-data local security-secret-store_db-data local security-secret-store_log-data local security-secret-store_vault-config local security-secret-store_vault-file local security-secret-store_vault-logs Display and inspect the container network ( security-secret-store_edgex-network ): important lines are highlighted sh> docker network ls NETWORK ID NAME DRIVER SCOPE 63227826fbc7 bridge bridge local 60763abffde3 host host local 1d236ab1dbbd none null local 0a7f7266d102 security-secret-store_edgex-network bridge local Using Consul Web UI For learning and verification purposes one might use the Consul Web UI interface to gather and double check specific Vault informations. Consul Web UI endpoint port is exposed by the Docker compose file. EdgeX Foundry platform uses the Consul default port number 8500. It is normally not recommended to expose Consul UI port number in production, at least the UI should not be accessible from outside the platform environment. However, because all the Vault secrets are encrypted before being transmitted and stored in the Consul backend, having access to Consul is not sufficient to access any secrets, the vault data encryption/decryption key would be absolutely necessary. Open a Web browser on http://<EdgeX Consul Server>:8500/ui . On the screenshot below, after selecting SERVICES and Vault , the UI will show the various Vault status (heartbeat and init/unseal states), coloring the boxes in green, orange or red depending on the level of importance (info, warning, error). By clicking each of the right side status indicators, more information will be accessible in order to better inspect any situation. As a practical example, we are going to navigate the Consul structure for Vault in order to check if the API Gateway (Kong) TLS certificate and private key were fetched and stored accordingly during the vault-worker process. First select KEY/VALUE menu, and then select vault root structure: We are now going to navigate deeper in the vault tree structure to reach and display the EdgeX Kong TLS assets. Continue by selecting logical/ : {.align-center width=\"348px\" height=\"287px\"} Then select d7809b... an arbitrary UID generated and created by Consul during Vault registration: {.align-center width=\"377px\" height=\"216px\"} Select edgex/ : {.align-center width=\"419px\" height=\"228px\"} Select pki/ : {.align-center width=\"417px\" height=\"222px\"} Select tls/ : {.align-center width=\"418px\" height=\"237px\"} Select edgex-kong/ : {.align-center width=\"423px\" height=\"233px\"} And we are now finally able to display the encrypted Vault secret containing the API Gateway (Kong) TLS server certificate and its corresponding private key. As you can see on the screenshot below the Vault key/value is encrypted and totally opaque to Consul, the Vault data encryption key (DEK) would be necessary to decrypt these secrets. Each Vault secret is encrypted before being transmitted to Consul node(s). Shell Access to Consul Container and Using Consul CLI sh> docker exec -it -e PS1 = '\\u@\\h:\\w \\$ ' edgex-core-consul sh root@edgex-core-consul:/ # consul members Node Address Status Type Build Protocol DC Segment edgex-core-consul 127 .0.0.1:8301 alive server 1 .1.0 2 dc1 <all> root@edgex-core-consul:/ # consul catalog nodes Node ID Address DC edgex-core-consul e49af36a 127 .0.0.1 dc1 root@edgex-core-consul:/ # consul catalog services consul edgex-mongo vault Note Line 5: Shows the Consul node status alive (1 node in EdgeX default configuration). Line 9: Shows the Consul nodes (1 node in EdgeX default configuration). Lines 12-14: Show the Consul registered services. Configuring the Secret Store Vault server configuration is essentially concentrated in one JSON file named local.json . This file was prepared during the Vault Docker image build process. In the eventuality of a change, the Vault server container should be accessed to then modify the JSON file. The absolute path being /vault/config/local.json . To reload the new configuration simply send Vault PID a HUP signal to trigger a configuration reload. Sample Vault server configuration file: listener \"tcp\" { address = \"edgex-vault:8200\" tls_disable = \"0\" cluster_address = \"edgex-vault:8201\" tls_min_version = \"tls12\" tls_client_ca_file =\"/vault/config/pki/EdgeXFoundryCA/EdgeXFoundryCA.pem\" tls_cert_file =\"/vault/config/pki/EdgeXFoundryCA/edgex-vault.pem\" tls_key_file = \"/vault/config/pki/EdgeXFoundryCA/edgex-vault.priv.key\" } backend \"consul\" { path = \"vault/\" address = \"edgex-core-consul:8500\" scheme = \"http\" redirect_addr = \"https://edgex-vault:8200\" cluster_addr = \"https://edgex-vault:8201\" } default_lease_ttl = \"168h\" max_lease_ttl = \"720h\" The listener clause refers to Vault server process (port, TLS and server name), the backend clause refers to the storage backend (i.e. Consul). To modify this configuration file, execute a shell session in the running Vault container: sh> docker exec -it -e PS1 = '\\u@\\h:\\w \\$ ' -e VAULT_CAPATH = '/vault/config/pki/EdgeXFoundryCA/EdgeXFoundryCA.pem' edgex-vault sh root@edgex-vault:/vault # ls -l total 12 drwxr-xr-x 4 vault vault 4096 Jan 13 13 :34 config drwxr-xr-x 2 vault vault 4096 Jun 7 2018 file drwxr-xr-x 2 vault vault 4096 Jun 7 2018 logs Pay attention to the VAULT_CAPATH environment variable passed to the session. This is necessary in order to run succesful Vault CLI command. Every Vault CLI command is a wrapper of the Vault HTTP API. The Vault server is configured with TLS using X.509 PKI materials generated and signed by a local self-signed CA (EdgeXFoundryCA). Therefore, in order for each Vault CLI command (or to that extent cURL commands) to verify the Vault server TLS certificate, the self-signing CA root certificate would have to be known by the CLI command interpreter. This VAULT_CAPATH variable is checked by every Vault CLI commands, alternatively each Vault CLI command can specify an option with the same certificate path if the variable is not set. The self-signed Root CA certificate path can be found in the Vault configuration file (see above local.json), with parameter tls_client_ca_file =\"/vault/config/pki/EdgeXFoundryCA/EdgeXFoundryCA.pem\" . The local.json configuration file can be read and modified within the running container: <root@edgex-vault>:/vault \\# cat config/local.json listener \"tcp\" { address = \"edgex-vault:8200\" tls\\_disable = \"0\" cluster\\_address =\"edgex-vault:8201\" tls\\_min\\_version = \"tls12\" tls\\_client\\_ca\\_file=\"/vault/config/pki/EdgeXFoundryCA/EdgeXFoundryCA.pem\" tls\\_cert\\_file=\"/vault/config/pki/EdgeXFoundryCA/edgex-vault.pem\" tls\\_key\\_file = \"/vault/config/pki/EdgeXFoundryCA/edgex-vault.priv.key\" } backend \"consul\" { path = \"vault/\" address = \"edgex-core-consul:8500\" scheme = \"http\" redirect\\_addr =\"<https://edgex-vault:8200>\" cluster\\_addr =\"<https://edgex-vault:8201>\" } default\\_lease\\_ttl = \"168h\" max\\_lease\\_ttl = \"720h\" A sample Vault CLI command to check Vault status: root@edgex-vault:/vault # vault status Key Value --- ----- Seal Type shamir Sealed false Total Shares 1 Threshold 1 Version 0 .10.2 Cluster Name vault-cluster-57b3c4ed Cluster ID fe6d18bf-fa9c-0d52-3278-bca0390af023 HA Enabled true HA Cluster https://edgex-vault:8201 HA Mode active All the X.509 PKI materials including the self-signing CA are located under /vault/config/pki/EdgeXFoundryCA . root@edgex-vault:/vault # ls -l config/pki/EdgeXFoundryCA/ total 24 -rw-r--r-- 1 vault vault 956 Dec 5 14 :05 EdgeXFoundryCA.pem -r-------- 1 vault vault 306 Dec 5 14 :05 EdgeXFoundryCA.priv.key -rw-r--r-- 1 vault vault 989 Dec 5 14 :05 edgex-kong.pem -rw------- 1 vault vault 306 Dec 5 14 :05 edgex-kong.priv.key -rw-r--r-- 1 vault vault 1001 Dec 5 14 :05 edgex-vault.pem -rw------- 1 vault vault 306 Dec 5 14 :05 edgex-vault.priv.key Note Line 3: self-signing root CA certificate. Line 4: self-signing root CA private key. Line 5: API Gateway (Kong) TLS server certificate. Line 6: API Gateway (Kong) TLS server certificate private key. Line 7: Vault TLS server certificate. Line 8: Vault TLS server certificate private key. The CA name (EdgeXFoundryCA) was defined by the pkisetup tool during the Vault image build process. This tool is also responsible for all the TLS server configuration and creation tasks. If you are willing to change any of the Vault X.509 PKI assets or configuration parameters you will have to modify the pkisetup-vault.json file and rebuild a new Vault Docker image. Similarly to Vault, each EdgeX Foundry service having a TLS server certificate and private key had its X.509 PKI assets generated and signed during the Vault Docker image build process. Therefore, the API Gateway (Kong) configuration file named pkisetup-kong.json would have to be modified accordingly. A new Vault Docker image would have to be built. The Vault Dockerfile contains the pkisetup executions, see below for a corresponding excerpt (highlighted lines): # Create assets folder (needed for unseal key/s, root token and tmp) # Run CA/Vault and Kong PKI/TLS setups and peform housekeeping tasks RUN mkdir /vault/config/assets && \\ chown -R vault:vault /vault && \\ chmod 644 /vault/config/local.json && \\ chmod 744 pkisetup* && \\ ./pkisetup --config pkisetup-vault.json && \\ echo \"\" && \\ ./pkisetup --config pkisetup-kong.json && \\ chown -R vault:vault /vault/config/pki && \\ rm -f /vault/pkisetup /vault/pkisetup-vault.json /vault/pkisetup-kong.json EdgeX Foundry Docker environment implements a basic Vault/Consul architecture that does not provide high availability guaranties. Only one Consul server and one Vault server will be running. In a more sophisticated production environment it would be possible to build a reliable high availability infrastructure regarding Consul and Vault. To facilitate the setup of a minimal failover architecture the security-secret-store repository provides a sample folder named Full-Architecture-Prototype that contains necessary materials (scripts, helpers, configurations, etc.) to achieve that goal. These samples describe an architecture design with two Vault servers in failover mode (active/standby), using each one a Consul client, which subsequently connects to a Consul cluster of 3 nodes (minimal Raft concensus quorum). The Consul clients and servers (nodes) have redundant paths. Using the Secret Store 1st alternative: executing a shell session in the active Vault container to run Vault CLI commands. See paragraph Configuring the Secret Store to have more details on the VAULT_CAPATH environment variable. See HashiCorp Vault API documentation for further details on syntax and usage ( https://www.vaultproject.io/api/ ). Execute a shell session in the running Vault container: sh> docker exec -it -e PS1 = '\\u@\\h:\\w \\$ ' -e VAULT_CAPATH = '/vault/config/pki/EdgeXFoundryCA/EdgeXFoundryCA.pem' edgex-vault sh Locate the assets folder, and the resp-init.json file: root@edgex-vault:/vault # ls -l config/assets/ total 12 -rw-r--r-- 1 root root 366 Jan 13 13 :35 admin-token.json -rw-r--r-- 1 root root 365 Jan 13 13 :35 kong-token.json -rw-r--r-- 1 root root 241 Jan 13 13 :35 resp-init.json Inspect the resp-init.json file to grab the Vault Root Token: root@edgex-vault:/vault # cat config/assets/resp-init.json { \"keys\" : [ \"564b9444eebe28b393c21a4dca1e32835b7dc27f5da03b73d22b666cb20224a9\" ] , \"keys_base64\" : [ \"VkuURO6+KLOTwhpNyh4yg1t9wn9doDtz0itmbLICJKk=\" ] , \"recovery_keys\" :null, \"recovery_keys_base64\" :null, \"root_token\" : \"01dbbae4-353a-8cdf-8189-4d50e5535a6f\" } Login to Vault using Vault CLI and the gathered Root Token: root@edgex-vault:/vault # vault login 01dbbae4-353a-8cdf-8189-4d50e5535a6f Success! You are now authenticated. The token information displayed below is already stored in the token helper. You do NOT need to run \"vault login\" again. Future Vault requests will automatically use this token. Key Value --- ----- token 01dbbae4-353a-8cdf-8189-4d50e5535a6f token_accessor 4d5eabf7-8710-81b1-b6a4-9ba17fdfdeb7 token_duration \u221e token_renewable false token_policies [ root ] Perform an introspection lookup on the current token login: root@edgex-vault:/vault # vault token lookup Key Value --- ----- accessor 4d5eabf7-8710-81b1-b6a4-9ba17fdfdeb7 creation_time 1547386542 creation_ttl 0 display_name root entity_id n/a expire_time <nil> explicit_max_ttl 0 id 01dbbae4-353a-8cdf-8189-4d50e5535a6f meta <nil> num_uses 0 orphan true path auth/token/root policies [ root ] ttl 0 Note Lines 9 & 10: the Root Token is the only token that has no expiration enforcement rules (Time to Live TTL counter). Perform a check on the current token login to display the corresponding capabilities (policies): root@edgex-vault:/vault # vault token capabilities 01dbbae4-353a-8cdf-8189-4d50e5535a6f root Perform a list request to display the currently mounted secret backends: root@edgex-vault:/vault # vault secrets list Path Type Accessor Description ---- ---- -------- ----------- cubbyhole/ cubbyhole cubbyhole_ad070930 per-token private secret storage identity/ identity identity_5397dc2f identity store secret/ kv kv_2362c227 key/value secret storage sys/ system system_410e4276 system endpoints used for control, policy and debugging Note Line 5: EdgeX Foundry platform is using the Key/Value secret storage named secret Let's drill down into the secret k/v storage and walk through a predefined hierarchical tree structure (path). Note the pkisetup tool used during the Vault Docker image build process generates all the related X.509 TLS materials. The vault-worker service is storing each service materials into Vault using arbitrary paths, setting up access policies accordingly. For example, the API Gateway (Kong) service X.509 TLS materials: root@edgex-vault:/vault # vault list secret Keys ---- edgex/ root@edgex-vault:/vault # vault list secret/edgex Keys ---- pki/ root@edgex-vault:/vault # vault list secret/edgex/pki Keys ---- tls/ root@edgex-vault:/vault # vault list secret/edgex/pki/tls Keys ---- edgex-kong Displaying the API gateway (Kong) service X.509 TLS materials (TLS certificate cert & corresponding private key key ): root@edgex-vault:/vault # vault read secret/edgex/pki/tls/edgex-kong Key Value --- ----- refresh_interval 168h cert -----BEGIN CERTIFICATE----- MIICrjCCAjWgAwIBAgIQDvZxhmU3nyG4cwXlQesMFDAKBggqhkjOPQQDAzB7MQsw CQYDVQQGEwJVUzELMAkGA1UECBMCQ0ExFjAUBgNVBAcTDVNhbiBGcmFuY2lzY28x FzAVBgNVBAoTDkVkZ2VYRm91bmRyeUNBMRUwEwYDVQQLEwxFZGdlWEZvdW5kcnkxt FzAVBgNVBAMTDkVkZ2VYRm91bmRyeUNBMB4XDTE4MTIwNTE0MDUyOFoXDTI4MTIw NTE0MDUyOFowazELMAkGA1UEBhMCVVMxCzAJBgNVBAgTAkNBMRYwFAYDVQQHEw1T YW4gRnJhbmNpc2NvMRMwEQYDVQQKEwplZGdleC1rb25nMQ0wCwYDVQQLEwRLb25n MRMwEQYDVQQDEwplZGdleC1rb25nMHYwEAYHKoZIzj0CAQYFK4EEACIDYgAE2dnb EboXET1TjzmWKFv3A0wklwNbs9t9JLT0ecpQr64a277UnTAQhgCv2e2/x9EP4eta gSlz5PCqdAykWW0URIEPSwUKWmx4x1DBwyUD2oDOPsFrywIVEC3DlqQAL6huo4GN MIGKMA4GA1UdDwEB/wQEAwIFoDATBgNVHSUEDDAKBggrBgEFBQcDATAMBgNVHRMB Af8EAjAAMB8GA1UdIwQYMBaAFFX63XbmPNpLceOJYyt2Y+LfW/gxMDQGA1UdEQQt MCuCCmVkZ2V4LWtvbmeCEGVkZ2V4LWtvbmcubG9jYWyBC2FkbWluQGxvY2FsMAoG CCqGSM49BAMDA2cAMGQCMCaH3sSKq6nlr6hBJx82wYEiK4slMbySiQZg5mLcwrsQ tIPGcQ2lgBdQYzI3ymOS5gIwNhpQmo/p3hkoFzA4rxIAZx/GUgZan51JlXW0rpgz 4HerRLe55EmvF10mF7VCGOXe -----END CERTIFICATE----- key -----BEGIN PRIVATE KEY----- MIG2AgEAMBAGByqGSM49AgEGBSuBBAAiBIGeMIGbAgEBBDC6BRUXqkJbey765+8b Oib2qG/jbai2rzp0+NQyJv4ijAyYjJlxhVGggZqPPBy8baqhZANiAATZ2dsRuhcR PVOPOZYoW/cDTCSXA1uz230ktPR5ylCvrhrbvtSdMBCGAK/Z7b/H0Q/h61qBKXPk 8Kp0DKRZbRREgQ9LBQpabHjHUMHDJQPagM4+wWvLAhUQLcOWpAAvqG4 = -----END PRIVATE KEY----- Note These two key values are in PEM format. 2nd alternative: using the Vault Web UI. Open a browser session on https://<EdgeX Vault Server>:8200 , accept the self-signed TLS server certificate and sign-in with the Root Token (see above 1st alternative to learn how to fetch this token): {.align-center width=\"606px\" height=\"504px\"} Upper left corner of the current Vault UI session, the sign-out menu displaying the current token name: {.align-center width=\"275px\" height=\"156px\"} Select the Vault secret backend: Navigate the API Gateway (Kong) service X.509 TLS materials path (edgex/pki/tls/edgex-kong): The Vault UI also allows entering Vault CLI commands (see above 1st alternative ) using an embedded console: 3rd alternative: directly using the Vault HTTP API with cURL commands. See paragraph Configuring the Secret Store to have more details on the --cacert option (identical purpose as the VAULT_CAPATH environment variable for Vault CLI). See paragraph Using the Secret Store to have more details on gathering the Vault Root Token (ref: /vault/config/assets/resp-init.json ). See HashiCorp Vault API documentation for further details on syntax and usage ( https://www.vaultproject.io/api/ ). Displaying (GET) the API gateway (Kong) service X.509 TLS materials (TLS certificate cert & corresponding private key key): curl -s --cacert /vault/config/pki/EdgeXFoundryCA/EdgeXFoundryCA.pem \\ --location \\ --header \"X-Vault-Token: 01dbbae4-353a-8cdf-8189-4d50e5535a6f\" \\ --request GET \\ https://edgex-vault:8200/v1/secret/edgex/pki/tls/edgex-kong | jq Note Line 2: the --location option allows following a redirection (necessary when using a Vault cluster) Line 5: the Vault API path prefix /v1/secret and the API Gateway X.509 TLS materials k/v /edgex/pki/tls/edgex-kong . Line 5: the jq tool is a lightweight and flexible command-line JSON processor ( https://stedolan.github.io/jq/ ) allowing JSON pretty printing in the terminal. Sample JSON returned: { \"request_id\" : \"eaa80a1b-0d31-8d11-6ce1-8d9aa3ac6a19\" , \"lease_id\" : \"\" , \"renewable\" : false , \"lease_duration\" : 604800 , \"data\" : { \"cert\" : \"-----BEGIN CERTIFICATE-----\\nMIICrjCCAjWgAwIBAgIQDvZxhmU3nyG4cwXlQesMFDAKBggqhkjOPQQDAzB7MQsw\\nCQYDVQQGEwJVUzELMAkGA1UECBMCQ0ExFjAUBgNVBAcTDVNhbiBGcmFuY2lzY28x\\nFzAVBgNVBAoTDkVkZ2VYRm91bmRyeUNBMRUwEwYDVQQLEwxFZGdlWEZvdW5kcnkx\\nFzAVBgNVBAMTDkVkZ2VYRm91bmRyeUNBMB4XDTE4MTIwNTE0MDUyOFoXDTI4MTIw\\nNTE0MDUyOFowazELMAkGA1UEBhMCVVMxCzAJBgNVBAgTAkNBMRYwFAYDVQQHEw1T\\nYW4gRnJhbmNpc2NvMRMwEQYDVQQKEwplZGdleC1rb25nMQ0wCwYDVQQLEwRLb25n\\nMRMwEQYDVQQDEwplZGdleC1rb25nMHYwEAYHKoZIzj0CAQYFK4EEACIDYgAE2dnb\\nEboXET1TjzmWKFv3A0wklwNbs9t9JLT0ecpQr64a277UnTAQhgCv2e2/x9EP4eta\\ngSlz5PCqdAykWW0URIEPSwUKWmx4x1DBwyUD2oDOPsFrywIVEC3DlqQAL6huo4GN\\nMIGKMA4GA1UdDwEB/wQEAwIFoDATBgNVHSUEDDAKBggrBgEFBQcDATAMBgNVHRMB\\nAf8EAjAAMB8GA1UdIwQYMBaAFFX63XbmPNpLceOJYyt2Y+LfW/gxMDQGA1UdEQQt\\nMCuCCmVkZ2V4LWtvbmeCEGVkZ2V4LWtvbmcubG9jYWyBC2FkbWluQGxvY2FsMAoG\\nCCqGSM49BAMDA2cAMGQCMCaH3sSKq6nlr6hBJx82wYEiK4slMbySiQZg5mLcwrsQ\\ntIPGcQ2lgBdQYzI3ymOS5gIwNhpQmo/p3hkoFzA4rxIAZx/GUgZan51JlXW0rpgz\\n4HerRLe55EmvF10mF7VCGOXe\\n-----END CERTIFICATE-----\\n\" , \"key\" : \"-----BEGIN PRIVATE KEY-----\\nMIG2AgEAMBAGByqGSM49AgEGBSuBBAAiBIGeMIGbAgEBBDC6BRUXqkJbey765+8b\\nOib2qG/jbai2rzp0+NQyJv4ijAyYjJlxhVGggZqPPBy8baqhZANiAATZ2dsRuhcR\\nPVOPOZYoW/cDTCSXA1uz230ktPR5ylCvrhrbvtSdMBCGAK/Z7b/H0Q/h61qBKXPk\\n8Kp0DKRZbRREgQ9LBQpabHjHUMHDJQPagM4+wWvLAhUQLcOWpAAvqG4=\\n-----END PRIVATE KEY-----\\n\" }, \"wrap_info\" : null , \"warnings\" : null , \"auth\" : null } Note Lines 7 & 8: the two key values (TLS certificate cert & corresponding private key key ) are in PEM format ( https://tools.ietf.org/html/rfc1421 ). Displaying (LIST) the root key path in the Vault secret backend for the EdgeX Foudry platform ( edgex ): curl -s --cacert /vault/config/pki/EdgeXFoundryCA/EdgeXFoundryCA.pem \\ --location \\ --header \"X-Vault-Token: 01dbbae4-353a-8cdf-8189-4d50e5535a6f\" \\ --request LIST \\ https://edgex-vault:8200/v1/secret | jq Sample JSON returned: { \"request_id\" : \"0e0ea024-176d-21b3-73cb-99f17729b230\" , \"lease_id\" : \"\" , \"renewable\" : false , \"lease_duration\" : 0 , \"data\" : { \"keys\" : [ \"edgex/\" ] }, \"wrap_info\" : null , \"warnings\" : null , \"auth\" : null } Displaying (GET) the Vault seal status ( API path: /v1/sys/seal-status ): curl -s --cacert /vault/config/pki/EdgeXFoundryCA/EdgeXFoundryCA.pem \\ --location \\ --header \"X-Vault-Token: 01dbbae4-353a-8cdf-8189-4d50e5535a6f\" \\ --request GET \\ https://edgex-vault:8200/v1/sys/seal-status | jq Sample JSON returned: { \"type\" : \"shamir\" , \"sealed\" : false , \"t\" : 1 , \"n\" : 1 , \"progress\" : 0 , \"nonce\" : \"\" , \"version\" : \"0.10.2\" , \"cluster_name\" : \"vault-cluster-57b3c4ed\" , \"cluster_id\" : \"fe6d18bf-fa9c-0d52-3278-bca0390af023\" } Note Line 3: Vault is unsealed therefore available and ready for requests. Line 4 & 5: Vault Shamir Secret Sharing default configuration for EdgeX Foundry: 1 share with threshold 1 (no sharding). See also Some of the command used in implementing security services have man-style documentation: security-file-token-provider - Generate Vault tokens for EdgeX services security-secrets-setup - Creates an on-device public-key infrastructure (PKI) to secure microservice secret management","title":"Secret Store"},{"location":"microservices/security/Ch-SecretStore/#secret-store","text":"There are all kinds of secrets used within EdgeX Foundry micro services, such as tokens, passwords, certificates etc. The secret store serves as the central repository to keep these secrets. The developers of other EdgeX Foundry micro services utilize the secret store to create, store and retrieve secrets relevant to their corresponding micro service. The communications the between secret store and other micro services are secured by TLS. Currently the EdgeX Foundry secret store is implemented with Vault , a HashiCorp open source software product. Vault is a tool for securely accessing secrets. A secret is anything that you want to tightly control access to, such as API keys, passwords, database credentials, service credentials, or certificates. Vault provides a unified interface to any secret, while providing tight access control and multiple authentication mechanisms (token, LDAP, etc.). Vault adds on key rolling, revocation rules, time-to-live access tokens, secure storage, Shamir Secret Sharing based unlocking mechanism, high availability and detailed auditing. Vault can use several backend systems (filesystem, databases, Consul, Etcd, S3, Azure, etc.) to securely store every sensitive asset. The current EdgeX Foundry implementation of Vault is using Consul , another HashiCorp open source software product. Consul is a distributed service mesh to connect, secure, and configure services across any runtime platform and public or private cloud. Consul uses a consensus protocol to provide Consistency as defined by CAP . The consensus protocol is based on \"Raft: In search of an Understandable Consensus Algorithm\" . For a visual explanation of Raft, see The Secret Lives of Data . The seamless integration of Vault and Consul provides a strong yet simple infrastructure to setup a reliable high availability architecture (Vault failover nodes, Consul Clustering) for the EdgeX Foundry Security services in production. The key features of Vault are: Secure Secret Storage: Arbitrary key/value secrets can be stored in Vault. Vault encrypts these secrets prior to writing them to persistent storage, so gaining access to the raw storage isn't enough to access your secrets. Authentication mechanisms (internal and/or external) and authorizations based upon policies provide access management. Dynamic Secrets: Vault can generate secrets on-demand for some systems, automatically revoking them after the lease is up. Data Encryption: Vault can encrypt and decrypt data without storing it. Leasing and Renewal: All secrets in Vault have a lease associated with them (automatic revocation). However, clients can renew leases via built-in renew APIs. Revocation: Vault has built-in support for secret revocation. Single secrets, but also a tree of secrets. Revocation assists in key rolling as well as locking down systems in the case of an intrusion.","title":"Secret Store"},{"location":"microservices/security/Ch-SecretStore/#start-the-secret-store","text":"Start the Secret Store with Docker Compose and a Docker Compose manifest file. The whole set of Docker Compose files for Geneva release can be found here: https://github.com/edgexfoundry/developer-scripts/blob/master/releases/geneva/compose-files The Compose file starts the entire EdgeX Foundry platform with Redis including the security services. The command to start EdgeX Foundry platform including the Secret Store and API gateway related services is: sh> docker-compose up -d For a pristine run, it is strongly recommended to thoroughly clean up any Docker artifacts remaining from the current run. sh> docker-compose down -v The \"down\" operation will remove containers, network and adding the -v option it will also remove persistent volumes: Stopping edgex-vault ... done Stopping edgex-core-consul ... done Stopping edgex-files ... done Removing edgex-vault-worker ... done Removing edgex-vault ... done Removing edgex-config-seed ... done Removing edgex-core-consul ... done Removing edgex-files ... done Removing network security-secret-store_edgex-network Removing volume security-secret-store_db-data Removing volume security-secret-store_log-data Removing volume security-secret-store_consul-config Removing volume security-secret-store_consul-data Removing volume security-secret-store_vault-config Removing volume security-secret-store_vault-file Removing volume security-secret-store_vault-logs","title":"Start the Secret Store"},{"location":"microservices/security/Ch-SecretStore/#troubleshooting-steps","text":"For debugging purpose, the Secret Store services can be started individually with these commands. A pre-requisite being to carefully follow the invocation sequence in order to avoid any dependency failure. Lines starting with # (hashtag) are contextual comments to explicit the purpose of the above corresponding command:","title":"Troubleshooting steps"},{"location":"microservices/security/Ch-SecretStore/#clean-up","text":"sh> cd <path-to-EdgeX-Foundry-Secret-Store> # <...>/security-secret-store/ sh> docker-compose down -v sh> docker-compose ps # Check no previous container is running sh> docker volume ls # Check and remove any previous persistent and/or unused volumes sh> docker volume prune sh> docker volume rm <volume-name> sh> docker network ls # Check and remove the previous EdgeX Foundry Docker network sh> docker network rm edgex-network","title":"Clean-up"},{"location":"microservices/security/Ch-SecretStore/#start-the-first-service-volume-platform-volume-initializations","text":"sh> docker-compose up -d volume Sample output: Creating network \"security-secret-store_edgex-network\" with driver \"bridge\" Creating volume \"security-secret-store_db-data\" with default driver Creating volume \"security-secret-store_log-data\" with default driver Creating volume \"security-secret-store_consul-config\" with default driver Creating volume \"security-secret-store_consul-data\" with default driver Creating volume \"security-secret-store_vault-config\" with default driver Creating volume \"security-secret-store_vault-file\" with default driver Creating volume \"security-secret-store_vault-logs\" with default driver Creating edgex-files ... done","title":"Start the first service: volume (platform volume initializations)"},{"location":"microservices/security/Ch-SecretStore/#start-the-second-service-consul-consul-is-vault-store-backend","text":"sh> docker-compose up -d consul Sample output: edgex-files is up-to-date Creating edgex-core-consul ... done Display and inspect consul service logs: important lines are highlighted sh> docker-compose logs consul Sample output: Attaching to edgex-core-consul edgex-core-consul | ==> Starting Consul agent... edgex-core-consul | ==> Consul agent running! edgex-core-consul | Version: 'v1.1.0' edgex-core-consul | Node ID: '371cbce6-02a8-65f6-ddea-6df5c40a4c50' edgex-core-consul | Node name: 'edgex-core-consul' edgex-core-consul | Datacenter: 'dc1' (Segment: '<all>') edgex-core-consul | Server: true (Bootstrap: false) edgex-core-consul | Client Addr: [0.0.0.0] (HTTP: 8500, HTTPS: -1, DNS: 8600) edgex-core-consul | Cluster Addr: 127.0.0.1 (LAN: 8301, WAN: 8302) edgex-core-consul | Encrypt: Gossip: false, TLS-Outgoing: false, TLS-Incoming: false edgex-core-consul | edgex-core-consul | ==> Log data will now stream in as it occurs: edgex-core-consul | edgex-core-consul | 2019/01/13 13:25:06 [DEBUG] agent: Using random ID \"371cbce6-02a8-65f6-ddea-6df5c40a4c50\" as node ID edgex-core-consul | 2019/01/13 13:25:06 [INFO] raft: Initial configuration (index=1): [{Suffrage:Voter ID:371cbce6-02a8-65f6-ddea-6df5c40a4c50 Address:127.0.0.1:8300}] edgex-core-consul | 2019/01/13 13:25:06 [INFO] raft: Node at 127.0.0.1:8300 [Follower] entering Follower state (Leader: \"\") edgex-core-consul | 2019/01/13 13:25:06 [INFO] serf: EventMemberJoin: edgex-core-consul.dc1 127.0.0.1 edgex-core-consul | 2019/01/13 13:25:06 [INFO] serf: EventMemberJoin: edgex-core-consul 127.0.0.1 edgex-core-consul | 2019/01/13 13:25:06 [INFO] consul: Adding LAN server edgex-core-consul (Addr: tcp/127.0.0.1:8300) (DC: dc1) edgex-core-consul | 2019/01/13 13:25:06 [INFO] consul: Handled member-join event for server \"edgex-core-consul.dc1\" in area \"wan\" edgex-core-consul | 2019/01/13 13:25:06 [INFO] agent: Started DNS server 0.0.0.0:8600 (tcp) edgex-core-consul | 2019/01/13 13:25:06 [INFO] agent: Started DNS server 0.0.0.0:8600 (udp) edgex-core-consul | 2019/01/13 13:25:06 [INFO] agent: Started HTTP server on [::]:8500 (tcp) edgex-core-consul | 2019/01/13 13:25:06 [INFO] agent: started state syncer edgex-core-consul | 2019/01/13 13:25:06 [WARN] raft: Heartbeat timeout from \"\" reached, starting election edgex-core-consul | 2019/01/13 13:25:06 [INFO] raft: Node at 127.0.0.1:8300 [Candidate] entering Candidate state in term 2 edgex-core-consul | 2019/01/13 13:25:06 [DEBUG] raft: Votes needed: 1 edgex-core-consul | 2019/01/13 13:25:06 [DEBUG] raft: Vote granted from 371cbce6-02a8-65f6-ddea-6df5c40a4c50 in term 2. Tally: 1 edgex-core-consul | 2019/01/13 13:25:06 [INFO] raft: Election won. Tally: 1 edgex-core-consul | 2019/01/13 13:25:06 [INFO] raft: Node at 127.0.0.1:8300 [Leader] entering Leader state edgex-core-consul | 2019/01/13 13:25:06 [INFO] consul: cluster leadership acquired","title":"Start the second service: consul (Consul is Vault store backend)"},{"location":"microservices/security/Ch-SecretStore/#start-the-third-service-config-seed-platform-configuration-initializations","text":"sh> docker-compose up -d config-seed Sample output: edgex-files is up-to-date edgex-core-consul is up-to-date Creating edgex-config-seed ... done Display and inspect the created container states: important lines are highlighted sh> docker-compose ps Sample output: Name Command State Ports ---------------------------------------------------------------------------------------------------------------------------------------edgex-config-seed /bin/sh -c /edgex/cmd/conf ... Exit 0 edgex-core-consul docker-entrypoint.sh agent ... Up 8300/tcp, 8301/tcp, 8301/udp, 8302/tcp, 8302/udp, 0.0.0.0:8400->8400/tcp, 0.0.0.0:8500->8500/tcp, 0.0.0.0:8600->8600/tcp, 8600/udp edgex-files /bin/sh -c /usr/bin/tail - ... Up Note Line 3: edgex-config-seed service has exited after successful processing (exit code 0)","title":"Start the third service: config-seed (platform configuration initializations)"},{"location":"microservices/security/Ch-SecretStore/#start-the-fourth-service-vault-vault-tool","text":"Note Vault will be uninitialized and unsealed upon success. The vault-worker service will process the initialization and unsealing tasks. sh> docker-compose up -d vault Sample output: edgex-files is up-to-date edgex-core-consul is up-to-date Creating edgex-vault ... done Display and inspect \"vault\" service logs: important lines are highlighted sh> docker-compose logs vault Sample output: Attaching to edgex-vault edgex-vault | ==> Vault server configuration: edgex-vault | edgex-vault | Api Address: https://edgex-vault:8200 edgex-vault | Cgo: disabled edgex-vault | Cluster Address: https://edgex-vault:8201 edgex-vault | Listener 1: tcp (addr: \"edgex-vault:8200\", cluster address: \"edgex-vault:8201\", tls: \"enabled\") edgex-vault | Log Level: info edgex-vault | Mlock: supported: true, enabled: true edgex-vault | Storage: consul (HA available) edgex-vault | Version: Vault v0.10.2 edgex-vault | Version Sha: 3ee0802ed08cb7f4046c2151ec4671a076b76166 edgex-vault | edgex-vault | ==> Vault server started! Log data will stream in below: edgex-vault | Note Line 4 & 7: Vault API endpoint on port 8200 (lines 4 and 7). Line 7: Vault has TLS enabled. Line 10: Vault backend storage is Consul .","title":"Start the fourth service: vault (Vault tool)"},{"location":"microservices/security/Ch-SecretStore/#start-the-fifth-service-vault-worker-vault-initunseal-process-and-setups","text":"sh> docker-compose up -d vault-worker Sample output: edgex-files is up-to-date edgex-core-consul is up-to-date edgex-vault is up-to-date Creating edgex-vault-worker ... done Display and inspect \"vault-worker\" service logs: important lines are highlighted sh> docker-compose logs vault-worker Sample output: Attaching to edgex-vault-worker edgex-vault-worker | INFO: 2019/01/13 13:35:42 successful loading the rootCA cert. edgex-vault-worker | INFO: 2019/01/13 13:35:43 {\"keys\":[\"564b9444eebe28b393c21a4dca1e32835b7dc27f5da03b73d22b666cb20224a9\"],\"keys_base64\":[\"VkuURO6+KLOTwhpNyh4yg1t9wn9doDtz0itmbLICJKk=\"],\"recovery_keys\":null,\"recovery_keys_base64\":null,\"root_token\":\"01dbbae4-353a-8cdf-8189-4d50e5535a6f\"} edgex-vault-worker | INFO: 2019/01/13 13:35:43 Vault has been initialized successfully. edgex-vault-worker | INFO: 2019/01/13 13:35:43 Vault has been unsealed successfully. edgex-vault-worker | INFO: 2019/01/13 13:35:48 Vault Health Check HTTP Status: 200 OK (StatusCode: 200) edgex-vault-worker | INFO: 2019/01/13 13:35:48 Verifying Admin policy file hash (SHA256). edgex-vault-worker | INFO: 2019/01/13 13:35:48 Vault policy file checksum (SHA256): 5ce8d58cf7d931735f6532742f677c109a91a263bcefe9aef73ab2a69f4b43d3 edgex-vault-worker | INFO: 2019/01/13 13:35:48 Reading Admin policy file. edgex-vault-worker | INFO: 2019/01/13 13:35:48 Importing Vault Admin policy. edgex-vault-worker | INFO: 2019/01/13 13:35:48 Import Policy Successfull. edgex-vault-worker | INFO: 2019/01/13 13:35:48 Reading Kong policy file. edgex-vault-worker | INFO: 2019/01/13 13:35:48 Importing Vault Kong policy. edgex-vault-worker | INFO: 2019/01/13 13:35:48 Import Policy Successfull. edgex-vault-worker | INFO: 2019/01/13 13:35:48 Creating Vault Admin token. edgex-vault-worker | INFO: 2019/01/13 13:35:48 Create Token Successfull. edgex-vault-worker | INFO: 2019/01/13 13:35:48 Creating Vault Kong token. edgex-vault-worker | INFO: 2019/01/13 13:35:48 Create Token Successfull. edgex-vault-worker | INFO: 2019/01/13 13:35:48 Successful on reading certificate from v1/secret/edgex/pki/tls/edgex-kong. edgex-vault-worker | INFO: 2019/01/13 13:35:48 Cert&key are not in the secret store yet, will need to upload them. edgex-vault-worker | INFO: 2019/01/13 13:35:48 Load cert&key pair from volume successfully, now will upload to secret store. edgex-vault-worker | INFO: 2019/01/13 13:35:48 Trying to upload cert&key to secret store. edgex-vault-worker | INFO: 2019/01/13 13:35:48 Successful to add certificate to the secret store. Display and inspect \"vault\" service logs: important lines are highlighted sh> docker-compose logs vault Sample output: Attaching to edgex-vault edgex-vault | ==> Vault server configuration: edgex-vault | edgex-vault | Api Address: https://edgex-vault:8200 edgex-vault | Cgo: disabled edgex-vault | Cluster Address: https://edgex-vault:8201 edgex-vault | Listener 1: tcp (addr: \"edgex-vault:8200\", cluster address: \"edgex-vault:8201\", tls: enabled\") edgex-vault | Log Level: info edgex-vault | Mlock: supported: true, enabled: true edgex-vault | Storage: consul (HA available) edgex-vault | Version: Vault v0.10.2 edgex-vault | Version Sha: 3ee0802ed08cb7f4046c2151ec4671a076b76166 edgex-vault | edgex-vault | ==> Vault server started! Log data will stream in below: edgex-vault | edgex-vault | 2019-01-13T13:35:42.549Z [INFO ] core: security barrier not initialized edgex-vault | 2019-01-13T13:35:42.551Z [INFO ] core: security barrier not initialized edgex-vault | 2019-01-13T13:35:42.554Z [INFO ] core: security barrier initialized: shares=1 threshold=1 edgex-vault | 2019-01-13T13:35:42.575Z [INFO ] core: post-unseal setup starting edgex-vault | 2019-01-13T13:35:42.583Z [INFO ] core: loaded wrapping token key edgex-vault | 2019-01-13T13:35:42.583Z [INFO ] core: successfully setup plugin catalog: plugin-directory= edgex-vault | 2019-01-13T13:35:42.584Z [INFO ] core: no mounts; adding default mount table edgex-vault | 2019-01-13T13:35:42.585Z [INFO ] core: successfully mounted backend: type=kv path=secret/ edgex-vault | 2019-01-13T13:35:42.586Z [INFO ] core: successfully mounted backend: type=cubbyhole path=cubbyhole/ edgex-vault | 2019-01-13T13:35:42.586Z [INFO ] core: successfully mounted backend: type=system path=sys/ edgex-vault | 2019-01-13T13:35:42.586Z [INFO ] core: successfully mounted backend: type=identity path=identity/ edgex-vault | 2019-01-13T13:35:42.593Z [INFO ] core: restoring leases edgex-vault | 2019-01-13T13:35:42.593Z [INFO ] rollback: starting rollback manager edgex-vault | 2019-01-13T13:35:42.594Z [INFO ] expiration: lease restore complete edgex-vault | 2019-01-13T13:35:42.596Z [INFO ] identity: entities restored edgex-vault | 2019-01-13T13:35:42.597Z [INFO ] identity: groups restored edgex-vault | 2019-01-13T13:35:42.597Z [INFO ] core: post-unseal setup complete edgex-vault | 2019-01-13T13:35:42.597Z [INFO ] core: core/startClusterListener: starting listener: listener_address=172.19.0.4:8201 edgex-vault | 2019-01-13T13:35:42.597Z [INFO ] core: core/startClusterListener: serving cluster requests: cluster_listen_address=172.19.0.4:8201 edgex-vault | 2019-01-13T13:35:42.600Z [INFO ] core: root token generated edgex-vault | 2019-01-13T13:35:42.600Z [INFO ] core: pre-seal teardown starting edgex-vault | 2019-01-13T13:35:42.600Z [INFO ] core: stopping cluster listeners edgex-vault | 2019-01-13T13:35:42.600Z [INFO ] core: shutting down forwarding rpc listeners edgex-vault | 2019-01-13T13:35:42.600Z [INFO ] core: forwarding rpc listeners stopped edgex-vault | 2019-01-13T13:35:43.099Z [INFO ] core: rpc listeners successfully shut down edgex-vault | 2019-01-13T13:35:43.099Z [INFO ] core: cluster listeners successfully shut down edgex-vault | 2019-01-13T13:35:43.100Z [INFO ] rollback: stopping rollback manager edgex-vault | 2019-01-13T13:35:43.100Z [INFO ] core: pre-seal teardown complete edgex-vault | 2019-01-13T13:35:43.105Z [INFO ] core: vault is unsealed edgex-vault | 2019-01-13T13:35:43.105Z [INFO ] core: entering standby mode edgex-vault | 2019-01-13T13:35:43.109Z [INFO ] core: acquired lock, enabling active operation edgex-vault | 2019-01-13T13:35:43.134Z [INFO ] core: post-unseal setup starting edgex-vault | 2019-01-13T13:35:43.135Z [INFO ] core: loaded wrapping token key edgex-vault | 2019-01-13T13:35:43.135Z [INFO ] core: successfully setup plugin catalog: plugin-directory= edgex-vault | 2019-01-13T13:35:43.137Z [INFO ] core: successfully mounted backend: type=kv path=secret/ edgex-vault | 2019-01-13T13:35:43.137Z [INFO ] core: successfully mounted backend: type=system path=sys/ edgex-vault | 2019-01-13T13:35:43.137Z [INFO ] core: successfully mounted backend: type=identity path=identity/ edgex-vault | 2019-01-13T13:35:43.137Z [INFO ] core: successfully mounted backend: type=cubbyhole path=cubbyhole/ edgex-vault | 2019-01-13T13:35:43.141Z [INFO ] core: restoring leases edgex-vault | 2019-01-13T13:35:43.142Z [INFO ] rollback: starting rollback manager edgex-vault | 2019-01-13T13:35:43.142Z [INFO ] expiration: lease restore complete edgex-vault | 2019-01-13T13:35:43.143Z [INFO ] identity: entities restored edgex-vault | 2019-01-13T13:35:43.143Z [INFO ] identity: groups restored edgex-vault | 2019-01-13T13:35:43.144Z [INFO ] core: post-unseal setup complete edgex-vault | 2019-01-13T13:35:43.144Z [INFO ] core: core/startClusterListener: starting listener: listener_address=172.19.0.4:8201 edgex-vault | 2019-01-13T13:35:43.144Z [INFO ] core: core/startClusterListener: serving cluster requests: cluster_listen_address=172.19.0.4:8201 Note Line 18: Vault initialization successful. Line 35: Vault root token generated. Line 44: Vault unsealing successful. Line 50: Vault key/value store secret successfully mounted . Line 60 & 61: Vault successfully started . Display and inspect the created container states: important lines are highlighted sh> docker-compose ps Sample output: Name Command State Ports ---------------------------------------------------------------------------------------------------------------------------------------edgex-config-seed /bin/sh -c /edgex/cmd/conf ... Exit 0 edgex-core-consul docker-entrypoint.sh agent ... Up 8300/tcp, 8301/tcp, 8301/udp, 8302/tcp, 8302/udp, 0.0.0.0:8400->8400/tcp, 0.0.0.0:8500->8500/tcp, 0.0.0.0:8600->8600/tcp, 8600/udp edgex-files /bin/sh -c /usr/bin/tail - ... Up edgex-vault docker-entrypoint.sh serve ... Up 0.0.0.0:8200->8200/tcp edgex-vault-worker ./edgex-vault-worker --ini ... Exit 0 Note Line 9: edgex-vault-worker service has exited after successful processing (exit code 0) Display and inspect the created container volumes: important lines are highlighted sh> docker volume ls DRIVER VOLUME NAME local security-secret-store_consul-config local security-secret-store_consul-data local security-secret-store_db-data local security-secret-store_log-data local security-secret-store_vault-config local security-secret-store_vault-file local security-secret-store_vault-logs Display and inspect the container network ( security-secret-store_edgex-network ): important lines are highlighted sh> docker network ls NETWORK ID NAME DRIVER SCOPE 63227826fbc7 bridge bridge local 60763abffde3 host host local 1d236ab1dbbd none null local 0a7f7266d102 security-secret-store_edgex-network bridge local","title":"Start the fifth service: vault-worker (Vault init/unseal process and setups)"},{"location":"microservices/security/Ch-SecretStore/#using-consul-web-ui","text":"For learning and verification purposes one might use the Consul Web UI interface to gather and double check specific Vault informations. Consul Web UI endpoint port is exposed by the Docker compose file. EdgeX Foundry platform uses the Consul default port number 8500. It is normally not recommended to expose Consul UI port number in production, at least the UI should not be accessible from outside the platform environment. However, because all the Vault secrets are encrypted before being transmitted and stored in the Consul backend, having access to Consul is not sufficient to access any secrets, the vault data encryption/decryption key would be absolutely necessary. Open a Web browser on http://<EdgeX Consul Server>:8500/ui . On the screenshot below, after selecting SERVICES and Vault , the UI will show the various Vault status (heartbeat and init/unseal states), coloring the boxes in green, orange or red depending on the level of importance (info, warning, error). By clicking each of the right side status indicators, more information will be accessible in order to better inspect any situation. As a practical example, we are going to navigate the Consul structure for Vault in order to check if the API Gateway (Kong) TLS certificate and private key were fetched and stored accordingly during the vault-worker process. First select KEY/VALUE menu, and then select vault root structure: We are now going to navigate deeper in the vault tree structure to reach and display the EdgeX Kong TLS assets. Continue by selecting logical/ : {.align-center width=\"348px\" height=\"287px\"} Then select d7809b... an arbitrary UID generated and created by Consul during Vault registration: {.align-center width=\"377px\" height=\"216px\"} Select edgex/ : {.align-center width=\"419px\" height=\"228px\"} Select pki/ : {.align-center width=\"417px\" height=\"222px\"} Select tls/ : {.align-center width=\"418px\" height=\"237px\"} Select edgex-kong/ : {.align-center width=\"423px\" height=\"233px\"} And we are now finally able to display the encrypted Vault secret containing the API Gateway (Kong) TLS server certificate and its corresponding private key. As you can see on the screenshot below the Vault key/value is encrypted and totally opaque to Consul, the Vault data encryption key (DEK) would be necessary to decrypt these secrets. Each Vault secret is encrypted before being transmitted to Consul node(s).","title":"Using Consul Web UI"},{"location":"microservices/security/Ch-SecretStore/#shell-access-to-consul-container-and-using-consul-cli","text":"sh> docker exec -it -e PS1 = '\\u@\\h:\\w \\$ ' edgex-core-consul sh root@edgex-core-consul:/ # consul members Node Address Status Type Build Protocol DC Segment edgex-core-consul 127 .0.0.1:8301 alive server 1 .1.0 2 dc1 <all> root@edgex-core-consul:/ # consul catalog nodes Node ID Address DC edgex-core-consul e49af36a 127 .0.0.1 dc1 root@edgex-core-consul:/ # consul catalog services consul edgex-mongo vault Note Line 5: Shows the Consul node status alive (1 node in EdgeX default configuration). Line 9: Shows the Consul nodes (1 node in EdgeX default configuration). Lines 12-14: Show the Consul registered services.","title":"Shell Access to Consul Container and Using Consul CLI"},{"location":"microservices/security/Ch-SecretStore/#configuring-the-secret-store","text":"Vault server configuration is essentially concentrated in one JSON file named local.json . This file was prepared during the Vault Docker image build process. In the eventuality of a change, the Vault server container should be accessed to then modify the JSON file. The absolute path being /vault/config/local.json . To reload the new configuration simply send Vault PID a HUP signal to trigger a configuration reload. Sample Vault server configuration file: listener \"tcp\" { address = \"edgex-vault:8200\" tls_disable = \"0\" cluster_address = \"edgex-vault:8201\" tls_min_version = \"tls12\" tls_client_ca_file =\"/vault/config/pki/EdgeXFoundryCA/EdgeXFoundryCA.pem\" tls_cert_file =\"/vault/config/pki/EdgeXFoundryCA/edgex-vault.pem\" tls_key_file = \"/vault/config/pki/EdgeXFoundryCA/edgex-vault.priv.key\" } backend \"consul\" { path = \"vault/\" address = \"edgex-core-consul:8500\" scheme = \"http\" redirect_addr = \"https://edgex-vault:8200\" cluster_addr = \"https://edgex-vault:8201\" } default_lease_ttl = \"168h\" max_lease_ttl = \"720h\" The listener clause refers to Vault server process (port, TLS and server name), the backend clause refers to the storage backend (i.e. Consul). To modify this configuration file, execute a shell session in the running Vault container: sh> docker exec -it -e PS1 = '\\u@\\h:\\w \\$ ' -e VAULT_CAPATH = '/vault/config/pki/EdgeXFoundryCA/EdgeXFoundryCA.pem' edgex-vault sh root@edgex-vault:/vault # ls -l total 12 drwxr-xr-x 4 vault vault 4096 Jan 13 13 :34 config drwxr-xr-x 2 vault vault 4096 Jun 7 2018 file drwxr-xr-x 2 vault vault 4096 Jun 7 2018 logs Pay attention to the VAULT_CAPATH environment variable passed to the session. This is necessary in order to run succesful Vault CLI command. Every Vault CLI command is a wrapper of the Vault HTTP API. The Vault server is configured with TLS using X.509 PKI materials generated and signed by a local self-signed CA (EdgeXFoundryCA). Therefore, in order for each Vault CLI command (or to that extent cURL commands) to verify the Vault server TLS certificate, the self-signing CA root certificate would have to be known by the CLI command interpreter. This VAULT_CAPATH variable is checked by every Vault CLI commands, alternatively each Vault CLI command can specify an option with the same certificate path if the variable is not set. The self-signed Root CA certificate path can be found in the Vault configuration file (see above local.json), with parameter tls_client_ca_file =\"/vault/config/pki/EdgeXFoundryCA/EdgeXFoundryCA.pem\" . The local.json configuration file can be read and modified within the running container: <root@edgex-vault>:/vault \\# cat config/local.json listener \"tcp\" { address = \"edgex-vault:8200\" tls\\_disable = \"0\" cluster\\_address =\"edgex-vault:8201\" tls\\_min\\_version = \"tls12\" tls\\_client\\_ca\\_file=\"/vault/config/pki/EdgeXFoundryCA/EdgeXFoundryCA.pem\" tls\\_cert\\_file=\"/vault/config/pki/EdgeXFoundryCA/edgex-vault.pem\" tls\\_key\\_file = \"/vault/config/pki/EdgeXFoundryCA/edgex-vault.priv.key\" } backend \"consul\" { path = \"vault/\" address = \"edgex-core-consul:8500\" scheme = \"http\" redirect\\_addr =\"<https://edgex-vault:8200>\" cluster\\_addr =\"<https://edgex-vault:8201>\" } default\\_lease\\_ttl = \"168h\" max\\_lease\\_ttl = \"720h\" A sample Vault CLI command to check Vault status: root@edgex-vault:/vault # vault status Key Value --- ----- Seal Type shamir Sealed false Total Shares 1 Threshold 1 Version 0 .10.2 Cluster Name vault-cluster-57b3c4ed Cluster ID fe6d18bf-fa9c-0d52-3278-bca0390af023 HA Enabled true HA Cluster https://edgex-vault:8201 HA Mode active All the X.509 PKI materials including the self-signing CA are located under /vault/config/pki/EdgeXFoundryCA . root@edgex-vault:/vault # ls -l config/pki/EdgeXFoundryCA/ total 24 -rw-r--r-- 1 vault vault 956 Dec 5 14 :05 EdgeXFoundryCA.pem -r-------- 1 vault vault 306 Dec 5 14 :05 EdgeXFoundryCA.priv.key -rw-r--r-- 1 vault vault 989 Dec 5 14 :05 edgex-kong.pem -rw------- 1 vault vault 306 Dec 5 14 :05 edgex-kong.priv.key -rw-r--r-- 1 vault vault 1001 Dec 5 14 :05 edgex-vault.pem -rw------- 1 vault vault 306 Dec 5 14 :05 edgex-vault.priv.key Note Line 3: self-signing root CA certificate. Line 4: self-signing root CA private key. Line 5: API Gateway (Kong) TLS server certificate. Line 6: API Gateway (Kong) TLS server certificate private key. Line 7: Vault TLS server certificate. Line 8: Vault TLS server certificate private key. The CA name (EdgeXFoundryCA) was defined by the pkisetup tool during the Vault image build process. This tool is also responsible for all the TLS server configuration and creation tasks. If you are willing to change any of the Vault X.509 PKI assets or configuration parameters you will have to modify the pkisetup-vault.json file and rebuild a new Vault Docker image. Similarly to Vault, each EdgeX Foundry service having a TLS server certificate and private key had its X.509 PKI assets generated and signed during the Vault Docker image build process. Therefore, the API Gateway (Kong) configuration file named pkisetup-kong.json would have to be modified accordingly. A new Vault Docker image would have to be built. The Vault Dockerfile contains the pkisetup executions, see below for a corresponding excerpt (highlighted lines): # Create assets folder (needed for unseal key/s, root token and tmp) # Run CA/Vault and Kong PKI/TLS setups and peform housekeeping tasks RUN mkdir /vault/config/assets && \\ chown -R vault:vault /vault && \\ chmod 644 /vault/config/local.json && \\ chmod 744 pkisetup* && \\ ./pkisetup --config pkisetup-vault.json && \\ echo \"\" && \\ ./pkisetup --config pkisetup-kong.json && \\ chown -R vault:vault /vault/config/pki && \\ rm -f /vault/pkisetup /vault/pkisetup-vault.json /vault/pkisetup-kong.json EdgeX Foundry Docker environment implements a basic Vault/Consul architecture that does not provide high availability guaranties. Only one Consul server and one Vault server will be running. In a more sophisticated production environment it would be possible to build a reliable high availability infrastructure regarding Consul and Vault. To facilitate the setup of a minimal failover architecture the security-secret-store repository provides a sample folder named Full-Architecture-Prototype that contains necessary materials (scripts, helpers, configurations, etc.) to achieve that goal. These samples describe an architecture design with two Vault servers in failover mode (active/standby), using each one a Consul client, which subsequently connects to a Consul cluster of 3 nodes (minimal Raft concensus quorum). The Consul clients and servers (nodes) have redundant paths.","title":"Configuring the Secret Store"},{"location":"microservices/security/Ch-SecretStore/#using-the-secret-store","text":"","title":"Using the Secret Store"},{"location":"microservices/security/Ch-SecretStore/#1st-alternative-executing-a-shell-session-in-the-active-vault-container-to-run-vault-cli-commands","text":"See paragraph Configuring the Secret Store to have more details on the VAULT_CAPATH environment variable. See HashiCorp Vault API documentation for further details on syntax and usage ( https://www.vaultproject.io/api/ ). Execute a shell session in the running Vault container: sh> docker exec -it -e PS1 = '\\u@\\h:\\w \\$ ' -e VAULT_CAPATH = '/vault/config/pki/EdgeXFoundryCA/EdgeXFoundryCA.pem' edgex-vault sh Locate the assets folder, and the resp-init.json file: root@edgex-vault:/vault # ls -l config/assets/ total 12 -rw-r--r-- 1 root root 366 Jan 13 13 :35 admin-token.json -rw-r--r-- 1 root root 365 Jan 13 13 :35 kong-token.json -rw-r--r-- 1 root root 241 Jan 13 13 :35 resp-init.json Inspect the resp-init.json file to grab the Vault Root Token: root@edgex-vault:/vault # cat config/assets/resp-init.json { \"keys\" : [ \"564b9444eebe28b393c21a4dca1e32835b7dc27f5da03b73d22b666cb20224a9\" ] , \"keys_base64\" : [ \"VkuURO6+KLOTwhpNyh4yg1t9wn9doDtz0itmbLICJKk=\" ] , \"recovery_keys\" :null, \"recovery_keys_base64\" :null, \"root_token\" : \"01dbbae4-353a-8cdf-8189-4d50e5535a6f\" } Login to Vault using Vault CLI and the gathered Root Token: root@edgex-vault:/vault # vault login 01dbbae4-353a-8cdf-8189-4d50e5535a6f Success! You are now authenticated. The token information displayed below is already stored in the token helper. You do NOT need to run \"vault login\" again. Future Vault requests will automatically use this token. Key Value --- ----- token 01dbbae4-353a-8cdf-8189-4d50e5535a6f token_accessor 4d5eabf7-8710-81b1-b6a4-9ba17fdfdeb7 token_duration \u221e token_renewable false token_policies [ root ] Perform an introspection lookup on the current token login: root@edgex-vault:/vault # vault token lookup Key Value --- ----- accessor 4d5eabf7-8710-81b1-b6a4-9ba17fdfdeb7 creation_time 1547386542 creation_ttl 0 display_name root entity_id n/a expire_time <nil> explicit_max_ttl 0 id 01dbbae4-353a-8cdf-8189-4d50e5535a6f meta <nil> num_uses 0 orphan true path auth/token/root policies [ root ] ttl 0 Note Lines 9 & 10: the Root Token is the only token that has no expiration enforcement rules (Time to Live TTL counter). Perform a check on the current token login to display the corresponding capabilities (policies): root@edgex-vault:/vault # vault token capabilities 01dbbae4-353a-8cdf-8189-4d50e5535a6f root Perform a list request to display the currently mounted secret backends: root@edgex-vault:/vault # vault secrets list Path Type Accessor Description ---- ---- -------- ----------- cubbyhole/ cubbyhole cubbyhole_ad070930 per-token private secret storage identity/ identity identity_5397dc2f identity store secret/ kv kv_2362c227 key/value secret storage sys/ system system_410e4276 system endpoints used for control, policy and debugging Note Line 5: EdgeX Foundry platform is using the Key/Value secret storage named secret Let's drill down into the secret k/v storage and walk through a predefined hierarchical tree structure (path). Note the pkisetup tool used during the Vault Docker image build process generates all the related X.509 TLS materials. The vault-worker service is storing each service materials into Vault using arbitrary paths, setting up access policies accordingly. For example, the API Gateway (Kong) service X.509 TLS materials: root@edgex-vault:/vault # vault list secret Keys ---- edgex/ root@edgex-vault:/vault # vault list secret/edgex Keys ---- pki/ root@edgex-vault:/vault # vault list secret/edgex/pki Keys ---- tls/ root@edgex-vault:/vault # vault list secret/edgex/pki/tls Keys ---- edgex-kong Displaying the API gateway (Kong) service X.509 TLS materials (TLS certificate cert & corresponding private key key ): root@edgex-vault:/vault # vault read secret/edgex/pki/tls/edgex-kong Key Value --- ----- refresh_interval 168h cert -----BEGIN CERTIFICATE----- MIICrjCCAjWgAwIBAgIQDvZxhmU3nyG4cwXlQesMFDAKBggqhkjOPQQDAzB7MQsw CQYDVQQGEwJVUzELMAkGA1UECBMCQ0ExFjAUBgNVBAcTDVNhbiBGcmFuY2lzY28x FzAVBgNVBAoTDkVkZ2VYRm91bmRyeUNBMRUwEwYDVQQLEwxFZGdlWEZvdW5kcnkxt FzAVBgNVBAMTDkVkZ2VYRm91bmRyeUNBMB4XDTE4MTIwNTE0MDUyOFoXDTI4MTIw NTE0MDUyOFowazELMAkGA1UEBhMCVVMxCzAJBgNVBAgTAkNBMRYwFAYDVQQHEw1T YW4gRnJhbmNpc2NvMRMwEQYDVQQKEwplZGdleC1rb25nMQ0wCwYDVQQLEwRLb25n MRMwEQYDVQQDEwplZGdleC1rb25nMHYwEAYHKoZIzj0CAQYFK4EEACIDYgAE2dnb EboXET1TjzmWKFv3A0wklwNbs9t9JLT0ecpQr64a277UnTAQhgCv2e2/x9EP4eta gSlz5PCqdAykWW0URIEPSwUKWmx4x1DBwyUD2oDOPsFrywIVEC3DlqQAL6huo4GN MIGKMA4GA1UdDwEB/wQEAwIFoDATBgNVHSUEDDAKBggrBgEFBQcDATAMBgNVHRMB Af8EAjAAMB8GA1UdIwQYMBaAFFX63XbmPNpLceOJYyt2Y+LfW/gxMDQGA1UdEQQt MCuCCmVkZ2V4LWtvbmeCEGVkZ2V4LWtvbmcubG9jYWyBC2FkbWluQGxvY2FsMAoG CCqGSM49BAMDA2cAMGQCMCaH3sSKq6nlr6hBJx82wYEiK4slMbySiQZg5mLcwrsQ tIPGcQ2lgBdQYzI3ymOS5gIwNhpQmo/p3hkoFzA4rxIAZx/GUgZan51JlXW0rpgz 4HerRLe55EmvF10mF7VCGOXe -----END CERTIFICATE----- key -----BEGIN PRIVATE KEY----- MIG2AgEAMBAGByqGSM49AgEGBSuBBAAiBIGeMIGbAgEBBDC6BRUXqkJbey765+8b Oib2qG/jbai2rzp0+NQyJv4ijAyYjJlxhVGggZqPPBy8baqhZANiAATZ2dsRuhcR PVOPOZYoW/cDTCSXA1uz230ktPR5ylCvrhrbvtSdMBCGAK/Z7b/H0Q/h61qBKXPk 8Kp0DKRZbRREgQ9LBQpabHjHUMHDJQPagM4+wWvLAhUQLcOWpAAvqG4 = -----END PRIVATE KEY----- Note These two key values are in PEM format.","title":"1st alternative: executing a shell session in the active Vault container to run Vault CLI commands."},{"location":"microservices/security/Ch-SecretStore/#2nd-alternative-using-the-vault-web-ui","text":"Open a browser session on https://<EdgeX Vault Server>:8200 , accept the self-signed TLS server certificate and sign-in with the Root Token (see above 1st alternative to learn how to fetch this token): {.align-center width=\"606px\" height=\"504px\"} Upper left corner of the current Vault UI session, the sign-out menu displaying the current token name: {.align-center width=\"275px\" height=\"156px\"} Select the Vault secret backend: Navigate the API Gateway (Kong) service X.509 TLS materials path (edgex/pki/tls/edgex-kong): The Vault UI also allows entering Vault CLI commands (see above 1st alternative ) using an embedded console:","title":"2nd alternative: using the Vault Web UI."},{"location":"microservices/security/Ch-SecretStore/#3rd-alternative-directly-using-the-vault-http-api-with-curl-commands","text":"See paragraph Configuring the Secret Store to have more details on the --cacert option (identical purpose as the VAULT_CAPATH environment variable for Vault CLI). See paragraph Using the Secret Store to have more details on gathering the Vault Root Token (ref: /vault/config/assets/resp-init.json ). See HashiCorp Vault API documentation for further details on syntax and usage ( https://www.vaultproject.io/api/ ). Displaying (GET) the API gateway (Kong) service X.509 TLS materials (TLS certificate cert & corresponding private key key): curl -s --cacert /vault/config/pki/EdgeXFoundryCA/EdgeXFoundryCA.pem \\ --location \\ --header \"X-Vault-Token: 01dbbae4-353a-8cdf-8189-4d50e5535a6f\" \\ --request GET \\ https://edgex-vault:8200/v1/secret/edgex/pki/tls/edgex-kong | jq Note Line 2: the --location option allows following a redirection (necessary when using a Vault cluster) Line 5: the Vault API path prefix /v1/secret and the API Gateway X.509 TLS materials k/v /edgex/pki/tls/edgex-kong . Line 5: the jq tool is a lightweight and flexible command-line JSON processor ( https://stedolan.github.io/jq/ ) allowing JSON pretty printing in the terminal. Sample JSON returned: { \"request_id\" : \"eaa80a1b-0d31-8d11-6ce1-8d9aa3ac6a19\" , \"lease_id\" : \"\" , \"renewable\" : false , \"lease_duration\" : 604800 , \"data\" : { \"cert\" : \"-----BEGIN CERTIFICATE-----\\nMIICrjCCAjWgAwIBAgIQDvZxhmU3nyG4cwXlQesMFDAKBggqhkjOPQQDAzB7MQsw\\nCQYDVQQGEwJVUzELMAkGA1UECBMCQ0ExFjAUBgNVBAcTDVNhbiBGcmFuY2lzY28x\\nFzAVBgNVBAoTDkVkZ2VYRm91bmRyeUNBMRUwEwYDVQQLEwxFZGdlWEZvdW5kcnkx\\nFzAVBgNVBAMTDkVkZ2VYRm91bmRyeUNBMB4XDTE4MTIwNTE0MDUyOFoXDTI4MTIw\\nNTE0MDUyOFowazELMAkGA1UEBhMCVVMxCzAJBgNVBAgTAkNBMRYwFAYDVQQHEw1T\\nYW4gRnJhbmNpc2NvMRMwEQYDVQQKEwplZGdleC1rb25nMQ0wCwYDVQQLEwRLb25n\\nMRMwEQYDVQQDEwplZGdleC1rb25nMHYwEAYHKoZIzj0CAQYFK4EEACIDYgAE2dnb\\nEboXET1TjzmWKFv3A0wklwNbs9t9JLT0ecpQr64a277UnTAQhgCv2e2/x9EP4eta\\ngSlz5PCqdAykWW0URIEPSwUKWmx4x1DBwyUD2oDOPsFrywIVEC3DlqQAL6huo4GN\\nMIGKMA4GA1UdDwEB/wQEAwIFoDATBgNVHSUEDDAKBggrBgEFBQcDATAMBgNVHRMB\\nAf8EAjAAMB8GA1UdIwQYMBaAFFX63XbmPNpLceOJYyt2Y+LfW/gxMDQGA1UdEQQt\\nMCuCCmVkZ2V4LWtvbmeCEGVkZ2V4LWtvbmcubG9jYWyBC2FkbWluQGxvY2FsMAoG\\nCCqGSM49BAMDA2cAMGQCMCaH3sSKq6nlr6hBJx82wYEiK4slMbySiQZg5mLcwrsQ\\ntIPGcQ2lgBdQYzI3ymOS5gIwNhpQmo/p3hkoFzA4rxIAZx/GUgZan51JlXW0rpgz\\n4HerRLe55EmvF10mF7VCGOXe\\n-----END CERTIFICATE-----\\n\" , \"key\" : \"-----BEGIN PRIVATE KEY-----\\nMIG2AgEAMBAGByqGSM49AgEGBSuBBAAiBIGeMIGbAgEBBDC6BRUXqkJbey765+8b\\nOib2qG/jbai2rzp0+NQyJv4ijAyYjJlxhVGggZqPPBy8baqhZANiAATZ2dsRuhcR\\nPVOPOZYoW/cDTCSXA1uz230ktPR5ylCvrhrbvtSdMBCGAK/Z7b/H0Q/h61qBKXPk\\n8Kp0DKRZbRREgQ9LBQpabHjHUMHDJQPagM4+wWvLAhUQLcOWpAAvqG4=\\n-----END PRIVATE KEY-----\\n\" }, \"wrap_info\" : null , \"warnings\" : null , \"auth\" : null } Note Lines 7 & 8: the two key values (TLS certificate cert & corresponding private key key ) are in PEM format ( https://tools.ietf.org/html/rfc1421 ). Displaying (LIST) the root key path in the Vault secret backend for the EdgeX Foudry platform ( edgex ): curl -s --cacert /vault/config/pki/EdgeXFoundryCA/EdgeXFoundryCA.pem \\ --location \\ --header \"X-Vault-Token: 01dbbae4-353a-8cdf-8189-4d50e5535a6f\" \\ --request LIST \\ https://edgex-vault:8200/v1/secret | jq Sample JSON returned: { \"request_id\" : \"0e0ea024-176d-21b3-73cb-99f17729b230\" , \"lease_id\" : \"\" , \"renewable\" : false , \"lease_duration\" : 0 , \"data\" : { \"keys\" : [ \"edgex/\" ] }, \"wrap_info\" : null , \"warnings\" : null , \"auth\" : null } Displaying (GET) the Vault seal status ( API path: /v1/sys/seal-status ): curl -s --cacert /vault/config/pki/EdgeXFoundryCA/EdgeXFoundryCA.pem \\ --location \\ --header \"X-Vault-Token: 01dbbae4-353a-8cdf-8189-4d50e5535a6f\" \\ --request GET \\ https://edgex-vault:8200/v1/sys/seal-status | jq Sample JSON returned: { \"type\" : \"shamir\" , \"sealed\" : false , \"t\" : 1 , \"n\" : 1 , \"progress\" : 0 , \"nonce\" : \"\" , \"version\" : \"0.10.2\" , \"cluster_name\" : \"vault-cluster-57b3c4ed\" , \"cluster_id\" : \"fe6d18bf-fa9c-0d52-3278-bca0390af023\" } Note Line 3: Vault is unsealed therefore available and ready for requests. Line 4 & 5: Vault Shamir Secret Sharing default configuration for EdgeX Foundry: 1 share with threshold 1 (no sharding).","title":"3rd alternative: directly using the Vault HTTP API with cURL commands."},{"location":"microservices/security/Ch-SecretStore/#see-also","text":"Some of the command used in implementing security services have man-style documentation: security-file-token-provider - Generate Vault tokens for EdgeX services security-secrets-setup - Creates an on-device public-key infrastructure (PKI) to secure microservice secret management","title":"See also"},{"location":"microservices/security/Ch-Security/","text":"Security Security elements, both inside and outside of EdgeX Foundry, protect the data and control of devices, sensors, and other IoT objects managed by EdgeX Foundry. Based on the fact that EdgeX is a \"vendor-neutral open source software platform at the edge of the network\", the EdgeX security features are also built on a foundation of open interfaces and pluggable, replaceable modules. With security service enabled, the administrator of the EdgeX would be able to initialize the security components, set up running environment for security services, manage user access control, and create JWT( JSON Web Token) for resource access for other EdgeX business services. There are two major EdgeX security components. The first is a security store, which is used to provide a safe place to keep the EdgeX secrets. The second is an API gateway, which is used as a reverse proxy to restrict access to EdgeX REST resources and perform access control related works. In summary, the current features are as below: Secret creation, store and retrieve (password, cert, access key etc.) API gateway for other existing EdgeX microservice REST APIs User account creation with optional either OAuth2 or JWT authentication User account with arbitrary Access Control List groups (ACL)","title":"Security"},{"location":"microservices/security/Ch-Security/#security","text":"Security elements, both inside and outside of EdgeX Foundry, protect the data and control of devices, sensors, and other IoT objects managed by EdgeX Foundry. Based on the fact that EdgeX is a \"vendor-neutral open source software platform at the edge of the network\", the EdgeX security features are also built on a foundation of open interfaces and pluggable, replaceable modules. With security service enabled, the administrator of the EdgeX would be able to initialize the security components, set up running environment for security services, manage user access control, and create JWT( JSON Web Token) for resource access for other EdgeX business services. There are two major EdgeX security components. The first is a security store, which is used to provide a safe place to keep the EdgeX secrets. The second is an API gateway, which is used as a reverse proxy to restrict access to EdgeX REST resources and perform access control related works. In summary, the current features are as below: Secret creation, store and retrieve (password, cert, access key etc.) API gateway for other existing EdgeX microservice REST APIs User account creation with optional either OAuth2 or JWT authentication User account with arbitrary Access Control List groups (ACL)","title":"Security"},{"location":"microservices/security/Ch-SecurityIssues/","text":"Security Issues This page describes how to report EdgeX Foundry security issues and how they are handled. Security Announcements Join the edgexfoundry-announce group at: https://groups.google.com/d/forum/edgexfoundry-announce ) for emails about security and major API announcements. Vulnerability Reporting The EdgeX Foundry Open Source Community is grateful for all security reports made by users and security researchers. All reports are thoroughly investigated by a set of community volunteers. To make a report, please email the private list: security-issues@edgexfoundry.org , providing as much detail as possible. Use the security issue template: security_issue_template . At this time we do not yet offer an encrypted bug reporting option. When to Report a Vulnerability? You think you discovered a potential security vulnerability in EdgeX Foundry You are unsure how a vulnerability affects EdgeX Foundry You think you discovered a vulnerability in another project that EdgeX Foundry depends upon (e.g. docker, MongoDB, Redis,..) When NOT to Report a Vulnerability? You need help tuning EdgeX Foundry components for security You need help applying security related updates Your issue is not security related Security Vulnerability Response Each report is acknowledged and analyzed by Security Issue Review (SIR) team within one week. Any vulnerability information shared with SIR stays private, and is shared with sub-projects as necessary to get the issue fixed. As the security issue moves from triage, to identified fix, to release planning we will keep the reporter updated. In the case of 3 rd party dependency (code or library not managed and maintained by the EdgeX community) related security issues, while the issue report triggers the same response workflow, the EdgeX community will defer to owning community for fixes. On receipt of a security issue report, SIR: Discusses the issue privately to understand it Uses the Common Vulnerability Scoring System to grade the issue Determines the sub-projects and developers to involve Develops a fix In conjunction with the product group determines when to release the fix Communicates the fix 7. Uploads a Common Vulnerabilities and Exposures (CVE) style report of the issue and associated threat The issue reporter will be kept in the loop as appropriate. Note that a critical or high severity issue can delay a scheduled release to incorporate a fix or mitigation. Public Disclosure Timing A public disclosure date is negotiated by the EdgeX Product Security Committee and the bug submitter. We prefer to fully disclose the bug as soon as possible AFTER a mitigation is available. It is reasonable to delay disclosure when the bug or the fix is not yet fully understood, the solution is not well-tested, or for vendor coordination. The timeframe for disclosure may be immediate (especially publicly known issues) to a few weeks. The EdgeX Foundry Product Security Committee holds the final say when setting a disclosure date.","title":"Security Issues"},{"location":"microservices/security/Ch-SecurityIssues/#security-issues","text":"This page describes how to report EdgeX Foundry security issues and how they are handled.","title":"Security Issues"},{"location":"microservices/security/Ch-SecurityIssues/#security-announcements","text":"Join the edgexfoundry-announce group at: https://groups.google.com/d/forum/edgexfoundry-announce ) for emails about security and major API announcements.","title":"Security Announcements"},{"location":"microservices/security/Ch-SecurityIssues/#vulnerability-reporting","text":"The EdgeX Foundry Open Source Community is grateful for all security reports made by users and security researchers. All reports are thoroughly investigated by a set of community volunteers. To make a report, please email the private list: security-issues@edgexfoundry.org , providing as much detail as possible. Use the security issue template: security_issue_template . At this time we do not yet offer an encrypted bug reporting option.","title":"Vulnerability Reporting"},{"location":"microservices/security/Ch-SecurityIssues/#when-to-report-a-vulnerability","text":"You think you discovered a potential security vulnerability in EdgeX Foundry You are unsure how a vulnerability affects EdgeX Foundry You think you discovered a vulnerability in another project that EdgeX Foundry depends upon (e.g. docker, MongoDB, Redis,..)","title":"When to Report a Vulnerability?"},{"location":"microservices/security/Ch-SecurityIssues/#when-not-to-report-a-vulnerability","text":"You need help tuning EdgeX Foundry components for security You need help applying security related updates Your issue is not security related","title":"When NOT to Report a Vulnerability?"},{"location":"microservices/security/Ch-SecurityIssues/#security-vulnerability-response","text":"Each report is acknowledged and analyzed by Security Issue Review (SIR) team within one week. Any vulnerability information shared with SIR stays private, and is shared with sub-projects as necessary to get the issue fixed. As the security issue moves from triage, to identified fix, to release planning we will keep the reporter updated. In the case of 3 rd party dependency (code or library not managed and maintained by the EdgeX community) related security issues, while the issue report triggers the same response workflow, the EdgeX community will defer to owning community for fixes. On receipt of a security issue report, SIR: Discusses the issue privately to understand it Uses the Common Vulnerability Scoring System to grade the issue Determines the sub-projects and developers to involve Develops a fix In conjunction with the product group determines when to release the fix Communicates the fix 7. Uploads a Common Vulnerabilities and Exposures (CVE) style report of the issue and associated threat The issue reporter will be kept in the loop as appropriate. Note that a critical or high severity issue can delay a scheduled release to incorporate a fix or mitigation.","title":"Security Vulnerability Response"},{"location":"microservices/security/Ch-SecurityIssues/#public-disclosure-timing","text":"A public disclosure date is negotiated by the EdgeX Product Security Committee and the bug submitter. We prefer to fully disclose the bug as soon as possible AFTER a mitigation is available. It is reasonable to delay disclosure when the bug or the fix is not yet fully understood, the solution is not well-tested, or for vendor coordination. The timeframe for disclosure may be immediate (especially publicly known issues) to a few weeks. The EdgeX Foundry Product Security Committee holds the final say when setting a disclosure date.","title":"Public Disclosure Timing"},{"location":"microservices/security/Ch-StartingSecurity/","text":"Starting security services within EdgeX Similar to other EdgeX services, the security service can be started with Docker Compose. The security services can be started automatically with docker-compose up --d with proper docker compose file. An working sample docker compose file can be found from the edgex repo of Github at https://github.com/edgexfoundry/security-api-gateway/ . If the user prefers to start the security service manually, the commands are described below. docker-compose up -d volume docker-compose up -d config-seed docker-compose up -d consul docker-compose up -d vault docker-compose up -d vault-worker docker-compose up -d kong-db docker-compose up -d kong-migrations docker-compose up -d kong docker-compose up -d edgex-proxy","title":"Starting security services within EdgeX"},{"location":"microservices/security/Ch-StartingSecurity/#starting-security-services-within-edgex","text":"Similar to other EdgeX services, the security service can be started with Docker Compose. The security services can be started automatically with docker-compose up --d with proper docker compose file. An working sample docker compose file can be found from the edgex repo of Github at https://github.com/edgexfoundry/security-api-gateway/ . If the user prefers to start the security service manually, the commands are described below. docker-compose up -d volume docker-compose up -d config-seed docker-compose up -d consul docker-compose up -d vault docker-compose up -d vault-worker docker-compose up -d kong-db docker-compose up -d kong-migrations docker-compose up -d kong docker-compose up -d edgex-proxy","title":"Starting security services within EdgeX"},{"location":"microservices/security/security-file-token-provider.1/","text":"NAME security-file-token-provider -- Generate Vault tokens for EdgeX services SYNOPSIS security-file-token-provider [-h--confdir \\<confdir>] [-p|--profile \\<name>] DESCRIPTION security-file-token-provider generates per-service Vault tokens for EdgeX services so that they can make authenticated connections to Vault to retrieve application secrets. security-file-token-provider implements a generic secret seeding mechanism based on pre-created files and is designed for maximum portability. security-file-token-provider takes a configuration file that specifies the services for which tokens shall be generated and the Vault access policy that shall be applied to those tokens. security-file-token-provider assumes that there is some underlying protection mechanism that will be used to prevent EdgeX services from reading each other's tokens. OPTIONS -h, --help : Display help text -c, --confdir \\<confdir> : Look in this directory for configuration.toml instead. -p, --profile \\<name> : Indicate configuration profile other than default FILES configuration.toml This file specifies the TCP/IP location of the Vault service and parameters used for Vault token generation. [SecretService] Scheme = \"https\" Server = \"localhost\" Port = 8200 [TokenFileProvider] PrivilegedTokenPath = /run/edgex/secrets/security-file-token-provider/secrets-token.json ConfigFile = token-config.json OutputDir = /run/edgex/secrets/ OutputFilename = secrets-token.json secrets-token.json This file contains a token used to authenticate to Vault. The filename is customizable via OutputFilename . { \"auth\": { \"client_token\": \"s.wOrq9dO9kzOcuvB06CMviJhZ\" } } token-config.json This configuration file tells security-file-token-provider which tokens to generate. In order to avoid a directory full of .hcl files, this configuration file uses the JSON serialization of HCL, documented at https://github.com/hashicorp/hcl/blob/master/README.md . Note that all paths are keys under the \"path\" object. { \"service-name\": { \"edgex_use_defaults\": true, \"custom_policy\": { \"path\": { \"secret/non/standard/location/*\": { \"capabilities\": [ \"list\", \"read\" ] } } }, \"custom_token_parameters\": { } } } When edgex-use-default is true (the default), the following is added to the policy specification for the auto-generated policy. The auto-generated policy is named edgex-secrets-XYZ where XYZ is service-name from the JSON key above. Thus, the final policy created for the token will be the union of the policy below (if using the default policy) plus the custom_policy defined above. { \"path\": { \"secret/edgex/service-name/*\": { \"capabilities\": [ \"create\", \"update\", \"delete\", \"list\", \"read\" ] } } } When edgex-use-default is true (the default), the following is inserted (if not overridden) to the token parameters for the generated token. (See https://www.vaultproject.io/api/auth/token/index.html#create-token .) \"display_name\": token-service-name \"no_parent\": true \"policies\": [ \"edgex-service-service-name\" ] Note that display_name is set by vault to be \"token-\" + the specified display name. This is hard-coded in Vault from versions 0.6 to 1.2.3 and cannot be changed. Additionally, a meta property, edgex-service-name is set to service-name . The edgex-service-name property may be used by clients to infer the location in the secret store where service-specific secrets are held. \"meta\": { \"edgex-service-name\": service-name } {OutputDir}/{service-name}/{OutputFilename} For example: /run/edgex/secrets/edgex-security-proxy-setup/secrets-token.json For each \"service-name\" in {ConfigFile} , a matching directory is created under {OutputDir} and the corresponding Vault token is stored as {OutputFilename} . This file contains the authorization token generated to allow the indicated EdgeX service to retrieve its secrets. PREREQUISITES PrivilegedTokenPath points to a non-expired Vault token that the security-file-token-provider will use to install policies and create per-service tokens. It will create policies with the naming convention \"edgex-service-service-name\" where service-name comes from JSON keys in the configuration file and the Vault policy will be configured to allow creation and modification of policies using this naming convention. This token must have the following policy ( edgex-privileged-token-creator ) configured. path \"auth/token/create\" { capabilities = [ \"create\" , \"update\" , \"sudo\" ] } path \"auth/token/create-orphan\" { capabilities = [ \"create\" , \"update\" , \"sudo\" ] } path \"auth/token/create/*\" { capabilities = [ \"create\" , \"update\" , \"sudo\" ] } path \"sys/policies/acl/edgex-service-*\" { capabilities = [ \"create\" , \"read\" , \"update\" , \"delete\" ] } path \"sys/policies/acl\" { capabilities = [ \"list\" ] } AUTHOR EdgeX Foundry \\< info@edgexfoundry.org >","title":"NAME"},{"location":"microservices/security/security-file-token-provider.1/#name","text":"security-file-token-provider -- Generate Vault tokens for EdgeX services","title":"NAME"},{"location":"microservices/security/security-file-token-provider.1/#synopsis","text":"security-file-token-provider [-h--confdir \\<confdir>] [-p|--profile \\<name>]","title":"SYNOPSIS"},{"location":"microservices/security/security-file-token-provider.1/#description","text":"security-file-token-provider generates per-service Vault tokens for EdgeX services so that they can make authenticated connections to Vault to retrieve application secrets. security-file-token-provider implements a generic secret seeding mechanism based on pre-created files and is designed for maximum portability. security-file-token-provider takes a configuration file that specifies the services for which tokens shall be generated and the Vault access policy that shall be applied to those tokens. security-file-token-provider assumes that there is some underlying protection mechanism that will be used to prevent EdgeX services from reading each other's tokens.","title":"DESCRIPTION"},{"location":"microservices/security/security-file-token-provider.1/#options","text":"-h, --help : Display help text -c, --confdir \\<confdir> : Look in this directory for configuration.toml instead. -p, --profile \\<name> : Indicate configuration profile other than default","title":"OPTIONS"},{"location":"microservices/security/security-file-token-provider.1/#files","text":"","title":"FILES"},{"location":"microservices/security/security-file-token-provider.1/#configurationtoml","text":"This file specifies the TCP/IP location of the Vault service and parameters used for Vault token generation. [SecretService] Scheme = \"https\" Server = \"localhost\" Port = 8200 [TokenFileProvider] PrivilegedTokenPath = /run/edgex/secrets/security-file-token-provider/secrets-token.json ConfigFile = token-config.json OutputDir = /run/edgex/secrets/ OutputFilename = secrets-token.json","title":"configuration.toml"},{"location":"microservices/security/security-file-token-provider.1/#secrets-tokenjson","text":"This file contains a token used to authenticate to Vault. The filename is customizable via OutputFilename . { \"auth\": { \"client_token\": \"s.wOrq9dO9kzOcuvB06CMviJhZ\" } }","title":"secrets-token.json"},{"location":"microservices/security/security-file-token-provider.1/#token-configjson","text":"This configuration file tells security-file-token-provider which tokens to generate. In order to avoid a directory full of .hcl files, this configuration file uses the JSON serialization of HCL, documented at https://github.com/hashicorp/hcl/blob/master/README.md . Note that all paths are keys under the \"path\" object. { \"service-name\": { \"edgex_use_defaults\": true, \"custom_policy\": { \"path\": { \"secret/non/standard/location/*\": { \"capabilities\": [ \"list\", \"read\" ] } } }, \"custom_token_parameters\": { } } } When edgex-use-default is true (the default), the following is added to the policy specification for the auto-generated policy. The auto-generated policy is named edgex-secrets-XYZ where XYZ is service-name from the JSON key above. Thus, the final policy created for the token will be the union of the policy below (if using the default policy) plus the custom_policy defined above. { \"path\": { \"secret/edgex/service-name/*\": { \"capabilities\": [ \"create\", \"update\", \"delete\", \"list\", \"read\" ] } } } When edgex-use-default is true (the default), the following is inserted (if not overridden) to the token parameters for the generated token. (See https://www.vaultproject.io/api/auth/token/index.html#create-token .) \"display_name\": token-service-name \"no_parent\": true \"policies\": [ \"edgex-service-service-name\" ] Note that display_name is set by vault to be \"token-\" + the specified display name. This is hard-coded in Vault from versions 0.6 to 1.2.3 and cannot be changed. Additionally, a meta property, edgex-service-name is set to service-name . The edgex-service-name property may be used by clients to infer the location in the secret store where service-specific secrets are held. \"meta\": { \"edgex-service-name\": service-name }","title":"token-config.json"},{"location":"microservices/security/security-file-token-provider.1/#outputdirservice-nameoutputfilename","text":"For example: /run/edgex/secrets/edgex-security-proxy-setup/secrets-token.json For each \"service-name\" in {ConfigFile} , a matching directory is created under {OutputDir} and the corresponding Vault token is stored as {OutputFilename} . This file contains the authorization token generated to allow the indicated EdgeX service to retrieve its secrets.","title":"{OutputDir}/{service-name}/{OutputFilename}"},{"location":"microservices/security/security-file-token-provider.1/#prerequisites","text":"PrivilegedTokenPath points to a non-expired Vault token that the security-file-token-provider will use to install policies and create per-service tokens. It will create policies with the naming convention \"edgex-service-service-name\" where service-name comes from JSON keys in the configuration file and the Vault policy will be configured to allow creation and modification of policies using this naming convention. This token must have the following policy ( edgex-privileged-token-creator ) configured. path \"auth/token/create\" { capabilities = [ \"create\" , \"update\" , \"sudo\" ] } path \"auth/token/create-orphan\" { capabilities = [ \"create\" , \"update\" , \"sudo\" ] } path \"auth/token/create/*\" { capabilities = [ \"create\" , \"update\" , \"sudo\" ] } path \"sys/policies/acl/edgex-service-*\" { capabilities = [ \"create\" , \"read\" , \"update\" , \"delete\" ] } path \"sys/policies/acl\" { capabilities = [ \"list\" ] }","title":"PREREQUISITES"},{"location":"microservices/security/security-file-token-provider.1/#author","text":"EdgeX Foundry \\< info@edgexfoundry.org >","title":"AUTHOR"},{"location":"microservices/security/security-secrets-setup.1/","text":"NAME security-secrets-setup --- Creates an on-device public-key infrastructure (PKI) to secure microservice secret management SYNOPSIS | security-secrets-setup generate [-confdir \\<confdir>] [-p|--profile \\<name>] | security-secrets-setup cache [-confdir \\<confdir>] [-p|--profile \\<name>] | security-secrets-setup import [-confdir \\<confdir>] [-p|--profile \\<name>] | security-secrets-setup [-h|--help] DESCRIPTION The Vault secret management component of EdgeX Foundry requires TLS encryption of secrets over the wire via a pre-created PKI. security-secrets-setup is responsible for creating a certificate authority and any needed TLS leaf certificates in order to secure the EdgeX security services. security-secrets-setup supports several modes of operation as defined in the OPTIONS section. As the PKI is security-sensitive, this tool takes a number of precautions to safeguard the PKI: The PKI can be deployed to transient storage to address potential attacks to the PKI at-rest. The PKI is deployed such that each service has its own assets folder, which is amenable to security controls imposed by container runtimes such as mandatory access controls or file system namespaces. The private key of the certificate authority (CA) is shredded (securely erased) prior to caching or deployment to block issuance of new CA descendants (this is most relevant in caching mode). Modes of operation generate : Causes a PKI to be generated afresh every time and deployed. Typically, this will be whenever the framework is started. cache : Causes a PKI to be generated exactly once and then copied to a designated cache location for future use. The PKI is then deployed from the cached location. import : This option is similar to cache in that it deploys a PKI from CacheDir to DeployDir , but it forces an error if CacheDir is empty instead of triggering PKI generation. This enables usage models for deploying a pre-populated PKI such as a Kong certificate signed by an external certificate authority or TLS keys signed by an offline enterprise certificate authority. OPTIONS -h, --help : Display help text --confdir \\<confdir> : Look in this directory for configuration.toml instead. -p, --profile \\<name> : Indicate configuration profile other than default FILES pkisetup-vault.json, pkisetup-kong.json --------------------------------- Configuration files for certificate parameters. These files conform to the following schema: { \"create_new_rootca\": \"true|false\", \"working_dir\": \"./config\", \"pki_setup_dir\": \"pki\", \"dump_config\": \"true\", \"key_scheme\": { \"dump_keys\": \"false\", \"rsa\": \"false\", \"rsa_key_size\": \"4096\", \"ec\": \"true\", \"ec_curve\": \"384\" }, \"x509_root_ca_parameters\": { \"ca_name\": \"EdgeXFoundryCA\", \"ca_c\": \"US\", \"ca_st\": \"CA\", \"ca_l\": \"San Francisco\", \"ca_o\": \"EdgeXFoundry\" }, \"x509_tls_server_parameters\": { \"tls_host\": \"edgex-vault|edgex-kong\", \"tls_domain\": \"local\", \"tls_c\": \"US\", \"tls_st\": \"CA\", \"tls_l\": \"San Francisco\", \"tls_o\": \"Kong\" } } When generating or caching, the utility hard-codes the names of the configuration files and always processes pkisetup-vault.json first and pkisetup-kong.json second. This will be configurable in the future; at that time the basename of the file would correspond to a directory under DeployDir . configuration.toml Configuration file for configurable directories that the options use. This file conforms to the following schema: [SecretsSetup] WorkDir = \"/path/to/temp/files\" CacheDir = \"/path/to/cached-or-importing/pki\" DeployDir = \"/path/to/deployed/pki\" WorkDir A work area (preferably on a ramdisk) to place working files during certificate generation. If not supplied, temporary files will be generated to a subdirectory ( /edgex/security-secrets-setup ) of $XDG_RUNTIME_DIR . If $XDG_RUNTIME_DIR is undefined, uses /tmp instead. DeployDir Points to the base directory for the final deployment location of the PKI. If not specified, defaults to /run/edgex/secrets/ . For example, if DeployDir was set to /edgex and the service name was edgex-vault then the following files would be placed in /edgex/edgex-vault/ : server.crt for a PEM-encoded end-entity TLS certificate and server.key for the corresponding private key .security-secrets-setup.complete is a sentinel file created after assets are deployed CacheDir Points to a base directory to hold the cached PKI. Identical in structure to that created in DeployDir . Defaults to /etc/edgex/pki if not specified. The PKI is deployed from here when the tool is run in caching or importing. ENVIRONMENT XDG_RUNTIME_DIR Used as default value for WorkDir if not otherwise specified. NOTES As security-secrets-setup is a helper utility to ensure that a PKI is created on first launch, it is intended that security-secrets-setup is always invoked with the same command. Changing from cache to generate will cause the cache to be ignored when deploying a PKI and changing it back will cause a reversion to a stale CA. Changing from cache to import mode of operation is not noticeable by the tool: the PKI that is in the cache will be the one deployed. To force regeneration of the PKI cache after the first launch, the PKI cache must be manually cleaned. The easiest way in Docker would be to delete the Docker volume holding the cached PKI.","title":"NAME"},{"location":"microservices/security/security-secrets-setup.1/#name","text":"security-secrets-setup --- Creates an on-device public-key infrastructure (PKI) to secure microservice secret management","title":"NAME"},{"location":"microservices/security/security-secrets-setup.1/#synopsis","text":"| security-secrets-setup generate [-confdir \\<confdir>] [-p|--profile \\<name>] | security-secrets-setup cache [-confdir \\<confdir>] [-p|--profile \\<name>] | security-secrets-setup import [-confdir \\<confdir>] [-p|--profile \\<name>] | security-secrets-setup [-h|--help]","title":"SYNOPSIS"},{"location":"microservices/security/security-secrets-setup.1/#description","text":"The Vault secret management component of EdgeX Foundry requires TLS encryption of secrets over the wire via a pre-created PKI. security-secrets-setup is responsible for creating a certificate authority and any needed TLS leaf certificates in order to secure the EdgeX security services. security-secrets-setup supports several modes of operation as defined in the OPTIONS section. As the PKI is security-sensitive, this tool takes a number of precautions to safeguard the PKI: The PKI can be deployed to transient storage to address potential attacks to the PKI at-rest. The PKI is deployed such that each service has its own assets folder, which is amenable to security controls imposed by container runtimes such as mandatory access controls or file system namespaces. The private key of the certificate authority (CA) is shredded (securely erased) prior to caching or deployment to block issuance of new CA descendants (this is most relevant in caching mode).","title":"DESCRIPTION"},{"location":"microservices/security/security-secrets-setup.1/#modes-of-operation","text":"generate : Causes a PKI to be generated afresh every time and deployed. Typically, this will be whenever the framework is started. cache : Causes a PKI to be generated exactly once and then copied to a designated cache location for future use. The PKI is then deployed from the cached location. import : This option is similar to cache in that it deploys a PKI from CacheDir to DeployDir , but it forces an error if CacheDir is empty instead of triggering PKI generation. This enables usage models for deploying a pre-populated PKI such as a Kong certificate signed by an external certificate authority or TLS keys signed by an offline enterprise certificate authority.","title":"Modes of operation"},{"location":"microservices/security/security-secrets-setup.1/#options","text":"-h, --help : Display help text --confdir \\<confdir> : Look in this directory for configuration.toml instead. -p, --profile \\<name> : Indicate configuration profile other than default","title":"OPTIONS"},{"location":"microservices/security/security-secrets-setup.1/#files","text":"pkisetup-vault.json, pkisetup-kong.json --------------------------------- Configuration files for certificate parameters. These files conform to the following schema: { \"create_new_rootca\": \"true|false\", \"working_dir\": \"./config\", \"pki_setup_dir\": \"pki\", \"dump_config\": \"true\", \"key_scheme\": { \"dump_keys\": \"false\", \"rsa\": \"false\", \"rsa_key_size\": \"4096\", \"ec\": \"true\", \"ec_curve\": \"384\" }, \"x509_root_ca_parameters\": { \"ca_name\": \"EdgeXFoundryCA\", \"ca_c\": \"US\", \"ca_st\": \"CA\", \"ca_l\": \"San Francisco\", \"ca_o\": \"EdgeXFoundry\" }, \"x509_tls_server_parameters\": { \"tls_host\": \"edgex-vault|edgex-kong\", \"tls_domain\": \"local\", \"tls_c\": \"US\", \"tls_st\": \"CA\", \"tls_l\": \"San Francisco\", \"tls_o\": \"Kong\" } } When generating or caching, the utility hard-codes the names of the configuration files and always processes pkisetup-vault.json first and pkisetup-kong.json second. This will be configurable in the future; at that time the basename of the file would correspond to a directory under DeployDir .","title":"FILES"},{"location":"microservices/security/security-secrets-setup.1/#configurationtoml","text":"Configuration file for configurable directories that the options use. This file conforms to the following schema: [SecretsSetup] WorkDir = \"/path/to/temp/files\" CacheDir = \"/path/to/cached-or-importing/pki\" DeployDir = \"/path/to/deployed/pki\"","title":"configuration.toml"},{"location":"microservices/security/security-secrets-setup.1/#workdir","text":"A work area (preferably on a ramdisk) to place working files during certificate generation. If not supplied, temporary files will be generated to a subdirectory ( /edgex/security-secrets-setup ) of $XDG_RUNTIME_DIR . If $XDG_RUNTIME_DIR is undefined, uses /tmp instead.","title":"WorkDir"},{"location":"microservices/security/security-secrets-setup.1/#deploydir","text":"Points to the base directory for the final deployment location of the PKI. If not specified, defaults to /run/edgex/secrets/ . For example, if DeployDir was set to /edgex and the service name was edgex-vault then the following files would be placed in /edgex/edgex-vault/ : server.crt for a PEM-encoded end-entity TLS certificate and server.key for the corresponding private key .security-secrets-setup.complete is a sentinel file created after assets are deployed","title":"DeployDir"},{"location":"microservices/security/security-secrets-setup.1/#cachedir","text":"Points to a base directory to hold the cached PKI. Identical in structure to that created in DeployDir . Defaults to /etc/edgex/pki if not specified. The PKI is deployed from here when the tool is run in caching or importing.","title":"CacheDir"},{"location":"microservices/security/security-secrets-setup.1/#environment","text":"XDG_RUNTIME_DIR Used as default value for WorkDir if not otherwise specified.","title":"ENVIRONMENT"},{"location":"microservices/security/security-secrets-setup.1/#notes","text":"As security-secrets-setup is a helper utility to ensure that a PKI is created on first launch, it is intended that security-secrets-setup is always invoked with the same command. Changing from cache to generate will cause the cache to be ignored when deploying a PKI and changing it back will cause a reversion to a stale CA. Changing from cache to import mode of operation is not noticeable by the tool: the PKI that is in the cache will be the one deployed. To force regeneration of the PKI cache after the first launch, the PKI cache must be manually cleaned. The easiest way in Docker would be to delete the Docker volume holding the cached PKI.","title":"NOTES"},{"location":"microservices/support/Ch-SupportingServices/","text":"Supporting Services Microservices The supporting services encompass a wide range of micro services to include edge analytics (also known as local analytics). Micro services in the supporting services layer perform normal software application duties such as logging, scheduling, and notifications/alerting . These services often need some amount of core services to function. In all cases, consider supporting service optional. Leave these services out of an EdgeX deployment depending on use case needs and system resources. Supporting services include: Rules Engine : the reference implementation edge analytics service that performs if-then conditional actuation at the edge based on sensor data collected by the EdgeX instance. Replace or augment this service with use case specific analytics capability. Scheduling : an internal EdgeX \u201cclock\u201d that can kick off operations in any EdgeX service. At a configuration specified time, the service will call on any EdgeX service API URL via REST to trigger an operation. For example, at appointed times, the scheduling service calls on core data APIs to expunge old sensed events already exported out of EdgeX. Logging : provides a central logging facility for EdgeX services. Services send log entries into the logging facility via a REST API where log entries can be persisted in a database or log file. Alerts and Notifications : provides EdgeX services with a central facility to send out an alert or notification. These are notices sent to another system or to a person monitoring the EdgeX instance (internal service communications are often handled more directly). Note Logging is being deprecated and will be removed in a future release. Services will still be able to log using standard output or log to a file. Most operating systems and logging facilities provide better logging aggregation then what EdgeX was providing through the logging service.","title":"Supporting Services Microservices"},{"location":"microservices/support/Ch-SupportingServices/#supporting-services-microservices","text":"The supporting services encompass a wide range of micro services to include edge analytics (also known as local analytics). Micro services in the supporting services layer perform normal software application duties such as logging, scheduling, and notifications/alerting . These services often need some amount of core services to function. In all cases, consider supporting service optional. Leave these services out of an EdgeX deployment depending on use case needs and system resources. Supporting services include: Rules Engine : the reference implementation edge analytics service that performs if-then conditional actuation at the edge based on sensor data collected by the EdgeX instance. Replace or augment this service with use case specific analytics capability. Scheduling : an internal EdgeX \u201cclock\u201d that can kick off operations in any EdgeX service. At a configuration specified time, the service will call on any EdgeX service API URL via REST to trigger an operation. For example, at appointed times, the scheduling service calls on core data APIs to expunge old sensed events already exported out of EdgeX. Logging : provides a central logging facility for EdgeX services. Services send log entries into the logging facility via a REST API where log entries can be persisted in a database or log file. Alerts and Notifications : provides EdgeX services with a central facility to send out an alert or notification. These are notices sent to another system or to a person monitoring the EdgeX instance (internal service communications are often handled more directly). Note Logging is being deprecated and will be removed in a future release. Services will still be able to log using standard output or log to a file. Most operating systems and logging facilities provide better logging aggregation then what EdgeX was providing through the logging service.","title":"Supporting Services Microservices"},{"location":"microservices/support/Kuiper/Ch-Kuiper/","text":"Kuiper Rules Engine Overview EMQ X Kuiper is the new EdgeX reference implementation rules engine (or edge analytcs ) implementation (replacing the Support Rules Engine - which wrapped the Java Drools engine). What is EMQ X Kuiper? EMQ X Kuiper is a lightweight open source software (Apache 2.0 open source license agreement) package for IoT edge analytics and stream processing implemented in Go lang, which can run on various resource constrained edge devices. Users can realize fast data processing on the edge and write rules in SQL. The Kuiper rules engine is based on three components Source , SQL and Sink . Source: Source of stream data, such as data from an MQTT server. For EdgeX, the data source is an EdgeX message bus, which can be implemented by ZeroMQ or MQTT; SQL: SQL is where the specified business logic is processed. Kuiper provides SQL statements to extract, filter, and transform data; Sink: Used to send the analysis result to a specific target, such as sending the analysis results to EdgeX's Command service, or an MQTT broker in the cloud; The relationship among Source, SQL and Sink in Kuiper is shown below. Kuiper runs very efficiently on resource constrained edge devices. For common IoT data processing, the throughput can reach 12k per second. Readers can refer to here to get more performance benchmark data for Kuiper. Kuiper rules engine of EdgeX An extension mechanism allows Kuiper to be customized to analyze and process data from different data sources. By default for the EdgeX configuration, Kuiper analyzes data coming from the EdgeX message bus . EdgeX provides an abstract message bus interface, and implements the ZeroMQ and MQTT protocols respectively to support information exchange between different micro-services. The integration of Kuiper and EdgeX mainly includes the following: Extend an EdgeX message bus source to support receiving data from the EdgeX message bus. By default, Kuiper listens to the port 5566 on which the Application Service publishes messages. After the data from the Core Data Service is processed by the Application Service, it will flow into the Kuiper rules engine for processing. Read the data type definition from Core Contract Service, convert EdgeX data to Kuiper data type, and process it according to the rules specified by the user. Kuiper supports sending analysis results to different Sink: The users can choose to send the analysis results to Command Service to control the equipment; The analysis results can be sent to the EdgeX message bus sink for further processing by other micro-services. Learn more EdgeX Kuiper Rules Engine Tutorial : A 10-minute quick start tutorial, readers can refer to this article to start trying out the rules engine. Control the device with the EdgeX Kuiper rules engine : This article describes how to use the Kuiper rule engine in EdgeX to control the device based on the analysis results. Read EdgeX Source to get more detailed information, and type conversions. How to use the meta function to extract more information sent in the EdgeX message bus? When the device service sends data to the bus, some additional information is also sent, such as creation time and id. If you want to use this information in SQL statements, please refer to this article. EdgeX Message Bus Sink : The document describes how to use EdgeX message bus sink. If you'd like to have your analysis result be consumed by other EdgeX services, you can send analysis data with EdgeX data format through this sink, and other EdgeX services can subscribe new message bus exposed by Kuiper sink. For more information on the EMQ X Kuiper project, please refer to the following resources. Kuiper Github Code library Kuiper Reference","title":"Kuiper Rules Engine"},{"location":"microservices/support/Kuiper/Ch-Kuiper/#kuiper-rules-engine","text":"","title":"Kuiper Rules Engine"},{"location":"microservices/support/Kuiper/Ch-Kuiper/#overview","text":"EMQ X Kuiper is the new EdgeX reference implementation rules engine (or edge analytcs ) implementation (replacing the Support Rules Engine - which wrapped the Java Drools engine).","title":"Overview"},{"location":"microservices/support/Kuiper/Ch-Kuiper/#what-is-emq-x-kuiper","text":"EMQ X Kuiper is a lightweight open source software (Apache 2.0 open source license agreement) package for IoT edge analytics and stream processing implemented in Go lang, which can run on various resource constrained edge devices. Users can realize fast data processing on the edge and write rules in SQL. The Kuiper rules engine is based on three components Source , SQL and Sink . Source: Source of stream data, such as data from an MQTT server. For EdgeX, the data source is an EdgeX message bus, which can be implemented by ZeroMQ or MQTT; SQL: SQL is where the specified business logic is processed. Kuiper provides SQL statements to extract, filter, and transform data; Sink: Used to send the analysis result to a specific target, such as sending the analysis results to EdgeX's Command service, or an MQTT broker in the cloud; The relationship among Source, SQL and Sink in Kuiper is shown below. Kuiper runs very efficiently on resource constrained edge devices. For common IoT data processing, the throughput can reach 12k per second. Readers can refer to here to get more performance benchmark data for Kuiper.","title":"What is EMQ X Kuiper?"},{"location":"microservices/support/Kuiper/Ch-Kuiper/#kuiper-rules-engine-of-edgex","text":"An extension mechanism allows Kuiper to be customized to analyze and process data from different data sources. By default for the EdgeX configuration, Kuiper analyzes data coming from the EdgeX message bus . EdgeX provides an abstract message bus interface, and implements the ZeroMQ and MQTT protocols respectively to support information exchange between different micro-services. The integration of Kuiper and EdgeX mainly includes the following: Extend an EdgeX message bus source to support receiving data from the EdgeX message bus. By default, Kuiper listens to the port 5566 on which the Application Service publishes messages. After the data from the Core Data Service is processed by the Application Service, it will flow into the Kuiper rules engine for processing. Read the data type definition from Core Contract Service, convert EdgeX data to Kuiper data type, and process it according to the rules specified by the user. Kuiper supports sending analysis results to different Sink: The users can choose to send the analysis results to Command Service to control the equipment; The analysis results can be sent to the EdgeX message bus sink for further processing by other micro-services.","title":"Kuiper rules engine of EdgeX"},{"location":"microservices/support/Kuiper/Ch-Kuiper/#learn-more","text":"EdgeX Kuiper Rules Engine Tutorial : A 10-minute quick start tutorial, readers can refer to this article to start trying out the rules engine. Control the device with the EdgeX Kuiper rules engine : This article describes how to use the Kuiper rule engine in EdgeX to control the device based on the analysis results. Read EdgeX Source to get more detailed information, and type conversions. How to use the meta function to extract more information sent in the EdgeX message bus? When the device service sends data to the bus, some additional information is also sent, such as creation time and id. If you want to use this information in SQL statements, please refer to this article. EdgeX Message Bus Sink : The document describes how to use EdgeX message bus sink. If you'd like to have your analysis result be consumed by other EdgeX services, you can send analysis data with EdgeX data format through this sink, and other EdgeX services can subscribe new message bus exposed by Kuiper sink. For more information on the EMQ X Kuiper project, please refer to the following resources. Kuiper Github Code library Kuiper Reference","title":"Learn more"},{"location":"microservices/support/logging/Ch-Logging/","text":"Logging Deprecation Notice Please note that the logging service has been deprecated with the Geneva release (v1.2) . The EdgeX community feels that there are better log aggregation services available in the open source community or by deployment/orchestration tools. Starting with the Geneva release, logging service will no longer be started as part of the reference implementations provided through the EdgeX Docker Compose files (the service is still available but commented out in those files). By default, all services now log to standard out (EnableRemote is set to false and File is set to ''). If users wish to still use the central logging service, they must configure each service to use it (set EnableRemote=true). Users can still alternately choose to have the services log to a file with additional configuration changes (set File to the appropriate file location). The Support Logging Service will removed in a future release of EdgeX Foundry. Logging Service Documentation For information on the logging service, see the Fuji release logging service documentation .","title":"Logging"},{"location":"microservices/support/logging/Ch-Logging/#logging","text":"","title":"Logging"},{"location":"microservices/support/logging/Ch-Logging/#deprecation-notice","text":"Please note that the logging service has been deprecated with the Geneva release (v1.2) . The EdgeX community feels that there are better log aggregation services available in the open source community or by deployment/orchestration tools. Starting with the Geneva release, logging service will no longer be started as part of the reference implementations provided through the EdgeX Docker Compose files (the service is still available but commented out in those files). By default, all services now log to standard out (EnableRemote is set to false and File is set to ''). If users wish to still use the central logging service, they must configure each service to use it (set EnableRemote=true). Users can still alternately choose to have the services log to a file with additional configuration changes (set File to the appropriate file location). The Support Logging Service will removed in a future release of EdgeX Foundry.","title":"Deprecation Notice"},{"location":"microservices/support/logging/Ch-Logging/#logging-service-documentation","text":"For information on the logging service, see the Fuji release logging service documentation .","title":"Logging Service Documentation"},{"location":"microservices/support/notifications/Ch-AlertsNotifications/","text":"Alerts & Notifications Introduction When another system or a person needs to know that something occurred in EdgeX, the alerts and notifications micro service sends that notification. Examples of alerts and notifications that other services could broadcast, include the provisioning of a new device, sensor data detected outside of certain parameters (usually detected by a device service or rules engine) or system or service malfunctions (usually detected by system management services). Terminology Notifications are informative, whereas Alerts are typically of a more important, critical, or urgent nature, possibly requiring immediate action. This diagram shows the high-level architecture of the notification service. On the left side, the APIs are provided for other micro services, on-box applications, and off-box applications to use. The APIs could be in REST, AMQP, MQTT, or any standard application protocols. Warning Currently in EdgeX Foundry, only the RESTful interface is provided. On the right side, the notification receiver could be a person or an application system on Cloud or in a server room. By invoking the Subscription RESTful interface to subscribe the specific types of notifications, the receiver obtains the appropriate notifications through defined receiving channels when events occur. The receiving channels include SMS message, e-mail, REST callback, AMQP, MQTT, and so on. Warning Currently in EdgeX Foundry, e-mail and REST callback channels are provided. When the notification service receives notifications from any interface, the notifications are passed to the Notifications Handler internally. The Notifications Handler persists the received notifications first, and passes them to the Distribution Coordinator immediately when a given notification is either critical (severity = \u201cCRITICAL\u201d) or to the Message Scheduler when it is normal (severity = \u201cNORMAL\u201d). When the Distribution Coordinator receives a notification, it first queries the Subscription database to get receivers who need this notification and their receiving channel information. According to the channel information, the Distribution Coordinator passes this notification to the corresponding channel senders. Then, the channel senders send out the notifications to the subscribed receivers. Workflow Normal Notifications When a client requests a notification to be sent with \"NORMAL\" status, the notification is queued up (batched with other normal notifications). The Message Scheduler, under a configurable interval, calls on the Distribution Coordinator to send all normal notifications to their receivers. When a normal notification fails to be sent, it is retried a configurable number of times (resend limit). After exceeding the resent tries, the notification is elevated to \"CRITICAL\" status and then sent through the critical notifications workflow below. Critical Notifications Notifications that are sent with \"CRITICAL\" status, or notifications that have failed to send via the NORMAL workflow are immediately sent to their receivers via the Distribution Coordinator. If a critical notification fails to send for a specified number of retries, the service escalates the notification in order to notify an escalation subscriber of the failure to notify the receiver. Data Model Data Dictionary Channel Property Description The object used to describe the notification end point. Channel supports transmissions and notifications with fields for delivery via email or REST Type object of ChannelType - indicates whether the channel facilitates email or REST MailAddresses An array of string email addresses Url A string REST API destination endpoint Notification Property Description The object used to describe the message and sender content of a notification. ID Uniquely identifies an notification, for example a UUID Slug acts as the name of the notification Sender a string indicating the notification message sender Category an enumeration string indicating whether the notification is about software health, hardware health or a security issue Severity an enumeration string indicating the severity of the notification - as either normal or critical Content The message sent to the receivers Description Human readable description explaining the reason for the notification or alert Status an enumeration string indicating the status of the notification as new, processed or escalated Labels array of associated means to label or tag a notification for better search and filtering ContentType string indicating the type of content in the notification message Transmission Property Description The object used to group Notifications ID Uniquely identifies an transmission, for example a UUID Notification a notification object - the message and sender content Receiver a string indicating the intended receiver of the notification Channel a channel object indicating the destination for the notification Status an enumeration string indicating whether the transmission failed, was sent, was acknowledged, or was escalated ResendCount number indicating the number of resent attempts Records an array of TransmissionRecords TransmissionRecord Property Description Information the status and response of a notification sent to a receiver Status an enumeration string indicating whether the transmission failed, was sent, was acknowledged, or escalated Response the response string from the receiver Sent A timestamp indicating when the notification was sent High Level Interaction Diagrams This section shows the sequence diagrams for some of the more critical or complex events regarding alerts and notifications. Critical Notifications Sequence When receiving a critical notification (SEVERITY = \"CRITICAL\"), it persists first and triggers the distribution process immediately. After updating the notification status, Alerts and Notifications respond to the client to indicate the notification has been accepted. Normal Notifications Sequence When receiving a normal notification (SEVERITY = \"NORMAL\"), it persists first and responds to the client to indicate the notification has been accepted immediately. After a configurable duration, a scheduler triggers the distribution process in batch. Critical Resend Sequence When encountering any error during sending critical notification, an individual resend task is scheduled, and each transmission record persists. If the resend tasks keeps failing and the resend count exceeds the configurable limit, the escalation process is triggered. The escalated notification is sent to particular receivers of a special subscription (slug = \"ESCALATION\"). Resend Sequence For other non-critical notifications, the resend operation is triggered by a scheduler. Cleanup Sequence Cleanup service removes old notification and transmission records. Configuration Properties Please refer to the general Configuration documentation for configuration properties common to all services. Writable Property Default Value Description Writable properties can be set and will dynamically take effect without service restart ResendLimit 2 Sets the retry limit for attempts to send notifications. NORMAL notifications are make CRITICAL after exceeding the resend limit. CRITICAL notifications are sent to the escalation subscriber when resend limit is exceeded. Service Property Default Value Description MaxResultCount 50000 Maximum number of objects (example: notifications) that are to be returned on any query of notifications database via its API Databases/Databases.Primary Property Default Value Description Properties used by the service to access the database Host 'localhost' Host running the notifications persistence database Name 'notifications' Document store or database name Password 'password' Password used to access the database Username 'notifications' Username used to access the database Port 6379 Port for accessing the database service - the Redis port by default Timeout 5000 Database connection timeout in milliseconds Type 'redisdb' Database to use - either redisdb or mongodb Smtp Property Default Value Description Config to connect to applicable SMTP (email) service. All the properties with prefix \"smtp\" are for mail server configuration. Configure the mail server appropriately to send alerts and notifications. The correct values depend on which mail server is used. Smtp Host smtp.gmail.com SMTP service host name Smtp Port 587 SMTP service port number Smtp EnableSelfSignedCert false Indicates whether a self-signed cert can be used for secure connectivity. Smtp Username username@mail.example.com A username for authentications with the Smtp server, if required. Smtp Password (empty string) SMTP service host access password Smtp Sender jdoe@gmail.com SMTP service sender/username Smtp Subject EdgeX Notification SMTP notification message subject Gmail Configuration Example Before using Gmail to send alerts and notifications, configure the sign-in security settings through one of the following two methods: Enable 2-Step Verification and use an App Password (Recommended). An App password is a 16-digit passcode that gives an app or device permission to access your Google Account. For more detail about this topic, please refer to this Google official document: https://support.google.com/accounts/answer/185833 . Allow less secure apps: If the 2-Step Verification is not enabled, you may need to allow less secure apps to access the Gmail account. Please see the instruction from this Google official document on this topic: https://support.google.com/accounts/answer/6010255 . Then, use the following settings for the mail server properties: Smtp Port=25 Smtp Host=smtp.gmail.com Smtp Sender= ${ Gmail account } Smtp Password= ${ Gmail password or App password } Yahoo Mail Configuration Example Similar to Gmail, configure the sign-in security settings for Yahoo through one of the following two methods: Enable 2-Step Verification and use an App Password (Recommended). Please see this Yahoo official document for more detail: https://help.yahoo.com/kb/SLN15241.html . Allow apps that use less secure sign in. Please see this Yahoo official document for more detail on this topic: https://help.yahoo.com/kb/SLN27791.html . Then, use the following settings for the mail server properties: Smtp Port=25 Smtp Host=smtp.mail.yahoo.com Smtp Sender= ${ Yahoo account } Smtp Password= ${ Yahoo password or App password } API Reference Support Notifications API Reference","title":"Alerts & Notifications"},{"location":"microservices/support/notifications/Ch-AlertsNotifications/#alerts-notifications","text":"","title":"Alerts &amp; Notifications"},{"location":"microservices/support/notifications/Ch-AlertsNotifications/#introduction","text":"When another system or a person needs to know that something occurred in EdgeX, the alerts and notifications micro service sends that notification. Examples of alerts and notifications that other services could broadcast, include the provisioning of a new device, sensor data detected outside of certain parameters (usually detected by a device service or rules engine) or system or service malfunctions (usually detected by system management services).","title":"Introduction"},{"location":"microservices/support/notifications/Ch-AlertsNotifications/#terminology","text":"Notifications are informative, whereas Alerts are typically of a more important, critical, or urgent nature, possibly requiring immediate action. This diagram shows the high-level architecture of the notification service. On the left side, the APIs are provided for other micro services, on-box applications, and off-box applications to use. The APIs could be in REST, AMQP, MQTT, or any standard application protocols. Warning Currently in EdgeX Foundry, only the RESTful interface is provided. On the right side, the notification receiver could be a person or an application system on Cloud or in a server room. By invoking the Subscription RESTful interface to subscribe the specific types of notifications, the receiver obtains the appropriate notifications through defined receiving channels when events occur. The receiving channels include SMS message, e-mail, REST callback, AMQP, MQTT, and so on. Warning Currently in EdgeX Foundry, e-mail and REST callback channels are provided. When the notification service receives notifications from any interface, the notifications are passed to the Notifications Handler internally. The Notifications Handler persists the received notifications first, and passes them to the Distribution Coordinator immediately when a given notification is either critical (severity = \u201cCRITICAL\u201d) or to the Message Scheduler when it is normal (severity = \u201cNORMAL\u201d). When the Distribution Coordinator receives a notification, it first queries the Subscription database to get receivers who need this notification and their receiving channel information. According to the channel information, the Distribution Coordinator passes this notification to the corresponding channel senders. Then, the channel senders send out the notifications to the subscribed receivers.","title":"Terminology"},{"location":"microservices/support/notifications/Ch-AlertsNotifications/#workflow","text":"","title":"Workflow"},{"location":"microservices/support/notifications/Ch-AlertsNotifications/#normal-notifications","text":"When a client requests a notification to be sent with \"NORMAL\" status, the notification is queued up (batched with other normal notifications). The Message Scheduler, under a configurable interval, calls on the Distribution Coordinator to send all normal notifications to their receivers. When a normal notification fails to be sent, it is retried a configurable number of times (resend limit). After exceeding the resent tries, the notification is elevated to \"CRITICAL\" status and then sent through the critical notifications workflow below.","title":"Normal Notifications"},{"location":"microservices/support/notifications/Ch-AlertsNotifications/#critical-notifications","text":"Notifications that are sent with \"CRITICAL\" status, or notifications that have failed to send via the NORMAL workflow are immediately sent to their receivers via the Distribution Coordinator. If a critical notification fails to send for a specified number of retries, the service escalates the notification in order to notify an escalation subscriber of the failure to notify the receiver.","title":"Critical Notifications"},{"location":"microservices/support/notifications/Ch-AlertsNotifications/#data-model","text":"","title":"Data Model"},{"location":"microservices/support/notifications/Ch-AlertsNotifications/#data-dictionary","text":"Channel Property Description The object used to describe the notification end point. Channel supports transmissions and notifications with fields for delivery via email or REST Type object of ChannelType - indicates whether the channel facilitates email or REST MailAddresses An array of string email addresses Url A string REST API destination endpoint Notification Property Description The object used to describe the message and sender content of a notification. ID Uniquely identifies an notification, for example a UUID Slug acts as the name of the notification Sender a string indicating the notification message sender Category an enumeration string indicating whether the notification is about software health, hardware health or a security issue Severity an enumeration string indicating the severity of the notification - as either normal or critical Content The message sent to the receivers Description Human readable description explaining the reason for the notification or alert Status an enumeration string indicating the status of the notification as new, processed or escalated Labels array of associated means to label or tag a notification for better search and filtering ContentType string indicating the type of content in the notification message Transmission Property Description The object used to group Notifications ID Uniquely identifies an transmission, for example a UUID Notification a notification object - the message and sender content Receiver a string indicating the intended receiver of the notification Channel a channel object indicating the destination for the notification Status an enumeration string indicating whether the transmission failed, was sent, was acknowledged, or was escalated ResendCount number indicating the number of resent attempts Records an array of TransmissionRecords TransmissionRecord Property Description Information the status and response of a notification sent to a receiver Status an enumeration string indicating whether the transmission failed, was sent, was acknowledged, or escalated Response the response string from the receiver Sent A timestamp indicating when the notification was sent","title":"Data Dictionary"},{"location":"microservices/support/notifications/Ch-AlertsNotifications/#high-level-interaction-diagrams","text":"This section shows the sequence diagrams for some of the more critical or complex events regarding alerts and notifications. Critical Notifications Sequence When receiving a critical notification (SEVERITY = \"CRITICAL\"), it persists first and triggers the distribution process immediately. After updating the notification status, Alerts and Notifications respond to the client to indicate the notification has been accepted. Normal Notifications Sequence When receiving a normal notification (SEVERITY = \"NORMAL\"), it persists first and responds to the client to indicate the notification has been accepted immediately. After a configurable duration, a scheduler triggers the distribution process in batch. Critical Resend Sequence When encountering any error during sending critical notification, an individual resend task is scheduled, and each transmission record persists. If the resend tasks keeps failing and the resend count exceeds the configurable limit, the escalation process is triggered. The escalated notification is sent to particular receivers of a special subscription (slug = \"ESCALATION\"). Resend Sequence For other non-critical notifications, the resend operation is triggered by a scheduler. Cleanup Sequence Cleanup service removes old notification and transmission records.","title":"High Level Interaction Diagrams"},{"location":"microservices/support/notifications/Ch-AlertsNotifications/#configuration-properties","text":"Please refer to the general Configuration documentation for configuration properties common to all services. Writable Property Default Value Description Writable properties can be set and will dynamically take effect without service restart ResendLimit 2 Sets the retry limit for attempts to send notifications. NORMAL notifications are make CRITICAL after exceeding the resend limit. CRITICAL notifications are sent to the escalation subscriber when resend limit is exceeded. Service Property Default Value Description MaxResultCount 50000 Maximum number of objects (example: notifications) that are to be returned on any query of notifications database via its API Databases/Databases.Primary Property Default Value Description Properties used by the service to access the database Host 'localhost' Host running the notifications persistence database Name 'notifications' Document store or database name Password 'password' Password used to access the database Username 'notifications' Username used to access the database Port 6379 Port for accessing the database service - the Redis port by default Timeout 5000 Database connection timeout in milliseconds Type 'redisdb' Database to use - either redisdb or mongodb Smtp Property Default Value Description Config to connect to applicable SMTP (email) service. All the properties with prefix \"smtp\" are for mail server configuration. Configure the mail server appropriately to send alerts and notifications. The correct values depend on which mail server is used. Smtp Host smtp.gmail.com SMTP service host name Smtp Port 587 SMTP service port number Smtp EnableSelfSignedCert false Indicates whether a self-signed cert can be used for secure connectivity. Smtp Username username@mail.example.com A username for authentications with the Smtp server, if required. Smtp Password (empty string) SMTP service host access password Smtp Sender jdoe@gmail.com SMTP service sender/username Smtp Subject EdgeX Notification SMTP notification message subject","title":"Configuration Properties"},{"location":"microservices/support/notifications/Ch-AlertsNotifications/#gmail-configuration-example","text":"Before using Gmail to send alerts and notifications, configure the sign-in security settings through one of the following two methods: Enable 2-Step Verification and use an App Password (Recommended). An App password is a 16-digit passcode that gives an app or device permission to access your Google Account. For more detail about this topic, please refer to this Google official document: https://support.google.com/accounts/answer/185833 . Allow less secure apps: If the 2-Step Verification is not enabled, you may need to allow less secure apps to access the Gmail account. Please see the instruction from this Google official document on this topic: https://support.google.com/accounts/answer/6010255 . Then, use the following settings for the mail server properties: Smtp Port=25 Smtp Host=smtp.gmail.com Smtp Sender= ${ Gmail account } Smtp Password= ${ Gmail password or App password }","title":"Gmail Configuration Example"},{"location":"microservices/support/notifications/Ch-AlertsNotifications/#yahoo-mail-configuration-example","text":"Similar to Gmail, configure the sign-in security settings for Yahoo through one of the following two methods: Enable 2-Step Verification and use an App Password (Recommended). Please see this Yahoo official document for more detail: https://help.yahoo.com/kb/SLN15241.html . Allow apps that use less secure sign in. Please see this Yahoo official document for more detail on this topic: https://help.yahoo.com/kb/SLN27791.html . Then, use the following settings for the mail server properties: Smtp Port=25 Smtp Host=smtp.mail.yahoo.com Smtp Sender= ${ Yahoo account } Smtp Password= ${ Yahoo password or App password }","title":"Yahoo Mail Configuration Example"},{"location":"microservices/support/notifications/Ch-AlertsNotifications/#api-reference","text":"Support Notifications API Reference","title":"API Reference"},{"location":"microservices/support/rulesengine/Ch-RulesEngine/","text":"Rules Engine Deprecation Notice Please note that the supporting rules engine service has been deprecated with the Geneva release (v1.2) . With the Geneva release, EdgeX has formed a partnership with the EMQ X Kuiper open source project and offers the Kuiper Rules Engine as the reference implementation rules engine. The EdgeX support rules engine was Java-based and wrapped the open source Drools rules engine . This was the last of the EdgeX Java services to be replaced. Starting with the Geneva release, by default, the EdgeX reference implementations (provided through the EdgeX Docker Compose files) will use Kuiper with a dedicated application service providing the data feed to the Kuiper engine. The support rules engine is still available but users must find and uncomment the support rules engine in the Docker Compose file. The Support Rules Engine will removed in a future release of EdgeX Foundry. Support Rules Engine Service Documentation For information on the support rules engine service, see the Fuji release rules engine service documentation .","title":"Rules Engine"},{"location":"microservices/support/rulesengine/Ch-RulesEngine/#rules-engine","text":"","title":"Rules Engine"},{"location":"microservices/support/rulesengine/Ch-RulesEngine/#deprecation-notice","text":"Please note that the supporting rules engine service has been deprecated with the Geneva release (v1.2) . With the Geneva release, EdgeX has formed a partnership with the EMQ X Kuiper open source project and offers the Kuiper Rules Engine as the reference implementation rules engine. The EdgeX support rules engine was Java-based and wrapped the open source Drools rules engine . This was the last of the EdgeX Java services to be replaced. Starting with the Geneva release, by default, the EdgeX reference implementations (provided through the EdgeX Docker Compose files) will use Kuiper with a dedicated application service providing the data feed to the Kuiper engine. The support rules engine is still available but users must find and uncomment the support rules engine in the Docker Compose file. The Support Rules Engine will removed in a future release of EdgeX Foundry.","title":"Deprecation Notice"},{"location":"microservices/support/rulesengine/Ch-RulesEngine/#support-rules-engine-service-documentation","text":"For information on the support rules engine service, see the Fuji release rules engine service documentation .","title":"Support Rules Engine Service Documentation"},{"location":"microservices/support/scheduler/Ch-Scheduling/","text":"Scheduling Introduction The support scheduler micro service provide an internal EdgeX \u201cclock\u201d that can kick off operations in any EdgeX service. At a configuration specified time (called an interval ), the service calls on any EdgeX service API URL via REST to trigger an operation (called an interval action ). For example, the scheduling service periodically calls on core data APIs to clean up old sensed events that have been successfully exported out of EdgeX. Default Interval Actions Scheduled interval actions configured by default with the reference implementation of the service include: Clean up Core-data events/readings that have been moved (\"pushed\") to external applications/systems like a cloud provider. This is the \"Scrubbed Pushed\" operation. Scheduler parameters around this operation determine how often and where to call into core data to invoke this clean up of unneeded data operation. Clean up of Core-data events/readings that have been persisted for an extended period. In order to prevent the edge node from running out of space, these old events/readings are removed. This is the \"ScrubAged\" operation. Scheduler parameters around this operation determine how often and where to call into Core-data to invoke this operation to expunge of old data. Note The removal of both exported records and stale records occurs on a configurable schedule. By default, both of the default actions above are invoked once a day at midnight. Scheduler Persistence Support scheduler uses a data store to persist the Interval(s) and IntervalAction(s). Persistence is accomplished the Scheduler DB located in your current configured database for EdgeX. Info Redis DB is used by default to persist all scheduler service information to include intervals and interval actions. ISO 8601 Standard The times and frequencies defined in the scheduler service's intervals are specified using the international date/time standard - ISO 8601 . So, for example, the start of an interval would be represented in YYYYMMDD'T'HHmmss format. 20180101T000000 represents January 1, 2018 at midnight. Frequencies are represented with ISO 8601 durations. Data Model Data Dictionary Interval Property Description An object defining a specific \"period\" in time ID Uniquely identifies an interval, for example a UUID Created A timestamp indicating when the interval was created in the database Modified A timestamp indicating when the interval was last modified Origin A timestamp indicating when the original interval was created Name the name of the given interval start The start time of the given interval in ISO 8601 format end The end time of the given interval in ISO 8601 format frequency Periodicity of the interval according to ISO 8601 cron cron styled regular expression indicating how often the action under interval should occur. Use either runOnce, frequency or cron and not all runOnce boolean indicating that this interval runs one time - at the time indicated by the start IntervalAction Property Description The action triggered by the service when the associated interval occurs ID Uniquely identifies an interval action, for example a UUID Created A timestamp indicating when the interval action was created in the database Modified A timestamp indicating when the interval action was last modified Origin A timestamp indicating when the original interval action was created Name the name of the interval action Interval associated interval that defines when the action occurs Host The host targeted by the action when it activates Parameters paremeters sent in the body of the action call request Target The name of the targeted application Protocol protocol used when interacting with the targeted host HTTPMethod assuming a RESTful operation, the HTTP method to be invoked by the action Address assuming a RESTful operation, the HTTP address to be invoked by the action Port The port on the targeted host Path assuming a RESTful operation, the path to be invoked in combination with the Method and Address Publisher assuming a message bus operation, the publisher to be used in invoking the operation via message (future use) User username used when the action must be invoked using user based authentication (future use) Password password used when the action must be invoked using user based authentication (future use) Topic assuming a message bus operation, the topic to push the invoking operation message into High Level Interaction Diagrams Scheduler interval actions to expunge old and exported (pushed) records from Core Data Configuration Properties Please refer to the general Configuration documentation for configuration properties common to all services. Writable Property Default Value Description Writable properties can be set and will dynamically take effect without service restart ScheduleIntervalTime 500 the time, in milliseconds, to trigger any applicable interval actions Service Property Default Value Description MaxResultCount 50000 Maximum number of objects (example: intervals) that are to be returned on any query of core data via its API Databases/Databases.Primary Property Default Value Description Properties used by the service to access the database Host 'localhost' Host running the scheduler persistence database Name 'scheduler' Document store or database name Password 'password' Password used to access the database Username 'scheduler' Username used to access the database Port 6379 Port for accessing the database service - the Redis port by default Timeout 5000 Database connection timeout in milliseconds Type 'redisdb' Database to use - either redisdb or mongodb Intervals/Intervals.Midnight Property Default Value Description Default intervals for use with default interval actions Name midnight Name of the every day at midnight interval Start 20180101T000000 Indicates the start time for the midnight interval which is a midnight, Jan 1, 2018 which effectively sets the start time as of right now since this is in the past Frequency 24 defines a frequency of every 24 hours IntervalActions.IntervalActions.ScrubPushed Property Default Value Description Configuration of the core data scrub operation which is to kick off every midnight Name 'scrub-pushed-events' name of the interval action Host 'localhost' run the request on core data assumed to be on the localhost Port 48080 run the request against the default core data port Protocol 'http' Make a RESTful request to core data Method 'DELETE' Make a RESTful delete operation request to core data Target 'core-data' target core data Path '/api/v1/event/scrub' request core data's scrub API Interval 'midnight' run the operation every midnight as specified by the configuration defined interval IntervalActions.IntervalActions.ScrubAged Property Default Value Description Configuration of the core data clean old events operation which is to kick off every midnight Name 'scrub-aged-events' name of the interval action Host 'localhost' run the request on core data assumed to be on the localhost Port 48080 run the request against the default core data port Protocol 'http' Make a RESTful request to core data Method 'DELETE' Make a RESTful delete operation request to core data Target 'core-data' target core data Path '/api/v1/event/removeold/age/604800000' request core data's remove old events API with parameter of 7 days in milliseconds Interval 'midnight' run the operation every midnight as specified by the configuration defined interval API Reference Support Scheduler API Reference","title":"Scheduling"},{"location":"microservices/support/scheduler/Ch-Scheduling/#scheduling","text":"","title":"Scheduling"},{"location":"microservices/support/scheduler/Ch-Scheduling/#introduction","text":"The support scheduler micro service provide an internal EdgeX \u201cclock\u201d that can kick off operations in any EdgeX service. At a configuration specified time (called an interval ), the service calls on any EdgeX service API URL via REST to trigger an operation (called an interval action ). For example, the scheduling service periodically calls on core data APIs to clean up old sensed events that have been successfully exported out of EdgeX.","title":"Introduction"},{"location":"microservices/support/scheduler/Ch-Scheduling/#default-interval-actions","text":"Scheduled interval actions configured by default with the reference implementation of the service include: Clean up Core-data events/readings that have been moved (\"pushed\") to external applications/systems like a cloud provider. This is the \"Scrubbed Pushed\" operation. Scheduler parameters around this operation determine how often and where to call into core data to invoke this clean up of unneeded data operation. Clean up of Core-data events/readings that have been persisted for an extended period. In order to prevent the edge node from running out of space, these old events/readings are removed. This is the \"ScrubAged\" operation. Scheduler parameters around this operation determine how often and where to call into Core-data to invoke this operation to expunge of old data. Note The removal of both exported records and stale records occurs on a configurable schedule. By default, both of the default actions above are invoked once a day at midnight.","title":"Default Interval Actions"},{"location":"microservices/support/scheduler/Ch-Scheduling/#scheduler-persistence","text":"Support scheduler uses a data store to persist the Interval(s) and IntervalAction(s). Persistence is accomplished the Scheduler DB located in your current configured database for EdgeX. Info Redis DB is used by default to persist all scheduler service information to include intervals and interval actions.","title":"Scheduler Persistence"},{"location":"microservices/support/scheduler/Ch-Scheduling/#iso-8601-standard","text":"The times and frequencies defined in the scheduler service's intervals are specified using the international date/time standard - ISO 8601 . So, for example, the start of an interval would be represented in YYYYMMDD'T'HHmmss format. 20180101T000000 represents January 1, 2018 at midnight. Frequencies are represented with ISO 8601 durations.","title":"ISO 8601 Standard"},{"location":"microservices/support/scheduler/Ch-Scheduling/#data-model","text":"","title":"Data Model"},{"location":"microservices/support/scheduler/Ch-Scheduling/#data-dictionary","text":"Interval Property Description An object defining a specific \"period\" in time ID Uniquely identifies an interval, for example a UUID Created A timestamp indicating when the interval was created in the database Modified A timestamp indicating when the interval was last modified Origin A timestamp indicating when the original interval was created Name the name of the given interval start The start time of the given interval in ISO 8601 format end The end time of the given interval in ISO 8601 format frequency Periodicity of the interval according to ISO 8601 cron cron styled regular expression indicating how often the action under interval should occur. Use either runOnce, frequency or cron and not all runOnce boolean indicating that this interval runs one time - at the time indicated by the start IntervalAction Property Description The action triggered by the service when the associated interval occurs ID Uniquely identifies an interval action, for example a UUID Created A timestamp indicating when the interval action was created in the database Modified A timestamp indicating when the interval action was last modified Origin A timestamp indicating when the original interval action was created Name the name of the interval action Interval associated interval that defines when the action occurs Host The host targeted by the action when it activates Parameters paremeters sent in the body of the action call request Target The name of the targeted application Protocol protocol used when interacting with the targeted host HTTPMethod assuming a RESTful operation, the HTTP method to be invoked by the action Address assuming a RESTful operation, the HTTP address to be invoked by the action Port The port on the targeted host Path assuming a RESTful operation, the path to be invoked in combination with the Method and Address Publisher assuming a message bus operation, the publisher to be used in invoking the operation via message (future use) User username used when the action must be invoked using user based authentication (future use) Password password used when the action must be invoked using user based authentication (future use) Topic assuming a message bus operation, the topic to push the invoking operation message into","title":"Data Dictionary"},{"location":"microservices/support/scheduler/Ch-Scheduling/#high-level-interaction-diagrams","text":"Scheduler interval actions to expunge old and exported (pushed) records from Core Data","title":"High Level Interaction Diagrams"},{"location":"microservices/support/scheduler/Ch-Scheduling/#configuration-properties","text":"Please refer to the general Configuration documentation for configuration properties common to all services. Writable Property Default Value Description Writable properties can be set and will dynamically take effect without service restart ScheduleIntervalTime 500 the time, in milliseconds, to trigger any applicable interval actions Service Property Default Value Description MaxResultCount 50000 Maximum number of objects (example: intervals) that are to be returned on any query of core data via its API Databases/Databases.Primary Property Default Value Description Properties used by the service to access the database Host 'localhost' Host running the scheduler persistence database Name 'scheduler' Document store or database name Password 'password' Password used to access the database Username 'scheduler' Username used to access the database Port 6379 Port for accessing the database service - the Redis port by default Timeout 5000 Database connection timeout in milliseconds Type 'redisdb' Database to use - either redisdb or mongodb Intervals/Intervals.Midnight Property Default Value Description Default intervals for use with default interval actions Name midnight Name of the every day at midnight interval Start 20180101T000000 Indicates the start time for the midnight interval which is a midnight, Jan 1, 2018 which effectively sets the start time as of right now since this is in the past Frequency 24 defines a frequency of every 24 hours IntervalActions.IntervalActions.ScrubPushed Property Default Value Description Configuration of the core data scrub operation which is to kick off every midnight Name 'scrub-pushed-events' name of the interval action Host 'localhost' run the request on core data assumed to be on the localhost Port 48080 run the request against the default core data port Protocol 'http' Make a RESTful request to core data Method 'DELETE' Make a RESTful delete operation request to core data Target 'core-data' target core data Path '/api/v1/event/scrub' request core data's scrub API Interval 'midnight' run the operation every midnight as specified by the configuration defined interval IntervalActions.IntervalActions.ScrubAged Property Default Value Description Configuration of the core data clean old events operation which is to kick off every midnight Name 'scrub-aged-events' name of the interval action Host 'localhost' run the request on core data assumed to be on the localhost Port 48080 run the request against the default core data port Protocol 'http' Make a RESTful request to core data Method 'DELETE' Make a RESTful delete operation request to core data Target 'core-data' target core data Path '/api/v1/event/removeold/age/604800000' request core data's remove old events API with parameter of 7 days in milliseconds Interval 'midnight' run the operation every midnight as specified by the configuration defined interval","title":"Configuration Properties"},{"location":"microservices/support/scheduler/Ch-Scheduling/#api-reference","text":"Support Scheduler API Reference","title":"API Reference"},{"location":"microservices/system-management/Ch_SystemManagement/","text":"System Management Micro Services System Management facilities provide the central point of contact for external management systems to start/stop/restart EdgeX services, get the configuration for a service, the status/health of a service, or get metrics on the EdgeX services (such as memory usage) so that the EdgeX services can be monitored. Facilitating Larger Management Systems EdgeX is an edge platform. It typically runs as close to the physical sensor/device world as it can in order to provide the fastest and most efficient collection and reaction to the data that it can. In a larger solution deployment, there could be several instances of EdgeX each managing and controlling a subset of the \u201cthings\u201d in the overall deployment. In a very big deployment, a larger management system will want to manage the edge systems and resources of the overall deployment. Just as there is a management system to control all the nodes and infrastructure within a cloud data center, and across cloud data centers, so too there will likely be management systems that will manage and control all the nodes (from edge to cloud) and infrastructure of a complete fog or IoT deployment. EdgeX system management is not the larger control management system. Instead, EdgeX system management capability is meant to facilitate the larger control management systems. When a management system wants to start or stop the entire deployment, EdgeX system management capability is there to receive the command and start or stop the EdgeX platform and associated infrastructure of the EdgeX instance that it is aware of. Likewise, when the larger central management system needs service metrics or configuration from EdgeX, it can call on the EdgeX system management services to provide the information it needs (thereby avoiding communications with each individual service). Use is Optional There are many control management systems today. Each of these systems operates differently. Some solutions may not require the EdgeX management components. For example, if your edge platform is large enough to support the use of something like Kubernetes or Swarm to deploy, orchestrate and manage your containerized edge applications, you may not require the system management services provided with EdgeX Foundry. Therefore, use of the system management services is considered optional. System Management Services There are two services that provide the EdgeX system management capability. System Management Agent : the micro service that other systems or services communicate with and make their management request (to start/stop/restart, get the configuration, get the status/health, or get metrics of the EdgeX service). It communicates with the EdgeX micro services or executor (see below) to satisfy the requests. System Management Executor : the excutable that performs the start, stop and restart of the services as well as metrics gathering from the EdgeX services. While EdgeX provides a single reference implementation of the system management executor today (one for Docker environments), there may be many implementations of the executor in the future.","title":"System Management Micro Services"},{"location":"microservices/system-management/Ch_SystemManagement/#system-management-micro-services","text":"System Management facilities provide the central point of contact for external management systems to start/stop/restart EdgeX services, get the configuration for a service, the status/health of a service, or get metrics on the EdgeX services (such as memory usage) so that the EdgeX services can be monitored.","title":"System Management Micro Services"},{"location":"microservices/system-management/Ch_SystemManagement/#facilitating-larger-management-systems","text":"EdgeX is an edge platform. It typically runs as close to the physical sensor/device world as it can in order to provide the fastest and most efficient collection and reaction to the data that it can. In a larger solution deployment, there could be several instances of EdgeX each managing and controlling a subset of the \u201cthings\u201d in the overall deployment. In a very big deployment, a larger management system will want to manage the edge systems and resources of the overall deployment. Just as there is a management system to control all the nodes and infrastructure within a cloud data center, and across cloud data centers, so too there will likely be management systems that will manage and control all the nodes (from edge to cloud) and infrastructure of a complete fog or IoT deployment. EdgeX system management is not the larger control management system. Instead, EdgeX system management capability is meant to facilitate the larger control management systems. When a management system wants to start or stop the entire deployment, EdgeX system management capability is there to receive the command and start or stop the EdgeX platform and associated infrastructure of the EdgeX instance that it is aware of. Likewise, when the larger central management system needs service metrics or configuration from EdgeX, it can call on the EdgeX system management services to provide the information it needs (thereby avoiding communications with each individual service).","title":"Facilitating Larger Management Systems"},{"location":"microservices/system-management/Ch_SystemManagement/#use-is-optional","text":"There are many control management systems today. Each of these systems operates differently. Some solutions may not require the EdgeX management components. For example, if your edge platform is large enough to support the use of something like Kubernetes or Swarm to deploy, orchestrate and manage your containerized edge applications, you may not require the system management services provided with EdgeX Foundry. Therefore, use of the system management services is considered optional.","title":"Use is Optional"},{"location":"microservices/system-management/Ch_SystemManagement/#system-management-services","text":"There are two services that provide the EdgeX system management capability. System Management Agent : the micro service that other systems or services communicate with and make their management request (to start/stop/restart, get the configuration, get the status/health, or get metrics of the EdgeX service). It communicates with the EdgeX micro services or executor (see below) to satisfy the requests. System Management Executor : the excutable that performs the start, stop and restart of the services as well as metrics gathering from the EdgeX services. While EdgeX provides a single reference implementation of the system management executor today (one for Docker environments), there may be many implementations of the executor in the future.","title":"System Management Services"},{"location":"microservices/system-management/agent/Ch_SysMgmtAgent/","text":"System Management Agent (SMA) Introduction The SMA serves as the connection point of management control for an EdgeX instance. Management Architecture The SMA serves as the proxy for management requests. Some management requests (metrics requests and operations to start, stop and restart services) are routed to an executor for execution. Other requests (for service configuration) are routed to the services for a response. Configuration information is only available by asking each service for its current configuration. Metrics and operations (tasks to start, stop, restart) typically need to be performed by some other software that can perform the task best under the platform / deployment environment. When running EdgeX in a Docker Engine, Docker can provide service metrics like memory and CPU usage to the requestor. If EdgeX services were running non-containerized in a Linux environment, the request may be best performed by some Linux shell script or by sysd. An executor encapsulates the implementation for the metrics gathering and start, stop, restart operations. That implementation of the executor can vary based on OS, platform environment, etc. EdgeX defines the system management executor interface and a reference implementation which utilizes Docker (for situations when EdgeX is run in Docker) to responsd to metrics and start, stop, and restart operations. Examples of API Calls To get an appreciation for some SMA API calls in action, it is instructive to look at what responses the SMA provides to the caller, for the respective calls. The tabs below provide the API path and corresponding response for each of the system management capabilities. Info Notice, too, the error messages returned by the SMA, should it encounter a problem. Metrics of a service Example request: /api/v1/metrics/edgex-core-command,edgex-core-data Corresponding response, in JSON format: { \"Metrics\" :{ \"edgex-core-command\" :{ \"CpuBusyAvg\" : 2.224995150836366 , \"Memory\" :{ \"Alloc\" : 1403648 , \"Frees\" : 1504 , \"LiveObjects\" : 18280 , \"Mallocs\" : 19784 , \"Sys\" : 71891192 , \"TotalAlloc\" : 1403648 } }, \"edgex-core-data\" :{ \"CpuBusyAvg\" : 2.854720153816541 , \"Memory\" :{ \"Alloc\" : 929080 , \"Frees\" : 1453 , \"LiveObjects\" : 7700 , \"Mallocs\" : 9153 , \"Sys\" : 70451200 , \"TotalAlloc\" : 929080 } } } } Configuration of a service Example request: /api/v1/config/device-simple,edgex-core-data Corresponding response, in JSON format: { \"Configuration\" : { \"device-simple\" : \"device-simple service is not registered. Might not have started... \" , \"edgex-core-data\" : { \"Clients\" : { \"Logging\" : { \"Host\" : \"localhost\" , \"Port\" : 48061 , \"Protocol\" : \"http\" }, \"Metadata\" : { \"Host\" : \"localhost\" , \"Port\" : 48081 , \"Protocol\" : \"http\" } }, \"Databases\" : { \"Primary\" : { \"Host\" : \"localhost\" , \"Name\" : \"coredata\" , \"Password\" : \"\" , \"Port\" : 27017 , \"Timeout\" : 5000 , \"Type\" : \"mongodb\" , \"Username\" : \"\" } }, \"Logging\" : { \"EnableRemote\" : false , \"File\" : \"./logs/edgex-core-data.log\" }, \"MessageQueue\" : { \"Host\" : \"*\" , \"Port\" : 5563 , \"Protocol\" : \"tcp\" , \"Type\" : \"zero\" }, \"Registry\" : { \"Host\" : \"localhost\" , \"Port\" : 8500 , \"Type\" : \"consul\" }, \"Service\" : { \"BootTimeout\" : 30000 , \"CheckInterval\" : \"10s\" , \"ClientMonitor\" : 15000 , \"Host\" : \"localhost\" , \"Port\" : 48080 , \"Protocol\" : \"http\" , \"MaxResultCount\" : 50000 , \"StartupMsg\" : \"This is the Core Data Microservice\" , \"Timeout\" : 5000 }, \"Writable\" : { \"DeviceUpdateLastConnected\" : false , \"LogLevel\" : \"INFO\" , \"MetaDataCheck\" : false , \"PersistData\" : true , \"ServiceUpdateLastConnected\" : false , \"ValidateCheck\" : false } } } } Start a service Example request: /api/v1/operation Example (POST) body accompanying the \"start\" request: { \"action\" : \"start\" , \"services\" :[ \"edgex-core-data\" , ], \"params\" :[ \"graceful\" ] } Corresponding response, in JSON format, on success: \"Done. Started the requested services.\" Corresponding response, in JSON format, on failure: \"HTTP 500 - Internal Server Error\" Stop a service Example request: /api/v1/operation Example (POST) body accompanying the \"stop\" request: { \"action\" : \"stop\" , \"services\" :[ \"edgex-support-notifications\" ], \"params\" :[ \"graceful\" ] } Corresponding response, in JSON format, on success: \"Done. Stopped the requested service.\" Corresponding response, in JSON format, on failure: \"HTTP 500 - Internal Server Error\" Restart a service Example request: /api/v1/operation Example (POST) body accompanying the \"restart\" request: { \"action\" : \"restart\" , \"services\" :[ \"edgex-support-notifications\" , \"edgex-core-data\" , ], \"params\" :[ \"graceful\" ] } Corresponding response, in JSON format, on success: \"Done. Restarted the requested services.\" Corresponding response, in JSON format, on failure: \"HTTP 500 - Internal Server Error\" Health check on a service Example request: /api/v1/health/device-simple,edgex-core-data,support-notifications Corresponding response, in JSON format: { \"device-simple\" : \"device-simple service is not registered. Might not have started... \" , \"edgex-core-data\" : true , \"support-notifications\" : true } Configuration Properties Please refer to the general Configuration documentation for configuration properties common to all services. Writable Property Default Value Description Writable properties can be set and will dynamically take effect without service restart ResendLimit 2 Number of attempts to perform a system management operation before raising an error General Property Default Value Description general system management configuration properties ExecutorPath '../sys-mgmt-executor/sys-mgmt-executor' path to the executor to use for system management requests other than configuration MetricsMechanism 'direct-service' either direct-service or executor to advise the SMA where to go for service metrics information Service Property Default Value Description these keys represent the system management service configuration settings FormatSpecifier '%(\\d+\\$)?([-#+ 0(\\<]*)?(\\d+)?(\\.\\d+)?([tT])?([a-zA-Z%])' metrics data output format specifier API Reference System Management API Reference","title":"System Management Agent (SMA)"},{"location":"microservices/system-management/agent/Ch_SysMgmtAgent/#system-management-agent-sma","text":"","title":"System Management Agent (SMA)"},{"location":"microservices/system-management/agent/Ch_SysMgmtAgent/#introduction","text":"The SMA serves as the connection point of management control for an EdgeX instance.","title":"Introduction"},{"location":"microservices/system-management/agent/Ch_SysMgmtAgent/#management-architecture","text":"The SMA serves as the proxy for management requests. Some management requests (metrics requests and operations to start, stop and restart services) are routed to an executor for execution. Other requests (for service configuration) are routed to the services for a response. Configuration information is only available by asking each service for its current configuration. Metrics and operations (tasks to start, stop, restart) typically need to be performed by some other software that can perform the task best under the platform / deployment environment. When running EdgeX in a Docker Engine, Docker can provide service metrics like memory and CPU usage to the requestor. If EdgeX services were running non-containerized in a Linux environment, the request may be best performed by some Linux shell script or by sysd. An executor encapsulates the implementation for the metrics gathering and start, stop, restart operations. That implementation of the executor can vary based on OS, platform environment, etc. EdgeX defines the system management executor interface and a reference implementation which utilizes Docker (for situations when EdgeX is run in Docker) to responsd to metrics and start, stop, and restart operations.","title":"Management Architecture"},{"location":"microservices/system-management/agent/Ch_SysMgmtAgent/#examples-of-api-calls","text":"To get an appreciation for some SMA API calls in action, it is instructive to look at what responses the SMA provides to the caller, for the respective calls. The tabs below provide the API path and corresponding response for each of the system management capabilities. Info Notice, too, the error messages returned by the SMA, should it encounter a problem. Metrics of a service Example request: /api/v1/metrics/edgex-core-command,edgex-core-data Corresponding response, in JSON format: { \"Metrics\" :{ \"edgex-core-command\" :{ \"CpuBusyAvg\" : 2.224995150836366 , \"Memory\" :{ \"Alloc\" : 1403648 , \"Frees\" : 1504 , \"LiveObjects\" : 18280 , \"Mallocs\" : 19784 , \"Sys\" : 71891192 , \"TotalAlloc\" : 1403648 } }, \"edgex-core-data\" :{ \"CpuBusyAvg\" : 2.854720153816541 , \"Memory\" :{ \"Alloc\" : 929080 , \"Frees\" : 1453 , \"LiveObjects\" : 7700 , \"Mallocs\" : 9153 , \"Sys\" : 70451200 , \"TotalAlloc\" : 929080 } } } } Configuration of a service Example request: /api/v1/config/device-simple,edgex-core-data Corresponding response, in JSON format: { \"Configuration\" : { \"device-simple\" : \"device-simple service is not registered. Might not have started... \" , \"edgex-core-data\" : { \"Clients\" : { \"Logging\" : { \"Host\" : \"localhost\" , \"Port\" : 48061 , \"Protocol\" : \"http\" }, \"Metadata\" : { \"Host\" : \"localhost\" , \"Port\" : 48081 , \"Protocol\" : \"http\" } }, \"Databases\" : { \"Primary\" : { \"Host\" : \"localhost\" , \"Name\" : \"coredata\" , \"Password\" : \"\" , \"Port\" : 27017 , \"Timeout\" : 5000 , \"Type\" : \"mongodb\" , \"Username\" : \"\" } }, \"Logging\" : { \"EnableRemote\" : false , \"File\" : \"./logs/edgex-core-data.log\" }, \"MessageQueue\" : { \"Host\" : \"*\" , \"Port\" : 5563 , \"Protocol\" : \"tcp\" , \"Type\" : \"zero\" }, \"Registry\" : { \"Host\" : \"localhost\" , \"Port\" : 8500 , \"Type\" : \"consul\" }, \"Service\" : { \"BootTimeout\" : 30000 , \"CheckInterval\" : \"10s\" , \"ClientMonitor\" : 15000 , \"Host\" : \"localhost\" , \"Port\" : 48080 , \"Protocol\" : \"http\" , \"MaxResultCount\" : 50000 , \"StartupMsg\" : \"This is the Core Data Microservice\" , \"Timeout\" : 5000 }, \"Writable\" : { \"DeviceUpdateLastConnected\" : false , \"LogLevel\" : \"INFO\" , \"MetaDataCheck\" : false , \"PersistData\" : true , \"ServiceUpdateLastConnected\" : false , \"ValidateCheck\" : false } } } } Start a service Example request: /api/v1/operation Example (POST) body accompanying the \"start\" request: { \"action\" : \"start\" , \"services\" :[ \"edgex-core-data\" , ], \"params\" :[ \"graceful\" ] } Corresponding response, in JSON format, on success: \"Done. Started the requested services.\" Corresponding response, in JSON format, on failure: \"HTTP 500 - Internal Server Error\" Stop a service Example request: /api/v1/operation Example (POST) body accompanying the \"stop\" request: { \"action\" : \"stop\" , \"services\" :[ \"edgex-support-notifications\" ], \"params\" :[ \"graceful\" ] } Corresponding response, in JSON format, on success: \"Done. Stopped the requested service.\" Corresponding response, in JSON format, on failure: \"HTTP 500 - Internal Server Error\" Restart a service Example request: /api/v1/operation Example (POST) body accompanying the \"restart\" request: { \"action\" : \"restart\" , \"services\" :[ \"edgex-support-notifications\" , \"edgex-core-data\" , ], \"params\" :[ \"graceful\" ] } Corresponding response, in JSON format, on success: \"Done. Restarted the requested services.\" Corresponding response, in JSON format, on failure: \"HTTP 500 - Internal Server Error\" Health check on a service Example request: /api/v1/health/device-simple,edgex-core-data,support-notifications Corresponding response, in JSON format: { \"device-simple\" : \"device-simple service is not registered. Might not have started... \" , \"edgex-core-data\" : true , \"support-notifications\" : true }","title":"Examples of API Calls"},{"location":"microservices/system-management/agent/Ch_SysMgmtAgent/#configuration-properties","text":"Please refer to the general Configuration documentation for configuration properties common to all services. Writable Property Default Value Description Writable properties can be set and will dynamically take effect without service restart ResendLimit 2 Number of attempts to perform a system management operation before raising an error General Property Default Value Description general system management configuration properties ExecutorPath '../sys-mgmt-executor/sys-mgmt-executor' path to the executor to use for system management requests other than configuration MetricsMechanism 'direct-service' either direct-service or executor to advise the SMA where to go for service metrics information Service Property Default Value Description these keys represent the system management service configuration settings FormatSpecifier '%(\\d+\\$)?([-#+ 0(\\<]*)?(\\d+)?(\\.\\d+)?([tT])?([a-zA-Z%])' metrics data output format specifier","title":"Configuration Properties"},{"location":"microservices/system-management/agent/Ch_SysMgmtAgent/#api-reference","text":"System Management API Reference","title":"API Reference"},{"location":"microservices/system-management/executor/Ch_SysMgmtExecutor/","text":"System Management Executor (SME) Introduction The executable applications that the system management agent (SMA) micro service calls on for some management requests are referred to as the \u201cexecutors\u201d. In particular, executors take care of service operations (start, stop, and restart functionality) as well as providing service metrics (CPU and memory usage). How the executor performs its duties is left for the implementer and is generally dictated by the available operating system, platform environment (existence and use of Docker for example) and associated programming language resources. EdgeX provides the executor interface and a reference implementation executor for use in Docker container runtime environments. The executor design allows use of other orchestrating software (example: Kubernetes or Swarm), scripts, OS specific technology (snaps or sysd), etc. to be used without having to build anything into the SMA \u2013 allowing for a more scalable solution in EdgeX but still allowing use of all sorts of implementation technology outside of EdgeX. The SMA will be informed of what executor to use for metrics and start/stop/restart functionality through a configuration option \u2013 ExecutorPath. The ExecutorPath will specify the location (which may be platform dependent) and executable to be called. Reference Implementation Executor Docker Executor When using the reference implementation Docker executor for metrics collection and start, stop and restart functions, the executor will make command line calls to the Docker Engine. However, this is not as straightforward as one would think. Complexity comes from the fact that the SMA (and associated executor) is itself containerized in this type of environment and so a call from within a normal container to Docker would fail as Docker is not installed inside of that container. Even if Docker were part of the SMA\u2019s container, a call to Docker to start (or stop or restart) the other services would be internal to the SMA\u2019s container. This would not be helpful since it would try to start the EdgeX services inside of the SMA\u2019s container and not on the Docker Engine where all the EdgeX containers exist. The solution to solve this issue is that the SMA must run inside of a special container \u2013 a Docker-in-Docker container - and that container must share a volume with the Docker Engine. This acts in a way as to expose the Docker calls out to the Docker Engine running on the base platform. Thereby allowing the SMA (and its executor) to effect calls to the original EdgeX services running on the same Docker Engine as the SMA. Info Metrics collection is accomplished by making calls to docker stats . Docker Executor Internals Again, the makeup of the executors is at the implementer\u2019s discretion. In the Docker executor reference implementation, code for calling Docker to execute start, stop and restart commands is exemplifeid in command.go while metrics collection (using docker stats ) is exemplified in metrics.go . Other executors for other environments can use these function templates to perform service operations and metrics collection by a variety of means. The reference implementation Docker executor is deployed inside of the SMA container. Therefore, there are no exposed APIs. The SMA makes a direct call to the executor executable inside the container.","title":"System Management Executor (SME)"},{"location":"microservices/system-management/executor/Ch_SysMgmtExecutor/#system-management-executor-sme","text":"","title":"System Management Executor (SME)"},{"location":"microservices/system-management/executor/Ch_SysMgmtExecutor/#introduction","text":"The executable applications that the system management agent (SMA) micro service calls on for some management requests are referred to as the \u201cexecutors\u201d. In particular, executors take care of service operations (start, stop, and restart functionality) as well as providing service metrics (CPU and memory usage). How the executor performs its duties is left for the implementer and is generally dictated by the available operating system, platform environment (existence and use of Docker for example) and associated programming language resources. EdgeX provides the executor interface and a reference implementation executor for use in Docker container runtime environments. The executor design allows use of other orchestrating software (example: Kubernetes or Swarm), scripts, OS specific technology (snaps or sysd), etc. to be used without having to build anything into the SMA \u2013 allowing for a more scalable solution in EdgeX but still allowing use of all sorts of implementation technology outside of EdgeX. The SMA will be informed of what executor to use for metrics and start/stop/restart functionality through a configuration option \u2013 ExecutorPath. The ExecutorPath will specify the location (which may be platform dependent) and executable to be called.","title":"Introduction"},{"location":"microservices/system-management/executor/Ch_SysMgmtExecutor/#reference-implementation-executor","text":"","title":"Reference Implementation Executor"},{"location":"microservices/system-management/executor/Ch_SysMgmtExecutor/#docker-executor","text":"When using the reference implementation Docker executor for metrics collection and start, stop and restart functions, the executor will make command line calls to the Docker Engine. However, this is not as straightforward as one would think. Complexity comes from the fact that the SMA (and associated executor) is itself containerized in this type of environment and so a call from within a normal container to Docker would fail as Docker is not installed inside of that container. Even if Docker were part of the SMA\u2019s container, a call to Docker to start (or stop or restart) the other services would be internal to the SMA\u2019s container. This would not be helpful since it would try to start the EdgeX services inside of the SMA\u2019s container and not on the Docker Engine where all the EdgeX containers exist. The solution to solve this issue is that the SMA must run inside of a special container \u2013 a Docker-in-Docker container - and that container must share a volume with the Docker Engine. This acts in a way as to expose the Docker calls out to the Docker Engine running on the base platform. Thereby allowing the SMA (and its executor) to effect calls to the original EdgeX services running on the same Docker Engine as the SMA. Info Metrics collection is accomplished by making calls to docker stats .","title":"Docker Executor"},{"location":"microservices/system-management/executor/Ch_SysMgmtExecutor/#docker-executor-internals","text":"Again, the makeup of the executors is at the implementer\u2019s discretion. In the Docker executor reference implementation, code for calling Docker to execute start, stop and restart commands is exemplifeid in command.go while metrics collection (using docker stats ) is exemplified in metrics.go . Other executors for other environments can use these function templates to perform service operations and metrics collection by a variety of means. The reference implementation Docker executor is deployed inside of the SMA container. Therefore, there are no exposed APIs. The SMA makes a direct call to the executor executable inside the container.","title":"Docker Executor Internals"},{"location":"walk-through/Ch-Walkthrough/","text":"EdgeX Demonstration API Walk Through In order to better appreciate the EdgeX Foundry micro services (what they do and how they work), how they inter-operate with each other, and some of the more important API calls that each micro service has to offer, this demonstration API walk through shows how a device service and device are established in EdgeX, how data is sent flowing through the various services, and how data is then shipped out of EdgeX to the cloud or enterprise system. Through this demonstration, you will play the part of various EdgeX micro services by manually making REST calls in a way that mimics EdgeX system behavior. After exploring this demonstration, and hopefully exercising the APIs yourself, you should have a much better understanding of how EdgeX Foundry works. To be clear, this walkthrough is not the way you setup all your device services, devices, etc. In this walkthrough, you manually call EdgeX APIs to perform the work that a device service would do to get a new device setup and to send data to/through EdgeX. In other words, you are simulating the work of a device service does automatically by manually executing EdgeX APIs. You will also exercise APIs to see the results of the work accomplished by the device service and all of EdgeX. Next>","title":"EdgeX Demonstration API Walk Through"},{"location":"walk-through/Ch-Walkthrough/#edgex-demonstration-api-walk-through","text":"In order to better appreciate the EdgeX Foundry micro services (what they do and how they work), how they inter-operate with each other, and some of the more important API calls that each micro service has to offer, this demonstration API walk through shows how a device service and device are established in EdgeX, how data is sent flowing through the various services, and how data is then shipped out of EdgeX to the cloud or enterprise system. Through this demonstration, you will play the part of various EdgeX micro services by manually making REST calls in a way that mimics EdgeX system behavior. After exploring this demonstration, and hopefully exercising the APIs yourself, you should have a much better understanding of how EdgeX Foundry works. To be clear, this walkthrough is not the way you setup all your device services, devices, etc. In this walkthrough, you manually call EdgeX APIs to perform the work that a device service would do to get a new device setup and to send data to/through EdgeX. In other words, you are simulating the work of a device service does automatically by manually executing EdgeX APIs. You will also exercise APIs to see the results of the work accomplished by the device service and all of EdgeX. Next>","title":"EdgeX Demonstration API Walk Through"},{"location":"walk-through/Ch-WalkthroughCommands/","text":"Calling commands Recall that the device profile (the camera monitor profile in this walkthrough) included a number of commands to get and set information from any device of that type. Also recall that the device (the countcamera1 in this walkthrough) was associated to the device profile (again, the camera monitor profile) when the device was provisioned. See core command API for more details. With the setup complete, you can ask the core command micro service for the list of commands associated to the device (the countcamera1 ). The command micro service exposes the commands in a common, normalized way that enables simplified communications with the devices for other micro services within EdgeX Foundry (for example, an edge analytics or rules engine micro service) other applications that may exist on the same host with EdgeX Foundry (for example, a management agent that needs to shutoff a sensor) any external system that needs to command those devices (for example, a cloud-based application that determined the need to modify the settings on a collection of devices) Walkthrough - Commands Use either the Postman or Curl tab below to walkthrough getting the list of commands. Postman Make a GET request to http://localhost:48082/api/v1/device/name/countcamera1 . Note Please note the change in port for the command request above. The command micro service is at port 48082 by default. Curl Make a curl GET request as shown below. curl -X GET localhost:48082/api/v1/device/name/countcamera1 | json_pp Explore all of the URLs returned as part of this response! These are the URLs that clients (internal or external to EdgeX) can call to trigger the various get and put offerings on the Device. However, do take note that the host for the URLs is edgex-core-command . This is the name of the host for core command inside Docker. To exercise the URL outside of Docker, you would have to use the name of the system host (localhost if executing on the same box). Check the Value Descriptors See core data API for more details. See that the value descriptors are in core data. There should be a total of 4 value descriptors in core data. Note that value descriptors are stored in core data, yet referenced by several objects in core metadata. This is because as data coming from a device is sent to core data, core data may need to validate the incoming values against the associated value descriptor parameters (like min, max, etc.) but without having to make a trip to core metadata to do that validation. Getting data into core data is a key function of EdgeX and must be accomplished as quickly as possible (without having to make additional REST requests). Walkthrough - Value Descriptors Use either the Postman or Curl tab below to walkthrough getting the list of value descriptors. Postman Make a GET request to http://localhost:48080/api/v1/valuedescriptor . Note Again, note the change in port for the core micro service request above. The core micro service is at port 48080 by default. Curl Make a curl GET request as shown below. curl -X GET localhost:48080/api/v1/valuedescriptor | json_pp Check the Events While we're at it, check that no data has yet been shipped to core data from the camera device. Since the device service and device in this demonstration are wholly manually driven by you, no sensor data should yet have been collected. You can test this theory by asking for the count of events in core data. Walkthrough - Events Use either the Postman or Curl tab below to walkthrough getting the list of events. Postman Make a GET request to http://localhost:48080/api/v1/event/count . Curl Make a curl GET request as shown below. curl -X GET localhost:48080/api/v1/event/count Execute a Command While there is no real device or device service in this walkthrough, EdgeX doesn't know that. Therefore, with all the configuration and setup you have performed, you can ask EdgeX to set the scan depth or set the snapshot duration to the camera, and EdgeX will dutifully try to perform the task. Of course, since no device service or device exists, as expected EdgeX will ultimately responds with an error. However, through the log files, you can see a command made of the core command micro service, attempts to call on the appropriate command of the fictitious device service that manages our fictitious camera. For example sake, let's launch a command to set the scan depth of countcamera1 (the name of the single human/dog counting camera device in EdgeX right now). The first task to launch a request to set the scan depth is to get the URL for the command to put or set a new scan depth on the device. Return to the results of the request to get a list of the commands by the device name above. Locate and copy the URL for the put depth command. Because of the IDs used, the IDs you see in the image above will be different on each system so a generic API call will not suffice here. Below is a picture containing a slice of the JSON returned by the GET request above and desired put Command URL highlighted - yours will vary based on IDs. Walkthrough - Actuation Command Use either the Postman or Curl tab below to walkthrough actuating the device. Postman Make a PUT request to http://localhost:48082/api/v1/device/<system specific device id>/command/<system specific command id> with the following body. { \"depth\" : \"9\" } Warning Notice that the URL above requires you to plugin the device and command IDs from your command list. Curl Make a curl PUT request as shown below - replacing the device id and command id obtained from your command list. curl -X PUT -d '{\"depth\":\"9\"}' localhost:48082/api/v1/device/<system specific device id>/command/<system specific command id> Check Command Service Log Again, because no device service (or device) actually exists, core command will respond with a connection refused error. However, checking the logging output will prove that the core command micro service did receive the request and attempted to call on the non-existent device service (at the Addressable address provided earlier in this walkthrough) to issue the actuating command. To see the core command service log issue the following Docker command : docker logs edgex-core-command The last lines of the log entries should highlight the attempt to contact the non-existent device. level=ERROR ts=2020-08-07T17:58:41.427153136Z app=edgex-core-command source=types.go:41 msg=\"Put http://localhost:49977/api/v1/devices/516baf46-c7a0-4fee-ad0c-b56df813bcb5/Depth: dial tcp 127.0.0.1:49977: connect: connection refused\" level=ERROR ts=2020-08-07T17:58:41.427220406Z app=edgex-core-command source=handler.go:47 msg=\"Put http://localhost:49977/api/v1/devices/516baf46-c7a0-4fee-ad0c-b56df813bcb5/Depth: dial tcp 127.0.0.1:49977: connect: connection refused\" <Back Next>","title":"Calling commands"},{"location":"walk-through/Ch-WalkthroughCommands/#calling-commands","text":"Recall that the device profile (the camera monitor profile in this walkthrough) included a number of commands to get and set information from any device of that type. Also recall that the device (the countcamera1 in this walkthrough) was associated to the device profile (again, the camera monitor profile) when the device was provisioned. See core command API for more details. With the setup complete, you can ask the core command micro service for the list of commands associated to the device (the countcamera1 ). The command micro service exposes the commands in a common, normalized way that enables simplified communications with the devices for other micro services within EdgeX Foundry (for example, an edge analytics or rules engine micro service) other applications that may exist on the same host with EdgeX Foundry (for example, a management agent that needs to shutoff a sensor) any external system that needs to command those devices (for example, a cloud-based application that determined the need to modify the settings on a collection of devices)","title":"Calling commands"},{"location":"walk-through/Ch-WalkthroughCommands/#walkthrough-commands","text":"Use either the Postman or Curl tab below to walkthrough getting the list of commands. Postman Make a GET request to http://localhost:48082/api/v1/device/name/countcamera1 . Note Please note the change in port for the command request above. The command micro service is at port 48082 by default. Curl Make a curl GET request as shown below. curl -X GET localhost:48082/api/v1/device/name/countcamera1 | json_pp Explore all of the URLs returned as part of this response! These are the URLs that clients (internal or external to EdgeX) can call to trigger the various get and put offerings on the Device. However, do take note that the host for the URLs is edgex-core-command . This is the name of the host for core command inside Docker. To exercise the URL outside of Docker, you would have to use the name of the system host (localhost if executing on the same box).","title":"Walkthrough - Commands"},{"location":"walk-through/Ch-WalkthroughCommands/#check-the-value-descriptors","text":"See core data API for more details. See that the value descriptors are in core data. There should be a total of 4 value descriptors in core data. Note that value descriptors are stored in core data, yet referenced by several objects in core metadata. This is because as data coming from a device is sent to core data, core data may need to validate the incoming values against the associated value descriptor parameters (like min, max, etc.) but without having to make a trip to core metadata to do that validation. Getting data into core data is a key function of EdgeX and must be accomplished as quickly as possible (without having to make additional REST requests).","title":"Check the Value Descriptors"},{"location":"walk-through/Ch-WalkthroughCommands/#walkthrough-value-descriptors","text":"Use either the Postman or Curl tab below to walkthrough getting the list of value descriptors. Postman Make a GET request to http://localhost:48080/api/v1/valuedescriptor . Note Again, note the change in port for the core micro service request above. The core micro service is at port 48080 by default. Curl Make a curl GET request as shown below. curl -X GET localhost:48080/api/v1/valuedescriptor | json_pp","title":"Walkthrough - Value Descriptors"},{"location":"walk-through/Ch-WalkthroughCommands/#check-the-events","text":"While we're at it, check that no data has yet been shipped to core data from the camera device. Since the device service and device in this demonstration are wholly manually driven by you, no sensor data should yet have been collected. You can test this theory by asking for the count of events in core data.","title":"Check the Events"},{"location":"walk-through/Ch-WalkthroughCommands/#walkthrough-events","text":"Use either the Postman or Curl tab below to walkthrough getting the list of events. Postman Make a GET request to http://localhost:48080/api/v1/event/count . Curl Make a curl GET request as shown below. curl -X GET localhost:48080/api/v1/event/count","title":"Walkthrough - Events"},{"location":"walk-through/Ch-WalkthroughCommands/#execute-a-command","text":"While there is no real device or device service in this walkthrough, EdgeX doesn't know that. Therefore, with all the configuration and setup you have performed, you can ask EdgeX to set the scan depth or set the snapshot duration to the camera, and EdgeX will dutifully try to perform the task. Of course, since no device service or device exists, as expected EdgeX will ultimately responds with an error. However, through the log files, you can see a command made of the core command micro service, attempts to call on the appropriate command of the fictitious device service that manages our fictitious camera. For example sake, let's launch a command to set the scan depth of countcamera1 (the name of the single human/dog counting camera device in EdgeX right now). The first task to launch a request to set the scan depth is to get the URL for the command to put or set a new scan depth on the device. Return to the results of the request to get a list of the commands by the device name above. Locate and copy the URL for the put depth command. Because of the IDs used, the IDs you see in the image above will be different on each system so a generic API call will not suffice here. Below is a picture containing a slice of the JSON returned by the GET request above and desired put Command URL highlighted - yours will vary based on IDs.","title":"Execute a Command"},{"location":"walk-through/Ch-WalkthroughCommands/#walkthrough-actuation-command","text":"Use either the Postman or Curl tab below to walkthrough actuating the device. Postman Make a PUT request to http://localhost:48082/api/v1/device/<system specific device id>/command/<system specific command id> with the following body. { \"depth\" : \"9\" } Warning Notice that the URL above requires you to plugin the device and command IDs from your command list. Curl Make a curl PUT request as shown below - replacing the device id and command id obtained from your command list. curl -X PUT -d '{\"depth\":\"9\"}' localhost:48082/api/v1/device/<system specific device id>/command/<system specific command id>","title":"Walkthrough - Actuation Command"},{"location":"walk-through/Ch-WalkthroughCommands/#check-command-service-log","text":"Again, because no device service (or device) actually exists, core command will respond with a connection refused error. However, checking the logging output will prove that the core command micro service did receive the request and attempted to call on the non-existent device service (at the Addressable address provided earlier in this walkthrough) to issue the actuating command. To see the core command service log issue the following Docker command : docker logs edgex-core-command The last lines of the log entries should highlight the attempt to contact the non-existent device. level=ERROR ts=2020-08-07T17:58:41.427153136Z app=edgex-core-command source=types.go:41 msg=\"Put http://localhost:49977/api/v1/devices/516baf46-c7a0-4fee-ad0c-b56df813bcb5/Depth: dial tcp 127.0.0.1:49977: connect: connection refused\" level=ERROR ts=2020-08-07T17:58:41.427220406Z app=edgex-core-command source=handler.go:47 msg=\"Put http://localhost:49977/api/v1/devices/516baf46-c7a0-4fee-ad0c-b56df813bcb5/Depth: dial tcp 127.0.0.1:49977: connect: connection refused\" <Back Next>","title":"Check Command Service Log"},{"location":"walk-through/Ch-WalkthroughData/","text":"Defining your data When a new device service is first started in EdgeX, there are many many tasks to perform - all in preparation for the device service to manage one or more devices, which are yet unknown to EdgeX. In general, the device service tasks when it first starts can be categorized into: Establish the reference information around the device service and device. Make the device service itself known to the rest of EdgeX Provision the devices the device service will manage with EdgeX Reference information includes things such as defining the address (called an Addressable ) of the device or establishing the new unit of measure (called a Value Descriptor in EdgeX) used by the device. The term \"provision\" is the way we talk about establishing the initial connection to the physical device and have it be known to and communication with EdgeX. After the first run of a device service, these steps are not repeated. For example, after its initial startup, a device service would not need to re-establish the reference information into EdgeX. Instead, it would simply check that these operations have been accomplished and do not need to be redone. Creating Reference Information in EdgeX There is a lot of background information that EdgeX needs to know about the device and device service before it can start collecting data from the device or send actuation commands to the device. Say, for example, the camera device wanted to report its human and canine counts. If it were to just start sending numbers into EdgeX, EdgeX would have no idea of what those numbers represented or even where they came from. Further, if someone/something wanted to send a command to the camera, it would not know how to reach the camera without some additional information like where the camera is located on the network. This background or reference information is what a device service must define in EdgeX when it first comes up. The API calls here give you a glimpse of this communication between the fledgling device service and the other EdgeX micro services. By the way, the order in which these calls are shown may not be the exact order that a real device service does them. As you become more familiar with device services and the device service SDK , the small nuances and differences will become clear. Addressables See core metadata API for more details. The device service will often establish at least two Addressable objects with the core metadata micro service. An Addressable is a flexible EdgeX object that specifies a physical address of something - in this case the physical address of the device service and the device (the camera). While an Addressable could be created for a named MQTT pipe or other protocol endpoint, for this example, we will assume that both the device service and device are able to be reached via HTTP REST calls. So in this case, the device service would make two calls to core metadata, to create the Addressable for the device service and the Addressable for the device (the camera in this case). Walkthrough - Addressables Use either the Postman or Curl tab below to begin your API walkthrough starting with setting up the Addressable s Postman Make two (2) POST requests to http://localhost:48081/api/v1/addressable with the following bodies: BODY: { \"name\" : \"camera control\" , \"protocol\" : \"HTTP\" , \"address\" : \"localhost\" , \"port\" : 49977 , \"path\" : \"/api/v1/callback\" , \"publisher\" : \"none\" , \"user\" : \"none\" , \"password\" : \"none\" , \"topic\" : \"none\" } BODY: { \"name\" : \"camera1 address\" , \"protocol\" : \"HTTP\" , \"address\" : \"localhost\" , \"port\" : 49999 , \"path\" : \"/camera1\" , \"publisher\" : \"none\" , \"user\" : \"none\" , \"password\" : \"none\" , \"topic\" : \"none\" } Be sure that you are POSTing raw data, not form-encoded data (as shown below). If your API calls are successful, you will get a generated ID (a UUID) for your new Addressable that looks similar to this: 9a110e5a-1ceb-4b6f-82a3-a77810630b4e Curl Make two (2) curl POST requests as shown below. curl -X POST -d '{\"name\":\"camera control\",\"protocol\":\"HTTP\",\"address\":\"localhost\",\"port\":49977,\"path\":\"/api/v1/callback\",\"publisher\":\"none\",\"user\":\"none\",\"password\":\"none\",\"topic\":\"none\"}' localhost:48081/api/v1/addressable curl -X POST -d '{\"name\":\"camera1 address\",\"protocol\":\"HTTP\",\"address\":\"localhost\",\"port\":49999,\"path\":\"/camera1\",\"publisher\":\"none\",\"user\":\"none\",\"password\":\"none\",\"topic\":\"none\"}' localhost:48081/api/v1/addressable If your API calls are successful, you will get a generated ID (a UUID) for your new Addressable that looks similar to this: 9a110e5a-1ceb-4b6f-82a3-a77810630b4e Note For an Addressable , a unique name must be provided. Obviously, these address, port numbers, and paths are phony and made up for the purposes of this exercise. This is OK and it will still allow you to see how your device and device services will work going forward. Value Descriptors See core data API for more details. Next, the device service needs to inform EdgeX about the type of data it will be sending on the behalf of the devices. If you are given the number 5, what does that mean to you? Nothing, without some context and unit of measure. For example, if I was to say 5 feet is the scan depth of the camera right now, you have a much better understanding about what the number 5 represents. In EdgeX, Value Descriptors provide the context and unit of measure for any data (or values) sent to and from a device. As the name implies, a Value Descriptor describes a value - its unit of measure, its min and max values (if there are any), the way to display the value when showing it on the screen, and more. Any data obtained from a device (we call this a GET from the device) or any data sent to the device for actuation (we call this SET or PUT to the device) requires a Value Descriptor to be associated with that data. In this demo, there are four Value Descriptors required: human count, canine count, scan depth, and snapshot duration. The device service would make four POST requests to core data to establish these Value Descriptors on initialization. Walkthrough - Value Descriptors Use either the Postman or Curl tab below to walkthrough the addition of the Value Descriptor s Warning Pay attention to the port numbers. In the previous section you were calling the core metadata service (port 48081), in these you will be calling core data (port 48080). Postman Make four (4) POST requests to http://localhost:48080/api/v1/valuedescriptor with the following bodies: BODY: { \"name\" : \"humancount\" , \"description\" : \"people count\" , \"min\" : \"0\" , \"max\" : \"100\" , \"type\" : \"Int16\" , \"uomLabel\" : \"count\" , \"defaultValue\" : \"0\" , \"formatting\" : \"%s\" , \"labels\" :[ \"count\" , \"humans\" ]} BODY: { \"name\" : \"caninecount\" , \"description\" : \"dog count\" , \"min\" : \"0\" , \"max\" : \"100\" , \"type\" : \"Int16\" , \"uomLabel\" : \"count\" , \"defaultValue\" : \"0\" , \"formatting\" : \"%s\" , \"labels\" :[ \"count\" , \"canines\" ]} BODY: { \"name\" : \"depth\" , \"description\" : \"scan distance\" , \"min\" : \"1\" , \"max\" : \"10\" , \"type\" : \"Int16\" , \"uomLabel\" : \"feet\" , \"defaultValue\" : \"1\" , \"formatting\" : \"%s\" , \"labels\" :[ \"scan\" , \"distance\" ]} BODY: { \"name\" : \"duration\" , \"description\" : \"time between events\" , \"min\" : \"10\" , \"max\" : \"180\" , \"type\" : \"Int15\" , \"uomLabel\" : \"seconds\" , \"defaultValue\" : \"10\" , \"formatting\" : \"%s\" , \"labels\" :[ \"duration\" , \"time\" ]} Curl Make four (4) curl POST requests as shown below. curl -X POST -d '{\"name\":\"humancount\",\"description\":\"people count\", \"min\":\"0\",\"max\":\"100\",\"type\":\"Int16\",\"uomLabel\":\"count\",\"defaultValue\":\"0\",\"formatting\":\"%s\",\"labels\":[\"count\",\"humans\"]}' localhost:48080/api/v1/valuedescriptor curl -X POST -d '{\"name\":\"caninecount\",\"description\":\"dog count\", \"min\":\"0\",\"max\":\"100\",\"type\":\"Int16\",\"uomLabel\":\"count\",\"defaultValue\":\"0\",\"formatting\":\"%s\",\"labels\":[\"count\",\"canines\"]}' localhost:48080/api/v1/valuedescriptor curl -X POST -d '{\"name\":\"depth\",\"description\":\"scan distance\", \"min\":\"1\",\"max\":\"10\",\"type\":\"Int16\",\"uomLabel\":\"feet\",\"defaultValue\":\"1\",\"formatting\":\"%s\",\"labels\":[\"scan\",\"distance\"]}' localhost:48080/api/v1/valuedescriptor curl -X POST -d '{\"name\":\"duration\",\"description\":\"time between events\", \"min\":\"10\",\"max\":\"180\",\"type\":\"Int15\",\"uomLabel\":\"seconds\",\"defaultValue\":\"10\",\"formatting\":\"%s\",\"labels\":[\"duration\",\"time\"]}' localhost:48080/api/v1/valuedescriptor Again, the name of each Value Descriptor must be unique (within all of EdgeX). The type of a Value Descriptor indicates the type of the associated value (in the examples above, all integer 16).Formatting is used by UIs and should follow the printf formatting standard for how to represent the associated value. Test the GET API If you make a GET call to the http://localhost:48080/api/v1/valuedescriptor URL (with Postman or curl) you will get a listing (in JSON) of all the Value Descriptors currently defined in your instance of EdgeX, including the ones you just added. <Back Next>","title":"Defining your data"},{"location":"walk-through/Ch-WalkthroughData/#defining-your-data","text":"When a new device service is first started in EdgeX, there are many many tasks to perform - all in preparation for the device service to manage one or more devices, which are yet unknown to EdgeX. In general, the device service tasks when it first starts can be categorized into: Establish the reference information around the device service and device. Make the device service itself known to the rest of EdgeX Provision the devices the device service will manage with EdgeX Reference information includes things such as defining the address (called an Addressable ) of the device or establishing the new unit of measure (called a Value Descriptor in EdgeX) used by the device. The term \"provision\" is the way we talk about establishing the initial connection to the physical device and have it be known to and communication with EdgeX. After the first run of a device service, these steps are not repeated. For example, after its initial startup, a device service would not need to re-establish the reference information into EdgeX. Instead, it would simply check that these operations have been accomplished and do not need to be redone.","title":"Defining your data"},{"location":"walk-through/Ch-WalkthroughData/#creating-reference-information-in-edgex","text":"There is a lot of background information that EdgeX needs to know about the device and device service before it can start collecting data from the device or send actuation commands to the device. Say, for example, the camera device wanted to report its human and canine counts. If it were to just start sending numbers into EdgeX, EdgeX would have no idea of what those numbers represented or even where they came from. Further, if someone/something wanted to send a command to the camera, it would not know how to reach the camera without some additional information like where the camera is located on the network. This background or reference information is what a device service must define in EdgeX when it first comes up. The API calls here give you a glimpse of this communication between the fledgling device service and the other EdgeX micro services. By the way, the order in which these calls are shown may not be the exact order that a real device service does them. As you become more familiar with device services and the device service SDK , the small nuances and differences will become clear.","title":"Creating Reference Information in EdgeX"},{"location":"walk-through/Ch-WalkthroughData/#addressables","text":"See core metadata API for more details. The device service will often establish at least two Addressable objects with the core metadata micro service. An Addressable is a flexible EdgeX object that specifies a physical address of something - in this case the physical address of the device service and the device (the camera). While an Addressable could be created for a named MQTT pipe or other protocol endpoint, for this example, we will assume that both the device service and device are able to be reached via HTTP REST calls. So in this case, the device service would make two calls to core metadata, to create the Addressable for the device service and the Addressable for the device (the camera in this case).","title":"Addressables"},{"location":"walk-through/Ch-WalkthroughData/#walkthrough-addressables","text":"Use either the Postman or Curl tab below to begin your API walkthrough starting with setting up the Addressable s Postman Make two (2) POST requests to http://localhost:48081/api/v1/addressable with the following bodies: BODY: { \"name\" : \"camera control\" , \"protocol\" : \"HTTP\" , \"address\" : \"localhost\" , \"port\" : 49977 , \"path\" : \"/api/v1/callback\" , \"publisher\" : \"none\" , \"user\" : \"none\" , \"password\" : \"none\" , \"topic\" : \"none\" } BODY: { \"name\" : \"camera1 address\" , \"protocol\" : \"HTTP\" , \"address\" : \"localhost\" , \"port\" : 49999 , \"path\" : \"/camera1\" , \"publisher\" : \"none\" , \"user\" : \"none\" , \"password\" : \"none\" , \"topic\" : \"none\" } Be sure that you are POSTing raw data, not form-encoded data (as shown below). If your API calls are successful, you will get a generated ID (a UUID) for your new Addressable that looks similar to this: 9a110e5a-1ceb-4b6f-82a3-a77810630b4e Curl Make two (2) curl POST requests as shown below. curl -X POST -d '{\"name\":\"camera control\",\"protocol\":\"HTTP\",\"address\":\"localhost\",\"port\":49977,\"path\":\"/api/v1/callback\",\"publisher\":\"none\",\"user\":\"none\",\"password\":\"none\",\"topic\":\"none\"}' localhost:48081/api/v1/addressable curl -X POST -d '{\"name\":\"camera1 address\",\"protocol\":\"HTTP\",\"address\":\"localhost\",\"port\":49999,\"path\":\"/camera1\",\"publisher\":\"none\",\"user\":\"none\",\"password\":\"none\",\"topic\":\"none\"}' localhost:48081/api/v1/addressable If your API calls are successful, you will get a generated ID (a UUID) for your new Addressable that looks similar to this: 9a110e5a-1ceb-4b6f-82a3-a77810630b4e Note For an Addressable , a unique name must be provided. Obviously, these address, port numbers, and paths are phony and made up for the purposes of this exercise. This is OK and it will still allow you to see how your device and device services will work going forward.","title":"Walkthrough - Addressables"},{"location":"walk-through/Ch-WalkthroughData/#value-descriptors","text":"See core data API for more details. Next, the device service needs to inform EdgeX about the type of data it will be sending on the behalf of the devices. If you are given the number 5, what does that mean to you? Nothing, without some context and unit of measure. For example, if I was to say 5 feet is the scan depth of the camera right now, you have a much better understanding about what the number 5 represents. In EdgeX, Value Descriptors provide the context and unit of measure for any data (or values) sent to and from a device. As the name implies, a Value Descriptor describes a value - its unit of measure, its min and max values (if there are any), the way to display the value when showing it on the screen, and more. Any data obtained from a device (we call this a GET from the device) or any data sent to the device for actuation (we call this SET or PUT to the device) requires a Value Descriptor to be associated with that data. In this demo, there are four Value Descriptors required: human count, canine count, scan depth, and snapshot duration. The device service would make four POST requests to core data to establish these Value Descriptors on initialization.","title":"Value Descriptors"},{"location":"walk-through/Ch-WalkthroughData/#walkthrough-value-descriptors","text":"Use either the Postman or Curl tab below to walkthrough the addition of the Value Descriptor s Warning Pay attention to the port numbers. In the previous section you were calling the core metadata service (port 48081), in these you will be calling core data (port 48080). Postman Make four (4) POST requests to http://localhost:48080/api/v1/valuedescriptor with the following bodies: BODY: { \"name\" : \"humancount\" , \"description\" : \"people count\" , \"min\" : \"0\" , \"max\" : \"100\" , \"type\" : \"Int16\" , \"uomLabel\" : \"count\" , \"defaultValue\" : \"0\" , \"formatting\" : \"%s\" , \"labels\" :[ \"count\" , \"humans\" ]} BODY: { \"name\" : \"caninecount\" , \"description\" : \"dog count\" , \"min\" : \"0\" , \"max\" : \"100\" , \"type\" : \"Int16\" , \"uomLabel\" : \"count\" , \"defaultValue\" : \"0\" , \"formatting\" : \"%s\" , \"labels\" :[ \"count\" , \"canines\" ]} BODY: { \"name\" : \"depth\" , \"description\" : \"scan distance\" , \"min\" : \"1\" , \"max\" : \"10\" , \"type\" : \"Int16\" , \"uomLabel\" : \"feet\" , \"defaultValue\" : \"1\" , \"formatting\" : \"%s\" , \"labels\" :[ \"scan\" , \"distance\" ]} BODY: { \"name\" : \"duration\" , \"description\" : \"time between events\" , \"min\" : \"10\" , \"max\" : \"180\" , \"type\" : \"Int15\" , \"uomLabel\" : \"seconds\" , \"defaultValue\" : \"10\" , \"formatting\" : \"%s\" , \"labels\" :[ \"duration\" , \"time\" ]} Curl Make four (4) curl POST requests as shown below. curl -X POST -d '{\"name\":\"humancount\",\"description\":\"people count\", \"min\":\"0\",\"max\":\"100\",\"type\":\"Int16\",\"uomLabel\":\"count\",\"defaultValue\":\"0\",\"formatting\":\"%s\",\"labels\":[\"count\",\"humans\"]}' localhost:48080/api/v1/valuedescriptor curl -X POST -d '{\"name\":\"caninecount\",\"description\":\"dog count\", \"min\":\"0\",\"max\":\"100\",\"type\":\"Int16\",\"uomLabel\":\"count\",\"defaultValue\":\"0\",\"formatting\":\"%s\",\"labels\":[\"count\",\"canines\"]}' localhost:48080/api/v1/valuedescriptor curl -X POST -d '{\"name\":\"depth\",\"description\":\"scan distance\", \"min\":\"1\",\"max\":\"10\",\"type\":\"Int16\",\"uomLabel\":\"feet\",\"defaultValue\":\"1\",\"formatting\":\"%s\",\"labels\":[\"scan\",\"distance\"]}' localhost:48080/api/v1/valuedescriptor curl -X POST -d '{\"name\":\"duration\",\"description\":\"time between events\", \"min\":\"10\",\"max\":\"180\",\"type\":\"Int15\",\"uomLabel\":\"seconds\",\"defaultValue\":\"10\",\"formatting\":\"%s\",\"labels\":[\"duration\",\"time\"]}' localhost:48080/api/v1/valuedescriptor Again, the name of each Value Descriptor must be unique (within all of EdgeX). The type of a Value Descriptor indicates the type of the associated value (in the examples above, all integer 16).Formatting is used by UIs and should follow the printf formatting standard for how to represent the associated value.","title":"Walkthrough - Value Descriptors"},{"location":"walk-through/Ch-WalkthroughData/#test-the-get-api","text":"If you make a GET call to the http://localhost:48080/api/v1/valuedescriptor URL (with Postman or curl) you will get a listing (in JSON) of all the Value Descriptors currently defined in your instance of EdgeX, including the ones you just added. <Back Next>","title":"Test the GET API"},{"location":"walk-through/Ch-WalkthroughDeviceProfile/","text":"Defining your device A device profile can be thought of as a template or as a type or classification of device. General characteristics about the type of device, the data theses devices provide, and how to command them is all provided in a device profile. Other pages within this document set provide more details about a device profile and its purpose (see core metadata to start). It is typical that as part of the reference information setup sequence, the device service provides the device profiles for the types of devices it manages. Device Profile See core metadata API for more details. Our fictitious device service will manage only the human/dog counting camera, so it only needs to make one POST request to create the monitoring camera device profile. Since device profiles are often represented in YAML, you make a multi-part form-data POST with the device profile file below to create the Camera Monitor profile. Each profile has a unique name along with a description, manufacturer, model and collection of labels to assist in queries for particular profiles. These are relatively straightforward attributes of a profile. Understanding Commands The device profile defines how to communicate with any device that abides by the profile. In particular, it defines the deviceResources , deviceCommands and coreCommands used to send requests to the device (via the device service). See the Device Profile documentation for more background on each of these. coreCommands specify the commands which are available via the core command micro service, for reading and writing to the device. coreCommands are named and have either a get (for retrieving data from the device) or put (to send data to the device) or both. Each command can have a single get and single put . Both get and put are optional, but it would not make sense to have a command without at least one get or at least one put . The command name must be unique for that profile (the coreCommand name does not have to be unique across all of EdgeX - for example, many profiles may contain a \"status\" coreCommand ). Understanding Get Command The get and put each have a path which is used by EdgeX to call on the specific command get or put at the URL address provided for the service. Hypothetically, if the address to a device service was <http://abc:9999> and the get command had a path of foo , then internally, EdgeX would know to use <http://abc:9999/foo> to call on the get Command. get s and put s have response objects (or an array of response objects). A get must have at least one response object. A put is not required to have a response. Responses might be \"good\" or \"error\" responses. Each get should have at least one \"good\" response, but it may have several error responses depending on what problems or issues the device service may need to reply with. Each response is made up of a code (which suggests if it is a good or error response), a description (human readable information about what is in the response), and an array of expected values. For practical purposes, the code is usually an HTTP status code like 200 (for good responses), 404 or 503 (examples of bad responses). The expected values in a response are an array of deviceResource or deviceCommand names. Per the walkthrough profile, if a call to an get command is expected to return back the human and dog count data, then the response's expected values would be the deviceResources [\"HumanCount\",\"CanineCount\"] . When the actual call to the device service is made, the body of the return response from the service is expected to return a value for each of the expected values in a map where the deviceResource names are used as keys. Again, using the human and dog counts as an example, if the expected values were [HumanCount, CanineCount] then the body of a good response from the service would contain a map that looks something like this: { \"HumanCount\" : 5 , \"CanineCount\" : 2 } Here is an example set of responses that might be used for a get command in the camera example. Note that one response is coded as the \"good\" response (code 200) while the other is for \"error\" response (code 404). The expected values for the good response are the Value Descriptor names for the camera's count data. The expected values for the \"error\" response is the Value Descriptor name for an error message. { \"responses\" :[ { \"description\" : \"Get the people and dog counts\" , \"expectedValues\" : [ \"HumanCount\" , \"CanineCount\" ], \"code\" : \"200\" }, { \"description\" : \"bad request\" , \"expectedValues\" : [ \"CameraError\" ], \"code\" : \"404\" } ] } Understanding Set Command Parameters coreCommand s are also used to send data to devices (via device services) as much as they are used to get data from devices. Therefore, any coreCommand may have a set of parameters associated with its call. Parameter data is added to the body of the command request. Parameters are defined via an array of parameterNames on a command. Here again, this array is just an array of deviceResource names. Each deviceResource defines the name and type of information to be supplied as a parameter to the command call. For example, if a command had a parameterNames array of [ScanDepth, SnapshotDuration] , then the receiving command is expecting values that match these deviceResource s. Similar to the way expected values are used to set the keys of the response body, the parameter names are used as keys in a map to pass parameter values in a command call that has parameters. Here might be what is populated in the body of the command call when the parameterNames are [ScanDepth, SnapshotDuration] . { \"ScanDepth\" : 1 , \"SnapshotDuration\" : 10 } If you open the Camera Monitor Profile YAML file , see that there are commands to get people and dog counts (and a command called Counts, which provides both values). There are also commands to get and put the snapshot duration and scan depth. Walkthrough - Device Profile Use either the Postman or Curl tab below to walkthrough uploading the device profile. Download the Device Profile Click on the link below to download and save the device profile (YAML) to your system. EdgeX_CameraMonitorProfile.yml Note Device profiles are stored in core metadata. Therefore, note that the calls in the walkthrough are to the metadata service, which defaults to port 48081. Upload the Device Profile to EdgeX Postman Make a POST request to http://localhost:48081/api/v1/deviceprofile/uploadfile . The request should not include any additional headers (leave the defaults). In the Body, make sure \"form-data\" is selected and set the Key to file and then select the device profile file where you saved it (as shown below). If your API call is successful, you will get a generated ID (a UUID) for your new DeviceProfile in the response area. Curl Make a curl POST request as shown below. curl -F 'file=@/path/to/your/profile/here/EdgeX_CameraMonitorProfile.yml' localhost:48081/api/v1/deviceprofile/uploadfile If your API call is successful, you will get a generated ID (a UUID) for your new DeviceProfile . Warning Note that the file location in the curl command above needs to be replaced with your actual file location path. Also, if you do not save the device profile file to EdgeX_CameraMonitorProfile.yml , then you will need to replace the file name as well. Test the GET API If you make a GET call to the http://localhost:48081/api/v1/deviceprofile URL (with Postman or curl) you will get a listing (in JSON) of all the device profiles (and all of its associated deviceResource , deviceCommand and coreCommand ) currently defined in your instance of EdgeX, including the one you just added. <Back Next>","title":"Defining your device"},{"location":"walk-through/Ch-WalkthroughDeviceProfile/#defining-your-device","text":"A device profile can be thought of as a template or as a type or classification of device. General characteristics about the type of device, the data theses devices provide, and how to command them is all provided in a device profile. Other pages within this document set provide more details about a device profile and its purpose (see core metadata to start). It is typical that as part of the reference information setup sequence, the device service provides the device profiles for the types of devices it manages.","title":"Defining your device"},{"location":"walk-through/Ch-WalkthroughDeviceProfile/#device-profile","text":"See core metadata API for more details. Our fictitious device service will manage only the human/dog counting camera, so it only needs to make one POST request to create the monitoring camera device profile. Since device profiles are often represented in YAML, you make a multi-part form-data POST with the device profile file below to create the Camera Monitor profile. Each profile has a unique name along with a description, manufacturer, model and collection of labels to assist in queries for particular profiles. These are relatively straightforward attributes of a profile.","title":"Device Profile"},{"location":"walk-through/Ch-WalkthroughDeviceProfile/#understanding-commands","text":"The device profile defines how to communicate with any device that abides by the profile. In particular, it defines the deviceResources , deviceCommands and coreCommands used to send requests to the device (via the device service). See the Device Profile documentation for more background on each of these. coreCommands specify the commands which are available via the core command micro service, for reading and writing to the device. coreCommands are named and have either a get (for retrieving data from the device) or put (to send data to the device) or both. Each command can have a single get and single put . Both get and put are optional, but it would not make sense to have a command without at least one get or at least one put . The command name must be unique for that profile (the coreCommand name does not have to be unique across all of EdgeX - for example, many profiles may contain a \"status\" coreCommand ).","title":"Understanding Commands"},{"location":"walk-through/Ch-WalkthroughDeviceProfile/#understanding-get-command","text":"The get and put each have a path which is used by EdgeX to call on the specific command get or put at the URL address provided for the service. Hypothetically, if the address to a device service was <http://abc:9999> and the get command had a path of foo , then internally, EdgeX would know to use <http://abc:9999/foo> to call on the get Command. get s and put s have response objects (or an array of response objects). A get must have at least one response object. A put is not required to have a response. Responses might be \"good\" or \"error\" responses. Each get should have at least one \"good\" response, but it may have several error responses depending on what problems or issues the device service may need to reply with. Each response is made up of a code (which suggests if it is a good or error response), a description (human readable information about what is in the response), and an array of expected values. For practical purposes, the code is usually an HTTP status code like 200 (for good responses), 404 or 503 (examples of bad responses). The expected values in a response are an array of deviceResource or deviceCommand names. Per the walkthrough profile, if a call to an get command is expected to return back the human and dog count data, then the response's expected values would be the deviceResources [\"HumanCount\",\"CanineCount\"] . When the actual call to the device service is made, the body of the return response from the service is expected to return a value for each of the expected values in a map where the deviceResource names are used as keys. Again, using the human and dog counts as an example, if the expected values were [HumanCount, CanineCount] then the body of a good response from the service would contain a map that looks something like this: { \"HumanCount\" : 5 , \"CanineCount\" : 2 } Here is an example set of responses that might be used for a get command in the camera example. Note that one response is coded as the \"good\" response (code 200) while the other is for \"error\" response (code 404). The expected values for the good response are the Value Descriptor names for the camera's count data. The expected values for the \"error\" response is the Value Descriptor name for an error message. { \"responses\" :[ { \"description\" : \"Get the people and dog counts\" , \"expectedValues\" : [ \"HumanCount\" , \"CanineCount\" ], \"code\" : \"200\" }, { \"description\" : \"bad request\" , \"expectedValues\" : [ \"CameraError\" ], \"code\" : \"404\" } ] }","title":"Understanding Get Command"},{"location":"walk-through/Ch-WalkthroughDeviceProfile/#understanding-set-command-parameters","text":"coreCommand s are also used to send data to devices (via device services) as much as they are used to get data from devices. Therefore, any coreCommand may have a set of parameters associated with its call. Parameter data is added to the body of the command request. Parameters are defined via an array of parameterNames on a command. Here again, this array is just an array of deviceResource names. Each deviceResource defines the name and type of information to be supplied as a parameter to the command call. For example, if a command had a parameterNames array of [ScanDepth, SnapshotDuration] , then the receiving command is expecting values that match these deviceResource s. Similar to the way expected values are used to set the keys of the response body, the parameter names are used as keys in a map to pass parameter values in a command call that has parameters. Here might be what is populated in the body of the command call when the parameterNames are [ScanDepth, SnapshotDuration] . { \"ScanDepth\" : 1 , \"SnapshotDuration\" : 10 } If you open the Camera Monitor Profile YAML file , see that there are commands to get people and dog counts (and a command called Counts, which provides both values). There are also commands to get and put the snapshot duration and scan depth.","title":"Understanding Set Command Parameters"},{"location":"walk-through/Ch-WalkthroughDeviceProfile/#walkthrough-device-profile","text":"Use either the Postman or Curl tab below to walkthrough uploading the device profile.","title":"Walkthrough - Device Profile"},{"location":"walk-through/Ch-WalkthroughDeviceProfile/#download-the-device-profile","text":"Click on the link below to download and save the device profile (YAML) to your system. EdgeX_CameraMonitorProfile.yml Note Device profiles are stored in core metadata. Therefore, note that the calls in the walkthrough are to the metadata service, which defaults to port 48081.","title":"Download the Device Profile"},{"location":"walk-through/Ch-WalkthroughDeviceProfile/#upload-the-device-profile-to-edgex","text":"Postman Make a POST request to http://localhost:48081/api/v1/deviceprofile/uploadfile . The request should not include any additional headers (leave the defaults). In the Body, make sure \"form-data\" is selected and set the Key to file and then select the device profile file where you saved it (as shown below). If your API call is successful, you will get a generated ID (a UUID) for your new DeviceProfile in the response area. Curl Make a curl POST request as shown below. curl -F 'file=@/path/to/your/profile/here/EdgeX_CameraMonitorProfile.yml' localhost:48081/api/v1/deviceprofile/uploadfile If your API call is successful, you will get a generated ID (a UUID) for your new DeviceProfile . Warning Note that the file location in the curl command above needs to be replaced with your actual file location path. Also, if you do not save the device profile file to EdgeX_CameraMonitorProfile.yml , then you will need to replace the file name as well.","title":"Upload the Device Profile to EdgeX"},{"location":"walk-through/Ch-WalkthroughDeviceProfile/#test-the-get-api","text":"If you make a GET call to the http://localhost:48081/api/v1/deviceprofile URL (with Postman or curl) you will get a listing (in JSON) of all the device profiles (and all of its associated deviceResource , deviceCommand and coreCommand ) currently defined in your instance of EdgeX, including the one you just added. <Back Next>","title":"Test the GET API"},{"location":"walk-through/Ch-WalkthroughDeviceService/","text":"Register your device service Once the reference information is established by the device service in core data and core metadata, the device service can register or define itself in EdgeX. That is, it can proclaim to EdgeX that \"I have arrived and am functional.\" Register with Core Configuration and Registration Part of that registration process of the device service, indeed any EdgeX micro service, is to register itself with the core configuration & registration . In this process, the micro service provides its location to the Config/Reg micro service and picks up any new/latest configuration information from this central service. Since there is no real device service in this walkthrough demonstration, this part of the inter-micro service exchange is not explored here. Device Service See core metadata API for more details. At this point in your walkthrough, the device service must create a representative instance of itself in core metadata. It is in this registration that the device service is associated to the Addressable that was created earlier in this walkthrough . The name of the device service must be unique across all of EdgeX. Note the admin and operating states. The administrative state (aka admin state) provides control of the device service by man or other systems. It can be set to locked or unlocked . When a device service is set to locked , it is not suppose to respond to any command requests nor send data from the devices. The operating state (aka op state) provides an indication on the part of EdgeX about the internal operating status of the device service. The operating state is not set externally (as by another system or man), it is a signal from within EdgeX (and potentially the device service itself) about the condition of the service. The operating state of the device service may be either enabled or disabled . When the operating state of the device service is disabled , it is either experiencing some difficulty or going through some process (for example an upgrade) which does not allow it to function in its normal capacity. Walkthrough - Device Service Use either the Postman or Curl tab below to walkthrough creating the DeviceService . Postman Make a POST request to http://localhost:48081/api/v1/deviceservice with the following body: BODY: { \"name\" : \"camera control device service\" , \"description\" : \"Manage human and dog counting cameras\" , \"labels\" :[ \"camera\" , \"counter\" ], \"adminState\" : \"unlocked\" , \"operatingState\" : \"enabled\" , \"addressable\" : { \"name\" : \"camera control\" }} Be sure that you are POSTing raw data, not form-encoded data. If your API call is successful, you will get a generated ID (a UUID) for your new DeviceService in the response area. Curl Make a curl POST request as shown below. curl -X POST -d '{\"name\":\"camera control device service\",\"description\":\"Manage human and dog counting cameras\",\"labels\":[\"camera\",\"counter\"],\"adminState\":\"unlocked\",\"operatingState\":\"enabled\",\"addressable\": {\"name\":\"camera control\"}}' localhost:48081/api/v1/deviceservice If your API call is successful, you will get a generated ID (a UUID) for your new DeviceService . Test the GET API If you make a GET call to the http://localhost:48081/api/v1/deviceservice URL (with Postman or curl) you will get a listing (in JSON) of all the device services currently defined in your instance of EdgeX, including the one you just added. <Back Next>","title":"Register your device service"},{"location":"walk-through/Ch-WalkthroughDeviceService/#register-your-device-service","text":"Once the reference information is established by the device service in core data and core metadata, the device service can register or define itself in EdgeX. That is, it can proclaim to EdgeX that \"I have arrived and am functional.\"","title":"Register your device service"},{"location":"walk-through/Ch-WalkthroughDeviceService/#register-with-core-configuration-and-registration","text":"Part of that registration process of the device service, indeed any EdgeX micro service, is to register itself with the core configuration & registration . In this process, the micro service provides its location to the Config/Reg micro service and picks up any new/latest configuration information from this central service. Since there is no real device service in this walkthrough demonstration, this part of the inter-micro service exchange is not explored here.","title":"Register with Core Configuration and Registration"},{"location":"walk-through/Ch-WalkthroughDeviceService/#device-service","text":"See core metadata API for more details. At this point in your walkthrough, the device service must create a representative instance of itself in core metadata. It is in this registration that the device service is associated to the Addressable that was created earlier in this walkthrough . The name of the device service must be unique across all of EdgeX. Note the admin and operating states. The administrative state (aka admin state) provides control of the device service by man or other systems. It can be set to locked or unlocked . When a device service is set to locked , it is not suppose to respond to any command requests nor send data from the devices. The operating state (aka op state) provides an indication on the part of EdgeX about the internal operating status of the device service. The operating state is not set externally (as by another system or man), it is a signal from within EdgeX (and potentially the device service itself) about the condition of the service. The operating state of the device service may be either enabled or disabled . When the operating state of the device service is disabled , it is either experiencing some difficulty or going through some process (for example an upgrade) which does not allow it to function in its normal capacity.","title":"Device Service"},{"location":"walk-through/Ch-WalkthroughDeviceService/#walkthrough-device-service","text":"Use either the Postman or Curl tab below to walkthrough creating the DeviceService . Postman Make a POST request to http://localhost:48081/api/v1/deviceservice with the following body: BODY: { \"name\" : \"camera control device service\" , \"description\" : \"Manage human and dog counting cameras\" , \"labels\" :[ \"camera\" , \"counter\" ], \"adminState\" : \"unlocked\" , \"operatingState\" : \"enabled\" , \"addressable\" : { \"name\" : \"camera control\" }} Be sure that you are POSTing raw data, not form-encoded data. If your API call is successful, you will get a generated ID (a UUID) for your new DeviceService in the response area. Curl Make a curl POST request as shown below. curl -X POST -d '{\"name\":\"camera control device service\",\"description\":\"Manage human and dog counting cameras\",\"labels\":[\"camera\",\"counter\"],\"adminState\":\"unlocked\",\"operatingState\":\"enabled\",\"addressable\": {\"name\":\"camera control\"}}' localhost:48081/api/v1/deviceservice If your API call is successful, you will get a generated ID (a UUID) for your new DeviceService .","title":"Walkthrough - Device Service"},{"location":"walk-through/Ch-WalkthroughDeviceService/#test-the-get-api","text":"If you make a GET call to the http://localhost:48081/api/v1/deviceservice URL (with Postman or curl) you will get a listing (in JSON) of all the device services currently defined in your instance of EdgeX, including the one you just added. <Back Next>","title":"Test the GET API"},{"location":"walk-through/Ch-WalkthroughExporting/","text":"Exporting your device data Great, so the data sent by the camera device makes it way to core data. How can that data be sent to an enterprise system or the Cloud? How can that data be used by an edge analytics system (like a rules engine) to actuate on a device? Getting data to the rules engine By default, data is already passed from the core data service to application services (app services) via 0MQ message. A preconfigured application service is provided with the EdgeX default Docker Compose files that gets this data and routes it to the Kuiper rules engine . The application service is called app-service-rules (see below). More specifically, it is an app service configurable . app-service-rules : image : edgexfoundry/docker-app-service-configurable:1.2.0 ports : - \"127.0.0.1:48100:48100\" container_name : edgex-app-service-configurable-rules hostname : edgex-app-service-configurable-rules networks : - edgex-network environment : << : *common-variables edgex_profile : rules-engine Service_Host : edgex-app-service-configurable-rules Service_Port : 48100 MessageBus_SubscribeHost_Host : edgex-core-data Binding_PublishTopic : events depends_on : - consul # - logging # uncomment if re-enabled remote logging - data Seeing the data export The log level of any EdgeX micro service is set to INFO by default. If you tune the log level of the app-service-rules micro service to DEBUG , you can see Event s pass through the app service on the way to the rules engine. Set the log level To set the log level of any service, open the Consul UI in a browser by visiting http://[host]:8500 . When the Consul UI opens, click on the Key/Value tab on the top of the screen. On the Key/Value display page, click on edgex > appservices > 1.0 > AppService-rules-engine > Writable > LogLevel . In the Value entry field that presents itself, replace INFO with DEBUG and hit the Save button. View the service log The log level change will be picked up by the application service. In a terminal window, execute the Docker command below to view the service log. docker logs -f edgex-app-service-configurable-rules Now push another event/reading into core data as you did earlier (see Send Event ). You should see each new event/reading created by acknowledged by the app service. With the right application service and rules engine configuration, the event/reading data is sent to the rules engine where it can then be used to trigger commands just as you did manually in this walkthrough. Exporting data to anywhere You can create an additional application service to get the data to another application or service, REST endpoint, MQTT topic, cloud provider, and more. See the Getting Started guide on exporting data for more information on how to use another app service configurable to get EdgeX data to any client. Building your own solutions Congratulations, you've made it all the way through the Walkthrough tutorial! <Back","title":"Exporting your device data"},{"location":"walk-through/Ch-WalkthroughExporting/#exporting-your-device-data","text":"Great, so the data sent by the camera device makes it way to core data. How can that data be sent to an enterprise system or the Cloud? How can that data be used by an edge analytics system (like a rules engine) to actuate on a device?","title":"Exporting your device data"},{"location":"walk-through/Ch-WalkthroughExporting/#getting-data-to-the-rules-engine","text":"By default, data is already passed from the core data service to application services (app services) via 0MQ message. A preconfigured application service is provided with the EdgeX default Docker Compose files that gets this data and routes it to the Kuiper rules engine . The application service is called app-service-rules (see below). More specifically, it is an app service configurable . app-service-rules : image : edgexfoundry/docker-app-service-configurable:1.2.0 ports : - \"127.0.0.1:48100:48100\" container_name : edgex-app-service-configurable-rules hostname : edgex-app-service-configurable-rules networks : - edgex-network environment : << : *common-variables edgex_profile : rules-engine Service_Host : edgex-app-service-configurable-rules Service_Port : 48100 MessageBus_SubscribeHost_Host : edgex-core-data Binding_PublishTopic : events depends_on : - consul # - logging # uncomment if re-enabled remote logging - data","title":"Getting data to the rules engine"},{"location":"walk-through/Ch-WalkthroughExporting/#seeing-the-data-export","text":"The log level of any EdgeX micro service is set to INFO by default. If you tune the log level of the app-service-rules micro service to DEBUG , you can see Event s pass through the app service on the way to the rules engine.","title":"Seeing the data export"},{"location":"walk-through/Ch-WalkthroughExporting/#set-the-log-level","text":"To set the log level of any service, open the Consul UI in a browser by visiting http://[host]:8500 . When the Consul UI opens, click on the Key/Value tab on the top of the screen. On the Key/Value display page, click on edgex > appservices > 1.0 > AppService-rules-engine > Writable > LogLevel . In the Value entry field that presents itself, replace INFO with DEBUG and hit the Save button.","title":"Set the log level"},{"location":"walk-through/Ch-WalkthroughExporting/#view-the-service-log","text":"The log level change will be picked up by the application service. In a terminal window, execute the Docker command below to view the service log. docker logs -f edgex-app-service-configurable-rules Now push another event/reading into core data as you did earlier (see Send Event ). You should see each new event/reading created by acknowledged by the app service. With the right application service and rules engine configuration, the event/reading data is sent to the rules engine where it can then be used to trigger commands just as you did manually in this walkthrough.","title":"View the service log"},{"location":"walk-through/Ch-WalkthroughExporting/#exporting-data-to-anywhere","text":"You can create an additional application service to get the data to another application or service, REST endpoint, MQTT topic, cloud provider, and more. See the Getting Started guide on exporting data for more information on how to use another app service configurable to get EdgeX data to any client.","title":"Exporting data to anywhere"},{"location":"walk-through/Ch-WalkthroughExporting/#building-your-own-solutions","text":"Congratulations, you've made it all the way through the Walkthrough tutorial! <Back","title":"Building your own solutions"},{"location":"walk-through/Ch-WalkthroughProvision/","text":"Provision a device In the last act of setup, a device service often discovers and provisions devices (either statically or dynamically ) and that it is going to manage on the part of EdgeX. Note the word \"often\" in the last sentence. Not all device services will discover new devices or provision them right away. Depending on the type of device and how the devices communicate, it is up to the device service to determine how/when to provision a device. In some cases, the provisioning may be triggered by a human request of the device service once everything is in place and once the human can provide the information the device service needs to physically connected to the device. Device See core metadata API for more details. For the sake of this demonstration, the call to core metadata will provision the human/dog counting monitor camera as if the device service discovered it (by some unknown means) and provisioned the device as part of some startup process. To create a Device , it must be associated to a DeviceProfile , a DeviceService , and contain one or more Protocols defining its address. Walkthrough - Device Use either the Postman or Curl tab below to walkthrough creating the Device . Postman Make a POST request to http://localhost:48081/api/v1/device with the following body: BODY: { \"name\" : \"countcamera1\" , \"description\" : \"human and dog counting camera #1\" , \"adminState\" : \"unlocked\" , \"operatingState\" : \"enabled\" , \"protocols\" :{ \"camera protocol\" :{ \"camera address\" : \"camera 1\" }}, \"labels\" : [ \"camera\" , \"counter\" ], \"location\" : \"\" , \"service\" :{ \"name\" : \"camera control device service\" }, \"profile\" :{ \"name\" : \"camera monitor profile\" }} Be sure that you are POSTing raw data, not form-encoded data. If your API call is successful, you will get a generated ID (a UUID) for your new DeviceService in the response area. Note The camera monitor profile was created by the device profile uploaded in a previous walkthrough step. The camera control device service was created in the last walkthough step. Curl Make a curl POST request as shown below. curl -X POST -d '{\"name\":\"countcamera1\",\"description\":\"human and dog counting camera #1\",\"adminState\":\"unlocked\",\"operatingState\":\"enabled\",\"protocols\":{\"camera protocol\":{\"camera address\":\"camera 1\"}},\"labels\": [\"camera\",\"counter\"],\"location\":\"\",\"service\":{\"name\":\"camera control device service\"},\"profile\":{\"name\":\"camera monitor profile\"}}' localhost:48081/api/v1/device If your API call is successful, you will get a generated ID (a UUID) for your new Device . Test the GET API Ensure the monitor camera is among the devices known to core metadata. If you make a GET call to the http://localhost:48081/api/v1/device URL (with Postman or curl) you will get a listing (in JSON) of all the device services currently defined of devices in your instance of EdgeX that should include the one you just added. There are many additional APIs on core metadata to retrieve a Device , DeviceService , etc. As an example, here is one to find all devices associated to a given DeviceProfile . ``` shell curl -X GET http://localhost:48081/api/v1/device/profilename/camera+monitor+profile | json_pp ``` <Back Next>","title":"Provision a device"},{"location":"walk-through/Ch-WalkthroughProvision/#provision-a-device","text":"In the last act of setup, a device service often discovers and provisions devices (either statically or dynamically ) and that it is going to manage on the part of EdgeX. Note the word \"often\" in the last sentence. Not all device services will discover new devices or provision them right away. Depending on the type of device and how the devices communicate, it is up to the device service to determine how/when to provision a device. In some cases, the provisioning may be triggered by a human request of the device service once everything is in place and once the human can provide the information the device service needs to physically connected to the device.","title":"Provision a device"},{"location":"walk-through/Ch-WalkthroughProvision/#device","text":"See core metadata API for more details. For the sake of this demonstration, the call to core metadata will provision the human/dog counting monitor camera as if the device service discovered it (by some unknown means) and provisioned the device as part of some startup process. To create a Device , it must be associated to a DeviceProfile , a DeviceService , and contain one or more Protocols defining its address.","title":"Device"},{"location":"walk-through/Ch-WalkthroughProvision/#walkthrough-device","text":"Use either the Postman or Curl tab below to walkthrough creating the Device . Postman Make a POST request to http://localhost:48081/api/v1/device with the following body: BODY: { \"name\" : \"countcamera1\" , \"description\" : \"human and dog counting camera #1\" , \"adminState\" : \"unlocked\" , \"operatingState\" : \"enabled\" , \"protocols\" :{ \"camera protocol\" :{ \"camera address\" : \"camera 1\" }}, \"labels\" : [ \"camera\" , \"counter\" ], \"location\" : \"\" , \"service\" :{ \"name\" : \"camera control device service\" }, \"profile\" :{ \"name\" : \"camera monitor profile\" }} Be sure that you are POSTing raw data, not form-encoded data. If your API call is successful, you will get a generated ID (a UUID) for your new DeviceService in the response area. Note The camera monitor profile was created by the device profile uploaded in a previous walkthrough step. The camera control device service was created in the last walkthough step. Curl Make a curl POST request as shown below. curl -X POST -d '{\"name\":\"countcamera1\",\"description\":\"human and dog counting camera #1\",\"adminState\":\"unlocked\",\"operatingState\":\"enabled\",\"protocols\":{\"camera protocol\":{\"camera address\":\"camera 1\"}},\"labels\": [\"camera\",\"counter\"],\"location\":\"\",\"service\":{\"name\":\"camera control device service\"},\"profile\":{\"name\":\"camera monitor profile\"}}' localhost:48081/api/v1/device If your API call is successful, you will get a generated ID (a UUID) for your new Device .","title":"Walkthrough - Device"},{"location":"walk-through/Ch-WalkthroughProvision/#test-the-get-api","text":"Ensure the monitor camera is among the devices known to core metadata. If you make a GET call to the http://localhost:48081/api/v1/device URL (with Postman or curl) you will get a listing (in JSON) of all the device services currently defined of devices in your instance of EdgeX that should include the one you just added. There are many additional APIs on core metadata to retrieve a Device , DeviceService , etc. As an example, here is one to find all devices associated to a given DeviceProfile . ``` shell curl -X GET http://localhost:48081/api/v1/device/profilename/camera+monitor+profile | json_pp ``` <Back Next>","title":"Test the GET API"},{"location":"walk-through/Ch-WalkthroughReading/","text":"Sending events and reading data In the real world, the human/dog counting camera would start to take pictures, count beings, and send that data to EdgeX. To simulate this activity in this section of the walkthrough, you will make core data API calls as if you were the camera's device and device service. That is, you will report human and dog counts to core data in the form of event/reading objects. Send an Event/Reading See core data API for more details. Data is submitted to core data as an Event object. An event is a collection of sensor readings from a device (associated to a device by its ID or name) at a particular point in time. A Reading object in an Event object is a particular value sensed by the device and associated to a Value Descriptor (by name) to provide context to the reading. So, the human/dog counting camera might determine that there are 5 people and 3 dogs in the space it is monitoring. In the EdgeX vernacular, the device service upon receiving these sensed values from the camera device would create an Event with two Reading s - one Reading would contain the key/value pair of HumanCount:5 and the other Reading would contain the key/value pair of CanineCount:3. The device service, on creating the Event and associated Reading objects would transmit this information to core data via REST call. Walkthrough - Send Event Use either the Postman or Curl tab below to walkthrough sending an Event with Reading s to core data. Postman Make a POST request to http://localhost:48080/api/v1/event with the body below. { \"device\" : \"countcamera1\" , \"readings\" :[{ \"name\" : \"HumanCount\" , \"value\" : \"5\" },{ \"name\" : \"CanineCount\" , \"value\" : \"3\" }]} If your API call is successful, you will get a generated ID (a UUID) for your new Event as shown in the image below. Curl Make a curl POST request as shown below. curl -X POST -d '{\"device\":\"countcamera1\",\"readings\":[{\"name\":\"HumanCount\",\"value\":\"5\"},{\"name\":\"CanineCount\",\"value\":\"3\"}]}' localhost:48080/api/v1/event Origin Timestamp If desired, the device service can also supply an origin property in the Event or Reading object to suggest the time (in Epoch timestamp/milliseconds format) at which the data was sensed/collected. If an origin is not provided, no origin will be set for the Event or Reading . However, every Event and Reading is provided a Created and Modified timestamp by the database when it is saved to give the data some time context. { \"device\" : \"countcamera1\" , \"origin\" : 1471806386919 , \"readings\" :[{ \"name\" : \"HumanCount\" , \"value\" : \"1\" , \"origin\" : 1471806386919 },{ \"name\" : \"CanineCount\" , \"value\" : \"0\" , \"origin\" : 1471806386919 }]} Note Smart devices will often timestamp sensor data and this timestamp can be used as the origin timestamp. In cases where the sensor/device is unable to provide a timestamp (\"dumb\" or brownfield sensors), it is recommended that the device service create a timestamp for the sensor data that it be applied as the origin timestamp for the device. Exploring Events/Readings Now that an Event (or two) and associated Readings have been sent to core data, you can use the core data API to explore that data that is now stored in the database. Recall from a previous walkthrough step , you checked that no data was yet stored in core data. Make a similar call to see event records have now been sent into core data.. Walkthrough - Query Events/Readings Use either the Postman or Curl tab below to walkthrough getting the list of events. Postman Make a GET request to retrieve 10 of the last Event s associated to the countcamera1 device: http://localhost:48080/api/v1/event/device/countcamera1/10 . Make a GET request to retrieve 10 of the human count Reading s associated to the countcamera1 device: http://localhost:48080/api/v1/reading/name/HumanCount/10 Curl Make a curl GET requests to retrieve 10 of the last Event s associated to the countcamera1 device and to retrieve 10 of the human count readings associated to countcamera1 curl -X GET localhost:48080/api/v1/event/device/countcamera1/10 | json_pp curl -X GET localhost:48080/api/v1/reading/name/HumanCount/10 | json_pp <Back Next>","title":"Sending events and reading data"},{"location":"walk-through/Ch-WalkthroughReading/#sending-events-and-reading-data","text":"In the real world, the human/dog counting camera would start to take pictures, count beings, and send that data to EdgeX. To simulate this activity in this section of the walkthrough, you will make core data API calls as if you were the camera's device and device service. That is, you will report human and dog counts to core data in the form of event/reading objects.","title":"Sending events and reading data"},{"location":"walk-through/Ch-WalkthroughReading/#send-an-eventreading","text":"See core data API for more details. Data is submitted to core data as an Event object. An event is a collection of sensor readings from a device (associated to a device by its ID or name) at a particular point in time. A Reading object in an Event object is a particular value sensed by the device and associated to a Value Descriptor (by name) to provide context to the reading. So, the human/dog counting camera might determine that there are 5 people and 3 dogs in the space it is monitoring. In the EdgeX vernacular, the device service upon receiving these sensed values from the camera device would create an Event with two Reading s - one Reading would contain the key/value pair of HumanCount:5 and the other Reading would contain the key/value pair of CanineCount:3. The device service, on creating the Event and associated Reading objects would transmit this information to core data via REST call.","title":"Send an Event/Reading"},{"location":"walk-through/Ch-WalkthroughReading/#walkthrough-send-event","text":"Use either the Postman or Curl tab below to walkthrough sending an Event with Reading s to core data. Postman Make a POST request to http://localhost:48080/api/v1/event with the body below. { \"device\" : \"countcamera1\" , \"readings\" :[{ \"name\" : \"HumanCount\" , \"value\" : \"5\" },{ \"name\" : \"CanineCount\" , \"value\" : \"3\" }]} If your API call is successful, you will get a generated ID (a UUID) for your new Event as shown in the image below. Curl Make a curl POST request as shown below. curl -X POST -d '{\"device\":\"countcamera1\",\"readings\":[{\"name\":\"HumanCount\",\"value\":\"5\"},{\"name\":\"CanineCount\",\"value\":\"3\"}]}' localhost:48080/api/v1/event","title":"Walkthrough - Send Event"},{"location":"walk-through/Ch-WalkthroughReading/#origin-timestamp","text":"If desired, the device service can also supply an origin property in the Event or Reading object to suggest the time (in Epoch timestamp/milliseconds format) at which the data was sensed/collected. If an origin is not provided, no origin will be set for the Event or Reading . However, every Event and Reading is provided a Created and Modified timestamp by the database when it is saved to give the data some time context. { \"device\" : \"countcamera1\" , \"origin\" : 1471806386919 , \"readings\" :[{ \"name\" : \"HumanCount\" , \"value\" : \"1\" , \"origin\" : 1471806386919 },{ \"name\" : \"CanineCount\" , \"value\" : \"0\" , \"origin\" : 1471806386919 }]} Note Smart devices will often timestamp sensor data and this timestamp can be used as the origin timestamp. In cases where the sensor/device is unable to provide a timestamp (\"dumb\" or brownfield sensors), it is recommended that the device service create a timestamp for the sensor data that it be applied as the origin timestamp for the device.","title":"Origin Timestamp"},{"location":"walk-through/Ch-WalkthroughReading/#exploring-eventsreadings","text":"Now that an Event (or two) and associated Readings have been sent to core data, you can use the core data API to explore that data that is now stored in the database. Recall from a previous walkthrough step , you checked that no data was yet stored in core data. Make a similar call to see event records have now been sent into core data..","title":"Exploring Events/Readings"},{"location":"walk-through/Ch-WalkthroughReading/#walkthrough-query-eventsreadings","text":"Use either the Postman or Curl tab below to walkthrough getting the list of events. Postman Make a GET request to retrieve 10 of the last Event s associated to the countcamera1 device: http://localhost:48080/api/v1/event/device/countcamera1/10 . Make a GET request to retrieve 10 of the human count Reading s associated to the countcamera1 device: http://localhost:48080/api/v1/reading/name/HumanCount/10 Curl Make a curl GET requests to retrieve 10 of the last Event s associated to the countcamera1 device and to retrieve 10 of the human count readings associated to countcamera1 curl -X GET localhost:48080/api/v1/event/device/countcamera1/10 | json_pp curl -X GET localhost:48080/api/v1/reading/name/HumanCount/10 | json_pp <Back Next>","title":"Walkthrough - Query Events/Readings"},{"location":"walk-through/Ch-WalkthroughSetup/","text":"Setup up your environment Install Docker, Docker Compose & EdgeX Foundry To explore EdgeX and walk through it's APIs and how it works, you will need: Docker Docker Compose EdgeX Foundry (the base set of containers) If you have not already done so, proceed to Getting Started With Docker for how to get these tools and run EdgeX Foundry. If you have the tools and EdgeX already installed and running, you can proceed to the Walkthrough Use Case . Install Postman (optional) You can follow this walkthrough making HTTP calls from the command-line with a tool like curl , but it's easier if you use a graphical user interface tool designed for exercising REST APIs. For that we like to use Postman . You can download the native Postman app for your operating system. Note Example curl commands will be provided with the walk through so that you can run this walkthrough without Postman. Alert It is assumed that for the purposes of this walk through demonstration all API micro services are running on localhost . If this is not the case, substitute your hostname for localhost. any POST call has the associated CONTENT-TYPE=application/JSON header associated to it unless explicitly stated otherwise. <Back Next>","title":"Setup up your environment"},{"location":"walk-through/Ch-WalkthroughSetup/#setup-up-your-environment","text":"","title":"Setup up your environment"},{"location":"walk-through/Ch-WalkthroughSetup/#install-docker-docker-compose-edgex-foundry","text":"To explore EdgeX and walk through it's APIs and how it works, you will need: Docker Docker Compose EdgeX Foundry (the base set of containers) If you have not already done so, proceed to Getting Started With Docker for how to get these tools and run EdgeX Foundry. If you have the tools and EdgeX already installed and running, you can proceed to the Walkthrough Use Case .","title":"Install Docker, Docker Compose &amp; EdgeX Foundry"},{"location":"walk-through/Ch-WalkthroughSetup/#install-postman-optional","text":"You can follow this walkthrough making HTTP calls from the command-line with a tool like curl , but it's easier if you use a graphical user interface tool designed for exercising REST APIs. For that we like to use Postman . You can download the native Postman app for your operating system. Note Example curl commands will be provided with the walk through so that you can run this walkthrough without Postman. Alert It is assumed that for the purposes of this walk through demonstration all API micro services are running on localhost . If this is not the case, substitute your hostname for localhost. any POST call has the associated CONTENT-TYPE=application/JSON header associated to it unless explicitly stated otherwise. <Back Next>","title":"Install Postman (optional)"},{"location":"walk-through/Ch-WalkthroughUseCase/","text":"Example Use Case In order to explore EdgeX, its services and APIs and to generally understand how it works, it helps to see EdgeX under the context of a real use case. While you exercise the APIs under a hypothetical situation in order to demonstrate how EdgeX works, the use case is very much a valid example of how EdgeX can be used to collect data from devices and actuate control of the sensed environment it monitors. People (and animal) counting camera technology as highlighted in this walk through does exist and has been connected to EdgeX before. Object Counting Camera Suppose you had a new device that you wanted to connect to EdgeX. The device was a camera that took a picture and then had an on-board chip that analyzed the picture and reported the number of humans and canines (dogs) it saw. How often the camera takes a picture and reports its findings can be configured. In fact, the camera device could be sent two actuation commands - that is sent two requests for which it must respond and do something. You could send a request to set its time, in seconds, between picture snapshots (and then calculating the number of humans and dogs it finds in that resulting image). You could also request it to set the scan depth, in feet, of the camera - that is set how far out the camera looks. The farther out it looks, the less accurate the count of humans and dogs becomes, so this is something the manufacturer wants to allow the user to set based on use case needs. EdgeX Device Representation In EdgeX, the camera must be represented by a Device . Each Device is managed by a device service . The device service communicates with the underlying hardware - in this case the camera - in the protocol of choice for that Device . The device service collects the data from the devices it manages and passes that data into EdgeX (into core data ). In this case, the device service would be collecting the count of humans and dogs that the camera sees. The device service also serves to translate the request for actuation from EdgeX and the rest of the world into protocol requests that the physical device would understand. So in this example, the device service would take requests to set the duration between snapshots and to set the scan depth and translate those requests into protocol commands that the camera understood. Exactly how this camera physically connects to the host machine running EdgeX and how the device service works under the covers to communicate with the camera Device is immaterial for the point of this demonstration. <Back Next>","title":"Example Use Case"},{"location":"walk-through/Ch-WalkthroughUseCase/#example-use-case","text":"In order to explore EdgeX, its services and APIs and to generally understand how it works, it helps to see EdgeX under the context of a real use case. While you exercise the APIs under a hypothetical situation in order to demonstrate how EdgeX works, the use case is very much a valid example of how EdgeX can be used to collect data from devices and actuate control of the sensed environment it monitors. People (and animal) counting camera technology as highlighted in this walk through does exist and has been connected to EdgeX before.","title":"Example Use Case"},{"location":"walk-through/Ch-WalkthroughUseCase/#object-counting-camera","text":"Suppose you had a new device that you wanted to connect to EdgeX. The device was a camera that took a picture and then had an on-board chip that analyzed the picture and reported the number of humans and canines (dogs) it saw. How often the camera takes a picture and reports its findings can be configured. In fact, the camera device could be sent two actuation commands - that is sent two requests for which it must respond and do something. You could send a request to set its time, in seconds, between picture snapshots (and then calculating the number of humans and dogs it finds in that resulting image). You could also request it to set the scan depth, in feet, of the camera - that is set how far out the camera looks. The farther out it looks, the less accurate the count of humans and dogs becomes, so this is something the manufacturer wants to allow the user to set based on use case needs.","title":"Object Counting Camera"},{"location":"walk-through/Ch-WalkthroughUseCase/#edgex-device-representation","text":"In EdgeX, the camera must be represented by a Device . Each Device is managed by a device service . The device service communicates with the underlying hardware - in this case the camera - in the protocol of choice for that Device . The device service collects the data from the devices it manages and passes that data into EdgeX (into core data ). In this case, the device service would be collecting the count of humans and dogs that the camera sees. The device service also serves to translate the request for actuation from EdgeX and the rest of the world into protocol requests that the physical device would understand. So in this example, the device service would take requests to set the duration between snapshots and to set the scan depth and translate those requests into protocol commands that the camera understood. Exactly how this camera physically connects to the host machine running EdgeX and how the device service works under the covers to communicate with the camera Device is immaterial for the point of this demonstration. <Back Next>","title":"EdgeX Device Representation"}]}